{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error as mse, mean_absolute_error as mae\n",
    "#plt.switch_backend('agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#保存打印文件\n",
    "f = open(\"1.1manualRNN.txt\", 'a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13580, 13) (3386, 13)\n",
      "[[0.09904153 0.09744409 0.11341853 ... 0.2284345  0.22683706 0.23162939]\n",
      " [0.09744409 0.11341853 0.13738019 ... 0.22683706 0.23162939 0.25878594]\n",
      " [0.11341853 0.13738019 0.16453674 ... 0.23162939 0.25878594 0.20127796]\n",
      " ...\n",
      " [0.0798722  0.09105431 0.06389776 ... 0.08626198 0.05591054 0.07667732]\n",
      " [0.09105431 0.06389776 0.07188498 ... 0.05591054 0.07667732 0.07827476]\n",
      " [0.06389776 0.07188498 0.07507987 ... 0.07667732 0.07827476 0.1086262 ]] [[0.11182109 0.13897764 0.08785942 ... 0.15335463 0.15974441 0.17891374]\n",
      " [0.13897764 0.08785942 0.07827476 ... 0.15974441 0.17891374 0.16453674]\n",
      " [0.08785942 0.07827476 0.07188498 ... 0.17891374 0.16453674 0.15974441]\n",
      " ...\n",
      " [0.24920128 0.21246006 0.17891374 ... 0.11182109 0.1086262  0.11980831]\n",
      " [0.21246006 0.17891374 0.19648562 ... 0.1086262  0.11980831 0.10543131]\n",
      " [0.17891374 0.19648562 0.1884984  ... 0.11980831 0.10543131 0.12300319]]\n"
     ]
    }
   ],
   "source": [
    "#读取数据集，进行划分\n",
    "def sliding_window(seq,window_size):\n",
    "    result = []\n",
    "    for i in range(len(seq)- window_size):\n",
    "        result.append(seq[i: i+window_size])\n",
    "    return result\n",
    "\n",
    "data = np.load(\"./实验4-数据/高速公路传感器数据/PEMS04/PEMS04.npz\")\n",
    "#因为数据集过大，这里只取了第一个传感器的数据\n",
    "data = data[\"data\"][:,0:1,0:1]\n",
    "#归一化\n",
    "dmin,dmax = data.min(),data.max()\n",
    "data = (data - dmin) / (dmax - dmin)\n",
    "sensordata_num,sensor_num,_ = data.shape\n",
    "train_set,test_set = [],[]\n",
    "for  i in range(sensor_num) :\n",
    "    train_seq = data[:int(sensordata_num*0.8),i,:]\n",
    "    test_seq = data[int(sensordata_num*0.8):,i,:]\n",
    "    train_set += sliding_window(train_seq,window_size=13)\n",
    "    test_set += sliding_window(test_seq,window_size=13)\n",
    "train_set,test_set= np.array(train_set).squeeze(), np.array(test_set).squeeze()\n",
    "print(train_set.shape,test_set.shape)\n",
    "print(train_set,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        :param input_size: 指定输入数据的维度。例如，对于简单的时间序列预测问题，每一步的输入均为一个采样值，因此input_size=1.\n",
    "        :param hidden_size: 指定隐藏状态的维度。这个值并不受输入和输出控制，但会影响模型的容量。\n",
    "        :param output_size: 指定输出数据的维度。此值取决于具体的预测要求。例如，对简单的时间序列预测问题，output_size=1.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # 可学习参数的维度设置，可以类比一下全连接网络的实现。其维度取决于输入数据的维度，以及指定的隐藏状态维度。\n",
    "        self.w_h = nn.Parameter(torch.rand(input_size, hidden_size))\n",
    "        self.u_h = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.zeros(hidden_size))\n",
    "        \n",
    "        self.w_y = nn.Parameter(torch.rand(hidden_size, output_size))\n",
    "        self.b_y = nn.Parameter(torch.zeros(output_size))\n",
    "        \n",
    "        # 准备激活函数。Dropout函数可选。\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "        \n",
    "        # 可选：使用性能更好的参数初始化函数\n",
    "        for param in self.parameters():\n",
    "            if param.dim() > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: 输入序列。一般来说，此输入包含三个维度：batch，序列长度，以及每条数据的特征。\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        \n",
    "        # 初始化隐藏状态，一般设为全0。由于是内部新建的变量，需要同步设备位置。\n",
    "        h = torch.zeros(batch_size, self.hidden_size).to(x.device)\n",
    "        # RNN实际上只能一步一步处理序列。因此需要用循环迭代。\n",
    "        y_list = []\n",
    "        for i in range(seq_len):\n",
    "            h = self.tanh(torch.matmul(x[:, i, :], self.w_h) + \n",
    "                             torch.matmul(h, self.u_h) + self.b_h)  # (batch_size, hidden_size)\n",
    "            y = self.leaky_relu(torch.matmul(h, self.w_y) + self.b_y)  # (batch_size, output_size)\n",
    "            y_list.append(y)\n",
    "        # 一般来说，RNN的返回值为最后一步的隐藏状态，以及每一步的输出状态。\n",
    "        return h, torch.stack(y_list, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model = MyRNN(input_size=1, hidden_size=32, output_size=1).to(device)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_index = (y_true > 0)\n",
    "    y_true = y_true[non_zero_index]\n",
    "    y_pred = y_pred[non_zero_index]\n",
    "\n",
    "    mape = np.abs((y_true - y_pred) / y_true)\n",
    "    mape[np.isinf(mape)] = 0\n",
    "    return np.mean(mape) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(data, batch_size):\n",
    "    data_length = len(data)\n",
    "    num_batches = math.ceil(data_length / batch_size)\n",
    "    for batch_index in range(num_batches):\n",
    "        start_index = batch_index * batch_size\n",
    "        end_index = min((batch_index + 1) * batch_size, data_length)\n",
    "        yield data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#反归一化\n",
    "def denormalize(x):\n",
    "    return x * (dmax - dmin) + dmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1, train_loss 0.194326,Time used 0.009973s\n",
      "batch 2, train_loss 0.228461,Time used 0.005983s\n",
      "batch 3, train_loss 0.199120,Time used 0.006982s\n",
      "batch 4, train_loss 0.202521,Time used 0.006981s\n",
      "batch 5, train_loss 0.189436,Time used 0.006981s\n",
      "batch 6, train_loss 0.203991,Time used 0.007979s\n",
      "batch 7, train_loss 0.172814,Time used 0.007979s\n",
      "batch 8, train_loss 0.195199,Time used 0.006981s\n",
      "batch 9, train_loss 0.176031,Time used 0.006981s\n",
      "batch 10, train_loss 0.161052,Time used 0.006981s\n",
      "batch 11, train_loss 0.197346,Time used 0.006982s\n",
      "batch 12, train_loss 0.188473,Time used 0.007979s\n",
      "batch 13, train_loss 0.194746,Time used 0.007978s\n",
      "batch 14, train_loss 0.212437,Time used 0.006982s\n",
      "batch 15, train_loss 0.196175,Time used 0.006981s\n",
      "batch 16, train_loss 0.190553,Time used 0.006981s\n",
      "batch 17, train_loss 0.218149,Time used 0.007979s\n",
      "batch 18, train_loss 0.211622,Time used 0.006981s\n",
      "batch 19, train_loss 0.187467,Time used 0.006981s\n",
      "batch 20, train_loss 0.183357,Time used 0.006981s\n",
      "batch 21, train_loss 0.168434,Time used 0.005985s\n",
      "batch 22, train_loss 0.153442,Time used 0.005983s\n",
      "batch 23, train_loss 0.142483,Time used 0.005984s\n",
      "batch 24, train_loss 0.181844,Time used 0.006981s\n",
      "batch 25, train_loss 0.165418,Time used 0.006981s\n",
      "batch 26, train_loss 0.152042,Time used 0.005984s\n",
      "batch 27, train_loss 0.111028,Time used 0.006982s\n",
      "batch 28, train_loss 0.177773,Time used 0.006981s\n",
      "batch 29, train_loss 0.150660,Time used 0.006981s\n",
      "batch 30, train_loss 0.130074,Time used 0.006981s\n",
      "batch 31, train_loss 0.137060,Time used 0.006981s\n",
      "batch 32, train_loss 0.141465,Time used 0.006981s\n",
      "batch 33, train_loss 0.119600,Time used 0.006982s\n",
      "batch 34, train_loss 0.104744,Time used 0.006981s\n",
      "batch 35, train_loss 0.106909,Time used 0.006981s\n",
      "batch 36, train_loss 0.085820,Time used 0.006981s\n",
      "batch 37, train_loss 0.101713,Time used 0.006993s\n",
      "batch 38, train_loss 0.099446,Time used 0.005973s\n",
      "batch 39, train_loss 0.096306,Time used 0.005984s\n",
      "batch 40, train_loss 0.089272,Time used 0.005984s\n",
      "batch 41, train_loss 0.081214,Time used 0.005984s\n",
      "batch 42, train_loss 0.074978,Time used 0.005984s\n",
      "batch 43, train_loss 0.059620,Time used 0.006982s\n",
      "batch 44, train_loss 0.066853,Time used 0.006982s\n",
      "batch 45, train_loss 0.066074,Time used 0.006981s\n",
      "batch 46, train_loss 0.050268,Time used 0.006983s\n",
      "batch 47, train_loss 0.053253,Time used 0.006982s\n",
      "batch 48, train_loss 0.048965,Time used 0.005984s\n",
      "batch 49, train_loss 0.044586,Time used 0.006982s\n",
      "batch 50, train_loss 0.038381,Time used 0.006981s\n",
      "batch 51, train_loss 0.040774,Time used 0.005984s\n",
      "batch 52, train_loss 0.036713,Time used 0.006981s\n",
      "batch 53, train_loss 0.033454,Time used 0.006982s\n",
      "batch 54, train_loss 0.020587,Time used 0.007978s\n",
      "batch 55, train_loss 0.029338,Time used 0.006982s\n",
      "batch 56, train_loss 0.021790,Time used 0.006981s\n",
      "batch 57, train_loss 0.021336,Time used 0.006981s\n",
      "batch 58, train_loss 0.023417,Time used 0.005984s\n",
      "batch 59, train_loss 0.017073,Time used 0.006982s\n",
      "batch 60, train_loss 0.023455,Time used 0.006981s\n",
      "batch 61, train_loss 0.025781,Time used 0.006980s\n",
      "batch 62, train_loss 0.018939,Time used 0.006981s\n",
      "batch 63, train_loss 0.016742,Time used 0.007978s\n",
      "batch 64, train_loss 0.015383,Time used 0.007979s\n",
      "batch 65, train_loss 0.012821,Time used 0.006981s\n",
      "batch 66, train_loss 0.015872,Time used 0.006981s\n",
      "batch 67, train_loss 0.014145,Time used 0.006982s\n",
      "batch 68, train_loss 0.018382,Time used 0.007979s\n",
      "batch 69, train_loss 0.013108,Time used 0.007978s\n",
      "batch 70, train_loss 0.019010,Time used 0.008976s\n",
      "batch 71, train_loss 0.017002,Time used 0.007978s\n",
      "batch 72, train_loss 0.012345,Time used 0.007979s\n",
      "batch 73, train_loss 0.013995,Time used 0.006981s\n",
      "batch 74, train_loss 0.016450,Time used 0.007979s\n",
      "batch 75, train_loss 0.013615,Time used 0.007979s\n",
      "batch 76, train_loss 0.016242,Time used 0.007979s\n",
      "batch 77, train_loss 0.012474,Time used 0.007979s\n",
      "batch 78, train_loss 0.014058,Time used 0.007978s\n",
      "batch 79, train_loss 0.013336,Time used 0.007979s\n",
      "batch 80, train_loss 0.014436,Time used 0.007978s\n",
      "batch 81, train_loss 0.016765,Time used 0.006982s\n",
      "batch 82, train_loss 0.016356,Time used 0.006982s\n",
      "batch 83, train_loss 0.018454,Time used 0.006981s\n",
      "batch 84, train_loss 0.014217,Time used 0.005983s\n",
      "batch 85, train_loss 0.018905,Time used 0.006981s\n",
      "batch 86, train_loss 0.014815,Time used 0.006981s\n",
      "batch 87, train_loss 0.015977,Time used 0.006982s\n",
      "batch 88, train_loss 0.013492,Time used 0.006981s\n",
      "batch 89, train_loss 0.017217,Time used 0.006981s\n",
      "batch 90, train_loss 0.016507,Time used 0.006981s\n",
      "batch 91, train_loss 0.011737,Time used 0.006982s\n",
      "batch 92, train_loss 0.017042,Time used 0.007978s\n",
      "batch 93, train_loss 0.014093,Time used 0.007979s\n",
      "batch 94, train_loss 0.015688,Time used 0.007978s\n",
      "batch 95, train_loss 0.011622,Time used 0.006981s\n",
      "batch 96, train_loss 0.013095,Time used 0.007979s\n",
      "batch 97, train_loss 0.018373,Time used 0.006981s\n",
      "batch 98, train_loss 0.013307,Time used 0.005983s\n",
      "batch 99, train_loss 0.016477,Time used 0.006981s\n",
      "batch 100, train_loss 0.015449,Time used 0.006982s\n",
      "***************************test_batch 100, test_rmse_loss 0.120522,test_mae_loss 0.095560,test_mape_loss 44.391050,Time used 0.095798s\n",
      "batch 101, train_loss 0.013755,Time used 0.007979s\n",
      "batch 102, train_loss 0.019063,Time used 0.007979s\n",
      "batch 103, train_loss 0.013226,Time used 0.007978s\n",
      "batch 104, train_loss 0.015307,Time used 0.006982s\n",
      "batch 105, train_loss 0.013805,Time used 0.007978s\n",
      "batch 106, train_loss 0.014896,Time used 0.007979s\n",
      "batch 107, train_loss 0.013270,Time used 0.006981s\n",
      "batch 108, train_loss 0.013381,Time used 0.006982s\n",
      "batch 109, train_loss 0.013831,Time used 0.006982s\n",
      "batch 110, train_loss 0.012159,Time used 0.005984s\n",
      "batch 111, train_loss 0.015340,Time used 0.006981s\n",
      "batch 112, train_loss 0.017473,Time used 0.006981s\n",
      "batch 113, train_loss 0.014187,Time used 0.006982s\n",
      "batch 114, train_loss 0.016981,Time used 0.006981s\n",
      "batch 115, train_loss 0.011622,Time used 0.006982s\n",
      "batch 116, train_loss 0.017636,Time used 0.006981s\n",
      "batch 117, train_loss 0.011428,Time used 0.006981s\n",
      "batch 118, train_loss 0.010252,Time used 0.006981s\n",
      "batch 119, train_loss 0.012931,Time used 0.007978s\n",
      "batch 120, train_loss 0.019626,Time used 0.007979s\n",
      "batch 121, train_loss 0.014953,Time used 0.006981s\n",
      "batch 122, train_loss 0.012944,Time used 0.006981s\n",
      "batch 123, train_loss 0.017085,Time used 0.007979s\n",
      "batch 124, train_loss 0.014492,Time used 0.005984s\n",
      "batch 125, train_loss 0.012773,Time used 0.007978s\n",
      "batch 126, train_loss 0.016320,Time used 0.006981s\n",
      "batch 127, train_loss 0.011345,Time used 0.007978s\n",
      "batch 128, train_loss 0.022158,Time used 0.006981s\n",
      "batch 129, train_loss 0.013405,Time used 0.007978s\n",
      "batch 130, train_loss 0.013959,Time used 0.006981s\n",
      "batch 131, train_loss 0.010502,Time used 0.005984s\n",
      "batch 132, train_loss 0.017348,Time used 0.006981s\n",
      "batch 133, train_loss 0.014212,Time used 0.007978s\n",
      "batch 134, train_loss 0.012892,Time used 0.006982s\n",
      "batch 135, train_loss 0.013593,Time used 0.006981s\n",
      "batch 136, train_loss 0.015042,Time used 0.006981s\n",
      "batch 137, train_loss 0.011287,Time used 0.005984s\n",
      "batch 138, train_loss 0.015781,Time used 0.005984s\n",
      "batch 139, train_loss 0.014447,Time used 0.005984s\n",
      "batch 140, train_loss 0.012958,Time used 0.006981s\n",
      "batch 141, train_loss 0.015085,Time used 0.011968s\n",
      "batch 142, train_loss 0.014057,Time used 0.008976s\n",
      "batch 143, train_loss 0.008571,Time used 0.005984s\n",
      "batch 144, train_loss 0.011878,Time used 0.006981s\n",
      "batch 145, train_loss 0.012991,Time used 0.006981s\n",
      "batch 146, train_loss 0.013265,Time used 0.007978s\n",
      "batch 147, train_loss 0.016978,Time used 0.007978s\n",
      "batch 148, train_loss 0.011392,Time used 0.006982s\n",
      "batch 149, train_loss 0.012694,Time used 0.007978s\n",
      "batch 150, train_loss 0.013991,Time used 0.006981s\n",
      "batch 151, train_loss 0.012774,Time used 0.007979s\n",
      "batch 152, train_loss 0.011589,Time used 0.008976s\n",
      "batch 153, train_loss 0.010723,Time used 0.006981s\n",
      "batch 154, train_loss 0.011267,Time used 0.006981s\n",
      "batch 155, train_loss 0.010926,Time used 0.005984s\n",
      "batch 156, train_loss 0.012809,Time used 0.005984s\n",
      "batch 157, train_loss 0.013418,Time used 0.005984s\n",
      "batch 158, train_loss 0.011856,Time used 0.006982s\n",
      "batch 159, train_loss 0.012887,Time used 0.006981s\n",
      "batch 160, train_loss 0.013213,Time used 0.006981s\n",
      "batch 161, train_loss 0.011300,Time used 0.006982s\n",
      "batch 162, train_loss 0.009528,Time used 0.006981s\n",
      "batch 163, train_loss 0.009187,Time used 0.005983s\n",
      "batch 164, train_loss 0.015750,Time used 0.006982s\n",
      "batch 165, train_loss 0.012643,Time used 0.006981s\n",
      "batch 166, train_loss 0.011310,Time used 0.006982s\n",
      "batch 167, train_loss 0.010832,Time used 0.007979s\n",
      "batch 168, train_loss 0.010629,Time used 0.006980s\n",
      "batch 169, train_loss 0.012922,Time used 0.005985s\n",
      "batch 170, train_loss 0.012918,Time used 0.006981s\n",
      "batch 171, train_loss 0.012748,Time used 0.007979s\n",
      "batch 172, train_loss 0.015013,Time used 0.006981s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 173, train_loss 0.010598,Time used 0.006980s\n",
      "batch 174, train_loss 0.013022,Time used 0.006981s\n",
      "batch 175, train_loss 0.011640,Time used 0.006981s\n",
      "batch 176, train_loss 0.009649,Time used 0.005984s\n",
      "batch 177, train_loss 0.013413,Time used 0.006982s\n",
      "batch 178, train_loss 0.014452,Time used 0.008975s\n",
      "batch 179, train_loss 0.009544,Time used 0.006982s\n",
      "batch 180, train_loss 0.012892,Time used 0.006981s\n",
      "batch 181, train_loss 0.015806,Time used 0.006981s\n",
      "batch 182, train_loss 0.011145,Time used 0.006981s\n",
      "batch 183, train_loss 0.011282,Time used 0.006981s\n",
      "batch 184, train_loss 0.011877,Time used 0.006981s\n",
      "batch 185, train_loss 0.013469,Time used 0.006981s\n",
      "batch 186, train_loss 0.017557,Time used 0.006981s\n",
      "batch 187, train_loss 0.015469,Time used 0.006981s\n",
      "batch 188, train_loss 0.009529,Time used 0.007980s\n",
      "batch 189, train_loss 0.012688,Time used 0.006981s\n",
      "batch 190, train_loss 0.011763,Time used 0.007978s\n",
      "batch 191, train_loss 0.009741,Time used 0.006981s\n",
      "batch 192, train_loss 0.010289,Time used 0.006981s\n",
      "batch 193, train_loss 0.014808,Time used 0.007978s\n",
      "batch 194, train_loss 0.012989,Time used 0.006981s\n",
      "batch 195, train_loss 0.014167,Time used 0.007979s\n",
      "batch 196, train_loss 0.010335,Time used 0.006981s\n",
      "batch 197, train_loss 0.012803,Time used 0.006981s\n",
      "batch 198, train_loss 0.008981,Time used 0.007978s\n",
      "batch 199, train_loss 0.012614,Time used 0.007979s\n",
      "batch 200, train_loss 0.012138,Time used 0.007979s\n",
      "***************************test_batch 200, test_rmse_loss 0.108227,test_mae_loss 0.085150,test_mape_loss 37.590488,Time used 0.099733s\n",
      "batch 201, train_loss 0.009504,Time used 0.007979s\n",
      "batch 202, train_loss 0.010871,Time used 0.006981s\n",
      "batch 203, train_loss 0.011728,Time used 0.006981s\n",
      "batch 204, train_loss 0.011554,Time used 0.006982s\n",
      "batch 205, train_loss 0.011673,Time used 0.006981s\n",
      "batch 206, train_loss 0.012805,Time used 0.006981s\n",
      "batch 207, train_loss 0.011382,Time used 0.006983s\n",
      "batch 208, train_loss 0.009361,Time used 0.005984s\n",
      "batch 209, train_loss 0.011791,Time used 0.006981s\n",
      "batch 210, train_loss 0.010067,Time used 0.007979s\n",
      "batch 211, train_loss 0.010125,Time used 0.006982s\n",
      "batch 212, train_loss 0.008281,Time used 0.005984s\n",
      "batch 213, train_loss 0.009731,Time used 0.006982s\n",
      "batch 214, train_loss 0.021617,Time used 0.005984s\n",
      "batch 215, train_loss 0.010126,Time used 0.006981s\n",
      "batch 216, train_loss 0.009104,Time used 0.006982s\n",
      "batch 217, train_loss 0.007948,Time used 0.007979s\n",
      "batch 218, train_loss 0.012055,Time used 0.007978s\n",
      "batch 219, train_loss 0.012649,Time used 0.007979s\n",
      "batch 220, train_loss 0.011322,Time used 0.007516s\n",
      "batch 221, train_loss 0.009939,Time used 0.007489s\n",
      "batch 222, train_loss 0.014622,Time used 0.007979s\n",
      "batch 223, train_loss 0.010015,Time used 0.008976s\n",
      "batch 224, train_loss 0.009759,Time used 0.008976s\n",
      "batch 225, train_loss 0.009597,Time used 0.008977s\n",
      "batch 226, train_loss 0.011390,Time used 0.008975s\n",
      "batch 227, train_loss 0.012401,Time used 0.008977s\n",
      "batch 228, train_loss 0.010712,Time used 0.008976s\n",
      "batch 229, train_loss 0.012816,Time used 0.007979s\n",
      "batch 230, train_loss 0.013305,Time used 0.007978s\n",
      "batch 231, train_loss 0.007955,Time used 0.008976s\n",
      "batch 232, train_loss 0.010514,Time used 0.008976s\n",
      "batch 233, train_loss 0.012381,Time used 0.008977s\n",
      "batch 234, train_loss 0.012217,Time used 0.008976s\n",
      "batch 235, train_loss 0.012622,Time used 0.008976s\n",
      "batch 236, train_loss 0.012290,Time used 0.007978s\n",
      "batch 237, train_loss 0.008943,Time used 0.008976s\n",
      "batch 238, train_loss 0.012016,Time used 0.007979s\n",
      "batch 239, train_loss 0.010169,Time used 0.007979s\n",
      "batch 240, train_loss 0.008202,Time used 0.008976s\n",
      "batch 241, train_loss 0.008758,Time used 0.007980s\n",
      "batch 242, train_loss 0.010416,Time used 0.007978s\n",
      "batch 243, train_loss 0.011203,Time used 0.008976s\n",
      "batch 244, train_loss 0.011143,Time used 0.008583s\n",
      "batch 245, train_loss 0.009588,Time used 0.008976s\n",
      "batch 246, train_loss 0.011040,Time used 0.009974s\n",
      "batch 247, train_loss 0.011121,Time used 0.008976s\n",
      "batch 248, train_loss 0.010697,Time used 0.008976s\n",
      "batch 249, train_loss 0.010047,Time used 0.008977s\n",
      "batch 250, train_loss 0.012032,Time used 0.009974s\n",
      "batch 251, train_loss 0.011696,Time used 0.009973s\n",
      "batch 252, train_loss 0.010830,Time used 0.009973s\n",
      "batch 253, train_loss 0.008392,Time used 0.008976s\n",
      "batch 254, train_loss 0.010688,Time used 0.008976s\n",
      "batch 255, train_loss 0.009052,Time used 0.008976s\n",
      "batch 256, train_loss 0.009141,Time used 0.007979s\n",
      "batch 257, train_loss 0.009599,Time used 0.008976s\n",
      "batch 258, train_loss 0.013855,Time used 0.009974s\n",
      "batch 259, train_loss 0.008453,Time used 0.009973s\n",
      "batch 260, train_loss 0.014222,Time used 0.009974s\n",
      "batch 261, train_loss 0.010591,Time used 0.009973s\n",
      "batch 262, train_loss 0.010306,Time used 0.009973s\n",
      "batch 263, train_loss 0.010202,Time used 0.008976s\n",
      "batch 264, train_loss 0.010883,Time used 0.008975s\n",
      "batch 265, train_loss 0.009675,Time used 0.008977s\n",
      "batch 266, train_loss 0.015102,Time used 0.008977s\n",
      "batch 267, train_loss 0.009819,Time used 0.008975s\n",
      "batch 268, train_loss 0.013788,Time used 0.008976s\n",
      "batch 269, train_loss 0.007052,Time used 0.007979s\n",
      "batch 270, train_loss 0.010658,Time used 0.008976s\n",
      "batch 271, train_loss 0.009256,Time used 0.008976s\n",
      "batch 272, train_loss 0.007256,Time used 0.008977s\n",
      "batch 273, train_loss 0.006944,Time used 0.008976s\n",
      "batch 274, train_loss 0.011917,Time used 0.008976s\n",
      "batch 275, train_loss 0.008740,Time used 0.008975s\n",
      "batch 276, train_loss 0.008364,Time used 0.008977s\n",
      "batch 277, train_loss 0.009982,Time used 0.008976s\n",
      "batch 278, train_loss 0.011921,Time used 0.008976s\n",
      "batch 279, train_loss 0.009512,Time used 0.008976s\n",
      "batch 280, train_loss 0.010177,Time used 0.008977s\n",
      "batch 281, train_loss 0.007032,Time used 0.007978s\n",
      "batch 282, train_loss 0.008891,Time used 0.007978s\n",
      "batch 283, train_loss 0.008064,Time used 0.007978s\n",
      "batch 284, train_loss 0.012471,Time used 0.008976s\n",
      "batch 285, train_loss 0.010585,Time used 0.009973s\n",
      "batch 286, train_loss 0.010976,Time used 0.008976s\n",
      "batch 287, train_loss 0.007873,Time used 0.009974s\n",
      "batch 288, train_loss 0.009106,Time used 0.008976s\n",
      "batch 289, train_loss 0.008951,Time used 0.008976s\n",
      "batch 290, train_loss 0.007070,Time used 0.008976s\n",
      "batch 291, train_loss 0.009325,Time used 0.009973s\n",
      "batch 292, train_loss 0.007932,Time used 0.008976s\n",
      "batch 293, train_loss 0.009670,Time used 0.009974s\n",
      "batch 294, train_loss 0.007151,Time used 0.009974s\n",
      "batch 295, train_loss 0.007316,Time used 0.009974s\n",
      "batch 296, train_loss 0.008834,Time used 0.008976s\n",
      "batch 297, train_loss 0.008671,Time used 0.008977s\n",
      "batch 298, train_loss 0.010135,Time used 0.008976s\n",
      "batch 299, train_loss 0.010352,Time used 0.009972s\n",
      "batch 300, train_loss 0.009935,Time used 0.009974s\n",
      "***************************test_batch 300, test_rmse_loss 0.097162,test_mae_loss 0.075056,test_mape_loss 30.294497,Time used 0.126173s\n",
      "batch 301, train_loss 0.010164,Time used 0.009974s\n",
      "batch 302, train_loss 0.008096,Time used 0.008976s\n",
      "batch 303, train_loss 0.009440,Time used 0.008976s\n",
      "batch 304, train_loss 0.010177,Time used 0.008976s\n",
      "batch 305, train_loss 0.013749,Time used 0.007979s\n",
      "batch 306, train_loss 0.010356,Time used 0.007979s\n",
      "batch 307, train_loss 0.008672,Time used 0.008976s\n",
      "batch 308, train_loss 0.008119,Time used 0.008975s\n",
      "batch 309, train_loss 0.009901,Time used 0.008977s\n",
      "batch 310, train_loss 0.006946,Time used 0.008976s\n",
      "batch 311, train_loss 0.006962,Time used 0.007979s\n",
      "batch 312, train_loss 0.008038,Time used 0.008975s\n",
      "batch 313, train_loss 0.011037,Time used 0.007979s\n",
      "batch 314, train_loss 0.009324,Time used 0.007979s\n",
      "batch 315, train_loss 0.009210,Time used 0.008977s\n",
      "batch 316, train_loss 0.007133,Time used 0.008975s\n",
      "batch 317, train_loss 0.008753,Time used 0.008976s\n",
      "batch 318, train_loss 0.015085,Time used 0.008486s\n",
      "batch 319, train_loss 0.008228,Time used 0.008976s\n",
      "batch 320, train_loss 0.009401,Time used 0.008977s\n",
      "batch 321, train_loss 0.007303,Time used 0.006982s\n",
      "batch 322, train_loss 0.008925,Time used 0.008977s\n",
      "batch 323, train_loss 0.009113,Time used 0.008976s\n",
      "batch 324, train_loss 0.010526,Time used 0.007979s\n",
      "batch 325, train_loss 0.007663,Time used 0.007979s\n",
      "batch 326, train_loss 0.009257,Time used 0.007979s\n",
      "batch 327, train_loss 0.008973,Time used 0.008976s\n",
      "batch 328, train_loss 0.009395,Time used 0.007978s\n",
      "batch 329, train_loss 0.005897,Time used 0.008976s\n",
      "batch 330, train_loss 0.008962,Time used 0.010970s\n",
      "batch 331, train_loss 0.009669,Time used 0.008977s\n",
      "batch 332, train_loss 0.008428,Time used 0.008975s\n",
      "batch 333, train_loss 0.009634,Time used 0.008976s\n",
      "batch 334, train_loss 0.009574,Time used 0.008976s\n",
      "batch 335, train_loss 0.009217,Time used 0.007979s\n",
      "batch 336, train_loss 0.009826,Time used 0.007978s\n",
      "batch 337, train_loss 0.007725,Time used 0.007979s\n",
      "batch 338, train_loss 0.009251,Time used 0.008976s\n",
      "batch 339, train_loss 0.009047,Time used 0.007978s\n",
      "batch 340, train_loss 0.006480,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 341, train_loss 0.008562,Time used 0.007979s\n",
      "batch 342, train_loss 0.007307,Time used 0.009974s\n",
      "batch 343, train_loss 0.008331,Time used 0.008975s\n",
      "batch 344, train_loss 0.007686,Time used 0.007979s\n",
      "batch 345, train_loss 0.011004,Time used 0.007979s\n",
      "batch 346, train_loss 0.008079,Time used 0.007979s\n",
      "batch 347, train_loss 0.009804,Time used 0.008976s\n",
      "batch 348, train_loss 0.009824,Time used 0.008975s\n",
      "batch 349, train_loss 0.008752,Time used 0.007979s\n",
      "batch 350, train_loss 0.007646,Time used 0.007979s\n",
      "batch 351, train_loss 0.008569,Time used 0.008976s\n",
      "batch 352, train_loss 0.007374,Time used 0.008975s\n",
      "batch 353, train_loss 0.009132,Time used 0.008995s\n",
      "batch 354, train_loss 0.005683,Time used 0.009484s\n",
      "batch 355, train_loss 0.006283,Time used 0.007977s\n",
      "batch 356, train_loss 0.007730,Time used 0.007978s\n",
      "batch 357, train_loss 0.007325,Time used 0.007979s\n",
      "batch 358, train_loss 0.006895,Time used 0.007979s\n",
      "batch 359, train_loss 0.007189,Time used 0.007978s\n",
      "batch 360, train_loss 0.007819,Time used 0.007979s\n",
      "batch 361, train_loss 0.007704,Time used 0.008976s\n",
      "batch 362, train_loss 0.009223,Time used 0.007979s\n",
      "batch 363, train_loss 0.006040,Time used 0.008976s\n",
      "batch 364, train_loss 0.006611,Time used 0.008976s\n",
      "batch 365, train_loss 0.006666,Time used 0.007979s\n",
      "batch 366, train_loss 0.006848,Time used 0.008976s\n",
      "batch 367, train_loss 0.007680,Time used 0.008976s\n",
      "batch 368, train_loss 0.007609,Time used 0.008975s\n",
      "batch 369, train_loss 0.007703,Time used 0.007979s\n",
      "batch 370, train_loss 0.009000,Time used 0.007979s\n",
      "batch 371, train_loss 0.009694,Time used 0.008976s\n",
      "batch 372, train_loss 0.007495,Time used 0.008976s\n",
      "batch 373, train_loss 0.007627,Time used 0.008976s\n",
      "batch 374, train_loss 0.006971,Time used 0.008976s\n",
      "batch 375, train_loss 0.008276,Time used 0.008976s\n",
      "batch 376, train_loss 0.007614,Time used 0.008976s\n",
      "batch 377, train_loss 0.006528,Time used 0.008976s\n",
      "batch 378, train_loss 0.009571,Time used 0.008976s\n",
      "batch 379, train_loss 0.007484,Time used 0.008976s\n",
      "batch 380, train_loss 0.005720,Time used 0.007979s\n",
      "batch 381, train_loss 0.005949,Time used 0.007979s\n",
      "batch 382, train_loss 0.007827,Time used 0.007979s\n",
      "batch 383, train_loss 0.005858,Time used 0.007979s\n",
      "batch 384, train_loss 0.007727,Time used 0.007979s\n",
      "batch 385, train_loss 0.006434,Time used 0.008976s\n",
      "batch 386, train_loss 0.007993,Time used 0.007979s\n",
      "batch 387, train_loss 0.007545,Time used 0.008976s\n",
      "batch 388, train_loss 0.006979,Time used 0.008976s\n",
      "batch 389, train_loss 0.008859,Time used 0.008976s\n",
      "batch 390, train_loss 0.009971,Time used 0.007978s\n",
      "batch 391, train_loss 0.007051,Time used 0.008977s\n",
      "batch 392, train_loss 0.009745,Time used 0.008975s\n",
      "batch 393, train_loss 0.007134,Time used 0.008975s\n",
      "batch 394, train_loss 0.007170,Time used 0.009973s\n",
      "batch 395, train_loss 0.007832,Time used 0.008976s\n",
      "batch 396, train_loss 0.006846,Time used 0.008976s\n",
      "batch 397, train_loss 0.009540,Time used 0.008975s\n",
      "batch 398, train_loss 0.007186,Time used 0.008976s\n",
      "batch 399, train_loss 0.006300,Time used 0.009973s\n",
      "batch 400, train_loss 0.007202,Time used 0.008977s\n",
      "***************************test_batch 400, test_rmse_loss 0.085990,test_mae_loss 0.066248,test_mape_loss 25.955043,Time used 0.117686s\n",
      "batch 401, train_loss 0.007574,Time used 0.008975s\n",
      "batch 402, train_loss 0.008061,Time used 0.007979s\n",
      "batch 403, train_loss 0.006661,Time used 0.007979s\n",
      "batch 404, train_loss 0.007487,Time used 0.007979s\n",
      "batch 405, train_loss 0.007802,Time used 0.007979s\n",
      "batch 406, train_loss 0.008899,Time used 0.008975s\n",
      "batch 407, train_loss 0.005639,Time used 0.008977s\n",
      "batch 408, train_loss 0.008137,Time used 0.007978s\n",
      "batch 409, train_loss 0.009996,Time used 0.007979s\n",
      "batch 410, train_loss 0.007516,Time used 0.007979s\n",
      "batch 411, train_loss 0.007072,Time used 0.007979s\n",
      "batch 412, train_loss 0.006897,Time used 0.008975s\n",
      "batch 413, train_loss 0.005903,Time used 0.009974s\n",
      "batch 414, train_loss 0.005619,Time used 0.008976s\n",
      "batch 415, train_loss 0.007455,Time used 0.008975s\n",
      "batch 416, train_loss 0.007435,Time used 0.008977s\n",
      "batch 417, train_loss 0.007660,Time used 0.008976s\n",
      "batch 418, train_loss 0.006032,Time used 0.008976s\n",
      "batch 419, train_loss 0.011341,Time used 0.008976s\n",
      "batch 420, train_loss 0.006360,Time used 0.008976s\n",
      "batch 421, train_loss 0.006804,Time used 0.008976s\n",
      "batch 422, train_loss 0.006212,Time used 0.009973s\n",
      "batch 423, train_loss 0.008774,Time used 0.009974s\n",
      "batch 424, train_loss 0.007576,Time used 0.008976s\n",
      "batch 425, train_loss 0.006010,Time used 0.008975s\n",
      "batch 426, train_loss 0.006923,Time used 0.008977s\n",
      "batch 427, train_loss 0.007361,Time used 0.007979s\n",
      "batch 428, train_loss 0.002259,Time used 0.006981s\n",
      "batch 429, train_loss 0.007022,Time used 0.007978s\n",
      "batch 430, train_loss 0.005556,Time used 0.006980s\n",
      "batch 431, train_loss 0.006447,Time used 0.007979s\n",
      "batch 432, train_loss 0.007620,Time used 0.007978s\n",
      "batch 433, train_loss 0.006461,Time used 0.006982s\n",
      "batch 434, train_loss 0.005561,Time used 0.007978s\n",
      "batch 435, train_loss 0.006439,Time used 0.008976s\n",
      "batch 436, train_loss 0.006209,Time used 0.007979s\n",
      "batch 437, train_loss 0.006861,Time used 0.008975s\n",
      "batch 438, train_loss 0.006451,Time used 0.007978s\n",
      "batch 439, train_loss 0.005783,Time used 0.008976s\n",
      "batch 440, train_loss 0.005716,Time used 0.008977s\n",
      "batch 441, train_loss 0.006139,Time used 0.008975s\n",
      "batch 442, train_loss 0.008168,Time used 0.008977s\n",
      "batch 443, train_loss 0.009050,Time used 0.009974s\n",
      "batch 444, train_loss 0.007737,Time used 0.008976s\n",
      "batch 445, train_loss 0.005770,Time used 0.007978s\n",
      "batch 446, train_loss 0.005002,Time used 0.008974s\n",
      "batch 447, train_loss 0.005736,Time used 0.009975s\n",
      "batch 448, train_loss 0.004713,Time used 0.008976s\n",
      "batch 449, train_loss 0.006003,Time used 0.008977s\n",
      "batch 450, train_loss 0.006030,Time used 0.013962s\n",
      "batch 451, train_loss 0.004863,Time used 0.008976s\n",
      "batch 452, train_loss 0.004301,Time used 0.007979s\n",
      "batch 453, train_loss 0.006713,Time used 0.008976s\n",
      "batch 454, train_loss 0.006291,Time used 0.008976s\n",
      "batch 455, train_loss 0.006627,Time used 0.007978s\n",
      "batch 456, train_loss 0.007356,Time used 0.007978s\n",
      "batch 457, train_loss 0.006702,Time used 0.008976s\n",
      "batch 458, train_loss 0.006660,Time used 0.008975s\n",
      "batch 459, train_loss 0.006447,Time used 0.008976s\n",
      "batch 460, train_loss 0.005293,Time used 0.008976s\n",
      "batch 461, train_loss 0.004851,Time used 0.008976s\n",
      "batch 462, train_loss 0.005575,Time used 0.009973s\n",
      "batch 463, train_loss 0.006092,Time used 0.008976s\n",
      "batch 464, train_loss 0.006627,Time used 0.008975s\n",
      "batch 465, train_loss 0.006752,Time used 0.009974s\n",
      "batch 466, train_loss 0.006330,Time used 0.008975s\n",
      "batch 467, train_loss 0.010697,Time used 0.008977s\n",
      "batch 468, train_loss 0.006509,Time used 0.008976s\n",
      "batch 469, train_loss 0.007568,Time used 0.008976s\n",
      "batch 470, train_loss 0.008085,Time used 0.008976s\n",
      "batch 471, train_loss 0.005713,Time used 0.008977s\n",
      "batch 472, train_loss 0.005872,Time used 0.008976s\n",
      "batch 473, train_loss 0.005324,Time used 0.008977s\n",
      "batch 474, train_loss 0.006794,Time used 0.009973s\n",
      "batch 475, train_loss 0.008874,Time used 0.008976s\n",
      "batch 476, train_loss 0.004579,Time used 0.008976s\n",
      "batch 477, train_loss 0.007361,Time used 0.009973s\n",
      "batch 478, train_loss 0.008608,Time used 0.008976s\n",
      "batch 479, train_loss 0.005927,Time used 0.008975s\n",
      "batch 480, train_loss 0.005845,Time used 0.008977s\n",
      "batch 481, train_loss 0.005940,Time used 0.009973s\n",
      "batch 482, train_loss 0.004926,Time used 0.009973s\n",
      "batch 483, train_loss 0.005951,Time used 0.008976s\n",
      "batch 484, train_loss 0.007884,Time used 0.008976s\n",
      "batch 485, train_loss 0.006705,Time used 0.008977s\n",
      "batch 486, train_loss 0.005486,Time used 0.008975s\n",
      "batch 487, train_loss 0.006921,Time used 0.008976s\n",
      "batch 488, train_loss 0.005283,Time used 0.008485s\n",
      "batch 489, train_loss 0.006652,Time used 0.009486s\n",
      "batch 490, train_loss 0.006963,Time used 0.009974s\n",
      "batch 491, train_loss 0.005659,Time used 0.008976s\n",
      "batch 492, train_loss 0.004474,Time used 0.008976s\n",
      "batch 493, train_loss 0.007610,Time used 0.008977s\n",
      "batch 494, train_loss 0.006270,Time used 0.008975s\n",
      "batch 495, train_loss 0.005497,Time used 0.008976s\n",
      "batch 496, train_loss 0.004412,Time used 0.008975s\n",
      "batch 497, train_loss 0.005276,Time used 0.008977s\n",
      "batch 498, train_loss 0.006727,Time used 0.008976s\n",
      "batch 499, train_loss 0.007162,Time used 0.008976s\n",
      "batch 500, train_loss 0.005878,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************test_batch 500, test_rmse_loss 0.076848,test_mae_loss 0.057985,test_mape_loss 20.629088,Time used 0.114693s\n",
      "batch 501, train_loss 0.005825,Time used 0.009973s\n",
      "batch 502, train_loss 0.005927,Time used 0.008976s\n",
      "batch 503, train_loss 0.005177,Time used 0.008976s\n",
      "batch 504, train_loss 0.004497,Time used 0.009973s\n",
      "batch 505, train_loss 0.005175,Time used 0.008976s\n",
      "batch 506, train_loss 0.005878,Time used 0.008975s\n",
      "batch 507, train_loss 0.004799,Time used 0.008977s\n",
      "batch 508, train_loss 0.008816,Time used 0.008976s\n",
      "batch 509, train_loss 0.006168,Time used 0.008976s\n",
      "batch 510, train_loss 0.004967,Time used 0.008976s\n",
      "batch 511, train_loss 0.005155,Time used 0.008976s\n",
      "batch 512, train_loss 0.005823,Time used 0.008976s\n",
      "batch 513, train_loss 0.005942,Time used 0.008976s\n",
      "batch 514, train_loss 0.005671,Time used 0.007979s\n",
      "batch 515, train_loss 0.006043,Time used 0.007979s\n",
      "batch 516, train_loss 0.007550,Time used 0.007979s\n",
      "batch 517, train_loss 0.006445,Time used 0.007979s\n",
      "batch 518, train_loss 0.005271,Time used 0.007979s\n",
      "batch 519, train_loss 0.004958,Time used 0.007978s\n",
      "batch 520, train_loss 0.005425,Time used 0.009974s\n",
      "batch 521, train_loss 0.005250,Time used 0.007979s\n",
      "batch 522, train_loss 0.005779,Time used 0.008977s\n",
      "batch 523, train_loss 0.004441,Time used 0.008976s\n",
      "batch 524, train_loss 0.006030,Time used 0.010970s\n",
      "batch 525, train_loss 0.005091,Time used 0.008976s\n",
      "batch 526, train_loss 0.004965,Time used 0.008977s\n",
      "batch 527, train_loss 0.006133,Time used 0.008976s\n",
      "batch 528, train_loss 0.004581,Time used 0.008976s\n",
      "batch 529, train_loss 0.006602,Time used 0.008976s\n",
      "batch 530, train_loss 0.005494,Time used 0.008976s\n",
      "batch 531, train_loss 0.005130,Time used 0.009973s\n",
      "batch 532, train_loss 0.005865,Time used 0.008976s\n",
      "batch 533, train_loss 0.004695,Time used 0.008976s\n",
      "batch 534, train_loss 0.005408,Time used 0.008977s\n",
      "batch 535, train_loss 0.008092,Time used 0.007978s\n",
      "batch 536, train_loss 0.004179,Time used 0.008977s\n",
      "batch 537, train_loss 0.005557,Time used 0.008975s\n",
      "batch 538, train_loss 0.005390,Time used 0.008976s\n",
      "batch 539, train_loss 0.005140,Time used 0.007978s\n",
      "batch 540, train_loss 0.005859,Time used 0.009973s\n",
      "batch 541, train_loss 0.003967,Time used 0.007978s\n",
      "batch 542, train_loss 0.007015,Time used 0.008976s\n",
      "batch 543, train_loss 0.004158,Time used 0.009974s\n",
      "batch 544, train_loss 0.004395,Time used 0.009973s\n",
      "batch 545, train_loss 0.007003,Time used 0.008976s\n",
      "batch 546, train_loss 0.004365,Time used 0.008976s\n",
      "batch 547, train_loss 0.006759,Time used 0.008976s\n",
      "batch 548, train_loss 0.004735,Time used 0.007979s\n",
      "batch 549, train_loss 0.004747,Time used 0.007979s\n",
      "batch 550, train_loss 0.004305,Time used 0.007979s\n",
      "batch 551, train_loss 0.005970,Time used 0.007979s\n",
      "batch 552, train_loss 0.005775,Time used 0.007979s\n",
      "batch 553, train_loss 0.005794,Time used 0.008975s\n",
      "batch 554, train_loss 0.004767,Time used 0.007979s\n",
      "batch 555, train_loss 0.006355,Time used 0.007978s\n",
      "batch 556, train_loss 0.004223,Time used 0.008977s\n",
      "batch 557, train_loss 0.005576,Time used 0.008976s\n",
      "batch 558, train_loss 0.004895,Time used 0.007979s\n",
      "batch 559, train_loss 0.005221,Time used 0.008977s\n",
      "batch 560, train_loss 0.005400,Time used 0.009973s\n",
      "batch 561, train_loss 0.005116,Time used 0.008976s\n",
      "batch 562, train_loss 0.006415,Time used 0.008976s\n",
      "batch 563, train_loss 0.004255,Time used 0.008976s\n",
      "batch 564, train_loss 0.007616,Time used 0.008976s\n",
      "batch 565, train_loss 0.003939,Time used 0.008975s\n",
      "batch 566, train_loss 0.004602,Time used 0.008977s\n",
      "batch 567, train_loss 0.004499,Time used 0.007978s\n",
      "batch 568, train_loss 0.004872,Time used 0.008977s\n",
      "batch 569, train_loss 0.004331,Time used 0.007978s\n",
      "batch 570, train_loss 0.004721,Time used 0.007979s\n",
      "batch 571, train_loss 0.003318,Time used 0.008976s\n",
      "batch 572, train_loss 0.005376,Time used 0.008975s\n",
      "batch 573, train_loss 0.005584,Time used 0.008977s\n",
      "batch 574, train_loss 0.006155,Time used 0.007978s\n",
      "batch 575, train_loss 0.005876,Time used 0.007978s\n",
      "batch 576, train_loss 0.005401,Time used 0.007978s\n",
      "batch 577, train_loss 0.006334,Time used 0.007979s\n",
      "batch 578, train_loss 0.003934,Time used 0.008975s\n",
      "batch 579, train_loss 0.005473,Time used 0.008976s\n",
      "batch 580, train_loss 0.004905,Time used 0.007979s\n",
      "batch 581, train_loss 0.005511,Time used 0.008976s\n",
      "batch 582, train_loss 0.004117,Time used 0.008977s\n",
      "batch 583, train_loss 0.003451,Time used 0.008976s\n",
      "batch 584, train_loss 0.004545,Time used 0.007979s\n",
      "batch 585, train_loss 0.004128,Time used 0.007978s\n",
      "batch 586, train_loss 0.006120,Time used 0.007979s\n",
      "batch 587, train_loss 0.005841,Time used 0.007979s\n",
      "batch 588, train_loss 0.005436,Time used 0.007979s\n",
      "batch 589, train_loss 0.005432,Time used 0.007979s\n",
      "batch 590, train_loss 0.005978,Time used 0.007979s\n",
      "batch 591, train_loss 0.004795,Time used 0.007978s\n",
      "batch 592, train_loss 0.010566,Time used 0.007978s\n",
      "batch 593, train_loss 0.004166,Time used 0.008976s\n",
      "batch 594, train_loss 0.003270,Time used 0.008977s\n",
      "batch 595, train_loss 0.004493,Time used 0.008975s\n",
      "batch 596, train_loss 0.005335,Time used 0.009973s\n",
      "batch 597, train_loss 0.003512,Time used 0.008977s\n",
      "batch 598, train_loss 0.004658,Time used 0.007979s\n",
      "batch 599, train_loss 0.005654,Time used 0.007978s\n",
      "batch 600, train_loss 0.004901,Time used 0.008975s\n",
      "***************************test_batch 600, test_rmse_loss 0.070476,test_mae_loss 0.052218,test_mape_loss 17.103879,Time used 0.114204s\n",
      "batch 601, train_loss 0.005463,Time used 0.009974s\n",
      "batch 602, train_loss 0.004987,Time used 0.009974s\n",
      "batch 603, train_loss 0.004118,Time used 0.009972s\n",
      "batch 604, train_loss 0.004328,Time used 0.008976s\n",
      "batch 605, train_loss 0.004880,Time used 0.008977s\n",
      "batch 606, train_loss 0.005280,Time used 0.008976s\n",
      "batch 607, train_loss 0.006901,Time used 0.008976s\n",
      "batch 608, train_loss 0.006843,Time used 0.008976s\n",
      "batch 609, train_loss 0.004699,Time used 0.008976s\n",
      "batch 610, train_loss 0.006257,Time used 0.007978s\n",
      "batch 611, train_loss 0.004749,Time used 0.007979s\n",
      "batch 612, train_loss 0.004338,Time used 0.008977s\n",
      "batch 613, train_loss 0.004380,Time used 0.008976s\n",
      "batch 614, train_loss 0.005079,Time used 0.008976s\n",
      "batch 615, train_loss 0.005213,Time used 0.007979s\n",
      "batch 616, train_loss 0.004938,Time used 0.007978s\n",
      "batch 617, train_loss 0.004944,Time used 0.008976s\n",
      "batch 618, train_loss 0.004405,Time used 0.008976s\n",
      "batch 619, train_loss 0.004189,Time used 0.008977s\n",
      "batch 620, train_loss 0.005221,Time used 0.008975s\n",
      "batch 621, train_loss 0.005177,Time used 0.009974s\n",
      "batch 622, train_loss 0.004499,Time used 0.008976s\n",
      "batch 623, train_loss 0.004986,Time used 0.008977s\n",
      "batch 624, train_loss 0.003828,Time used 0.009972s\n",
      "batch 625, train_loss 0.005311,Time used 0.008976s\n",
      "batch 626, train_loss 0.004315,Time used 0.008976s\n",
      "batch 627, train_loss 0.004722,Time used 0.008976s\n",
      "batch 628, train_loss 0.006235,Time used 0.007979s\n",
      "batch 629, train_loss 0.005248,Time used 0.009974s\n",
      "batch 630, train_loss 0.005666,Time used 0.007978s\n",
      "batch 631, train_loss 0.003209,Time used 0.009973s\n",
      "batch 632, train_loss 0.003762,Time used 0.007979s\n",
      "batch 633, train_loss 0.004483,Time used 0.007979s\n",
      "batch 634, train_loss 0.006017,Time used 0.007978s\n",
      "batch 635, train_loss 0.005655,Time used 0.008976s\n",
      "batch 636, train_loss 0.004255,Time used 0.008976s\n",
      "batch 637, train_loss 0.003638,Time used 0.008976s\n",
      "batch 638, train_loss 0.003614,Time used 0.009973s\n",
      "batch 639, train_loss 0.003800,Time used 0.008976s\n",
      "batch 640, train_loss 0.003271,Time used 0.008976s\n",
      "batch 641, train_loss 0.004196,Time used 0.008976s\n",
      "batch 642, train_loss 0.003032,Time used 0.006982s\n",
      "batch 643, train_loss 0.005181,Time used 0.008976s\n",
      "batch 644, train_loss 0.003276,Time used 0.007978s\n",
      "batch 645, train_loss 0.003369,Time used 0.007981s\n",
      "batch 646, train_loss 0.005319,Time used 0.007979s\n",
      "batch 647, train_loss 0.004174,Time used 0.007979s\n",
      "batch 648, train_loss 0.005212,Time used 0.007978s\n",
      "batch 649, train_loss 0.004953,Time used 0.008975s\n",
      "batch 650, train_loss 0.005167,Time used 0.007979s\n",
      "batch 651, train_loss 0.003846,Time used 0.007979s\n",
      "batch 652, train_loss 0.004750,Time used 0.007978s\n",
      "batch 653, train_loss 0.003759,Time used 0.007978s\n",
      "batch 654, train_loss 0.005873,Time used 0.007979s\n",
      "batch 655, train_loss 0.005059,Time used 0.007978s\n",
      "batch 656, train_loss 0.004792,Time used 0.008976s\n",
      "batch 657, train_loss 0.004931,Time used 0.008976s\n",
      "batch 658, train_loss 0.004609,Time used 0.007979s\n",
      "batch 659, train_loss 0.003541,Time used 0.007979s\n",
      "batch 660, train_loss 0.004366,Time used 0.007978s\n",
      "batch 661, train_loss 0.004651,Time used 0.008976s\n",
      "batch 662, train_loss 0.004278,Time used 0.007979s\n",
      "batch 663, train_loss 0.004703,Time used 0.007978s\n",
      "batch 664, train_loss 0.006677,Time used 0.007978s\n",
      "batch 665, train_loss 0.005537,Time used 0.008976s\n",
      "batch 666, train_loss 0.004151,Time used 0.008977s\n",
      "batch 667, train_loss 0.004131,Time used 0.008975s\n",
      "batch 668, train_loss 0.004998,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 669, train_loss 0.004609,Time used 0.008976s\n",
      "batch 670, train_loss 0.006160,Time used 0.008975s\n",
      "batch 671, train_loss 0.003211,Time used 0.008976s\n",
      "batch 672, train_loss 0.004833,Time used 0.008976s\n",
      "batch 673, train_loss 0.003754,Time used 0.008976s\n",
      "batch 674, train_loss 0.005810,Time used 0.007979s\n",
      "batch 675, train_loss 0.003363,Time used 0.007978s\n",
      "batch 676, train_loss 0.003778,Time used 0.007979s\n",
      "batch 677, train_loss 0.004778,Time used 0.007979s\n",
      "batch 678, train_loss 0.003797,Time used 0.007979s\n",
      "batch 679, train_loss 0.005448,Time used 0.008977s\n",
      "batch 680, train_loss 0.004523,Time used 0.007978s\n",
      "batch 681, train_loss 0.004267,Time used 0.007979s\n",
      "batch 682, train_loss 0.005631,Time used 0.007979s\n",
      "batch 683, train_loss 0.004560,Time used 0.008976s\n",
      "batch 684, train_loss 0.005512,Time used 0.008976s\n",
      "batch 685, train_loss 0.005129,Time used 0.008977s\n",
      "batch 686, train_loss 0.004624,Time used 0.007978s\n",
      "batch 687, train_loss 0.004211,Time used 0.007978s\n",
      "batch 688, train_loss 0.004760,Time used 0.007979s\n",
      "batch 689, train_loss 0.004920,Time used 0.007978s\n",
      "batch 690, train_loss 0.004358,Time used 0.007979s\n",
      "batch 691, train_loss 0.004864,Time used 0.007978s\n",
      "batch 692, train_loss 0.003846,Time used 0.006982s\n",
      "batch 693, train_loss 0.004254,Time used 0.007979s\n",
      "batch 694, train_loss 0.005104,Time used 0.008977s\n",
      "batch 695, train_loss 0.003901,Time used 0.008975s\n",
      "batch 696, train_loss 0.004687,Time used 0.007979s\n",
      "batch 697, train_loss 0.003667,Time used 0.007978s\n",
      "batch 698, train_loss 0.004260,Time used 0.007978s\n",
      "batch 699, train_loss 0.005583,Time used 0.008977s\n",
      "batch 700, train_loss 0.005797,Time used 0.008976s\n",
      "***************************test_batch 700, test_rmse_loss 0.066824,test_mae_loss 0.048643,test_mape_loss 15.050806,Time used 0.103723s\n",
      "batch 701, train_loss 0.004620,Time used 0.009973s\n",
      "batch 702, train_loss 0.003872,Time used 0.008976s\n",
      "batch 703, train_loss 0.003226,Time used 0.007979s\n",
      "batch 704, train_loss 0.004268,Time used 0.007978s\n",
      "batch 705, train_loss 0.004411,Time used 0.007978s\n",
      "batch 706, train_loss 0.004187,Time used 0.007979s\n",
      "batch 707, train_loss 0.004710,Time used 0.008976s\n",
      "batch 708, train_loss 0.004863,Time used 0.008977s\n",
      "batch 709, train_loss 0.004571,Time used 0.008976s\n",
      "batch 710, train_loss 0.004195,Time used 0.008976s\n",
      "batch 711, train_loss 0.003947,Time used 0.008976s\n",
      "batch 712, train_loss 0.004052,Time used 0.008977s\n",
      "batch 713, train_loss 0.004560,Time used 0.008975s\n",
      "batch 714, train_loss 0.004555,Time used 0.008976s\n",
      "batch 715, train_loss 0.004239,Time used 0.008977s\n",
      "batch 716, train_loss 0.003897,Time used 0.008975s\n",
      "batch 717, train_loss 0.003303,Time used 0.008977s\n",
      "batch 718, train_loss 0.004207,Time used 0.008976s\n",
      "batch 719, train_loss 0.004642,Time used 0.008977s\n",
      "batch 720, train_loss 0.004866,Time used 0.008975s\n",
      "batch 721, train_loss 0.003846,Time used 0.008976s\n",
      "batch 722, train_loss 0.003870,Time used 0.008976s\n",
      "batch 723, train_loss 0.005063,Time used 0.008976s\n",
      "batch 724, train_loss 0.003182,Time used 0.006980s\n",
      "batch 725, train_loss 0.004254,Time used 0.007978s\n",
      "batch 726, train_loss 0.003563,Time used 0.018950s\n",
      "batch 727, train_loss 0.004332,Time used 0.008977s\n",
      "batch 728, train_loss 0.004142,Time used 0.008976s\n",
      "batch 729, train_loss 0.005102,Time used 0.008976s\n",
      "batch 730, train_loss 0.004475,Time used 0.008976s\n",
      "batch 731, train_loss 0.003514,Time used 0.008976s\n",
      "batch 732, train_loss 0.003182,Time used 0.007978s\n",
      "batch 733, train_loss 0.004470,Time used 0.007978s\n",
      "batch 734, train_loss 0.003603,Time used 0.008976s\n",
      "batch 735, train_loss 0.004664,Time used 0.007979s\n",
      "batch 736, train_loss 0.004029,Time used 0.006981s\n",
      "batch 737, train_loss 0.005074,Time used 0.007978s\n",
      "batch 738, train_loss 0.004796,Time used 0.007979s\n",
      "batch 739, train_loss 0.004735,Time used 0.007979s\n",
      "batch 740, train_loss 0.004851,Time used 0.008976s\n",
      "batch 741, train_loss 0.004510,Time used 0.009973s\n",
      "batch 742, train_loss 0.003442,Time used 0.008976s\n",
      "batch 743, train_loss 0.003921,Time used 0.008976s\n",
      "batch 744, train_loss 0.003973,Time used 0.007979s\n",
      "batch 745, train_loss 0.003959,Time used 0.007978s\n",
      "batch 746, train_loss 0.004097,Time used 0.008976s\n",
      "batch 747, train_loss 0.006384,Time used 0.007979s\n",
      "batch 748, train_loss 0.004510,Time used 0.007979s\n",
      "batch 749, train_loss 0.004041,Time used 0.006982s\n",
      "batch 750, train_loss 0.007265,Time used 0.007979s\n",
      "batch 751, train_loss 0.004697,Time used 0.007978s\n",
      "batch 752, train_loss 0.003474,Time used 0.007979s\n",
      "batch 753, train_loss 0.003598,Time used 0.007978s\n",
      "batch 754, train_loss 0.003650,Time used 0.007978s\n",
      "batch 755, train_loss 0.004105,Time used 0.007978s\n",
      "batch 756, train_loss 0.004740,Time used 0.007978s\n",
      "batch 757, train_loss 0.005911,Time used 0.008976s\n",
      "batch 758, train_loss 0.003231,Time used 0.008976s\n",
      "batch 759, train_loss 0.004374,Time used 0.008976s\n",
      "batch 760, train_loss 0.005318,Time used 0.008976s\n",
      "batch 761, train_loss 0.002987,Time used 0.008976s\n",
      "batch 762, train_loss 0.004212,Time used 0.008976s\n",
      "batch 763, train_loss 0.003606,Time used 0.007979s\n",
      "batch 764, train_loss 0.005130,Time used 0.008976s\n",
      "batch 765, train_loss 0.003516,Time used 0.008976s\n",
      "batch 766, train_loss 0.003227,Time used 0.008976s\n",
      "batch 767, train_loss 0.003334,Time used 0.009973s\n",
      "batch 768, train_loss 0.003441,Time used 0.008976s\n",
      "batch 769, train_loss 0.003651,Time used 0.008976s\n",
      "batch 770, train_loss 0.004849,Time used 0.008976s\n",
      "batch 771, train_loss 0.004648,Time used 0.008976s\n",
      "batch 772, train_loss 0.004683,Time used 0.008975s\n",
      "batch 773, train_loss 0.005488,Time used 0.007979s\n",
      "batch 774, train_loss 0.004499,Time used 0.008976s\n",
      "batch 775, train_loss 0.003513,Time used 0.009973s\n",
      "batch 776, train_loss 0.004850,Time used 0.009973s\n",
      "batch 777, train_loss 0.003435,Time used 0.008976s\n",
      "batch 778, train_loss 0.003473,Time used 0.008976s\n",
      "batch 779, train_loss 0.003575,Time used 0.008977s\n",
      "batch 780, train_loss 0.004469,Time used 0.008977s\n",
      "batch 781, train_loss 0.002680,Time used 0.008975s\n",
      "batch 782, train_loss 0.003916,Time used 0.009974s\n",
      "batch 783, train_loss 0.003899,Time used 0.008976s\n",
      "batch 784, train_loss 0.004423,Time used 0.008976s\n",
      "batch 785, train_loss 0.004837,Time used 0.008977s\n",
      "batch 786, train_loss 0.004382,Time used 0.008976s\n",
      "batch 787, train_loss 0.004524,Time used 0.008976s\n",
      "batch 788, train_loss 0.002826,Time used 0.007979s\n",
      "batch 789, train_loss 0.005195,Time used 0.008976s\n",
      "batch 790, train_loss 0.005087,Time used 0.008976s\n",
      "batch 791, train_loss 0.003603,Time used 0.007979s\n",
      "batch 792, train_loss 0.004417,Time used 0.008976s\n",
      "batch 793, train_loss 0.003128,Time used 0.008976s\n",
      "batch 794, train_loss 0.005274,Time used 0.008977s\n",
      "batch 795, train_loss 0.004140,Time used 0.009101s\n",
      "batch 796, train_loss 0.005310,Time used 0.008965s\n",
      "batch 797, train_loss 0.003780,Time used 0.008977s\n",
      "batch 798, train_loss 0.005490,Time used 0.008975s\n",
      "batch 799, train_loss 0.005170,Time used 0.008976s\n",
      "batch 800, train_loss 0.004807,Time used 0.010970s\n",
      "***************************test_batch 800, test_rmse_loss 0.064983,test_mae_loss 0.047005,test_mape_loss 14.310032,Time used 0.113696s\n",
      "batch 801, train_loss 0.004742,Time used 0.007978s\n",
      "batch 802, train_loss 0.004272,Time used 0.007978s\n",
      "batch 803, train_loss 0.003586,Time used 0.007979s\n",
      "batch 804, train_loss 0.004628,Time used 0.008976s\n",
      "batch 805, train_loss 0.005553,Time used 0.008977s\n",
      "batch 806, train_loss 0.002956,Time used 0.008977s\n",
      "batch 807, train_loss 0.004272,Time used 0.006981s\n",
      "batch 808, train_loss 0.004920,Time used 0.008975s\n",
      "batch 809, train_loss 0.003504,Time used 0.008977s\n",
      "batch 810, train_loss 0.003867,Time used 0.011969s\n",
      "batch 811, train_loss 0.004271,Time used 0.010970s\n",
      "batch 812, train_loss 0.003316,Time used 0.009973s\n",
      "batch 813, train_loss 0.004206,Time used 0.008976s\n",
      "batch 814, train_loss 0.004277,Time used 0.007979s\n",
      "batch 815, train_loss 0.004241,Time used 0.008976s\n",
      "batch 816, train_loss 0.003422,Time used 0.008975s\n",
      "batch 817, train_loss 0.002981,Time used 0.008977s\n",
      "batch 818, train_loss 0.003148,Time used 0.007979s\n",
      "batch 819, train_loss 0.006096,Time used 0.007979s\n",
      "batch 820, train_loss 0.003865,Time used 0.008976s\n",
      "batch 821, train_loss 0.003142,Time used 0.007979s\n",
      "batch 822, train_loss 0.005369,Time used 0.007979s\n",
      "batch 823, train_loss 0.005592,Time used 0.007979s\n",
      "batch 824, train_loss 0.003126,Time used 0.008976s\n",
      "batch 825, train_loss 0.004614,Time used 0.008976s\n",
      "batch 826, train_loss 0.003187,Time used 0.008976s\n",
      "batch 827, train_loss 0.004050,Time used 0.008976s\n",
      "batch 828, train_loss 0.004298,Time used 0.007978s\n",
      "batch 829, train_loss 0.005774,Time used 0.007978s\n",
      "batch 830, train_loss 0.004941,Time used 0.007979s\n",
      "batch 831, train_loss 0.004368,Time used 0.007978s\n",
      "batch 832, train_loss 0.003964,Time used 0.008977s\n",
      "batch 833, train_loss 0.003710,Time used 0.008975s\n",
      "batch 834, train_loss 0.005486,Time used 0.008976s\n",
      "batch 835, train_loss 0.004305,Time used 0.009973s\n",
      "batch 836, train_loss 0.004814,Time used 0.008976s\n",
      "batch 837, train_loss 0.004434,Time used 0.008976s\n",
      "batch 838, train_loss 0.004700,Time used 0.008976s\n",
      "batch 839, train_loss 0.003705,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 840, train_loss 0.004315,Time used 0.008976s\n",
      "batch 841, train_loss 0.004121,Time used 0.008977s\n",
      "batch 842, train_loss 0.003417,Time used 0.008976s\n",
      "batch 843, train_loss 0.002925,Time used 0.008976s\n",
      "batch 844, train_loss 0.002520,Time used 0.008976s\n",
      "batch 845, train_loss 0.003472,Time used 0.007979s\n",
      "batch 846, train_loss 0.003405,Time used 0.007978s\n",
      "batch 847, train_loss 0.003525,Time used 0.008977s\n",
      "batch 848, train_loss 0.005163,Time used 0.008975s\n",
      "batch 849, train_loss 0.004303,Time used 0.008976s\n",
      "batch 850, train_loss 0.003551,Time used 0.008976s\n",
      "batch 851, train_loss 0.003913,Time used 0.007977s\n",
      "batch 852, train_loss 0.003903,Time used 0.008976s\n",
      "batch 853, train_loss 0.003823,Time used 0.008976s\n",
      "batch 854, train_loss 0.003698,Time used 0.008976s\n",
      "batch 855, train_loss 0.005820,Time used 0.008975s\n",
      "batch 856, train_loss 0.000650,Time used 0.006981s\n",
      "batch 857, train_loss 0.003222,Time used 0.008977s\n",
      "batch 858, train_loss 0.004165,Time used 0.008975s\n",
      "batch 859, train_loss 0.003910,Time used 0.008976s\n",
      "batch 860, train_loss 0.004268,Time used 0.008976s\n",
      "batch 861, train_loss 0.004099,Time used 0.009973s\n",
      "batch 862, train_loss 0.004702,Time used 0.009974s\n",
      "batch 863, train_loss 0.004218,Time used 0.008976s\n",
      "batch 864, train_loss 0.004219,Time used 0.007978s\n",
      "batch 865, train_loss 0.004009,Time used 0.007978s\n",
      "batch 866, train_loss 0.003822,Time used 0.007979s\n",
      "batch 867, train_loss 0.003200,Time used 0.007978s\n",
      "batch 868, train_loss 0.006128,Time used 0.024934s\n",
      "batch 869, train_loss 0.005147,Time used 0.009973s\n",
      "batch 870, train_loss 0.005337,Time used 0.009973s\n",
      "batch 871, train_loss 0.002408,Time used 0.011969s\n",
      "batch 872, train_loss 0.004040,Time used 0.030917s\n",
      "batch 873, train_loss 0.005328,Time used 0.012965s\n",
      "batch 874, train_loss 0.003888,Time used 0.009974s\n",
      "batch 875, train_loss 0.003675,Time used 0.009973s\n",
      "batch 876, train_loss 0.004530,Time used 0.012966s\n",
      "batch 877, train_loss 0.003337,Time used 0.009973s\n",
      "batch 878, train_loss 0.003001,Time used 0.009974s\n",
      "batch 879, train_loss 0.003428,Time used 0.010971s\n",
      "batch 880, train_loss 0.004008,Time used 0.009974s\n",
      "batch 881, train_loss 0.004632,Time used 0.009973s\n",
      "batch 882, train_loss 0.005453,Time used 0.009973s\n",
      "batch 883, train_loss 0.003929,Time used 0.008976s\n",
      "batch 884, train_loss 0.003543,Time used 0.009973s\n",
      "batch 885, train_loss 0.004499,Time used 0.008976s\n",
      "batch 886, train_loss 0.003461,Time used 0.010970s\n",
      "batch 887, train_loss 0.004908,Time used 0.011969s\n",
      "batch 888, train_loss 0.004105,Time used 0.010971s\n",
      "batch 889, train_loss 0.003484,Time used 0.010970s\n",
      "batch 890, train_loss 0.003158,Time used 0.011968s\n",
      "batch 891, train_loss 0.004017,Time used 0.011968s\n",
      "batch 892, train_loss 0.004755,Time used 0.012966s\n",
      "batch 893, train_loss 0.004382,Time used 0.018950s\n",
      "batch 894, train_loss 0.005329,Time used 0.010970s\n",
      "batch 895, train_loss 0.002595,Time used 0.011967s\n",
      "batch 896, train_loss 0.004422,Time used 0.009973s\n",
      "batch 897, train_loss 0.005323,Time used 0.009974s\n",
      "batch 898, train_loss 0.004317,Time used 0.008976s\n",
      "batch 899, train_loss 0.004726,Time used 0.009973s\n",
      "batch 900, train_loss 0.005559,Time used 0.008977s\n",
      "***************************test_batch 900, test_rmse_loss 0.064056,test_mae_loss 0.046086,test_mape_loss 13.831442,Time used 0.119680s\n",
      "batch 901, train_loss 0.005863,Time used 0.009973s\n",
      "batch 902, train_loss 0.003230,Time used 0.008977s\n",
      "batch 903, train_loss 0.004072,Time used 0.007980s\n",
      "batch 904, train_loss 0.003681,Time used 0.008976s\n",
      "batch 905, train_loss 0.006181,Time used 0.008976s\n",
      "batch 906, train_loss 0.004309,Time used 0.008977s\n",
      "batch 907, train_loss 0.004098,Time used 0.008976s\n",
      "batch 908, train_loss 0.002757,Time used 0.008976s\n",
      "batch 909, train_loss 0.003961,Time used 0.008977s\n",
      "batch 910, train_loss 0.004106,Time used 0.009991s\n",
      "batch 911, train_loss 0.004867,Time used 0.008976s\n",
      "batch 912, train_loss 0.004597,Time used 0.007978s\n",
      "batch 913, train_loss 0.004075,Time used 0.007978s\n",
      "batch 914, train_loss 0.006040,Time used 0.008976s\n",
      "batch 915, train_loss 0.002784,Time used 0.008976s\n",
      "batch 916, train_loss 0.004694,Time used 0.008976s\n",
      "batch 917, train_loss 0.004884,Time used 0.009973s\n",
      "batch 918, train_loss 0.003221,Time used 0.008976s\n",
      "batch 919, train_loss 0.004841,Time used 0.009973s\n",
      "batch 920, train_loss 0.004592,Time used 0.008976s\n",
      "batch 921, train_loss 0.003526,Time used 0.011969s\n",
      "batch 922, train_loss 0.005617,Time used 0.009973s\n",
      "batch 923, train_loss 0.003674,Time used 0.009974s\n",
      "batch 924, train_loss 0.003191,Time used 0.009973s\n",
      "batch 925, train_loss 0.002966,Time used 0.008977s\n",
      "batch 926, train_loss 0.003965,Time used 0.010970s\n",
      "batch 927, train_loss 0.003102,Time used 0.011968s\n",
      "batch 928, train_loss 0.003869,Time used 0.008976s\n",
      "batch 929, train_loss 0.003085,Time used 0.008977s\n",
      "batch 930, train_loss 0.005002,Time used 0.009974s\n",
      "batch 931, train_loss 0.002848,Time used 0.008488s\n",
      "batch 932, train_loss 0.003298,Time used 0.008976s\n",
      "batch 933, train_loss 0.004312,Time used 0.009973s\n",
      "batch 934, train_loss 0.003698,Time used 0.008976s\n",
      "batch 935, train_loss 0.004124,Time used 0.008976s\n",
      "batch 936, train_loss 0.002535,Time used 0.008976s\n",
      "batch 937, train_loss 0.004608,Time used 0.007979s\n",
      "batch 938, train_loss 0.004148,Time used 0.008976s\n",
      "batch 939, train_loss 0.003241,Time used 0.008977s\n",
      "batch 940, train_loss 0.004139,Time used 0.009973s\n",
      "batch 941, train_loss 0.004206,Time used 0.008976s\n",
      "batch 942, train_loss 0.004391,Time used 0.008976s\n",
      "batch 943, train_loss 0.003149,Time used 0.008976s\n",
      "batch 944, train_loss 0.003127,Time used 0.007978s\n",
      "batch 945, train_loss 0.003383,Time used 0.008976s\n",
      "batch 946, train_loss 0.004973,Time used 0.007978s\n",
      "batch 947, train_loss 0.003959,Time used 0.008977s\n",
      "batch 948, train_loss 0.004356,Time used 0.008976s\n",
      "batch 949, train_loss 0.002858,Time used 0.008976s\n",
      "batch 950, train_loss 0.003869,Time used 0.008975s\n",
      "batch 951, train_loss 0.004570,Time used 0.011968s\n",
      "batch 952, train_loss 0.004053,Time used 0.008975s\n",
      "batch 953, train_loss 0.003957,Time used 0.008976s\n",
      "batch 954, train_loss 0.005604,Time used 0.008975s\n",
      "batch 955, train_loss 0.003063,Time used 0.008976s\n",
      "batch 956, train_loss 0.004057,Time used 0.008976s\n",
      "batch 957, train_loss 0.002957,Time used 0.008976s\n",
      "batch 958, train_loss 0.003141,Time used 0.008977s\n",
      "batch 959, train_loss 0.003001,Time used 0.010970s\n",
      "batch 960, train_loss 0.004412,Time used 0.008976s\n",
      "batch 961, train_loss 0.003284,Time used 0.008976s\n",
      "batch 962, train_loss 0.003387,Time used 0.008976s\n",
      "batch 963, train_loss 0.002100,Time used 0.006982s\n",
      "batch 964, train_loss 0.003731,Time used 0.008976s\n",
      "batch 965, train_loss 0.003104,Time used 0.008975s\n",
      "batch 966, train_loss 0.003527,Time used 0.008976s\n",
      "batch 967, train_loss 0.004613,Time used 0.008976s\n",
      "batch 968, train_loss 0.005945,Time used 0.008976s\n",
      "batch 969, train_loss 0.003358,Time used 0.007980s\n",
      "batch 970, train_loss 0.004401,Time used 0.007978s\n",
      "batch 971, train_loss 0.003297,Time used 0.007978s\n",
      "batch 972, train_loss 0.003238,Time used 0.007978s\n",
      "batch 973, train_loss 0.003963,Time used 0.007979s\n",
      "batch 974, train_loss 0.006276,Time used 0.007979s\n",
      "batch 975, train_loss 0.005503,Time used 0.007978s\n",
      "batch 976, train_loss 0.003959,Time used 0.007980s\n",
      "batch 977, train_loss 0.003631,Time used 0.007978s\n",
      "batch 978, train_loss 0.003886,Time used 0.009973s\n",
      "batch 979, train_loss 0.004165,Time used 0.008976s\n",
      "batch 980, train_loss 0.004830,Time used 0.007979s\n",
      "batch 981, train_loss 0.004307,Time used 0.008976s\n",
      "batch 982, train_loss 0.002326,Time used 0.007978s\n",
      "batch 983, train_loss 0.004878,Time used 0.008977s\n",
      "batch 984, train_loss 0.005065,Time used 0.008975s\n",
      "batch 985, train_loss 0.005306,Time used 0.008975s\n",
      "batch 986, train_loss 0.005928,Time used 0.009974s\n",
      "batch 987, train_loss 0.004748,Time used 0.008976s\n",
      "batch 988, train_loss 0.003761,Time used 0.007979s\n",
      "batch 989, train_loss 0.003297,Time used 0.007979s\n",
      "batch 990, train_loss 0.002896,Time used 0.007978s\n",
      "batch 991, train_loss 0.002411,Time used 0.007980s\n",
      "batch 992, train_loss 0.003759,Time used 0.007979s\n",
      "batch 993, train_loss 0.004560,Time used 0.008976s\n",
      "batch 994, train_loss 0.003271,Time used 0.008976s\n",
      "batch 995, train_loss 0.002883,Time used 0.008976s\n",
      "batch 996, train_loss 0.004695,Time used 0.008976s\n",
      "batch 997, train_loss 0.002684,Time used 0.008976s\n",
      "batch 998, train_loss 0.002922,Time used 0.009974s\n",
      "batch 999, train_loss 0.004328,Time used 0.008976s\n",
      "batch 1000, train_loss 0.003435,Time used 0.008977s\n",
      "***************************test_batch 1000, test_rmse_loss 0.063280,test_mae_loss 0.045465,test_mape_loss 13.719047,Time used 0.119680s\n",
      "batch 1001, train_loss 0.004042,Time used 0.008975s\n",
      "batch 1002, train_loss 0.004137,Time used 0.007978s\n",
      "batch 1003, train_loss 0.003537,Time used 0.007979s\n",
      "batch 1004, train_loss 0.005767,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1005, train_loss 0.004098,Time used 0.008976s\n",
      "batch 1006, train_loss 0.005075,Time used 0.009973s\n",
      "batch 1007, train_loss 0.004793,Time used 0.008976s\n",
      "batch 1008, train_loss 0.003597,Time used 0.008976s\n",
      "batch 1009, train_loss 0.003379,Time used 0.007978s\n",
      "batch 1010, train_loss 0.004713,Time used 0.007980s\n",
      "batch 1011, train_loss 0.003476,Time used 0.006982s\n",
      "batch 1012, train_loss 0.003614,Time used 0.006981s\n",
      "batch 1013, train_loss 0.003559,Time used 0.008975s\n",
      "batch 1014, train_loss 0.004407,Time used 0.007979s\n",
      "batch 1015, train_loss 0.003667,Time used 0.007979s\n",
      "batch 1016, train_loss 0.003794,Time used 0.007979s\n",
      "batch 1017, train_loss 0.004389,Time used 0.008976s\n",
      "batch 1018, train_loss 0.005013,Time used 0.007978s\n",
      "batch 1019, train_loss 0.004088,Time used 0.007978s\n",
      "batch 1020, train_loss 0.003175,Time used 0.007979s\n",
      "batch 1021, train_loss 0.003012,Time used 0.006982s\n",
      "batch 1022, train_loss 0.003008,Time used 0.007978s\n",
      "batch 1023, train_loss 0.003806,Time used 0.007980s\n",
      "batch 1024, train_loss 0.004109,Time used 0.007978s\n",
      "batch 1025, train_loss 0.003773,Time used 0.008976s\n",
      "batch 1026, train_loss 0.003029,Time used 0.007979s\n",
      "batch 1027, train_loss 0.004080,Time used 0.009974s\n",
      "batch 1028, train_loss 0.003273,Time used 0.008975s\n",
      "batch 1029, train_loss 0.004195,Time used 0.007978s\n",
      "batch 1030, train_loss 0.003271,Time used 0.007979s\n",
      "batch 1031, train_loss 0.002798,Time used 0.007979s\n",
      "batch 1032, train_loss 0.003285,Time used 0.007978s\n",
      "batch 1033, train_loss 0.003744,Time used 0.007979s\n",
      "batch 1034, train_loss 0.004052,Time used 0.006982s\n",
      "batch 1035, train_loss 0.003857,Time used 0.006982s\n",
      "batch 1036, train_loss 0.003464,Time used 0.007978s\n",
      "batch 1037, train_loss 0.003644,Time used 0.008976s\n",
      "batch 1038, train_loss 0.004331,Time used 0.008975s\n",
      "batch 1039, train_loss 0.004385,Time used 0.008977s\n",
      "batch 1040, train_loss 0.003091,Time used 0.007978s\n",
      "batch 1041, train_loss 0.004344,Time used 0.007978s\n",
      "batch 1042, train_loss 0.004193,Time used 0.006981s\n",
      "batch 1043, train_loss 0.003754,Time used 0.007979s\n",
      "batch 1044, train_loss 0.003819,Time used 0.007978s\n",
      "batch 1045, train_loss 0.005345,Time used 0.007979s\n",
      "batch 1046, train_loss 0.003870,Time used 0.007978s\n",
      "batch 1047, train_loss 0.003244,Time used 0.006981s\n",
      "batch 1048, train_loss 0.003273,Time used 0.007979s\n",
      "batch 1049, train_loss 0.007756,Time used 0.008976s\n",
      "batch 1050, train_loss 0.003310,Time used 0.009974s\n",
      "batch 1051, train_loss 0.004540,Time used 0.009972s\n",
      "batch 1052, train_loss 0.002690,Time used 0.009974s\n",
      "batch 1053, train_loss 0.003974,Time used 0.009974s\n",
      "batch 1054, train_loss 0.005316,Time used 0.009973s\n",
      "batch 1055, train_loss 0.003647,Time used 0.009973s\n",
      "batch 1056, train_loss 0.005620,Time used 0.008977s\n",
      "batch 1057, train_loss 0.004528,Time used 0.008977s\n",
      "batch 1058, train_loss 0.003012,Time used 0.008976s\n",
      "batch 1059, train_loss 0.003842,Time used 0.008976s\n",
      "batch 1060, train_loss 0.004080,Time used 0.008976s\n",
      "batch 1061, train_loss 0.005378,Time used 0.008976s\n",
      "batch 1062, train_loss 0.002632,Time used 0.009973s\n",
      "batch 1063, train_loss 0.003614,Time used 0.009974s\n",
      "batch 1064, train_loss 0.004655,Time used 0.008976s\n",
      "batch 1065, train_loss 0.003474,Time used 0.009973s\n",
      "batch 1066, train_loss 0.003100,Time used 0.009974s\n",
      "batch 1067, train_loss 0.002729,Time used 0.009973s\n",
      "batch 1068, train_loss 0.003933,Time used 0.009973s\n",
      "batch 1069, train_loss 0.004555,Time used 0.009974s\n",
      "batch 1070, train_loss 0.002410,Time used 0.007979s\n",
      "batch 1071, train_loss 0.002828,Time used 0.008976s\n",
      "batch 1072, train_loss 0.003239,Time used 0.008976s\n",
      "batch 1073, train_loss 0.004950,Time used 0.008975s\n",
      "batch 1074, train_loss 0.004091,Time used 0.008976s\n",
      "batch 1075, train_loss 0.004333,Time used 0.007979s\n",
      "batch 1076, train_loss 0.003991,Time used 0.008975s\n",
      "batch 1077, train_loss 0.003182,Time used 0.009974s\n",
      "batch 1078, train_loss 0.003217,Time used 0.009973s\n",
      "batch 1079, train_loss 0.004301,Time used 0.008976s\n",
      "batch 1080, train_loss 0.004314,Time used 0.007978s\n",
      "batch 1081, train_loss 0.003838,Time used 0.007979s\n",
      "batch 1082, train_loss 0.002791,Time used 0.007978s\n",
      "batch 1083, train_loss 0.003517,Time used 0.008976s\n",
      "batch 1084, train_loss 0.003191,Time used 0.007978s\n",
      "batch 1085, train_loss 0.004581,Time used 0.007978s\n",
      "batch 1086, train_loss 0.003571,Time used 0.007978s\n",
      "batch 1087, train_loss 0.004321,Time used 0.007978s\n",
      "batch 1088, train_loss 0.003265,Time used 0.008977s\n",
      "batch 1089, train_loss 0.003251,Time used 0.008976s\n",
      "batch 1090, train_loss 0.004454,Time used 0.008976s\n",
      "batch 1091, train_loss 0.003616,Time used 0.008976s\n",
      "batch 1092, train_loss 0.004403,Time used 0.008976s\n",
      "batch 1093, train_loss 0.003621,Time used 0.007979s\n",
      "batch 1094, train_loss 0.004608,Time used 0.009069s\n",
      "batch 1095, train_loss 0.003053,Time used 0.008975s\n",
      "batch 1096, train_loss 0.003744,Time used 0.008977s\n",
      "batch 1097, train_loss 0.005637,Time used 0.008975s\n",
      "batch 1098, train_loss 0.003910,Time used 0.008977s\n",
      "batch 1099, train_loss 0.003556,Time used 0.008976s\n",
      "batch 1100, train_loss 0.003813,Time used 0.007979s\n",
      "***************************test_batch 1100, test_rmse_loss 0.062803,test_mae_loss 0.045060,test_mape_loss 13.628603,Time used 0.116689s\n",
      "batch 1101, train_loss 0.004878,Time used 0.008976s\n",
      "batch 1102, train_loss 0.003331,Time used 0.008975s\n",
      "batch 1103, train_loss 0.004684,Time used 0.008976s\n",
      "batch 1104, train_loss 0.004379,Time used 0.008975s\n",
      "batch 1105, train_loss 0.004063,Time used 0.009973s\n",
      "batch 1106, train_loss 0.004406,Time used 0.009974s\n",
      "batch 1107, train_loss 0.003598,Time used 0.009973s\n",
      "batch 1108, train_loss 0.002472,Time used 0.009974s\n",
      "batch 1109, train_loss 0.005039,Time used 0.009973s\n",
      "batch 1110, train_loss 0.003349,Time used 0.008977s\n",
      "batch 1111, train_loss 0.004188,Time used 0.008976s\n",
      "batch 1112, train_loss 0.003183,Time used 0.009973s\n",
      "batch 1113, train_loss 0.004456,Time used 0.008976s\n",
      "batch 1114, train_loss 0.003834,Time used 0.008976s\n",
      "batch 1115, train_loss 0.003007,Time used 0.008977s\n",
      "batch 1116, train_loss 0.003730,Time used 0.008976s\n",
      "batch 1117, train_loss 0.003731,Time used 0.008976s\n",
      "batch 1118, train_loss 0.005302,Time used 0.007979s\n",
      "batch 1119, train_loss 0.002971,Time used 0.008976s\n",
      "batch 1120, train_loss 0.004060,Time used 0.008975s\n",
      "batch 1121, train_loss 0.004174,Time used 0.008976s\n",
      "batch 1122, train_loss 0.003732,Time used 0.007978s\n",
      "batch 1123, train_loss 0.003132,Time used 0.008976s\n",
      "batch 1124, train_loss 0.005156,Time used 0.008976s\n",
      "batch 1125, train_loss 0.004651,Time used 0.009002s\n",
      "batch 1126, train_loss 0.004294,Time used 0.009967s\n",
      "batch 1127, train_loss 0.003375,Time used 0.008976s\n",
      "batch 1128, train_loss 0.003899,Time used 0.010971s\n",
      "batch 1129, train_loss 0.004505,Time used 0.009973s\n",
      "batch 1130, train_loss 0.002804,Time used 0.008976s\n",
      "batch 1131, train_loss 0.003120,Time used 0.007978s\n",
      "batch 1132, train_loss 0.002583,Time used 0.008976s\n",
      "batch 1133, train_loss 0.005467,Time used 0.008976s\n",
      "batch 1134, train_loss 0.003972,Time used 0.008976s\n",
      "batch 1135, train_loss 0.004083,Time used 0.008976s\n",
      "batch 1136, train_loss 0.003099,Time used 0.008976s\n",
      "batch 1137, train_loss 0.003367,Time used 0.008977s\n",
      "batch 1138, train_loss 0.006422,Time used 0.008975s\n",
      "batch 1139, train_loss 0.003821,Time used 0.009973s\n",
      "batch 1140, train_loss 0.003939,Time used 0.010971s\n",
      "batch 1141, train_loss 0.003474,Time used 0.008976s\n",
      "batch 1142, train_loss 0.003269,Time used 0.008976s\n",
      "batch 1143, train_loss 0.002977,Time used 0.007979s\n",
      "batch 1144, train_loss 0.003276,Time used 0.008977s\n",
      "batch 1145, train_loss 0.004892,Time used 0.008975s\n",
      "batch 1146, train_loss 0.004063,Time used 0.009973s\n",
      "batch 1147, train_loss 0.002979,Time used 0.010482s\n",
      "batch 1148, train_loss 0.003752,Time used 0.008976s\n",
      "batch 1149, train_loss 0.004009,Time used 0.008976s\n",
      "batch 1150, train_loss 0.003628,Time used 0.008977s\n",
      "batch 1151, train_loss 0.004313,Time used 0.008976s\n",
      "batch 1152, train_loss 0.003034,Time used 0.009973s\n",
      "batch 1153, train_loss 0.004567,Time used 0.008976s\n",
      "batch 1154, train_loss 0.004082,Time used 0.008976s\n",
      "batch 1155, train_loss 0.003320,Time used 0.008977s\n",
      "batch 1156, train_loss 0.004534,Time used 0.008975s\n",
      "batch 1157, train_loss 0.005425,Time used 0.008976s\n",
      "batch 1158, train_loss 0.003491,Time used 0.008975s\n",
      "batch 1159, train_loss 0.003056,Time used 0.007979s\n",
      "batch 1160, train_loss 0.002563,Time used 0.008975s\n",
      "batch 1161, train_loss 0.004756,Time used 0.008977s\n",
      "batch 1162, train_loss 0.003449,Time used 0.007979s\n",
      "batch 1163, train_loss 0.003306,Time used 0.008976s\n",
      "batch 1164, train_loss 0.003299,Time used 0.008976s\n",
      "batch 1165, train_loss 0.003942,Time used 0.008976s\n",
      "batch 1166, train_loss 0.003717,Time used 0.007978s\n",
      "batch 1167, train_loss 0.003379,Time used 0.009973s\n",
      "batch 1168, train_loss 0.003760,Time used 0.008976s\n",
      "batch 1169, train_loss 0.005537,Time used 0.008975s\n",
      "batch 1170, train_loss 0.003525,Time used 0.008977s\n",
      "batch 1171, train_loss 0.004604,Time used 0.008976s\n",
      "batch 1172, train_loss 0.004993,Time used 0.008976s\n",
      "batch 1173, train_loss 0.004615,Time used 0.008977s\n",
      "batch 1174, train_loss 0.005290,Time used 0.007978s\n",
      "batch 1175, train_loss 0.003891,Time used 0.007979s\n",
      "batch 1176, train_loss 0.004346,Time used 0.008976s\n",
      "batch 1177, train_loss 0.001833,Time used 0.006981s\n",
      "batch 1178, train_loss 0.003642,Time used 0.008977s\n",
      "batch 1179, train_loss 0.003132,Time used 0.008975s\n",
      "batch 1180, train_loss 0.004100,Time used 0.008976s\n",
      "batch 1181, train_loss 0.003618,Time used 0.009974s\n",
      "batch 1182, train_loss 0.003975,Time used 0.008977s\n",
      "batch 1183, train_loss 0.003136,Time used 0.009973s\n",
      "batch 1184, train_loss 0.003452,Time used 0.009973s\n",
      "batch 1185, train_loss 0.005589,Time used 0.007979s\n",
      "batch 1186, train_loss 0.004922,Time used 0.008976s\n",
      "batch 1187, train_loss 0.003635,Time used 0.008976s\n",
      "batch 1188, train_loss 0.004414,Time used 0.007979s\n",
      "batch 1189, train_loss 0.005208,Time used 0.007979s\n",
      "batch 1190, train_loss 0.004743,Time used 0.007978s\n",
      "batch 1191, train_loss 0.003648,Time used 0.008976s\n",
      "batch 1192, train_loss 0.003937,Time used 0.008975s\n",
      "batch 1193, train_loss 0.003841,Time used 0.009973s\n",
      "batch 1194, train_loss 0.003398,Time used 0.008976s\n",
      "batch 1195, train_loss 0.003266,Time used 0.009973s\n",
      "batch 1196, train_loss 0.003821,Time used 0.008975s\n",
      "batch 1197, train_loss 0.003418,Time used 0.008976s\n",
      "batch 1198, train_loss 0.003633,Time used 0.009974s\n",
      "batch 1199, train_loss 0.003941,Time used 0.009973s\n",
      "batch 1200, train_loss 0.002846,Time used 0.008976s\n",
      "***************************test_batch 1200, test_rmse_loss 0.062431,test_mae_loss 0.044745,test_mape_loss 13.564875,Time used 0.104737s\n",
      "batch 1201, train_loss 0.003456,Time used 0.008975s\n",
      "batch 1202, train_loss 0.003378,Time used 0.007978s\n",
      "batch 1203, train_loss 0.003263,Time used 0.008991s\n",
      "batch 1204, train_loss 0.005057,Time used 0.008961s\n",
      "batch 1205, train_loss 0.005424,Time used 0.008976s\n",
      "batch 1206, train_loss 0.004227,Time used 0.008976s\n",
      "batch 1207, train_loss 0.004528,Time used 0.008976s\n",
      "batch 1208, train_loss 0.003429,Time used 0.008975s\n",
      "batch 1209, train_loss 0.003489,Time used 0.008977s\n",
      "batch 1210, train_loss 0.003947,Time used 0.008975s\n",
      "batch 1211, train_loss 0.003016,Time used 0.008975s\n",
      "batch 1212, train_loss 0.003056,Time used 0.008976s\n",
      "batch 1213, train_loss 0.004614,Time used 0.008976s\n",
      "batch 1214, train_loss 0.002951,Time used 0.007979s\n",
      "batch 1215, train_loss 0.003739,Time used 0.008976s\n",
      "batch 1216, train_loss 0.003828,Time used 0.008976s\n",
      "batch 1217, train_loss 0.003324,Time used 0.008976s\n",
      "batch 1218, train_loss 0.003580,Time used 0.009973s\n",
      "batch 1219, train_loss 0.003662,Time used 0.008976s\n",
      "batch 1220, train_loss 0.003770,Time used 0.009973s\n",
      "batch 1221, train_loss 0.003411,Time used 0.008976s\n",
      "batch 1222, train_loss 0.003529,Time used 0.008976s\n",
      "batch 1223, train_loss 0.004059,Time used 0.008976s\n",
      "batch 1224, train_loss 0.003786,Time used 0.008976s\n",
      "batch 1225, train_loss 0.003487,Time used 0.008976s\n",
      "batch 1226, train_loss 0.002480,Time used 0.007979s\n",
      "batch 1227, train_loss 0.003704,Time used 0.008976s\n",
      "batch 1228, train_loss 0.003961,Time used 0.008976s\n",
      "batch 1229, train_loss 0.003608,Time used 0.007978s\n",
      "batch 1230, train_loss 0.003532,Time used 0.007978s\n",
      "batch 1231, train_loss 0.003955,Time used 0.007978s\n",
      "batch 1232, train_loss 0.003163,Time used 0.008976s\n",
      "batch 1233, train_loss 0.005088,Time used 0.008977s\n",
      "batch 1234, train_loss 0.004834,Time used 0.007978s\n",
      "batch 1235, train_loss 0.004460,Time used 0.008976s\n",
      "batch 1236, train_loss 0.005418,Time used 0.007979s\n",
      "batch 1237, train_loss 0.003733,Time used 0.007978s\n",
      "batch 1238, train_loss 0.003934,Time used 0.007979s\n",
      "batch 1239, train_loss 0.005533,Time used 0.007979s\n",
      "batch 1240, train_loss 0.004495,Time used 0.007978s\n",
      "batch 1241, train_loss 0.003947,Time used 0.007978s\n",
      "batch 1242, train_loss 0.004301,Time used 0.007979s\n",
      "batch 1243, train_loss 0.004185,Time used 0.007978s\n",
      "batch 1244, train_loss 0.005163,Time used 0.007979s\n",
      "batch 1245, train_loss 0.003951,Time used 0.007978s\n",
      "batch 1246, train_loss 0.003922,Time used 0.008976s\n",
      "batch 1247, train_loss 0.005923,Time used 0.007979s\n",
      "batch 1248, train_loss 0.002857,Time used 0.007979s\n",
      "batch 1249, train_loss 0.003681,Time used 0.008975s\n",
      "batch 1250, train_loss 0.003190,Time used 0.007978s\n",
      "batch 1251, train_loss 0.004031,Time used 0.007979s\n",
      "batch 1252, train_loss 0.003520,Time used 0.008976s\n",
      "batch 1253, train_loss 0.003897,Time used 0.006980s\n",
      "batch 1254, train_loss 0.004526,Time used 0.007978s\n",
      "batch 1255, train_loss 0.003735,Time used 0.007979s\n",
      "batch 1256, train_loss 0.003417,Time used 0.007980s\n",
      "batch 1257, train_loss 0.003703,Time used 0.006981s\n",
      "batch 1258, train_loss 0.003197,Time used 0.006982s\n",
      "batch 1259, train_loss 0.003728,Time used 0.007979s\n",
      "batch 1260, train_loss 0.002726,Time used 0.007979s\n",
      "batch 1261, train_loss 0.005207,Time used 0.007977s\n",
      "batch 1262, train_loss 0.003304,Time used 0.007979s\n",
      "batch 1263, train_loss 0.002627,Time used 0.008976s\n",
      "batch 1264, train_loss 0.003968,Time used 0.008976s\n",
      "batch 1265, train_loss 0.004154,Time used 0.007979s\n",
      "batch 1266, train_loss 0.006496,Time used 0.006982s\n",
      "batch 1267, train_loss 0.003751,Time used 0.007978s\n",
      "batch 1268, train_loss 0.002974,Time used 0.007978s\n",
      "batch 1269, train_loss 0.004193,Time used 0.007980s\n",
      "batch 1270, train_loss 0.003237,Time used 0.007978s\n",
      "batch 1271, train_loss 0.003965,Time used 0.008977s\n",
      "batch 1272, train_loss 0.002547,Time used 0.008976s\n",
      "batch 1273, train_loss 0.002627,Time used 0.008976s\n",
      "batch 1274, train_loss 0.003321,Time used 0.008976s\n",
      "batch 1275, train_loss 0.003376,Time used 0.008976s\n",
      "batch 1276, train_loss 0.003816,Time used 0.008976s\n",
      "batch 1277, train_loss 0.004328,Time used 0.008976s\n",
      "batch 1278, train_loss 0.003621,Time used 0.007980s\n",
      "batch 1279, train_loss 0.003066,Time used 0.007978s\n",
      "batch 1280, train_loss 0.004150,Time used 0.007978s\n",
      "batch 1281, train_loss 0.004572,Time used 0.008976s\n",
      "batch 1282, train_loss 0.003166,Time used 0.007979s\n",
      "batch 1283, train_loss 0.004331,Time used 0.007980s\n",
      "batch 1284, train_loss 0.002491,Time used 0.007978s\n",
      "batch 1285, train_loss 0.004870,Time used 0.008975s\n",
      "batch 1286, train_loss 0.003060,Time used 0.007979s\n",
      "batch 1287, train_loss 0.002497,Time used 0.007978s\n",
      "batch 1288, train_loss 0.004064,Time used 0.007978s\n",
      "batch 1289, train_loss 0.003419,Time used 0.008976s\n",
      "batch 1290, train_loss 0.003975,Time used 0.008975s\n",
      "batch 1291, train_loss 0.005134,Time used 0.007979s\n",
      "batch 1292, train_loss 0.003122,Time used 0.008976s\n",
      "batch 1293, train_loss 0.002938,Time used 0.007978s\n",
      "batch 1294, train_loss 0.003218,Time used 0.007978s\n",
      "batch 1295, train_loss 0.003602,Time used 0.007979s\n",
      "batch 1296, train_loss 0.003577,Time used 0.007978s\n",
      "batch 1297, train_loss 0.005079,Time used 0.007979s\n",
      "batch 1298, train_loss 0.003504,Time used 0.007977s\n",
      "batch 1299, train_loss 0.004235,Time used 0.008976s\n",
      "batch 1300, train_loss 0.004468,Time used 0.007978s\n",
      "***************************test_batch 1300, test_rmse_loss 0.062127,test_mae_loss 0.044455,test_mape_loss 13.375663,Time used 0.114694s\n",
      "batch 1301, train_loss 0.004542,Time used 0.009972s\n",
      "batch 1302, train_loss 0.004850,Time used 0.008976s\n",
      "batch 1303, train_loss 0.003294,Time used 0.008976s\n",
      "batch 1304, train_loss 0.003477,Time used 0.008976s\n",
      "batch 1305, train_loss 0.004391,Time used 0.008976s\n",
      "batch 1306, train_loss 0.004175,Time used 0.007979s\n",
      "batch 1307, train_loss 0.004504,Time used 0.007978s\n",
      "batch 1308, train_loss 0.003299,Time used 0.008976s\n",
      "batch 1309, train_loss 0.003359,Time used 0.008976s\n",
      "batch 1310, train_loss 0.003837,Time used 0.009973s\n",
      "batch 1311, train_loss 0.003431,Time used 0.008976s\n",
      "batch 1312, train_loss 0.002936,Time used 0.008976s\n",
      "batch 1313, train_loss 0.003524,Time used 0.007978s\n",
      "batch 1314, train_loss 0.003789,Time used 0.008976s\n",
      "batch 1315, train_loss 0.003724,Time used 0.008975s\n",
      "batch 1316, train_loss 0.004399,Time used 0.008976s\n",
      "batch 1317, train_loss 0.003381,Time used 0.008976s\n",
      "batch 1318, train_loss 0.004176,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1319, train_loss 0.003700,Time used 0.008977s\n",
      "batch 1320, train_loss 0.004109,Time used 0.008977s\n",
      "batch 1321, train_loss 0.004185,Time used 0.008977s\n",
      "batch 1322, train_loss 0.003588,Time used 0.007978s\n",
      "batch 1323, train_loss 0.003779,Time used 0.007979s\n",
      "batch 1324, train_loss 0.003925,Time used 0.008976s\n",
      "batch 1325, train_loss 0.004791,Time used 0.007979s\n",
      "batch 1326, train_loss 0.004926,Time used 0.008976s\n",
      "batch 1327, train_loss 0.002930,Time used 0.008975s\n",
      "batch 1328, train_loss 0.004398,Time used 0.008976s\n",
      "batch 1329, train_loss 0.002965,Time used 0.007979s\n",
      "batch 1330, train_loss 0.003617,Time used 0.007978s\n",
      "batch 1331, train_loss 0.004462,Time used 0.008977s\n",
      "batch 1332, train_loss 0.003972,Time used 0.007978s\n",
      "batch 1333, train_loss 0.003462,Time used 0.007979s\n",
      "batch 1334, train_loss 0.004482,Time used 0.008976s\n",
      "batch 1335, train_loss 0.003086,Time used 0.007979s\n",
      "batch 1336, train_loss 0.007650,Time used 0.007979s\n",
      "batch 1337, train_loss 0.003999,Time used 0.007978s\n",
      "batch 1338, train_loss 0.004685,Time used 0.007979s\n",
      "batch 1339, train_loss 0.003107,Time used 0.007979s\n",
      "batch 1340, train_loss 0.003916,Time used 0.007979s\n",
      "batch 1341, train_loss 0.003044,Time used 0.009974s\n",
      "batch 1342, train_loss 0.003110,Time used 0.008975s\n",
      "batch 1343, train_loss 0.003763,Time used 0.007978s\n",
      "batch 1344, train_loss 0.003480,Time used 0.007978s\n",
      "batch 1345, train_loss 0.003003,Time used 0.007979s\n",
      "batch 1346, train_loss 0.004232,Time used 0.008977s\n",
      "batch 1347, train_loss 0.004422,Time used 0.007979s\n",
      "batch 1348, train_loss 0.002546,Time used 0.008976s\n",
      "batch 1349, train_loss 0.004153,Time used 0.008976s\n",
      "batch 1350, train_loss 0.003870,Time used 0.008976s\n",
      "batch 1351, train_loss 0.003234,Time used 0.008976s\n",
      "batch 1352, train_loss 0.004418,Time used 0.007978s\n",
      "batch 1353, train_loss 0.005563,Time used 0.007978s\n",
      "batch 1354, train_loss 0.003848,Time used 0.008977s\n",
      "batch 1355, train_loss 0.002533,Time used 0.008975s\n",
      "batch 1356, train_loss 0.004513,Time used 0.007979s\n",
      "batch 1357, train_loss 0.003510,Time used 0.007979s\n",
      "batch 1358, train_loss 0.004375,Time used 0.007979s\n",
      "batch 1359, train_loss 0.004124,Time used 0.007978s\n",
      "batch 1360, train_loss 0.002863,Time used 0.007979s\n",
      "batch 1361, train_loss 0.004157,Time used 0.007979s\n",
      "batch 1362, train_loss 0.004441,Time used 0.010971s\n",
      "batch 1363, train_loss 0.005672,Time used 0.007978s\n",
      "batch 1364, train_loss 0.003756,Time used 0.008976s\n",
      "batch 1365, train_loss 0.004797,Time used 0.009973s\n",
      "batch 1366, train_loss 0.003294,Time used 0.008976s\n",
      "batch 1367, train_loss 0.004076,Time used 0.008977s\n",
      "batch 1368, train_loss 0.003159,Time used 0.007980s\n",
      "batch 1369, train_loss 0.003348,Time used 0.008976s\n",
      "batch 1370, train_loss 0.003508,Time used 0.008977s\n",
      "batch 1371, train_loss 0.002344,Time used 0.008975s\n",
      "batch 1372, train_loss 0.003070,Time used 0.008976s\n",
      "batch 1373, train_loss 0.003500,Time used 0.008976s\n",
      "batch 1374, train_loss 0.002968,Time used 0.008976s\n",
      "batch 1375, train_loss 0.004597,Time used 0.008976s\n",
      "batch 1376, train_loss 0.002726,Time used 0.008976s\n",
      "batch 1377, train_loss 0.004062,Time used 0.008976s\n",
      "batch 1378, train_loss 0.003778,Time used 0.008976s\n",
      "batch 1379, train_loss 0.003908,Time used 0.007979s\n",
      "batch 1380, train_loss 0.002800,Time used 0.008977s\n",
      "batch 1381, train_loss 0.004125,Time used 0.008976s\n",
      "batch 1382, train_loss 0.005121,Time used 0.010971s\n",
      "batch 1383, train_loss 0.002080,Time used 0.011968s\n",
      "batch 1384, train_loss 0.003333,Time used 0.009974s\n",
      "batch 1385, train_loss 0.002750,Time used 0.009973s\n",
      "batch 1386, train_loss 0.004876,Time used 0.008977s\n",
      "batch 1387, train_loss 0.003164,Time used 0.007979s\n",
      "batch 1388, train_loss 0.003755,Time used 0.008976s\n",
      "batch 1389, train_loss 0.004214,Time used 0.007979s\n",
      "batch 1390, train_loss 0.004151,Time used 0.008976s\n",
      "batch 1391, train_loss 0.002442,Time used 0.006981s\n",
      "batch 1392, train_loss 0.003576,Time used 0.007979s\n",
      "batch 1393, train_loss 0.005161,Time used 0.008976s\n",
      "batch 1394, train_loss 0.004206,Time used 0.008976s\n",
      "batch 1395, train_loss 0.002385,Time used 0.008976s\n",
      "batch 1396, train_loss 0.004197,Time used 0.008976s\n",
      "batch 1397, train_loss 0.006468,Time used 0.009974s\n",
      "batch 1398, train_loss 0.004632,Time used 0.008976s\n",
      "batch 1399, train_loss 0.003832,Time used 0.008976s\n",
      "batch 1400, train_loss 0.002851,Time used 0.008976s\n",
      "***************************test_batch 1400, test_rmse_loss 0.061920,test_mae_loss 0.044289,test_mape_loss 13.434410,Time used 0.119680s\n",
      "batch 1401, train_loss 0.004447,Time used 0.008976s\n",
      "batch 1402, train_loss 0.003721,Time used 0.008976s\n",
      "batch 1403, train_loss 0.002764,Time used 0.008977s\n",
      "batch 1404, train_loss 0.002838,Time used 0.008975s\n",
      "batch 1405, train_loss 0.003528,Time used 0.009974s\n",
      "batch 1406, train_loss 0.003300,Time used 0.007979s\n",
      "batch 1407, train_loss 0.004422,Time used 0.008976s\n",
      "batch 1408, train_loss 0.003191,Time used 0.008976s\n",
      "batch 1409, train_loss 0.003797,Time used 0.009973s\n",
      "batch 1410, train_loss 0.004305,Time used 0.008975s\n",
      "batch 1411, train_loss 0.003705,Time used 0.009974s\n",
      "batch 1412, train_loss 0.004598,Time used 0.008976s\n",
      "batch 1413, train_loss 0.004327,Time used 0.007979s\n",
      "batch 1414, train_loss 0.003454,Time used 0.008976s\n",
      "batch 1415, train_loss 0.003325,Time used 0.007979s\n",
      "batch 1416, train_loss 0.003740,Time used 0.010971s\n",
      "batch 1417, train_loss 0.003624,Time used 0.009973s\n",
      "batch 1418, train_loss 0.003538,Time used 0.008976s\n",
      "batch 1419, train_loss 0.003677,Time used 0.008976s\n",
      "batch 1420, train_loss 0.003497,Time used 0.007979s\n",
      "batch 1421, train_loss 0.003743,Time used 0.007980s\n",
      "batch 1422, train_loss 0.003860,Time used 0.007978s\n",
      "batch 1423, train_loss 0.004333,Time used 0.007979s\n",
      "batch 1424, train_loss 0.004329,Time used 0.008976s\n",
      "batch 1425, train_loss 0.003999,Time used 0.007978s\n",
      "batch 1426, train_loss 0.004167,Time used 0.007979s\n",
      "batch 1427, train_loss 0.004511,Time used 0.007978s\n",
      "batch 1428, train_loss 0.004417,Time used 0.008976s\n",
      "batch 1429, train_loss 0.002986,Time used 0.008976s\n",
      "batch 1430, train_loss 0.004401,Time used 0.007979s\n",
      "batch 1431, train_loss 0.004929,Time used 0.006982s\n",
      "batch 1432, train_loss 0.003799,Time used 0.007978s\n",
      "batch 1433, train_loss 0.003851,Time used 0.008977s\n",
      "batch 1434, train_loss 0.003246,Time used 0.008976s\n",
      "batch 1435, train_loss 0.005087,Time used 0.006982s\n",
      "batch 1436, train_loss 0.002985,Time used 0.007979s\n",
      "batch 1437, train_loss 0.002878,Time used 0.006982s\n",
      "batch 1438, train_loss 0.005767,Time used 0.006982s\n",
      "batch 1439, train_loss 0.003355,Time used 0.007979s\n",
      "batch 1440, train_loss 0.006400,Time used 0.006981s\n",
      "batch 1441, train_loss 0.002953,Time used 0.007978s\n",
      "batch 1442, train_loss 0.003937,Time used 0.008976s\n",
      "batch 1443, train_loss 0.003591,Time used 0.008976s\n",
      "batch 1444, train_loss 0.003375,Time used 0.008976s\n",
      "batch 1445, train_loss 0.003936,Time used 0.007979s\n",
      "batch 1446, train_loss 0.004234,Time used 0.007978s\n",
      "batch 1447, train_loss 0.002671,Time used 0.007979s\n",
      "batch 1448, train_loss 0.003896,Time used 0.006982s\n",
      "batch 1449, train_loss 0.003072,Time used 0.007979s\n",
      "batch 1450, train_loss 0.003731,Time used 0.008976s\n",
      "batch 1451, train_loss 0.004491,Time used 0.008976s\n",
      "batch 1452, train_loss 0.003036,Time used 0.008977s\n",
      "batch 1453, train_loss 0.003905,Time used 0.008976s\n",
      "batch 1454, train_loss 0.003967,Time used 0.008977s\n",
      "batch 1455, train_loss 0.002653,Time used 0.008975s\n",
      "batch 1456, train_loss 0.002902,Time used 0.008976s\n",
      "batch 1457, train_loss 0.002065,Time used 0.008977s\n",
      "batch 1458, train_loss 0.004109,Time used 0.008976s\n",
      "batch 1459, train_loss 0.003830,Time used 0.008977s\n",
      "batch 1460, train_loss 0.004049,Time used 0.008976s\n",
      "batch 1461, train_loss 0.003431,Time used 0.008976s\n",
      "batch 1462, train_loss 0.004142,Time used 0.008975s\n",
      "batch 1463, train_loss 0.003421,Time used 0.008977s\n",
      "batch 1464, train_loss 0.003596,Time used 0.008976s\n",
      "batch 1465, train_loss 0.004816,Time used 0.008976s\n",
      "batch 1466, train_loss 0.003623,Time used 0.008976s\n",
      "batch 1467, train_loss 0.003495,Time used 0.008977s\n",
      "batch 1468, train_loss 0.003527,Time used 0.008976s\n",
      "batch 1469, train_loss 0.003023,Time used 0.008976s\n",
      "batch 1470, train_loss 0.003329,Time used 0.008976s\n",
      "batch 1471, train_loss 0.003447,Time used 0.008976s\n",
      "batch 1472, train_loss 0.003655,Time used 0.008977s\n",
      "batch 1473, train_loss 0.004877,Time used 0.008975s\n",
      "batch 1474, train_loss 0.003791,Time used 0.008976s\n",
      "batch 1475, train_loss 0.003378,Time used 0.007979s\n",
      "batch 1476, train_loss 0.004454,Time used 0.007978s\n",
      "batch 1477, train_loss 0.004071,Time used 0.007978s\n",
      "batch 1478, train_loss 0.005348,Time used 0.007977s\n",
      "batch 1479, train_loss 0.003415,Time used 0.008976s\n",
      "batch 1480, train_loss 0.004449,Time used 0.008976s\n",
      "batch 1481, train_loss 0.004721,Time used 0.008976s\n",
      "batch 1482, train_loss 0.004931,Time used 0.007979s\n",
      "batch 1483, train_loss 0.003491,Time used 0.007979s\n",
      "batch 1484, train_loss 0.003698,Time used 0.008976s\n",
      "batch 1485, train_loss 0.002707,Time used 0.008976s\n",
      "batch 1486, train_loss 0.002900,Time used 0.008976s\n",
      "batch 1487, train_loss 0.003801,Time used 0.007979s\n",
      "batch 1488, train_loss 0.003985,Time used 0.006981s\n",
      "batch 1489, train_loss 0.004108,Time used 0.007979s\n",
      "batch 1490, train_loss 0.002930,Time used 0.007978s\n",
      "batch 1491, train_loss 0.003237,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1492, train_loss 0.004316,Time used 0.009974s\n",
      "batch 1493, train_loss 0.002255,Time used 0.008976s\n",
      "batch 1494, train_loss 0.004017,Time used 0.008977s\n",
      "batch 1495, train_loss 0.003320,Time used 0.008976s\n",
      "batch 1496, train_loss 0.003137,Time used 0.008976s\n",
      "batch 1497, train_loss 0.003071,Time used 0.008976s\n",
      "batch 1498, train_loss 0.003555,Time used 0.006981s\n",
      "batch 1499, train_loss 0.005101,Time used 0.007978s\n",
      "batch 1500, train_loss 0.003196,Time used 0.007978s\n",
      "***************************test_batch 1500, test_rmse_loss 0.061699,test_mae_loss 0.044079,test_mape_loss 13.212676,Time used 0.110706s\n",
      "batch 1501, train_loss 0.004622,Time used 0.009971s\n",
      "batch 1502, train_loss 0.003495,Time used 0.008977s\n",
      "batch 1503, train_loss 0.003979,Time used 0.007979s\n",
      "batch 1504, train_loss 0.002119,Time used 0.007979s\n",
      "batch 1505, train_loss 0.004747,Time used 0.008976s\n",
      "batch 1506, train_loss 0.003959,Time used 0.008976s\n",
      "batch 1507, train_loss 0.003003,Time used 0.008977s\n",
      "batch 1508, train_loss 0.003371,Time used 0.007979s\n",
      "batch 1509, train_loss 0.003524,Time used 0.008977s\n",
      "batch 1510, train_loss 0.004518,Time used 0.008976s\n",
      "batch 1511, train_loss 0.003128,Time used 0.008976s\n",
      "batch 1512, train_loss 0.003530,Time used 0.008977s\n",
      "batch 1513, train_loss 0.004552,Time used 0.008976s\n",
      "batch 1514, train_loss 0.003467,Time used 0.007979s\n",
      "batch 1515, train_loss 0.005527,Time used 0.007978s\n",
      "batch 1516, train_loss 0.004117,Time used 0.007978s\n",
      "batch 1517, train_loss 0.004877,Time used 0.007978s\n",
      "batch 1518, train_loss 0.003318,Time used 0.007978s\n",
      "batch 1519, train_loss 0.003992,Time used 0.007980s\n",
      "batch 1520, train_loss 0.002613,Time used 0.008977s\n",
      "batch 1521, train_loss 0.004181,Time used 0.009973s\n",
      "batch 1522, train_loss 0.003064,Time used 0.009974s\n",
      "batch 1523, train_loss 0.004059,Time used 0.008976s\n",
      "batch 1524, train_loss 0.003318,Time used 0.008976s\n",
      "batch 1525, train_loss 0.002971,Time used 0.008976s\n",
      "batch 1526, train_loss 0.003797,Time used 0.007978s\n",
      "batch 1527, train_loss 0.003652,Time used 0.008976s\n",
      "batch 1528, train_loss 0.004317,Time used 0.008976s\n",
      "batch 1529, train_loss 0.003930,Time used 0.007979s\n",
      "batch 1530, train_loss 0.003705,Time used 0.008976s\n",
      "batch 1531, train_loss 0.004406,Time used 0.008976s\n",
      "batch 1532, train_loss 0.003488,Time used 0.007980s\n",
      "batch 1533, train_loss 0.003373,Time used 0.007979s\n",
      "batch 1534, train_loss 0.004159,Time used 0.008977s\n",
      "batch 1535, train_loss 0.003989,Time used 0.008976s\n",
      "batch 1536, train_loss 0.003700,Time used 0.008977s\n",
      "batch 1537, train_loss 0.004494,Time used 0.008975s\n",
      "batch 1538, train_loss 0.004880,Time used 0.008976s\n",
      "batch 1539, train_loss 0.003602,Time used 0.008976s\n",
      "batch 1540, train_loss 0.004549,Time used 0.008977s\n",
      "batch 1541, train_loss 0.003746,Time used 0.007978s\n",
      "batch 1542, train_loss 0.003377,Time used 0.009974s\n",
      "batch 1543, train_loss 0.003064,Time used 0.007979s\n",
      "batch 1544, train_loss 0.003513,Time used 0.007979s\n",
      "batch 1545, train_loss 0.004371,Time used 0.008976s\n",
      "batch 1546, train_loss 0.003008,Time used 0.008976s\n",
      "batch 1547, train_loss 0.002617,Time used 0.008976s\n",
      "batch 1548, train_loss 0.004292,Time used 0.007978s\n",
      "batch 1549, train_loss 0.003730,Time used 0.007979s\n",
      "batch 1550, train_loss 0.003370,Time used 0.008976s\n",
      "batch 1551, train_loss 0.003774,Time used 0.007978s\n",
      "batch 1552, train_loss 0.005147,Time used 0.008976s\n",
      "batch 1553, train_loss 0.002627,Time used 0.008975s\n",
      "batch 1554, train_loss 0.003789,Time used 0.009974s\n",
      "batch 1555, train_loss 0.003352,Time used 0.008976s\n",
      "batch 1556, train_loss 0.003498,Time used 0.007978s\n",
      "batch 1557, train_loss 0.003634,Time used 0.007978s\n",
      "batch 1558, train_loss 0.002654,Time used 0.008976s\n",
      "batch 1559, train_loss 0.004481,Time used 0.008976s\n",
      "batch 1560, train_loss 0.003683,Time used 0.008976s\n",
      "batch 1561, train_loss 0.003348,Time used 0.007979s\n",
      "batch 1562, train_loss 0.003678,Time used 0.009974s\n",
      "batch 1563, train_loss 0.003654,Time used 0.009974s\n",
      "batch 1564, train_loss 0.003174,Time used 0.008976s\n",
      "batch 1565, train_loss 0.004762,Time used 0.008976s\n",
      "batch 1566, train_loss 0.003951,Time used 0.007978s\n",
      "batch 1567, train_loss 0.003689,Time used 0.008487s\n",
      "batch 1568, train_loss 0.003522,Time used 0.007979s\n",
      "batch 1569, train_loss 0.003773,Time used 0.008976s\n",
      "batch 1570, train_loss 0.002569,Time used 0.008976s\n",
      "batch 1571, train_loss 0.004343,Time used 0.008976s\n",
      "batch 1572, train_loss 0.004131,Time used 0.008977s\n",
      "batch 1573, train_loss 0.002950,Time used 0.008975s\n",
      "batch 1574, train_loss 0.003380,Time used 0.008976s\n",
      "batch 1575, train_loss 0.003795,Time used 0.009974s\n",
      "batch 1576, train_loss 0.004120,Time used 0.009973s\n",
      "batch 1577, train_loss 0.004834,Time used 0.008977s\n",
      "batch 1578, train_loss 0.004604,Time used 0.008976s\n",
      "batch 1579, train_loss 0.003042,Time used 0.008976s\n",
      "batch 1580, train_loss 0.004007,Time used 0.008977s\n",
      "batch 1581, train_loss 0.003751,Time used 0.009973s\n",
      "batch 1582, train_loss 0.004597,Time used 0.008976s\n",
      "batch 1583, train_loss 0.003655,Time used 0.008976s\n",
      "batch 1584, train_loss 0.003865,Time used 0.008976s\n",
      "batch 1585, train_loss 0.004032,Time used 0.007978s\n",
      "batch 1586, train_loss 0.003874,Time used 0.007979s\n",
      "batch 1587, train_loss 0.004358,Time used 0.008976s\n",
      "batch 1588, train_loss 0.003967,Time used 0.008976s\n",
      "batch 1589, train_loss 0.003387,Time used 0.008976s\n",
      "batch 1590, train_loss 0.004957,Time used 0.011968s\n",
      "batch 1591, train_loss 0.002832,Time used 0.008976s\n",
      "batch 1592, train_loss 0.003624,Time used 0.008975s\n",
      "batch 1593, train_loss 0.003365,Time used 0.007978s\n",
      "batch 1594, train_loss 0.004856,Time used 0.007978s\n",
      "batch 1595, train_loss 0.003030,Time used 0.007979s\n",
      "batch 1596, train_loss 0.004142,Time used 0.007979s\n",
      "batch 1597, train_loss 0.004142,Time used 0.007979s\n",
      "batch 1598, train_loss 0.002699,Time used 0.007978s\n",
      "batch 1599, train_loss 0.003093,Time used 0.008976s\n",
      "batch 1600, train_loss 0.002959,Time used 0.008976s\n",
      "***************************test_batch 1600, test_rmse_loss 0.061562,test_mae_loss 0.043950,test_mape_loss 13.097950,Time used 0.119739s\n",
      "batch 1601, train_loss 0.003849,Time used 0.009973s\n",
      "batch 1602, train_loss 0.002873,Time used 0.008976s\n",
      "batch 1603, train_loss 0.003983,Time used 0.007979s\n",
      "batch 1604, train_loss 0.004139,Time used 0.008976s\n",
      "batch 1605, train_loss 0.001604,Time used 0.007979s\n",
      "batch 1606, train_loss 0.002193,Time used 0.008976s\n",
      "batch 1607, train_loss 0.006694,Time used 0.007979s\n",
      "batch 1608, train_loss 0.004518,Time used 0.007979s\n",
      "batch 1609, train_loss 0.003131,Time used 0.008977s\n",
      "batch 1610, train_loss 0.003021,Time used 0.008976s\n",
      "batch 1611, train_loss 0.003093,Time used 0.008976s\n",
      "batch 1612, train_loss 0.004208,Time used 0.008975s\n",
      "batch 1613, train_loss 0.003542,Time used 0.008976s\n",
      "batch 1614, train_loss 0.003876,Time used 0.007979s\n",
      "batch 1615, train_loss 0.003722,Time used 0.007979s\n",
      "batch 1616, train_loss 0.004379,Time used 0.007979s\n",
      "batch 1617, train_loss 0.003314,Time used 0.007978s\n",
      "batch 1618, train_loss 0.005036,Time used 0.007979s\n",
      "batch 1619, train_loss 0.004753,Time used 0.008976s\n",
      "batch 1620, train_loss 0.005049,Time used 0.007978s\n",
      "batch 1621, train_loss 0.003707,Time used 0.007980s\n",
      "batch 1622, train_loss 0.004098,Time used 0.008976s\n",
      "batch 1623, train_loss 0.002994,Time used 0.008976s\n",
      "batch 1624, train_loss 0.003185,Time used 0.010971s\n",
      "batch 1625, train_loss 0.003844,Time used 0.011969s\n",
      "batch 1626, train_loss 0.003856,Time used 0.008976s\n",
      "batch 1627, train_loss 0.003354,Time used 0.010971s\n",
      "batch 1628, train_loss 0.005073,Time used 0.009973s\n",
      "batch 1629, train_loss 0.002770,Time used 0.009974s\n",
      "batch 1630, train_loss 0.003621,Time used 0.008976s\n",
      "batch 1631, train_loss 0.004742,Time used 0.007979s\n",
      "batch 1632, train_loss 0.002788,Time used 0.008976s\n",
      "batch 1633, train_loss 0.003045,Time used 0.008976s\n",
      "batch 1634, train_loss 0.002787,Time used 0.008976s\n",
      "batch 1635, train_loss 0.003428,Time used 0.007979s\n",
      "batch 1636, train_loss 0.004738,Time used 0.008976s\n",
      "batch 1637, train_loss 0.002450,Time used 0.007978s\n",
      "batch 1638, train_loss 0.003975,Time used 0.008977s\n",
      "batch 1639, train_loss 0.003053,Time used 0.007979s\n",
      "batch 1640, train_loss 0.004444,Time used 0.007979s\n",
      "batch 1641, train_loss 0.003229,Time used 0.009973s\n",
      "batch 1642, train_loss 0.003397,Time used 0.008976s\n",
      "batch 1643, train_loss 0.005801,Time used 0.008975s\n",
      "batch 1644, train_loss 0.002811,Time used 0.008975s\n",
      "batch 1645, train_loss 0.003092,Time used 0.009974s\n",
      "batch 1646, train_loss 0.004834,Time used 0.009974s\n",
      "batch 1647, train_loss 0.003607,Time used 0.008977s\n",
      "batch 1648, train_loss 0.002380,Time used 0.008976s\n",
      "batch 1649, train_loss 0.003346,Time used 0.008976s\n",
      "batch 1650, train_loss 0.003284,Time used 0.008977s\n",
      "batch 1651, train_loss 0.003916,Time used 0.006981s\n",
      "batch 1652, train_loss 0.003764,Time used 0.007979s\n",
      "batch 1653, train_loss 0.002983,Time used 0.006981s\n",
      "batch 1654, train_loss 0.004618,Time used 0.007978s\n",
      "batch 1655, train_loss 0.004748,Time used 0.007979s\n",
      "batch 1656, train_loss 0.002335,Time used 0.006981s\n",
      "batch 1657, train_loss 0.004727,Time used 0.007979s\n",
      "batch 1658, train_loss 0.004490,Time used 0.007978s\n",
      "batch 1659, train_loss 0.004849,Time used 0.008977s\n",
      "batch 1660, train_loss 0.004716,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1661, train_loss 0.003521,Time used 0.008976s\n",
      "batch 1662, train_loss 0.003430,Time used 0.009974s\n",
      "batch 1663, train_loss 0.003512,Time used 0.009973s\n",
      "batch 1664, train_loss 0.003206,Time used 0.008976s\n",
      "batch 1665, train_loss 0.004086,Time used 0.007978s\n",
      "batch 1666, train_loss 0.002769,Time used 0.007980s\n",
      "batch 1667, train_loss 0.003761,Time used 0.007978s\n",
      "batch 1668, train_loss 0.004079,Time used 0.008975s\n",
      "batch 1669, train_loss 0.003315,Time used 0.007979s\n",
      "batch 1670, train_loss 0.004082,Time used 0.008976s\n",
      "batch 1671, train_loss 0.004922,Time used 0.008976s\n",
      "batch 1672, train_loss 0.003608,Time used 0.008976s\n",
      "batch 1673, train_loss 0.003710,Time used 0.008976s\n",
      "batch 1674, train_loss 0.003326,Time used 0.008977s\n",
      "batch 1675, train_loss 0.003636,Time used 0.009973s\n",
      "batch 1676, train_loss 0.003662,Time used 0.007979s\n",
      "batch 1677, train_loss 0.003859,Time used 0.009974s\n",
      "batch 1678, train_loss 0.004459,Time used 0.007979s\n",
      "batch 1679, train_loss 0.005675,Time used 0.007979s\n",
      "batch 1680, train_loss 0.002808,Time used 0.007980s\n",
      "batch 1681, train_loss 0.003369,Time used 0.009974s\n",
      "batch 1682, train_loss 0.003404,Time used 0.009973s\n",
      "batch 1683, train_loss 0.003789,Time used 0.007979s\n",
      "batch 1684, train_loss 0.003045,Time used 0.007979s\n",
      "batch 1685, train_loss 0.003668,Time used 0.009974s\n",
      "batch 1686, train_loss 0.003764,Time used 0.007979s\n",
      "batch 1687, train_loss 0.003844,Time used 0.007979s\n",
      "batch 1688, train_loss 0.003732,Time used 0.007979s\n",
      "batch 1689, train_loss 0.003423,Time used 0.007980s\n",
      "batch 1690, train_loss 0.002614,Time used 0.007978s\n",
      "batch 1691, train_loss 0.003278,Time used 0.007980s\n",
      "batch 1692, train_loss 0.004063,Time used 0.008975s\n",
      "batch 1693, train_loss 0.004669,Time used 0.007978s\n",
      "batch 1694, train_loss 0.003167,Time used 0.007978s\n",
      "batch 1695, train_loss 0.003124,Time used 0.008976s\n",
      "batch 1696, train_loss 0.002577,Time used 0.008975s\n",
      "batch 1697, train_loss 0.003554,Time used 0.007979s\n",
      "batch 1698, train_loss 0.003414,Time used 0.007977s\n",
      "batch 1699, train_loss 0.003749,Time used 0.008975s\n",
      "batch 1700, train_loss 0.003139,Time used 0.010971s\n",
      "***************************test_batch 1700, test_rmse_loss 0.061528,test_mae_loss 0.043914,test_mape_loss 12.996062,Time used 0.119681s\n",
      "batch 1701, train_loss 0.004224,Time used 0.009972s\n",
      "batch 1702, train_loss 0.004075,Time used 0.008976s\n",
      "batch 1703, train_loss 0.004465,Time used 0.008976s\n",
      "batch 1704, train_loss 0.003518,Time used 0.008976s\n",
      "batch 1705, train_loss 0.003777,Time used 0.009974s\n",
      "batch 1706, train_loss 0.005426,Time used 0.008976s\n",
      "batch 1707, train_loss 0.002262,Time used 0.008976s\n",
      "batch 1708, train_loss 0.002629,Time used 0.008976s\n",
      "batch 1709, train_loss 0.004818,Time used 0.008976s\n",
      "batch 1710, train_loss 0.003948,Time used 0.009974s\n",
      "batch 1711, train_loss 0.003052,Time used 0.008977s\n",
      "batch 1712, train_loss 0.002377,Time used 0.007978s\n",
      "batch 1713, train_loss 0.002661,Time used 0.008976s\n",
      "batch 1714, train_loss 0.003583,Time used 0.008976s\n",
      "batch 1715, train_loss 0.003769,Time used 0.008977s\n",
      "batch 1716, train_loss 0.004230,Time used 0.008977s\n",
      "batch 1717, train_loss 0.004372,Time used 0.008976s\n",
      "batch 1718, train_loss 0.003822,Time used 0.008976s\n",
      "batch 1719, train_loss 0.003394,Time used 0.008976s\n",
      "batch 1720, train_loss 0.003389,Time used 0.008976s\n",
      "batch 1721, train_loss 0.003775,Time used 0.008977s\n",
      "batch 1722, train_loss 0.002948,Time used 0.008975s\n",
      "batch 1723, train_loss 0.003564,Time used 0.007979s\n",
      "batch 1724, train_loss 0.004005,Time used 0.008976s\n",
      "batch 1725, train_loss 0.004132,Time used 0.008976s\n",
      "batch 1726, train_loss 0.003680,Time used 0.007979s\n",
      "batch 1727, train_loss 0.003533,Time used 0.007979s\n",
      "batch 1728, train_loss 0.002506,Time used 0.009973s\n",
      "batch 1729, train_loss 0.003664,Time used 0.008976s\n",
      "batch 1730, train_loss 0.003205,Time used 0.007978s\n",
      "batch 1731, train_loss 0.003470,Time used 0.007979s\n",
      "batch 1732, train_loss 0.003963,Time used 0.007979s\n",
      "batch 1733, train_loss 0.002472,Time used 0.007978s\n",
      "batch 1734, train_loss 0.004526,Time used 0.007979s\n",
      "batch 1735, train_loss 0.005364,Time used 0.007979s\n",
      "batch 1736, train_loss 0.002455,Time used 0.007979s\n",
      "batch 1737, train_loss 0.003507,Time used 0.007979s\n",
      "batch 1738, train_loss 0.003513,Time used 0.008976s\n",
      "batch 1739, train_loss 0.003092,Time used 0.007978s\n",
      "batch 1740, train_loss 0.003911,Time used 0.007978s\n",
      "batch 1741, train_loss 0.003616,Time used 0.007979s\n",
      "batch 1742, train_loss 0.003011,Time used 0.008976s\n",
      "batch 1743, train_loss 0.003029,Time used 0.008975s\n",
      "batch 1744, train_loss 0.003089,Time used 0.007979s\n",
      "batch 1745, train_loss 0.003440,Time used 0.007978s\n",
      "batch 1746, train_loss 0.004532,Time used 0.008976s\n",
      "batch 1747, train_loss 0.003200,Time used 0.008976s\n",
      "batch 1748, train_loss 0.003104,Time used 0.008976s\n",
      "batch 1749, train_loss 0.004438,Time used 0.008976s\n",
      "batch 1750, train_loss 0.003625,Time used 0.008976s\n",
      "batch 1751, train_loss 0.003318,Time used 0.008976s\n",
      "batch 1752, train_loss 0.003623,Time used 0.008977s\n",
      "batch 1753, train_loss 0.002524,Time used 0.008976s\n",
      "batch 1754, train_loss 0.003117,Time used 0.008976s\n",
      "batch 1755, train_loss 0.005694,Time used 0.008977s\n",
      "batch 1756, train_loss 0.002946,Time used 0.008975s\n",
      "batch 1757, train_loss 0.003665,Time used 0.008977s\n",
      "batch 1758, train_loss 0.003880,Time used 0.007977s\n",
      "batch 1759, train_loss 0.004624,Time used 0.008976s\n",
      "batch 1760, train_loss 0.002798,Time used 0.008976s\n",
      "batch 1761, train_loss 0.002663,Time used 0.007979s\n",
      "batch 1762, train_loss 0.003823,Time used 0.007979s\n",
      "batch 1763, train_loss 0.002797,Time used 0.007978s\n",
      "batch 1764, train_loss 0.004135,Time used 0.007978s\n",
      "batch 1765, train_loss 0.003464,Time used 0.007979s\n",
      "batch 1766, train_loss 0.003856,Time used 0.008976s\n",
      "batch 1767, train_loss 0.004294,Time used 0.007979s\n",
      "batch 1768, train_loss 0.003672,Time used 0.009973s\n",
      "batch 1769, train_loss 0.004506,Time used 0.007978s\n",
      "batch 1770, train_loss 0.008584,Time used 0.008976s\n",
      "batch 1771, train_loss 0.003949,Time used 0.007978s\n",
      "batch 1772, train_loss 0.003926,Time used 0.008976s\n",
      "batch 1773, train_loss 0.003428,Time used 0.009974s\n",
      "batch 1774, train_loss 0.003942,Time used 0.008976s\n",
      "batch 1775, train_loss 0.003427,Time used 0.007979s\n",
      "batch 1776, train_loss 0.003299,Time used 0.008976s\n",
      "batch 1777, train_loss 0.003924,Time used 0.008976s\n",
      "batch 1778, train_loss 0.004673,Time used 0.007979s\n",
      "batch 1779, train_loss 0.004223,Time used 0.008976s\n",
      "batch 1780, train_loss 0.003767,Time used 0.007979s\n",
      "batch 1781, train_loss 0.004320,Time used 0.010971s\n",
      "batch 1782, train_loss 0.003585,Time used 0.008976s\n",
      "batch 1783, train_loss 0.005356,Time used 0.008976s\n",
      "batch 1784, train_loss 0.004310,Time used 0.008976s\n",
      "batch 1785, train_loss 0.003237,Time used 0.008976s\n",
      "batch 1786, train_loss 0.002864,Time used 0.007978s\n",
      "batch 1787, train_loss 0.004340,Time used 0.007979s\n",
      "batch 1788, train_loss 0.003515,Time used 0.007978s\n",
      "batch 1789, train_loss 0.003482,Time used 0.007979s\n",
      "batch 1790, train_loss 0.003692,Time used 0.008976s\n",
      "batch 1791, train_loss 0.003818,Time used 0.008977s\n",
      "batch 1792, train_loss 0.003771,Time used 0.008975s\n",
      "batch 1793, train_loss 0.004349,Time used 0.008977s\n",
      "batch 1794, train_loss 0.004165,Time used 0.008975s\n",
      "batch 1795, train_loss 0.003074,Time used 0.008976s\n",
      "batch 1796, train_loss 0.004155,Time used 0.007978s\n",
      "batch 1797, train_loss 0.004186,Time used 0.008976s\n",
      "batch 1798, train_loss 0.005451,Time used 0.007978s\n",
      "batch 1799, train_loss 0.002688,Time used 0.008976s\n",
      "batch 1800, train_loss 0.002883,Time used 0.008977s\n",
      "***************************test_batch 1800, test_rmse_loss 0.061406,test_mae_loss 0.043846,test_mape_loss 13.358411,Time used 0.100730s\n",
      "batch 1801, train_loss 0.003707,Time used 0.008975s\n",
      "batch 1802, train_loss 0.003961,Time used 0.008976s\n",
      "batch 1803, train_loss 0.003043,Time used 0.008977s\n",
      "batch 1804, train_loss 0.004995,Time used 0.007978s\n",
      "batch 1805, train_loss 0.003262,Time used 0.007978s\n",
      "batch 1806, train_loss 0.003619,Time used 0.007978s\n",
      "batch 1807, train_loss 0.004022,Time used 0.006982s\n",
      "batch 1808, train_loss 0.003379,Time used 0.007979s\n",
      "batch 1809, train_loss 0.004397,Time used 0.007978s\n",
      "batch 1810, train_loss 0.004107,Time used 0.007978s\n",
      "batch 1811, train_loss 0.003048,Time used 0.007978s\n",
      "batch 1812, train_loss 0.004110,Time used 0.006982s\n",
      "batch 1813, train_loss 0.003713,Time used 0.007979s\n",
      "batch 1814, train_loss 0.003038,Time used 0.006981s\n",
      "batch 1815, train_loss 0.003538,Time used 0.007978s\n",
      "batch 1816, train_loss 0.002507,Time used 0.008977s\n",
      "batch 1817, train_loss 0.004475,Time used 0.008975s\n",
      "batch 1818, train_loss 0.002813,Time used 0.007979s\n",
      "batch 1819, train_loss 0.004403,Time used 0.006982s\n",
      "batch 1820, train_loss 0.003212,Time used 0.007979s\n",
      "batch 1821, train_loss 0.004471,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1822, train_loss 0.003374,Time used 0.007979s\n",
      "batch 1823, train_loss 0.003498,Time used 0.007979s\n",
      "batch 1824, train_loss 0.005000,Time used 0.007979s\n",
      "batch 1825, train_loss 0.003160,Time used 0.007978s\n",
      "batch 1826, train_loss 0.003877,Time used 0.008977s\n",
      "batch 1827, train_loss 0.003399,Time used 0.008976s\n",
      "batch 1828, train_loss 0.004316,Time used 0.007978s\n",
      "batch 1829, train_loss 0.003124,Time used 0.007980s\n",
      "batch 1830, train_loss 0.003642,Time used 0.008975s\n",
      "batch 1831, train_loss 0.004561,Time used 0.008976s\n",
      "batch 1832, train_loss 0.005455,Time used 0.008976s\n",
      "batch 1833, train_loss 0.002987,Time used 0.008976s\n",
      "batch 1834, train_loss 0.004578,Time used 0.007979s\n",
      "batch 1835, train_loss 0.003129,Time used 0.008975s\n",
      "batch 1836, train_loss 0.002973,Time used 0.008976s\n",
      "batch 1837, train_loss 0.004440,Time used 0.008976s\n",
      "batch 1838, train_loss 0.004665,Time used 0.008976s\n",
      "batch 1839, train_loss 0.004356,Time used 0.008023s\n",
      "batch 1840, train_loss 0.003365,Time used 0.007979s\n",
      "batch 1841, train_loss 0.002957,Time used 0.007978s\n",
      "batch 1842, train_loss 0.003984,Time used 0.007978s\n",
      "batch 1843, train_loss 0.002746,Time used 0.007979s\n",
      "batch 1844, train_loss 0.002868,Time used 0.008976s\n",
      "batch 1845, train_loss 0.004223,Time used 0.008976s\n",
      "batch 1846, train_loss 0.003501,Time used 0.008977s\n",
      "batch 1847, train_loss 0.002958,Time used 0.007979s\n",
      "batch 1848, train_loss 0.004283,Time used 0.008977s\n",
      "batch 1849, train_loss 0.003341,Time used 0.008993s\n",
      "batch 1850, train_loss 0.002815,Time used 0.008959s\n",
      "batch 1851, train_loss 0.002392,Time used 0.008976s\n",
      "batch 1852, train_loss 0.003624,Time used 0.008976s\n",
      "batch 1853, train_loss 0.004128,Time used 0.008976s\n",
      "batch 1854, train_loss 0.003273,Time used 0.008976s\n",
      "batch 1855, train_loss 0.003597,Time used 0.008976s\n",
      "batch 1856, train_loss 0.004301,Time used 0.007979s\n",
      "batch 1857, train_loss 0.004211,Time used 0.007979s\n",
      "batch 1858, train_loss 0.003894,Time used 0.007979s\n",
      "batch 1859, train_loss 0.004779,Time used 0.007978s\n",
      "batch 1860, train_loss 0.003858,Time used 0.007979s\n",
      "batch 1861, train_loss 0.003442,Time used 0.007979s\n",
      "batch 1862, train_loss 0.003409,Time used 0.007979s\n",
      "batch 1863, train_loss 0.002848,Time used 0.007979s\n",
      "batch 1864, train_loss 0.002984,Time used 0.008977s\n",
      "batch 1865, train_loss 0.004189,Time used 0.008975s\n",
      "batch 1866, train_loss 0.003208,Time used 0.008976s\n",
      "batch 1867, train_loss 0.003896,Time used 0.008975s\n",
      "batch 1868, train_loss 0.004003,Time used 0.007979s\n",
      "batch 1869, train_loss 0.002820,Time used 0.007979s\n",
      "batch 1870, train_loss 0.003539,Time used 0.007979s\n",
      "batch 1871, train_loss 0.002811,Time used 0.007978s\n",
      "batch 1872, train_loss 0.003760,Time used 0.007979s\n",
      "batch 1873, train_loss 0.003790,Time used 0.007979s\n",
      "batch 1874, train_loss 0.003434,Time used 0.007979s\n",
      "batch 1875, train_loss 0.005121,Time used 0.007979s\n",
      "batch 1876, train_loss 0.002894,Time used 0.007979s\n",
      "batch 1877, train_loss 0.003277,Time used 0.007978s\n",
      "batch 1878, train_loss 0.003392,Time used 0.007979s\n",
      "batch 1879, train_loss 0.003841,Time used 0.007978s\n",
      "batch 1880, train_loss 0.004903,Time used 0.007978s\n",
      "batch 1881, train_loss 0.003951,Time used 0.008976s\n",
      "batch 1882, train_loss 0.002971,Time used 0.007978s\n",
      "batch 1883, train_loss 0.004066,Time used 0.008976s\n",
      "batch 1884, train_loss 0.003738,Time used 0.007979s\n",
      "batch 1885, train_loss 0.005329,Time used 0.007978s\n",
      "batch 1886, train_loss 0.006210,Time used 0.008976s\n",
      "batch 1887, train_loss 0.003514,Time used 0.008976s\n",
      "batch 1888, train_loss 0.003182,Time used 0.007979s\n",
      "batch 1889, train_loss 0.003750,Time used 0.008977s\n",
      "batch 1890, train_loss 0.002718,Time used 0.008975s\n",
      "batch 1891, train_loss 0.002153,Time used 0.008977s\n",
      "batch 1892, train_loss 0.004378,Time used 0.008975s\n",
      "batch 1893, train_loss 0.004751,Time used 0.008977s\n",
      "batch 1894, train_loss 0.003947,Time used 0.008975s\n",
      "batch 1895, train_loss 0.003496,Time used 0.007979s\n",
      "batch 1896, train_loss 0.003302,Time used 0.007977s\n",
      "batch 1897, train_loss 0.003608,Time used 0.007979s\n",
      "batch 1898, train_loss 0.002750,Time used 0.007979s\n",
      "batch 1899, train_loss 0.003659,Time used 0.007978s\n",
      "batch 1900, train_loss 0.004163,Time used 0.007979s\n",
      "***************************test_batch 1900, test_rmse_loss 0.061657,test_mae_loss 0.044024,test_mape_loss 12.880017,Time used 0.111702s\n",
      "batch 1901, train_loss 0.004041,Time used 0.008976s\n",
      "batch 1902, train_loss 0.003849,Time used 0.008976s\n",
      "batch 1903, train_loss 0.004022,Time used 0.007979s\n",
      "batch 1904, train_loss 0.003360,Time used 0.008976s\n",
      "batch 1905, train_loss 0.004550,Time used 0.008976s\n",
      "batch 1906, train_loss 0.003132,Time used 0.008977s\n",
      "batch 1907, train_loss 0.004674,Time used 0.007978s\n",
      "batch 1908, train_loss 0.003603,Time used 0.008976s\n",
      "batch 1909, train_loss 0.003360,Time used 0.008977s\n",
      "batch 1910, train_loss 0.002882,Time used 0.008976s\n",
      "batch 1911, train_loss 0.004511,Time used 0.009973s\n",
      "batch 1912, train_loss 0.003283,Time used 0.008976s\n",
      "batch 1913, train_loss 0.005728,Time used 0.008977s\n",
      "batch 1914, train_loss 0.002728,Time used 0.007978s\n",
      "batch 1915, train_loss 0.002518,Time used 0.007979s\n",
      "batch 1916, train_loss 0.004224,Time used 0.007979s\n",
      "batch 1917, train_loss 0.004533,Time used 0.008976s\n",
      "batch 1918, train_loss 0.003310,Time used 0.007979s\n",
      "batch 1919, train_loss 0.002869,Time used 0.008976s\n",
      "batch 1920, train_loss 0.004050,Time used 0.007978s\n",
      "batch 1921, train_loss 0.003352,Time used 0.007979s\n",
      "batch 1922, train_loss 0.004180,Time used 0.008975s\n",
      "batch 1923, train_loss 0.002944,Time used 0.007978s\n",
      "batch 1924, train_loss 0.004372,Time used 0.007978s\n",
      "batch 1925, train_loss 0.003101,Time used 0.006981s\n",
      "batch 1926, train_loss 0.001881,Time used 0.007978s\n",
      "batch 1927, train_loss 0.004775,Time used 0.008976s\n",
      "batch 1928, train_loss 0.002749,Time used 0.009974s\n",
      "batch 1929, train_loss 0.003585,Time used 0.009974s\n",
      "batch 1930, train_loss 0.003357,Time used 0.008976s\n",
      "batch 1931, train_loss 0.004268,Time used 0.008976s\n",
      "batch 1932, train_loss 0.004146,Time used 0.007978s\n",
      "batch 1933, train_loss 0.003201,Time used 0.008976s\n",
      "batch 1934, train_loss 0.003156,Time used 0.008976s\n",
      "batch 1935, train_loss 0.002950,Time used 0.007979s\n",
      "batch 1936, train_loss 0.003483,Time used 0.008976s\n",
      "batch 1937, train_loss 0.003372,Time used 0.007979s\n",
      "batch 1938, train_loss 0.004705,Time used 0.007978s\n",
      "batch 1939, train_loss 0.003656,Time used 0.007979s\n",
      "batch 1940, train_loss 0.002587,Time used 0.007979s\n",
      "batch 1941, train_loss 0.003597,Time used 0.007979s\n",
      "batch 1942, train_loss 0.003925,Time used 0.009974s\n",
      "batch 1943, train_loss 0.003884,Time used 0.009974s\n",
      "batch 1944, train_loss 0.003652,Time used 0.008976s\n",
      "batch 1945, train_loss 0.003965,Time used 0.009973s\n",
      "batch 1946, train_loss 0.004612,Time used 0.008975s\n",
      "batch 1947, train_loss 0.004038,Time used 0.009973s\n",
      "batch 1948, train_loss 0.004558,Time used 0.009974s\n",
      "batch 1949, train_loss 0.003066,Time used 0.008976s\n",
      "batch 1950, train_loss 0.004032,Time used 0.008978s\n",
      "batch 1951, train_loss 0.003154,Time used 0.008974s\n",
      "batch 1952, train_loss 0.004192,Time used 0.007979s\n",
      "batch 1953, train_loss 0.005460,Time used 0.008976s\n",
      "batch 1954, train_loss 0.002764,Time used 0.008976s\n",
      "batch 1955, train_loss 0.005795,Time used 0.007978s\n",
      "batch 1956, train_loss 0.004802,Time used 0.007979s\n",
      "batch 1957, train_loss 0.003540,Time used 0.007979s\n",
      "batch 1958, train_loss 0.004239,Time used 0.007980s\n",
      "batch 1959, train_loss 0.003205,Time used 0.007979s\n",
      "batch 1960, train_loss 0.004467,Time used 0.007979s\n",
      "batch 1961, train_loss 0.003643,Time used 0.008976s\n",
      "batch 1962, train_loss 0.003252,Time used 0.008976s\n",
      "batch 1963, train_loss 0.003243,Time used 0.008977s\n",
      "batch 1964, train_loss 0.002815,Time used 0.008976s\n",
      "batch 1965, train_loss 0.004199,Time used 0.009972s\n",
      "batch 1966, train_loss 0.003103,Time used 0.009974s\n",
      "batch 1967, train_loss 0.003678,Time used 0.008975s\n",
      "batch 1968, train_loss 0.003032,Time used 0.009974s\n",
      "batch 1969, train_loss 0.003267,Time used 0.008977s\n",
      "batch 1970, train_loss 0.003043,Time used 0.008976s\n",
      "batch 1971, train_loss 0.004108,Time used 0.007978s\n",
      "batch 1972, train_loss 0.002800,Time used 0.008976s\n",
      "batch 1973, train_loss 0.002748,Time used 0.008976s\n",
      "batch 1974, train_loss 0.004620,Time used 0.008976s\n",
      "batch 1975, train_loss 0.002868,Time used 0.007979s\n",
      "batch 1976, train_loss 0.003455,Time used 0.007980s\n",
      "batch 1977, train_loss 0.004198,Time used 0.007978s\n",
      "batch 1978, train_loss 0.003989,Time used 0.007979s\n",
      "batch 1979, train_loss 0.004644,Time used 0.010970s\n",
      "batch 1980, train_loss 0.003468,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1981, train_loss 0.003054,Time used 0.008976s\n",
      "batch 1982, train_loss 0.003009,Time used 0.008976s\n",
      "batch 1983, train_loss 0.004605,Time used 0.008976s\n",
      "batch 1984, train_loss 0.005274,Time used 0.008976s\n",
      "batch 1985, train_loss 0.003684,Time used 0.008976s\n",
      "batch 1986, train_loss 0.004427,Time used 0.008976s\n",
      "batch 1987, train_loss 0.004478,Time used 0.008976s\n",
      "batch 1988, train_loss 0.003313,Time used 0.007979s\n",
      "batch 1989, train_loss 0.003560,Time used 0.007979s\n",
      "batch 1990, train_loss 0.003385,Time used 0.007978s\n",
      "batch 1991, train_loss 0.003213,Time used 0.008976s\n",
      "batch 1992, train_loss 0.003776,Time used 0.007979s\n",
      "batch 1993, train_loss 0.003350,Time used 0.007978s\n",
      "batch 1994, train_loss 0.002993,Time used 0.008975s\n",
      "batch 1995, train_loss 0.003705,Time used 0.007979s\n",
      "batch 1996, train_loss 0.004711,Time used 0.007978s\n",
      "batch 1997, train_loss 0.004350,Time used 0.007978s\n",
      "batch 1998, train_loss 0.002829,Time used 0.007977s\n",
      "batch 1999, train_loss 0.003370,Time used 0.007979s\n",
      "batch 2000, train_loss 0.003423,Time used 0.007979s\n",
      "***************************test_batch 2000, test_rmse_loss 0.061125,test_mae_loss 0.043585,test_mape_loss 13.009710,Time used 0.114694s\n",
      "batch 2001, train_loss 0.004048,Time used 0.007978s\n",
      "batch 2002, train_loss 0.002924,Time used 0.007979s\n",
      "batch 2003, train_loss 0.003644,Time used 0.007978s\n",
      "batch 2004, train_loss 0.004107,Time used 0.007979s\n",
      "batch 2005, train_loss 0.003514,Time used 0.007978s\n",
      "batch 2006, train_loss 0.004051,Time used 0.007979s\n",
      "batch 2007, train_loss 0.004742,Time used 0.006980s\n",
      "batch 2008, train_loss 0.004249,Time used 0.007979s\n",
      "batch 2009, train_loss 0.004428,Time used 0.007979s\n",
      "batch 2010, train_loss 0.003649,Time used 0.007979s\n",
      "batch 2011, train_loss 0.003465,Time used 0.007978s\n",
      "batch 2012, train_loss 0.003557,Time used 0.007979s\n",
      "batch 2013, train_loss 0.003342,Time used 0.007979s\n",
      "batch 2014, train_loss 0.003740,Time used 0.007979s\n",
      "batch 2015, train_loss 0.002497,Time used 0.007979s\n",
      "batch 2016, train_loss 0.003220,Time used 0.007978s\n",
      "batch 2017, train_loss 0.005056,Time used 0.007979s\n",
      "batch 2018, train_loss 0.002742,Time used 0.007978s\n",
      "batch 2019, train_loss 0.003160,Time used 0.007978s\n",
      "batch 2020, train_loss 0.003239,Time used 0.007979s\n",
      "batch 2021, train_loss 0.003139,Time used 0.007979s\n",
      "batch 2022, train_loss 0.004635,Time used 0.008975s\n",
      "batch 2023, train_loss 0.004054,Time used 0.007979s\n",
      "batch 2024, train_loss 0.003428,Time used 0.006982s\n",
      "batch 2025, train_loss 0.004600,Time used 0.007979s\n",
      "batch 2026, train_loss 0.002880,Time used 0.006980s\n",
      "batch 2027, train_loss 0.002696,Time used 0.007979s\n",
      "batch 2028, train_loss 0.003956,Time used 0.007978s\n",
      "batch 2029, train_loss 0.002754,Time used 0.007978s\n",
      "batch 2030, train_loss 0.003507,Time used 0.008976s\n",
      "batch 2031, train_loss 0.003368,Time used 0.008976s\n",
      "batch 2032, train_loss 0.002973,Time used 0.007978s\n",
      "batch 2033, train_loss 0.010588,Time used 0.006982s\n",
      "batch 2034, train_loss 0.003959,Time used 0.007979s\n",
      "batch 2035, train_loss 0.002833,Time used 0.007979s\n",
      "batch 2036, train_loss 0.005441,Time used 0.008976s\n",
      "batch 2037, train_loss 0.002789,Time used 0.008976s\n",
      "batch 2038, train_loss 0.004454,Time used 0.008976s\n",
      "batch 2039, train_loss 0.002260,Time used 0.008976s\n",
      "batch 2040, train_loss 0.002945,Time used 0.008976s\n",
      "batch 2041, train_loss 0.003632,Time used 0.008976s\n",
      "batch 2042, train_loss 0.003156,Time used 0.008976s\n",
      "batch 2043, train_loss 0.003309,Time used 0.008976s\n",
      "batch 2044, train_loss 0.004742,Time used 0.008976s\n",
      "batch 2045, train_loss 0.003044,Time used 0.009973s\n",
      "batch 2046, train_loss 0.003301,Time used 0.009973s\n",
      "batch 2047, train_loss 0.003169,Time used 0.009974s\n",
      "batch 2048, train_loss 0.003150,Time used 0.009973s\n",
      "batch 2049, train_loss 0.003151,Time used 0.009973s\n",
      "batch 2050, train_loss 0.002999,Time used 0.011969s\n",
      "batch 2051, train_loss 0.003746,Time used 0.008976s\n",
      "batch 2052, train_loss 0.003197,Time used 0.008976s\n",
      "batch 2053, train_loss 0.002985,Time used 0.008976s\n",
      "batch 2054, train_loss 0.003564,Time used 0.008976s\n",
      "batch 2055, train_loss 0.003153,Time used 0.008976s\n",
      "batch 2056, train_loss 0.003383,Time used 0.008976s\n",
      "batch 2057, train_loss 0.005616,Time used 0.007979s\n",
      "batch 2058, train_loss 0.003549,Time used 0.007980s\n",
      "batch 2059, train_loss 0.003366,Time used 0.007978s\n",
      "batch 2060, train_loss 0.003440,Time used 0.007979s\n",
      "batch 2061, train_loss 0.003972,Time used 0.008976s\n",
      "batch 2062, train_loss 0.003548,Time used 0.008976s\n",
      "batch 2063, train_loss 0.002667,Time used 0.012846s\n",
      "batch 2064, train_loss 0.003345,Time used 0.008993s\n",
      "batch 2065, train_loss 0.004104,Time used 0.009974s\n",
      "batch 2066, train_loss 0.004711,Time used 0.007980s\n",
      "batch 2067, train_loss 0.002934,Time used 0.007978s\n",
      "batch 2068, train_loss 0.003068,Time used 0.007978s\n",
      "batch 2069, train_loss 0.003271,Time used 0.008976s\n",
      "batch 2070, train_loss 0.003390,Time used 0.007979s\n",
      "batch 2071, train_loss 0.004341,Time used 0.008976s\n",
      "batch 2072, train_loss 0.004575,Time used 0.008976s\n",
      "batch 2073, train_loss 0.003541,Time used 0.007978s\n",
      "batch 2074, train_loss 0.003916,Time used 0.007979s\n",
      "batch 2075, train_loss 0.004212,Time used 0.008975s\n",
      "batch 2076, train_loss 0.004456,Time used 0.007979s\n",
      "batch 2077, train_loss 0.002957,Time used 0.007978s\n",
      "batch 2078, train_loss 0.002623,Time used 0.007979s\n",
      "batch 2079, train_loss 0.004009,Time used 0.009973s\n",
      "batch 2080, train_loss 0.003465,Time used 0.008977s\n",
      "batch 2081, train_loss 0.003869,Time used 0.007977s\n",
      "batch 2082, train_loss 0.002871,Time used 0.007978s\n",
      "batch 2083, train_loss 0.003645,Time used 0.007979s\n",
      "batch 2084, train_loss 0.003553,Time used 0.007979s\n",
      "batch 2085, train_loss 0.003717,Time used 0.007979s\n",
      "batch 2086, train_loss 0.004471,Time used 0.008976s\n",
      "batch 2087, train_loss 0.002974,Time used 0.007979s\n",
      "batch 2088, train_loss 0.003212,Time used 0.007979s\n",
      "batch 2089, train_loss 0.004120,Time used 0.007979s\n",
      "batch 2090, train_loss 0.002572,Time used 0.007978s\n",
      "batch 2091, train_loss 0.002449,Time used 0.007979s\n",
      "batch 2092, train_loss 0.003705,Time used 0.008976s\n",
      "batch 2093, train_loss 0.003391,Time used 0.009485s\n",
      "batch 2094, train_loss 0.002961,Time used 0.008976s\n",
      "batch 2095, train_loss 0.003954,Time used 0.008976s\n",
      "batch 2096, train_loss 0.003744,Time used 0.007978s\n",
      "batch 2097, train_loss 0.004371,Time used 0.007978s\n",
      "batch 2098, train_loss 0.003029,Time used 0.007979s\n",
      "batch 2099, train_loss 0.003477,Time used 0.008976s\n",
      "batch 2100, train_loss 0.004307,Time used 0.008976s\n",
      "***************************test_batch 2100, test_rmse_loss 0.061316,test_mae_loss 0.043767,test_mape_loss 13.307485,Time used 0.105717s\n",
      "batch 2101, train_loss 0.003797,Time used 0.007978s\n",
      "batch 2102, train_loss 0.002829,Time used 0.007979s\n",
      "batch 2103, train_loss 0.004876,Time used 0.007980s\n",
      "batch 2104, train_loss 0.003550,Time used 0.007978s\n",
      "batch 2105, train_loss 0.003519,Time used 0.007979s\n",
      "batch 2106, train_loss 0.003487,Time used 0.008976s\n",
      "batch 2107, train_loss 0.003779,Time used 0.007978s\n",
      "batch 2108, train_loss 0.003405,Time used 0.007979s\n",
      "batch 2109, train_loss 0.004447,Time used 0.007978s\n",
      "batch 2110, train_loss 0.002472,Time used 0.007979s\n",
      "batch 2111, train_loss 0.003706,Time used 0.007979s\n",
      "batch 2112, train_loss 0.003661,Time used 0.008976s\n",
      "batch 2113, train_loss 0.003442,Time used 0.007978s\n",
      "batch 2114, train_loss 0.004918,Time used 0.008977s\n",
      "batch 2115, train_loss 0.004261,Time used 0.007979s\n",
      "batch 2116, train_loss 0.003470,Time used 0.007979s\n",
      "batch 2117, train_loss 0.004033,Time used 0.008976s\n",
      "batch 2118, train_loss 0.004520,Time used 0.007979s\n",
      "batch 2119, train_loss 0.003637,Time used 0.007979s\n",
      "batch 2120, train_loss 0.002941,Time used 0.007978s\n",
      "batch 2121, train_loss 0.003748,Time used 0.007979s\n",
      "batch 2122, train_loss 0.003083,Time used 0.008975s\n",
      "batch 2123, train_loss 0.003655,Time used 0.008976s\n",
      "batch 2124, train_loss 0.002212,Time used 0.007978s\n",
      "batch 2125, train_loss 0.003379,Time used 0.008976s\n",
      "batch 2126, train_loss 0.003129,Time used 0.008976s\n",
      "batch 2127, train_loss 0.005883,Time used 0.008976s\n",
      "batch 2128, train_loss 0.002548,Time used 0.007979s\n",
      "batch 2129, train_loss 0.003996,Time used 0.008976s\n",
      "batch 2130, train_loss 0.005684,Time used 0.007979s\n",
      "batch 2131, train_loss 0.003771,Time used 0.007979s\n",
      "batch 2132, train_loss 0.005773,Time used 0.007978s\n",
      "batch 2133, train_loss 0.005831,Time used 0.007979s\n",
      "batch 2134, train_loss 0.004766,Time used 0.008975s\n",
      "batch 2135, train_loss 0.003550,Time used 0.008977s\n",
      "batch 2136, train_loss 0.004509,Time used 0.008975s\n",
      "batch 2137, train_loss 0.004634,Time used 0.007978s\n",
      "batch 2138, train_loss 0.003185,Time used 0.008976s\n",
      "batch 2139, train_loss 0.005167,Time used 0.007980s\n",
      "batch 2140, train_loss 0.005730,Time used 0.006981s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2141, train_loss 0.003011,Time used 0.007979s\n",
      "batch 2142, train_loss 0.002923,Time used 0.008976s\n",
      "batch 2143, train_loss 0.003181,Time used 0.008976s\n",
      "batch 2144, train_loss 0.003112,Time used 0.007979s\n",
      "batch 2145, train_loss 0.003959,Time used 0.007979s\n",
      "batch 2146, train_loss 0.003299,Time used 0.008976s\n",
      "batch 2147, train_loss 0.003097,Time used 0.007978s\n",
      "batch 2148, train_loss 0.004435,Time used 0.007979s\n",
      "batch 2149, train_loss 0.003716,Time used 0.008975s\n",
      "batch 2150, train_loss 0.003329,Time used 0.007979s\n",
      "batch 2151, train_loss 0.003948,Time used 0.007979s\n",
      "batch 2152, train_loss 0.004063,Time used 0.008975s\n",
      "batch 2153, train_loss 0.003643,Time used 0.007978s\n",
      "batch 2154, train_loss 0.003233,Time used 0.007978s\n",
      "batch 2155, train_loss 0.003935,Time used 0.007979s\n",
      "batch 2156, train_loss 0.002904,Time used 0.007979s\n",
      "batch 2157, train_loss 0.003582,Time used 0.008975s\n",
      "batch 2158, train_loss 0.003217,Time used 0.007979s\n",
      "batch 2159, train_loss 0.004492,Time used 0.008977s\n",
      "batch 2160, train_loss 0.002847,Time used 0.007978s\n",
      "batch 2161, train_loss 0.004539,Time used 0.007979s\n",
      "batch 2162, train_loss 0.003280,Time used 0.007979s\n",
      "batch 2163, train_loss 0.003079,Time used 0.009973s\n",
      "batch 2164, train_loss 0.003995,Time used 0.008975s\n",
      "batch 2165, train_loss 0.003548,Time used 0.007978s\n",
      "batch 2166, train_loss 0.003210,Time used 0.007979s\n",
      "batch 2167, train_loss 0.003173,Time used 0.008977s\n",
      "batch 2168, train_loss 0.003293,Time used 0.007978s\n",
      "batch 2169, train_loss 0.004233,Time used 0.007978s\n",
      "batch 2170, train_loss 0.003906,Time used 0.007978s\n",
      "batch 2171, train_loss 0.003455,Time used 0.008976s\n",
      "batch 2172, train_loss 0.002410,Time used 0.007978s\n",
      "batch 2173, train_loss 0.003502,Time used 0.020945s\n",
      "batch 2174, train_loss 0.006458,Time used 0.010970s\n",
      "batch 2175, train_loss 0.003716,Time used 0.011968s\n",
      "batch 2176, train_loss 0.002621,Time used 0.010971s\n",
      "batch 2177, train_loss 0.004732,Time used 0.009973s\n",
      "batch 2178, train_loss 0.004420,Time used 0.015958s\n",
      "batch 2179, train_loss 0.003424,Time used 0.010971s\n",
      "batch 2180, train_loss 0.002868,Time used 0.008976s\n",
      "batch 2181, train_loss 0.004680,Time used 0.009973s\n",
      "batch 2182, train_loss 0.005511,Time used 0.009973s\n",
      "batch 2183, train_loss 0.002930,Time used 0.009973s\n",
      "batch 2184, train_loss 0.003682,Time used 0.009974s\n",
      "batch 2185, train_loss 0.003036,Time used 0.008976s\n",
      "batch 2186, train_loss 0.004382,Time used 0.008976s\n",
      "batch 2187, train_loss 0.003917,Time used 0.009973s\n",
      "batch 2188, train_loss 0.003849,Time used 0.009974s\n",
      "batch 2189, train_loss 0.002951,Time used 0.009974s\n",
      "batch 2190, train_loss 0.005630,Time used 0.009973s\n",
      "batch 2191, train_loss 0.003352,Time used 0.009974s\n",
      "batch 2192, train_loss 0.004931,Time used 0.008977s\n",
      "batch 2193, train_loss 0.003255,Time used 0.008975s\n",
      "batch 2194, train_loss 0.002835,Time used 0.008976s\n",
      "batch 2195, train_loss 0.003674,Time used 0.008975s\n",
      "batch 2196, train_loss 0.002524,Time used 0.008977s\n",
      "batch 2197, train_loss 0.003811,Time used 0.009972s\n",
      "batch 2198, train_loss 0.003777,Time used 0.008976s\n",
      "batch 2199, train_loss 0.005117,Time used 0.010971s\n",
      "batch 2200, train_loss 0.004164,Time used 0.008976s\n",
      "***************************test_batch 2200, test_rmse_loss 0.061056,test_mae_loss 0.043540,test_mape_loss 13.112199,Time used 0.114693s\n",
      "batch 2201, train_loss 0.002971,Time used 0.008976s\n",
      "batch 2202, train_loss 0.003172,Time used 0.007979s\n",
      "batch 2203, train_loss 0.004733,Time used 0.008976s\n",
      "batch 2204, train_loss 0.002940,Time used 0.008975s\n",
      "batch 2205, train_loss 0.002953,Time used 0.007979s\n",
      "batch 2206, train_loss 0.003949,Time used 0.008976s\n",
      "batch 2207, train_loss 0.004987,Time used 0.009973s\n",
      "batch 2208, train_loss 0.003244,Time used 0.009973s\n",
      "batch 2209, train_loss 0.004399,Time used 0.008976s\n",
      "batch 2210, train_loss 0.002469,Time used 0.008976s\n",
      "batch 2211, train_loss 0.003555,Time used 0.007978s\n",
      "batch 2212, train_loss 0.003782,Time used 0.007979s\n",
      "batch 2213, train_loss 0.003476,Time used 0.008976s\n",
      "batch 2214, train_loss 0.003530,Time used 0.007979s\n",
      "batch 2215, train_loss 0.003824,Time used 0.007979s\n",
      "batch 2216, train_loss 0.002547,Time used 0.007980s\n",
      "batch 2217, train_loss 0.003173,Time used 0.007978s\n",
      "batch 2218, train_loss 0.004097,Time used 0.007978s\n",
      "batch 2219, train_loss 0.003374,Time used 0.008976s\n",
      "batch 2220, train_loss 0.002812,Time used 0.008975s\n",
      "batch 2221, train_loss 0.003194,Time used 0.008976s\n",
      "batch 2222, train_loss 0.003607,Time used 0.008976s\n",
      "batch 2223, train_loss 0.003083,Time used 0.007979s\n",
      "batch 2224, train_loss 0.003741,Time used 0.007978s\n",
      "batch 2225, train_loss 0.002795,Time used 0.007978s\n",
      "batch 2226, train_loss 0.004284,Time used 0.008976s\n",
      "batch 2227, train_loss 0.004447,Time used 0.007979s\n",
      "batch 2228, train_loss 0.002643,Time used 0.009973s\n",
      "batch 2229, train_loss 0.003649,Time used 0.008976s\n",
      "batch 2230, train_loss 0.002940,Time used 0.008977s\n",
      "batch 2231, train_loss 0.003192,Time used 0.008976s\n",
      "batch 2232, train_loss 0.003934,Time used 0.009973s\n",
      "batch 2233, train_loss 0.003828,Time used 0.008977s\n",
      "batch 2234, train_loss 0.003539,Time used 0.009972s\n",
      "batch 2235, train_loss 0.004935,Time used 0.008977s\n",
      "batch 2236, train_loss 0.003484,Time used 0.008976s\n",
      "batch 2237, train_loss 0.003222,Time used 0.010970s\n",
      "batch 2238, train_loss 0.004899,Time used 0.017952s\n",
      "batch 2239, train_loss 0.005242,Time used 0.008976s\n",
      "batch 2240, train_loss 0.005327,Time used 0.009973s\n",
      "batch 2241, train_loss 0.002839,Time used 0.007979s\n",
      "batch 2242, train_loss 0.004415,Time used 0.009974s\n",
      "batch 2243, train_loss 0.005317,Time used 0.008976s\n",
      "batch 2244, train_loss 0.002335,Time used 0.008977s\n",
      "batch 2245, train_loss 0.003324,Time used 0.008975s\n",
      "batch 2246, train_loss 0.003811,Time used 0.009973s\n",
      "batch 2247, train_loss 0.004203,Time used 0.007978s\n",
      "batch 2248, train_loss 0.005565,Time used 0.008976s\n",
      "batch 2249, train_loss 0.004333,Time used 0.008975s\n",
      "batch 2250, train_loss 0.003997,Time used 0.008975s\n",
      "batch 2251, train_loss 0.003364,Time used 0.008976s\n",
      "batch 2252, train_loss 0.004259,Time used 0.008976s\n",
      "batch 2253, train_loss 0.003318,Time used 0.008976s\n",
      "batch 2254, train_loss 0.004364,Time used 0.008976s\n",
      "batch 2255, train_loss 0.004154,Time used 0.007979s\n",
      "batch 2256, train_loss 0.003651,Time used 0.007979s\n",
      "batch 2257, train_loss 0.003302,Time used 0.008976s\n",
      "batch 2258, train_loss 0.004789,Time used 0.007979s\n",
      "batch 2259, train_loss 0.002178,Time used 0.007978s\n",
      "batch 2260, train_loss 0.003855,Time used 0.007979s\n",
      "batch 2261, train_loss 0.003372,Time used 0.007979s\n",
      "batch 2262, train_loss 0.004624,Time used 0.007979s\n",
      "batch 2263, train_loss 0.004449,Time used 0.008976s\n",
      "batch 2264, train_loss 0.003894,Time used 0.009973s\n",
      "batch 2265, train_loss 0.002950,Time used 0.008977s\n",
      "batch 2266, train_loss 0.004564,Time used 0.009973s\n",
      "batch 2267, train_loss 0.004473,Time used 0.009973s\n",
      "batch 2268, train_loss 0.002727,Time used 0.008976s\n",
      "batch 2269, train_loss 0.003744,Time used 0.010971s\n",
      "batch 2270, train_loss 0.004088,Time used 0.009974s\n",
      "batch 2271, train_loss 0.004430,Time used 0.007978s\n",
      "batch 2272, train_loss 0.003775,Time used 0.008976s\n",
      "batch 2273, train_loss 0.003063,Time used 0.007979s\n",
      "batch 2274, train_loss 0.002836,Time used 0.008976s\n",
      "batch 2275, train_loss 0.004070,Time used 0.008977s\n",
      "batch 2276, train_loss 0.003146,Time used 0.008976s\n",
      "batch 2277, train_loss 0.003527,Time used 0.008975s\n",
      "batch 2278, train_loss 0.003133,Time used 0.008976s\n",
      "batch 2279, train_loss 0.003410,Time used 0.008976s\n",
      "batch 2280, train_loss 0.003378,Time used 0.008976s\n",
      "batch 2281, train_loss 0.002815,Time used 0.008975s\n",
      "batch 2282, train_loss 0.004266,Time used 0.008976s\n",
      "batch 2283, train_loss 0.003366,Time used 0.008976s\n",
      "batch 2284, train_loss 0.003464,Time used 0.008976s\n",
      "batch 2285, train_loss 0.003732,Time used 0.008975s\n",
      "batch 2286, train_loss 0.002965,Time used 0.009974s\n",
      "batch 2287, train_loss 0.003319,Time used 0.008976s\n",
      "batch 2288, train_loss 0.004042,Time used 0.008977s\n",
      "batch 2289, train_loss 0.003262,Time used 0.008976s\n",
      "batch 2290, train_loss 0.003935,Time used 0.008975s\n",
      "batch 2291, train_loss 0.004285,Time used 0.008977s\n",
      "batch 2292, train_loss 0.003397,Time used 0.009974s\n",
      "batch 2293, train_loss 0.003297,Time used 0.008975s\n",
      "batch 2294, train_loss 0.003493,Time used 0.007979s\n",
      "batch 2295, train_loss 0.004618,Time used 0.008975s\n",
      "batch 2296, train_loss 0.004296,Time used 0.008977s\n",
      "batch 2297, train_loss 0.003644,Time used 0.008976s\n",
      "batch 2298, train_loss 0.003531,Time used 0.008977s\n",
      "batch 2299, train_loss 0.002848,Time used 0.008975s\n",
      "batch 2300, train_loss 0.003746,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************test_batch 2300, test_rmse_loss 0.061233,test_mae_loss 0.043691,test_mape_loss 12.863174,Time used 0.112698s\n",
      "batch 2301, train_loss 0.003402,Time used 0.007979s\n",
      "batch 2302, train_loss 0.003378,Time used 0.007979s\n",
      "batch 2303, train_loss 0.003274,Time used 0.008976s\n",
      "batch 2304, train_loss 0.003324,Time used 0.007979s\n",
      "batch 2305, train_loss 0.005020,Time used 0.007978s\n",
      "batch 2306, train_loss 0.003730,Time used 0.007980s\n",
      "batch 2307, train_loss 0.002685,Time used 0.006981s\n",
      "batch 2308, train_loss 0.003709,Time used 0.007979s\n",
      "batch 2309, train_loss 0.004828,Time used 0.007978s\n",
      "batch 2310, train_loss 0.002796,Time used 0.007979s\n",
      "batch 2311, train_loss 0.003886,Time used 0.007979s\n",
      "batch 2312, train_loss 0.003155,Time used 0.008009s\n",
      "batch 2313, train_loss 0.003112,Time used 0.007978s\n",
      "batch 2314, train_loss 0.004345,Time used 0.006982s\n",
      "batch 2315, train_loss 0.003144,Time used 0.007979s\n",
      "batch 2316, train_loss 0.003757,Time used 0.007979s\n",
      "batch 2317, train_loss 0.003275,Time used 0.007978s\n",
      "batch 2318, train_loss 0.004567,Time used 0.006982s\n",
      "batch 2319, train_loss 0.003696,Time used 0.006983s\n",
      "batch 2320, train_loss 0.003616,Time used 0.007977s\n",
      "batch 2321, train_loss 0.003927,Time used 0.008976s\n",
      "batch 2322, train_loss 0.003671,Time used 0.007980s\n",
      "batch 2323, train_loss 0.003792,Time used 0.007978s\n",
      "batch 2324, train_loss 0.002943,Time used 0.007979s\n",
      "batch 2325, train_loss 0.004077,Time used 0.006982s\n",
      "batch 2326, train_loss 0.003753,Time used 0.007977s\n",
      "batch 2327, train_loss 0.003912,Time used 0.007979s\n",
      "batch 2328, train_loss 0.003399,Time used 0.007979s\n",
      "batch 2329, train_loss 0.004805,Time used 0.007978s\n",
      "batch 2330, train_loss 0.003500,Time used 0.007979s\n",
      "batch 2331, train_loss 0.002973,Time used 0.007979s\n",
      "batch 2332, train_loss 0.005185,Time used 0.007979s\n",
      "batch 2333, train_loss 0.003197,Time used 0.006982s\n",
      "batch 2334, train_loss 0.003603,Time used 0.007978s\n",
      "batch 2335, train_loss 0.002804,Time used 0.007979s\n",
      "batch 2336, train_loss 0.004089,Time used 0.007979s\n",
      "batch 2337, train_loss 0.003414,Time used 0.007978s\n",
      "batch 2338, train_loss 0.004066,Time used 0.008976s\n",
      "batch 2339, train_loss 0.003085,Time used 0.008976s\n",
      "batch 2340, train_loss 0.003789,Time used 0.007979s\n",
      "batch 2341, train_loss 0.003375,Time used 0.007978s\n",
      "batch 2342, train_loss 0.003086,Time used 0.007979s\n",
      "batch 2343, train_loss 0.003693,Time used 0.007979s\n",
      "batch 2344, train_loss 0.004094,Time used 0.007979s\n",
      "batch 2345, train_loss 0.002960,Time used 0.008976s\n",
      "batch 2346, train_loss 0.002790,Time used 0.007979s\n",
      "batch 2347, train_loss 0.002625,Time used 0.008976s\n",
      "batch 2348, train_loss 0.004691,Time used 0.008977s\n",
      "batch 2349, train_loss 0.003084,Time used 0.008975s\n",
      "batch 2350, train_loss 0.003293,Time used 0.008976s\n",
      "batch 2351, train_loss 0.004493,Time used 0.008976s\n",
      "batch 2352, train_loss 0.004449,Time used 0.008976s\n",
      "batch 2353, train_loss 0.003495,Time used 0.007978s\n",
      "batch 2354, train_loss 0.006948,Time used 0.006982s\n",
      "batch 2355, train_loss 0.002935,Time used 0.008976s\n",
      "batch 2356, train_loss 0.003497,Time used 0.008976s\n",
      "batch 2357, train_loss 0.003748,Time used 0.008977s\n",
      "batch 2358, train_loss 0.002991,Time used 0.008976s\n",
      "batch 2359, train_loss 0.003788,Time used 0.008976s\n",
      "batch 2360, train_loss 0.002784,Time used 0.007978s\n",
      "batch 2361, train_loss 0.003627,Time used 0.008976s\n",
      "batch 2362, train_loss 0.002806,Time used 0.008977s\n",
      "batch 2363, train_loss 0.002823,Time used 0.008976s\n",
      "batch 2364, train_loss 0.002811,Time used 0.008976s\n",
      "batch 2365, train_loss 0.003125,Time used 0.008976s\n",
      "batch 2366, train_loss 0.003036,Time used 0.008976s\n",
      "batch 2367, train_loss 0.004094,Time used 0.008977s\n",
      "batch 2368, train_loss 0.003712,Time used 0.007979s\n",
      "batch 2369, train_loss 0.003993,Time used 0.007978s\n",
      "batch 2370, train_loss 0.003345,Time used 0.008975s\n",
      "batch 2371, train_loss 0.002894,Time used 0.007979s\n",
      "batch 2372, train_loss 0.003279,Time used 0.008976s\n",
      "batch 2373, train_loss 0.003778,Time used 0.008976s\n",
      "batch 2374, train_loss 0.003386,Time used 0.008976s\n",
      "batch 2375, train_loss 0.003339,Time used 0.007979s\n",
      "batch 2376, train_loss 0.003949,Time used 0.007979s\n",
      "batch 2377, train_loss 0.004761,Time used 0.007978s\n",
      "batch 2378, train_loss 0.002962,Time used 0.008976s\n",
      "batch 2379, train_loss 0.003186,Time used 0.008977s\n",
      "batch 2380, train_loss 0.003691,Time used 0.007978s\n",
      "batch 2381, train_loss 0.003327,Time used 0.006981s\n",
      "batch 2382, train_loss 0.006112,Time used 0.007979s\n",
      "batch 2383, train_loss 0.003277,Time used 0.007979s\n",
      "batch 2384, train_loss 0.004726,Time used 0.007979s\n",
      "batch 2385, train_loss 0.003233,Time used 0.006981s\n",
      "batch 2386, train_loss 0.004448,Time used 0.007979s\n",
      "batch 2387, train_loss 0.002807,Time used 0.007979s\n",
      "batch 2388, train_loss 0.003782,Time used 0.007978s\n",
      "batch 2389, train_loss 0.003092,Time used 0.007978s\n",
      "batch 2390, train_loss 0.004182,Time used 0.007978s\n",
      "batch 2391, train_loss 0.003799,Time used 0.008976s\n",
      "batch 2392, train_loss 0.004394,Time used 0.007979s\n",
      "batch 2393, train_loss 0.002823,Time used 0.007978s\n",
      "batch 2394, train_loss 0.003133,Time used 0.007979s\n",
      "batch 2395, train_loss 0.003877,Time used 0.005984s\n",
      "batch 2396, train_loss 0.005678,Time used 0.006982s\n",
      "batch 2397, train_loss 0.004904,Time used 0.006981s\n",
      "batch 2398, train_loss 0.004032,Time used 0.007978s\n",
      "batch 2399, train_loss 0.003951,Time used 0.007978s\n",
      "batch 2400, train_loss 0.003815,Time used 0.006981s\n",
      "***************************test_batch 2400, test_rmse_loss 0.061639,test_mae_loss 0.044056,test_mape_loss 12.831201,Time used 0.114695s\n",
      "batch 2401, train_loss 0.004015,Time used 0.007978s\n",
      "batch 2402, train_loss 0.004206,Time used 0.009974s\n",
      "batch 2403, train_loss 0.003532,Time used 0.007978s\n",
      "batch 2404, train_loss 0.005946,Time used 0.006981s\n",
      "batch 2405, train_loss 0.003157,Time used 0.007979s\n",
      "batch 2406, train_loss 0.003536,Time used 0.006980s\n",
      "batch 2407, train_loss 0.003934,Time used 0.008976s\n",
      "batch 2408, train_loss 0.002633,Time used 0.008977s\n",
      "batch 2409, train_loss 0.002780,Time used 0.009973s\n",
      "batch 2410, train_loss 0.003559,Time used 0.008976s\n",
      "batch 2411, train_loss 0.003409,Time used 0.009974s\n",
      "batch 2412, train_loss 0.004255,Time used 0.008976s\n",
      "batch 2413, train_loss 0.004242,Time used 0.008976s\n",
      "batch 2414, train_loss 0.003787,Time used 0.009973s\n",
      "batch 2415, train_loss 0.005023,Time used 0.008976s\n",
      "batch 2416, train_loss 0.002450,Time used 0.008976s\n",
      "batch 2417, train_loss 0.003729,Time used 0.008976s\n",
      "batch 2418, train_loss 0.002708,Time used 0.008977s\n",
      "batch 2419, train_loss 0.003325,Time used 0.008975s\n",
      "batch 2420, train_loss 0.003662,Time used 0.008976s\n",
      "batch 2421, train_loss 0.004416,Time used 0.009973s\n",
      "batch 2422, train_loss 0.002637,Time used 0.007979s\n",
      "batch 2423, train_loss 0.003731,Time used 0.008976s\n",
      "batch 2424, train_loss 0.005471,Time used 0.008976s\n",
      "batch 2425, train_loss 0.003111,Time used 0.008976s\n",
      "batch 2426, train_loss 0.004075,Time used 0.007979s\n",
      "batch 2427, train_loss 0.004898,Time used 0.007979s\n",
      "batch 2428, train_loss 0.003936,Time used 0.008976s\n",
      "batch 2429, train_loss 0.002945,Time used 0.009973s\n",
      "batch 2430, train_loss 0.003349,Time used 0.009974s\n",
      "batch 2431, train_loss 0.004823,Time used 0.008976s\n",
      "batch 2432, train_loss 0.003403,Time used 0.008976s\n",
      "batch 2433, train_loss 0.003906,Time used 0.008975s\n",
      "batch 2434, train_loss 0.003528,Time used 0.008976s\n",
      "batch 2435, train_loss 0.004214,Time used 0.010971s\n",
      "batch 2436, train_loss 0.002593,Time used 0.009974s\n",
      "batch 2437, train_loss 0.002768,Time used 0.009973s\n",
      "batch 2438, train_loss 0.004027,Time used 0.008976s\n",
      "batch 2439, train_loss 0.002694,Time used 0.008977s\n",
      "batch 2440, train_loss 0.003253,Time used 0.008976s\n",
      "batch 2441, train_loss 0.004306,Time used 0.008976s\n",
      "batch 2442, train_loss 0.003835,Time used 0.008976s\n",
      "batch 2443, train_loss 0.004057,Time used 0.008975s\n",
      "batch 2444, train_loss 0.002850,Time used 0.008977s\n",
      "batch 2445, train_loss 0.003023,Time used 0.008975s\n",
      "batch 2446, train_loss 0.004730,Time used 0.008976s\n",
      "batch 2447, train_loss 0.003179,Time used 0.008976s\n",
      "batch 2448, train_loss 0.003782,Time used 0.008977s\n",
      "batch 2449, train_loss 0.003789,Time used 0.008976s\n",
      "batch 2450, train_loss 0.003895,Time used 0.008976s\n",
      "batch 2451, train_loss 0.005325,Time used 0.007998s\n",
      "batch 2452, train_loss 0.003899,Time used 0.008487s\n",
      "batch 2453, train_loss 0.002988,Time used 0.008977s\n",
      "batch 2454, train_loss 0.004611,Time used 0.007978s\n",
      "batch 2455, train_loss 0.003903,Time used 0.007979s\n",
      "batch 2456, train_loss 0.003280,Time used 0.007979s\n",
      "batch 2457, train_loss 0.002174,Time used 0.008976s\n",
      "batch 2458, train_loss 0.003651,Time used 0.008977s\n",
      "batch 2459, train_loss 0.003443,Time used 0.008976s\n",
      "batch 2460, train_loss 0.003213,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2461, train_loss 0.001376,Time used 0.006981s\n",
      "batch 2462, train_loss 0.004392,Time used 0.009973s\n",
      "batch 2463, train_loss 0.003480,Time used 0.009974s\n",
      "batch 2464, train_loss 0.002517,Time used 0.008976s\n",
      "batch 2465, train_loss 0.004500,Time used 0.008976s\n",
      "batch 2466, train_loss 0.002652,Time used 0.007979s\n",
      "batch 2467, train_loss 0.003165,Time used 0.008976s\n",
      "batch 2468, train_loss 0.002393,Time used 0.008976s\n",
      "batch 2469, train_loss 0.002907,Time used 0.008976s\n",
      "batch 2470, train_loss 0.002836,Time used 0.008975s\n",
      "batch 2471, train_loss 0.004832,Time used 0.007979s\n",
      "batch 2472, train_loss 0.004256,Time used 0.007979s\n",
      "batch 2473, train_loss 0.003631,Time used 0.008976s\n",
      "batch 2474, train_loss 0.004146,Time used 0.007979s\n",
      "batch 2475, train_loss 0.003233,Time used 0.007978s\n",
      "batch 2476, train_loss 0.003692,Time used 0.007978s\n",
      "batch 2477, train_loss 0.003323,Time used 0.007979s\n",
      "batch 2478, train_loss 0.003402,Time used 0.007979s\n",
      "batch 2479, train_loss 0.002798,Time used 0.007978s\n",
      "batch 2480, train_loss 0.004211,Time used 0.007978s\n",
      "batch 2481, train_loss 0.002745,Time used 0.009974s\n",
      "batch 2482, train_loss 0.003312,Time used 0.008976s\n",
      "batch 2483, train_loss 0.004073,Time used 0.008975s\n",
      "batch 2484, train_loss 0.003368,Time used 0.008977s\n",
      "batch 2485, train_loss 0.004311,Time used 0.008976s\n",
      "batch 2486, train_loss 0.004498,Time used 0.007977s\n",
      "batch 2487, train_loss 0.003036,Time used 0.007979s\n",
      "batch 2488, train_loss 0.003308,Time used 0.007978s\n",
      "batch 2489, train_loss 0.003562,Time used 0.007980s\n",
      "batch 2490, train_loss 0.003762,Time used 0.008975s\n",
      "batch 2491, train_loss 0.003252,Time used 0.007979s\n",
      "batch 2492, train_loss 0.003679,Time used 0.007978s\n",
      "batch 2493, train_loss 0.004735,Time used 0.007979s\n",
      "batch 2494, train_loss 0.003532,Time used 0.007978s\n",
      "batch 2495, train_loss 0.002328,Time used 0.007980s\n",
      "batch 2496, train_loss 0.004549,Time used 0.007979s\n",
      "batch 2497, train_loss 0.003058,Time used 0.007979s\n",
      "batch 2498, train_loss 0.004327,Time used 0.007978s\n",
      "batch 2499, train_loss 0.005477,Time used 0.007979s\n",
      "batch 2500, train_loss 0.003428,Time used 0.007979s\n",
      "***************************test_batch 2500, test_rmse_loss 0.061092,test_mae_loss 0.043575,test_mape_loss 12.846029,Time used 0.111702s\n",
      "batch 2501, train_loss 0.003212,Time used 0.007978s\n",
      "batch 2502, train_loss 0.003124,Time used 0.007978s\n",
      "batch 2503, train_loss 0.003103,Time used 0.007979s\n",
      "batch 2504, train_loss 0.003082,Time used 0.007979s\n",
      "batch 2505, train_loss 0.003978,Time used 0.007979s\n",
      "batch 2506, train_loss 0.004671,Time used 0.006982s\n",
      "batch 2507, train_loss 0.004176,Time used 0.007978s\n",
      "batch 2508, train_loss 0.004059,Time used 0.008976s\n",
      "batch 2509, train_loss 0.003814,Time used 0.007979s\n",
      "batch 2510, train_loss 0.003300,Time used 0.007978s\n",
      "batch 2511, train_loss 0.002528,Time used 0.008977s\n",
      "batch 2512, train_loss 0.002680,Time used 0.008975s\n",
      "batch 2513, train_loss 0.004067,Time used 0.009974s\n",
      "batch 2514, train_loss 0.003608,Time used 0.008977s\n",
      "batch 2515, train_loss 0.004449,Time used 0.008976s\n",
      "batch 2516, train_loss 0.003607,Time used 0.007978s\n",
      "batch 2517, train_loss 0.004077,Time used 0.008976s\n",
      "batch 2518, train_loss 0.003733,Time used 0.006982s\n",
      "batch 2519, train_loss 0.003567,Time used 0.007979s\n",
      "batch 2520, train_loss 0.003233,Time used 0.008976s\n",
      "batch 2521, train_loss 0.003267,Time used 0.008976s\n",
      "batch 2522, train_loss 0.004811,Time used 0.007978s\n",
      "batch 2523, train_loss 0.003874,Time used 0.009974s\n",
      "batch 2524, train_loss 0.004563,Time used 0.009972s\n",
      "batch 2525, train_loss 0.003283,Time used 0.008976s\n",
      "batch 2526, train_loss 0.003517,Time used 0.008976s\n",
      "batch 2527, train_loss 0.003267,Time used 0.008976s\n",
      "batch 2528, train_loss 0.004286,Time used 0.008977s\n",
      "batch 2529, train_loss 0.002740,Time used 0.008976s\n",
      "batch 2530, train_loss 0.003862,Time used 0.008976s\n",
      "batch 2531, train_loss 0.004383,Time used 0.009974s\n",
      "batch 2532, train_loss 0.002158,Time used 0.008977s\n",
      "batch 2533, train_loss 0.003756,Time used 0.009974s\n",
      "batch 2534, train_loss 0.003213,Time used 0.009973s\n",
      "batch 2535, train_loss 0.003260,Time used 0.008977s\n",
      "batch 2536, train_loss 0.003058,Time used 0.008976s\n",
      "batch 2537, train_loss 0.005763,Time used 0.007979s\n",
      "batch 2538, train_loss 0.003864,Time used 0.008975s\n",
      "batch 2539, train_loss 0.003712,Time used 0.008976s\n",
      "batch 2540, train_loss 0.004210,Time used 0.008975s\n",
      "batch 2541, train_loss 0.003516,Time used 0.008977s\n",
      "batch 2542, train_loss 0.003644,Time used 0.007979s\n",
      "batch 2543, train_loss 0.003937,Time used 0.008976s\n",
      "batch 2544, train_loss 0.003592,Time used 0.008976s\n",
      "batch 2545, train_loss 0.005939,Time used 0.008976s\n",
      "batch 2546, train_loss 0.003685,Time used 0.007979s\n",
      "batch 2547, train_loss 0.003229,Time used 0.008975s\n",
      "batch 2548, train_loss 0.003854,Time used 0.007979s\n",
      "batch 2549, train_loss 0.003125,Time used 0.008977s\n",
      "batch 2550, train_loss 0.004794,Time used 0.007979s\n",
      "batch 2551, train_loss 0.004157,Time used 0.007979s\n",
      "batch 2552, train_loss 0.004313,Time used 0.007979s\n",
      "batch 2553, train_loss 0.002609,Time used 0.007979s\n",
      "batch 2554, train_loss 0.002605,Time used 0.007978s\n",
      "batch 2555, train_loss 0.003972,Time used 0.007979s\n",
      "batch 2556, train_loss 0.004119,Time used 0.007978s\n",
      "batch 2557, train_loss 0.003516,Time used 0.007978s\n",
      "batch 2558, train_loss 0.002506,Time used 0.007979s\n",
      "batch 2559, train_loss 0.004023,Time used 0.007978s\n",
      "batch 2560, train_loss 0.002826,Time used 0.007978s\n",
      "batch 2561, train_loss 0.003046,Time used 0.007979s\n",
      "batch 2562, train_loss 0.003879,Time used 0.007979s\n",
      "batch 2563, train_loss 0.002643,Time used 0.008976s\n",
      "batch 2564, train_loss 0.003707,Time used 0.008976s\n",
      "batch 2565, train_loss 0.004052,Time used 0.009974s\n",
      "batch 2566, train_loss 0.004500,Time used 0.010971s\n",
      "batch 2567, train_loss 0.005406,Time used 0.007978s\n",
      "batch 2568, train_loss 0.001933,Time used 0.006980s\n",
      "batch 2569, train_loss 0.002466,Time used 0.008977s\n",
      "batch 2570, train_loss 0.004037,Time used 0.008976s\n",
      "batch 2571, train_loss 0.002932,Time used 0.008976s\n",
      "batch 2572, train_loss 0.002721,Time used 0.008976s\n",
      "batch 2573, train_loss 0.005540,Time used 0.008977s\n",
      "batch 2574, train_loss 0.003995,Time used 0.008975s\n",
      "batch 2575, train_loss 0.003676,Time used 0.007979s\n",
      "batch 2576, train_loss 0.005064,Time used 0.007511s\n",
      "batch 2577, train_loss 0.004088,Time used 0.008487s\n",
      "batch 2578, train_loss 0.003270,Time used 0.008976s\n",
      "batch 2579, train_loss 0.003009,Time used 0.007979s\n",
      "batch 2580, train_loss 0.003085,Time used 0.008976s\n",
      "batch 2581, train_loss 0.003000,Time used 0.007978s\n",
      "batch 2582, train_loss 0.002996,Time used 0.007979s\n",
      "batch 2583, train_loss 0.005256,Time used 0.007978s\n",
      "batch 2584, train_loss 0.002619,Time used 0.008976s\n",
      "batch 2585, train_loss 0.002915,Time used 0.009973s\n",
      "batch 2586, train_loss 0.003124,Time used 0.008978s\n",
      "batch 2587, train_loss 0.003507,Time used 0.008975s\n",
      "batch 2588, train_loss 0.003008,Time used 0.009974s\n",
      "batch 2589, train_loss 0.003136,Time used 0.008976s\n",
      "batch 2590, train_loss 0.003092,Time used 0.007978s\n",
      "batch 2591, train_loss 0.004081,Time used 0.008976s\n",
      "batch 2592, train_loss 0.003273,Time used 0.008976s\n",
      "batch 2593, train_loss 0.003796,Time used 0.008976s\n",
      "batch 2594, train_loss 0.003493,Time used 0.007978s\n",
      "batch 2595, train_loss 0.003055,Time used 0.008976s\n",
      "batch 2596, train_loss 0.004136,Time used 0.008977s\n",
      "batch 2597, train_loss 0.002651,Time used 0.008975s\n",
      "batch 2598, train_loss 0.003292,Time used 0.008976s\n",
      "batch 2599, train_loss 0.003504,Time used 0.007978s\n",
      "batch 2600, train_loss 0.003859,Time used 0.008977s\n",
      "***************************test_batch 2600, test_rmse_loss 0.060938,test_mae_loss 0.043443,test_mape_loss 13.042593,Time used 0.101727s\n",
      "batch 2601, train_loss 0.005225,Time used 0.008977s\n",
      "batch 2602, train_loss 0.002872,Time used 0.008976s\n",
      "batch 2603, train_loss 0.003791,Time used 0.008975s\n",
      "batch 2604, train_loss 0.002649,Time used 0.008976s\n",
      "batch 2605, train_loss 0.003974,Time used 0.007979s\n",
      "batch 2606, train_loss 0.003480,Time used 0.008976s\n",
      "batch 2607, train_loss 0.005609,Time used 0.007979s\n",
      "batch 2608, train_loss 0.003102,Time used 0.007979s\n",
      "batch 2609, train_loss 0.003418,Time used 0.007979s\n",
      "batch 2610, train_loss 0.003079,Time used 0.007978s\n",
      "batch 2611, train_loss 0.004335,Time used 0.007979s\n",
      "batch 2612, train_loss 0.003805,Time used 0.006982s\n",
      "batch 2613, train_loss 0.003951,Time used 0.007978s\n",
      "batch 2614, train_loss 0.006679,Time used 0.007979s\n",
      "batch 2615, train_loss 0.004048,Time used 0.008976s\n",
      "batch 2616, train_loss 0.004337,Time used 0.008976s\n",
      "batch 2617, train_loss 0.003100,Time used 0.008976s\n",
      "batch 2618, train_loss 0.003091,Time used 0.008975s\n",
      "batch 2619, train_loss 0.004705,Time used 0.007979s\n",
      "batch 2620, train_loss 0.002611,Time used 0.008975s\n",
      "batch 2621, train_loss 0.003122,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2622, train_loss 0.004434,Time used 0.008976s\n",
      "batch 2623, train_loss 0.002385,Time used 0.008976s\n",
      "batch 2624, train_loss 0.003687,Time used 0.008976s\n",
      "batch 2625, train_loss 0.003063,Time used 0.008976s\n",
      "batch 2626, train_loss 0.003679,Time used 0.009973s\n",
      "batch 2627, train_loss 0.005074,Time used 0.008977s\n",
      "batch 2628, train_loss 0.003081,Time used 0.008976s\n",
      "batch 2629, train_loss 0.003684,Time used 0.007978s\n",
      "batch 2630, train_loss 0.003249,Time used 0.007979s\n",
      "batch 2631, train_loss 0.004253,Time used 0.008976s\n",
      "batch 2632, train_loss 0.003513,Time used 0.008976s\n",
      "batch 2633, train_loss 0.003313,Time used 0.007978s\n",
      "batch 2634, train_loss 0.003506,Time used 0.007980s\n",
      "batch 2635, train_loss 0.005364,Time used 0.008977s\n",
      "batch 2636, train_loss 0.003008,Time used 0.007978s\n",
      "batch 2637, train_loss 0.003900,Time used 0.007979s\n",
      "batch 2638, train_loss 0.003308,Time used 0.008976s\n",
      "batch 2639, train_loss 0.003318,Time used 0.007979s\n",
      "batch 2640, train_loss 0.004494,Time used 0.007979s\n",
      "batch 2641, train_loss 0.003935,Time used 0.008976s\n",
      "batch 2642, train_loss 0.003350,Time used 0.007979s\n",
      "batch 2643, train_loss 0.003504,Time used 0.008976s\n",
      "batch 2644, train_loss 0.003429,Time used 0.008976s\n",
      "batch 2645, train_loss 0.004778,Time used 0.007979s\n",
      "batch 2646, train_loss 0.007165,Time used 0.007979s\n",
      "batch 2647, train_loss 0.003821,Time used 0.007978s\n",
      "batch 2648, train_loss 0.002669,Time used 0.007978s\n",
      "batch 2649, train_loss 0.004345,Time used 0.007978s\n",
      "batch 2650, train_loss 0.002400,Time used 0.007979s\n",
      "batch 2651, train_loss 0.003832,Time used 0.007978s\n",
      "batch 2652, train_loss 0.003960,Time used 0.008976s\n",
      "batch 2653, train_loss 0.004024,Time used 0.008976s\n",
      "batch 2654, train_loss 0.003399,Time used 0.008976s\n",
      "batch 2655, train_loss 0.004436,Time used 0.007979s\n",
      "batch 2656, train_loss 0.003381,Time used 0.009973s\n",
      "batch 2657, train_loss 0.002827,Time used 0.009974s\n",
      "batch 2658, train_loss 0.003277,Time used 0.010482s\n",
      "batch 2659, train_loss 0.003903,Time used 0.008976s\n",
      "batch 2660, train_loss 0.004515,Time used 0.008976s\n",
      "batch 2661, train_loss 0.003469,Time used 0.009973s\n",
      "batch 2662, train_loss 0.003813,Time used 0.009974s\n",
      "batch 2663, train_loss 0.004901,Time used 0.008977s\n",
      "batch 2664, train_loss 0.004273,Time used 0.009076s\n",
      "batch 2665, train_loss 0.002832,Time used 0.009873s\n",
      "batch 2666, train_loss 0.003094,Time used 0.008976s\n",
      "batch 2667, train_loss 0.001887,Time used 0.008976s\n",
      "batch 2668, train_loss 0.003887,Time used 0.008976s\n",
      "batch 2669, train_loss 0.003170,Time used 0.009973s\n",
      "batch 2670, train_loss 0.002641,Time used 0.008977s\n",
      "batch 2671, train_loss 0.003247,Time used 0.008977s\n",
      "batch 2672, train_loss 0.005568,Time used 0.009973s\n",
      "batch 2673, train_loss 0.004620,Time used 0.008977s\n",
      "batch 2674, train_loss 0.003443,Time used 0.008976s\n",
      "batch 2675, train_loss 0.002347,Time used 0.007978s\n",
      "batch 2676, train_loss 0.003365,Time used 0.008975s\n",
      "batch 2677, train_loss 0.003934,Time used 0.009974s\n",
      "batch 2678, train_loss 0.003001,Time used 0.009973s\n",
      "batch 2679, train_loss 0.003615,Time used 0.009972s\n",
      "batch 2680, train_loss 0.003283,Time used 0.009974s\n",
      "batch 2681, train_loss 0.002544,Time used 0.008975s\n",
      "batch 2682, train_loss 0.002391,Time used 0.009973s\n",
      "batch 2683, train_loss 0.002696,Time used 0.009974s\n",
      "batch 2684, train_loss 0.003240,Time used 0.009974s\n",
      "batch 2685, train_loss 0.003365,Time used 0.008976s\n",
      "batch 2686, train_loss 0.003238,Time used 0.008976s\n",
      "batch 2687, train_loss 0.004075,Time used 0.008976s\n",
      "batch 2688, train_loss 0.003586,Time used 0.007978s\n",
      "batch 2689, train_loss 0.005047,Time used 0.008976s\n",
      "batch 2690, train_loss 0.003745,Time used 0.008976s\n",
      "batch 2691, train_loss 0.002824,Time used 0.008976s\n",
      "batch 2692, train_loss 0.003352,Time used 0.008976s\n",
      "batch 2693, train_loss 0.003022,Time used 0.008977s\n",
      "batch 2694, train_loss 0.006791,Time used 0.009974s\n",
      "batch 2695, train_loss 0.003866,Time used 0.009974s\n",
      "batch 2696, train_loss 0.003614,Time used 0.009973s\n",
      "batch 2697, train_loss 0.003270,Time used 0.008976s\n",
      "batch 2698, train_loss 0.004244,Time used 0.009973s\n",
      "batch 2699, train_loss 0.004550,Time used 0.008976s\n",
      "batch 2700, train_loss 0.002386,Time used 0.008976s\n",
      "***************************test_batch 2700, test_rmse_loss 0.061148,test_mae_loss 0.043630,test_mape_loss 12.852608,Time used 0.119681s\n",
      "batch 2701, train_loss 0.004362,Time used 0.008975s\n",
      "batch 2702, train_loss 0.003233,Time used 0.008977s\n",
      "batch 2703, train_loss 0.002860,Time used 0.008976s\n",
      "batch 2704, train_loss 0.003332,Time used 0.008976s\n",
      "batch 2705, train_loss 0.003419,Time used 0.008976s\n",
      "batch 2706, train_loss 0.004883,Time used 0.007979s\n",
      "batch 2707, train_loss 0.003768,Time used 0.008976s\n",
      "batch 2708, train_loss 0.004292,Time used 0.008976s\n",
      "batch 2709, train_loss 0.002723,Time used 0.008976s\n",
      "batch 2710, train_loss 0.003327,Time used 0.008976s\n",
      "batch 2711, train_loss 0.004160,Time used 0.008976s\n",
      "batch 2712, train_loss 0.002931,Time used 0.007979s\n",
      "batch 2713, train_loss 0.004235,Time used 0.007977s\n",
      "batch 2714, train_loss 0.002750,Time used 0.008976s\n",
      "batch 2715, train_loss 0.005012,Time used 0.008976s\n",
      "batch 2716, train_loss 0.002809,Time used 0.007980s\n",
      "batch 2717, train_loss 0.003953,Time used 0.007979s\n",
      "batch 2718, train_loss 0.002900,Time used 0.007979s\n",
      "batch 2719, train_loss 0.003429,Time used 0.008977s\n",
      "batch 2720, train_loss 0.004288,Time used 0.009973s\n",
      "batch 2721, train_loss 0.003306,Time used 0.008976s\n",
      "batch 2722, train_loss 0.003826,Time used 0.008976s\n",
      "batch 2723, train_loss 0.002479,Time used 0.007979s\n",
      "batch 2724, train_loss 0.004896,Time used 0.008976s\n",
      "batch 2725, train_loss 0.003918,Time used 0.008976s\n",
      "batch 2726, train_loss 0.003554,Time used 0.007978s\n",
      "batch 2727, train_loss 0.003220,Time used 0.007979s\n",
      "batch 2728, train_loss 0.004669,Time used 0.008977s\n",
      "batch 2729, train_loss 0.004440,Time used 0.008976s\n",
      "batch 2730, train_loss 0.004055,Time used 0.008976s\n",
      "batch 2731, train_loss 0.004008,Time used 0.008975s\n",
      "batch 2732, train_loss 0.002999,Time used 0.008486s\n",
      "batch 2733, train_loss 0.003145,Time used 0.008976s\n",
      "batch 2734, train_loss 0.003308,Time used 0.007979s\n",
      "batch 2735, train_loss 0.004548,Time used 0.008976s\n",
      "batch 2736, train_loss 0.002811,Time used 0.008977s\n",
      "batch 2737, train_loss 0.003475,Time used 0.008976s\n",
      "batch 2738, train_loss 0.004389,Time used 0.008976s\n",
      "batch 2739, train_loss 0.003699,Time used 0.007979s\n",
      "batch 2740, train_loss 0.002429,Time used 0.008975s\n",
      "batch 2741, train_loss 0.004185,Time used 0.008976s\n",
      "batch 2742, train_loss 0.004066,Time used 0.007979s\n",
      "batch 2743, train_loss 0.004665,Time used 0.007978s\n",
      "batch 2744, train_loss 0.002656,Time used 0.007979s\n",
      "batch 2745, train_loss 0.005741,Time used 0.008976s\n",
      "batch 2746, train_loss 0.004549,Time used 0.007979s\n",
      "batch 2747, train_loss 0.002898,Time used 0.008976s\n",
      "batch 2748, train_loss 0.005906,Time used 0.008976s\n",
      "batch 2749, train_loss 0.003101,Time used 0.008975s\n",
      "batch 2750, train_loss 0.003282,Time used 0.007977s\n",
      "batch 2751, train_loss 0.003345,Time used 0.007979s\n",
      "batch 2752, train_loss 0.004888,Time used 0.008976s\n",
      "batch 2753, train_loss 0.004221,Time used 0.007978s\n",
      "batch 2754, train_loss 0.003994,Time used 0.008977s\n",
      "batch 2755, train_loss 0.003144,Time used 0.008976s\n",
      "batch 2756, train_loss 0.002657,Time used 0.008976s\n",
      "batch 2757, train_loss 0.004851,Time used 0.008975s\n",
      "batch 2758, train_loss 0.003625,Time used 0.009974s\n",
      "batch 2759, train_loss 0.003659,Time used 0.008975s\n",
      "batch 2760, train_loss 0.004304,Time used 0.008977s\n",
      "batch 2761, train_loss 0.002688,Time used 0.008976s\n",
      "batch 2762, train_loss 0.004356,Time used 0.008977s\n",
      "batch 2763, train_loss 0.003219,Time used 0.008975s\n",
      "batch 2764, train_loss 0.004218,Time used 0.008977s\n",
      "batch 2765, train_loss 0.003077,Time used 0.008975s\n",
      "batch 2766, train_loss 0.002223,Time used 0.008977s\n",
      "batch 2767, train_loss 0.003148,Time used 0.008976s\n",
      "batch 2768, train_loss 0.003449,Time used 0.007979s\n",
      "batch 2769, train_loss 0.003675,Time used 0.009973s\n",
      "batch 2770, train_loss 0.003045,Time used 0.008977s\n",
      "batch 2771, train_loss 0.003358,Time used 0.007979s\n",
      "batch 2772, train_loss 0.003474,Time used 0.007979s\n",
      "batch 2773, train_loss 0.003018,Time used 0.007979s\n",
      "batch 2774, train_loss 0.003862,Time used 0.008976s\n",
      "batch 2775, train_loss 0.002594,Time used 0.008975s\n",
      "batch 2776, train_loss 0.003954,Time used 0.008977s\n",
      "batch 2777, train_loss 0.004421,Time used 0.008976s\n",
      "batch 2778, train_loss 0.003705,Time used 0.008976s\n",
      "batch 2779, train_loss 0.004085,Time used 0.008976s\n",
      "batch 2780, train_loss 0.003262,Time used 0.008976s\n",
      "batch 2781, train_loss 0.004192,Time used 0.008976s\n",
      "batch 2782, train_loss 0.001947,Time used 0.006981s\n",
      "batch 2783, train_loss 0.002632,Time used 0.008976s\n",
      "batch 2784, train_loss 0.003322,Time used 0.007979s\n",
      "batch 2785, train_loss 0.003185,Time used 0.008976s\n",
      "batch 2786, train_loss 0.003802,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2787, train_loss 0.002780,Time used 0.026481s\n",
      "batch 2788, train_loss 0.003778,Time used 0.014471s\n",
      "batch 2789, train_loss 0.003626,Time used 0.019947s\n",
      "batch 2790, train_loss 0.004299,Time used 0.038896s\n",
      "batch 2791, train_loss 0.003732,Time used 0.018498s\n",
      "batch 2792, train_loss 0.002902,Time used 0.010971s\n",
      "batch 2793, train_loss 0.003241,Time used 0.011968s\n",
      "batch 2794, train_loss 0.002515,Time used 0.010971s\n",
      "batch 2795, train_loss 0.004160,Time used 0.010971s\n",
      "batch 2796, train_loss 0.005148,Time used 0.010971s\n",
      "batch 2797, train_loss 0.002800,Time used 0.011968s\n",
      "batch 2798, train_loss 0.003976,Time used 0.011967s\n",
      "batch 2799, train_loss 0.003636,Time used 0.011968s\n",
      "batch 2800, train_loss 0.004921,Time used 0.010972s\n",
      "***************************test_batch 2800, test_rmse_loss 0.061036,test_mae_loss 0.043528,test_mape_loss 13.148428,Time used 0.133643s\n",
      "batch 2801, train_loss 0.004746,Time used 0.008976s\n",
      "batch 2802, train_loss 0.003180,Time used 0.009973s\n",
      "batch 2803, train_loss 0.002981,Time used 0.008976s\n",
      "batch 2804, train_loss 0.005828,Time used 0.009973s\n",
      "batch 2805, train_loss 0.004789,Time used 0.008976s\n",
      "batch 2806, train_loss 0.003032,Time used 0.009973s\n",
      "batch 2807, train_loss 0.003466,Time used 0.009974s\n",
      "batch 2808, train_loss 0.003276,Time used 0.009974s\n",
      "batch 2809, train_loss 0.004756,Time used 0.008976s\n",
      "batch 2810, train_loss 0.002988,Time used 0.008976s\n",
      "batch 2811, train_loss 0.005105,Time used 0.008976s\n",
      "batch 2812, train_loss 0.003571,Time used 0.007978s\n",
      "batch 2813, train_loss 0.004113,Time used 0.008976s\n",
      "batch 2814, train_loss 0.002533,Time used 0.008976s\n",
      "batch 2815, train_loss 0.003464,Time used 0.007979s\n",
      "batch 2816, train_loss 0.004649,Time used 0.008976s\n",
      "batch 2817, train_loss 0.005225,Time used 0.008977s\n",
      "batch 2818, train_loss 0.003181,Time used 0.009973s\n",
      "batch 2819, train_loss 0.002960,Time used 0.008976s\n",
      "batch 2820, train_loss 0.003331,Time used 0.008975s\n",
      "batch 2821, train_loss 0.003064,Time used 0.008977s\n",
      "batch 2822, train_loss 0.004897,Time used 0.008976s\n",
      "batch 2823, train_loss 0.003847,Time used 0.009973s\n",
      "batch 2824, train_loss 0.002878,Time used 0.008976s\n",
      "batch 2825, train_loss 0.002850,Time used 0.008976s\n",
      "batch 2826, train_loss 0.002937,Time used 0.009974s\n",
      "batch 2827, train_loss 0.003350,Time used 0.007979s\n",
      "batch 2828, train_loss 0.005005,Time used 0.008976s\n",
      "batch 2829, train_loss 0.003884,Time used 0.007978s\n",
      "batch 2830, train_loss 0.003704,Time used 0.008241s\n",
      "batch 2831, train_loss 0.004768,Time used 0.008486s\n",
      "batch 2832, train_loss 0.002961,Time used 0.008976s\n",
      "batch 2833, train_loss 0.003414,Time used 0.008976s\n",
      "batch 2834, train_loss 0.003007,Time used 0.008976s\n",
      "batch 2835, train_loss 0.002816,Time used 0.009974s\n",
      "batch 2836, train_loss 0.003569,Time used 0.008976s\n",
      "batch 2837, train_loss 0.003771,Time used 0.009973s\n",
      "batch 2838, train_loss 0.003247,Time used 0.008977s\n",
      "batch 2839, train_loss 0.003391,Time used 0.008976s\n",
      "batch 2840, train_loss 0.003033,Time used 0.007979s\n",
      "batch 2841, train_loss 0.004959,Time used 0.007978s\n",
      "batch 2842, train_loss 0.003056,Time used 0.007978s\n",
      "batch 2843, train_loss 0.003364,Time used 0.008976s\n",
      "batch 2844, train_loss 0.002882,Time used 0.009973s\n",
      "batch 2845, train_loss 0.002838,Time used 0.008976s\n",
      "batch 2846, train_loss 0.004224,Time used 0.007979s\n",
      "batch 2847, train_loss 0.003299,Time used 0.007978s\n",
      "batch 2848, train_loss 0.006215,Time used 0.007979s\n",
      "batch 2849, train_loss 0.004476,Time used 0.007978s\n",
      "batch 2850, train_loss 0.003185,Time used 0.008976s\n",
      "batch 2851, train_loss 0.002412,Time used 0.008975s\n",
      "batch 2852, train_loss 0.002944,Time used 0.009974s\n",
      "batch 2853, train_loss 0.002679,Time used 0.010970s\n",
      "batch 2854, train_loss 0.003562,Time used 0.014961s\n",
      "batch 2855, train_loss 0.004283,Time used 0.014960s\n",
      "batch 2856, train_loss 0.004137,Time used 0.010970s\n",
      "batch 2857, train_loss 0.003254,Time used 0.011968s\n",
      "batch 2858, train_loss 0.005017,Time used 0.011968s\n",
      "batch 2859, train_loss 0.003834,Time used 0.009974s\n",
      "batch 2860, train_loss 0.003402,Time used 0.008975s\n",
      "batch 2861, train_loss 0.004601,Time used 0.009974s\n",
      "batch 2862, train_loss 0.002674,Time used 0.007979s\n",
      "batch 2863, train_loss 0.002866,Time used 0.009974s\n",
      "batch 2864, train_loss 0.004834,Time used 0.008975s\n",
      "batch 2865, train_loss 0.003083,Time used 0.008976s\n",
      "batch 2866, train_loss 0.003600,Time used 0.008976s\n",
      "batch 2867, train_loss 0.003348,Time used 0.007979s\n",
      "batch 2868, train_loss 0.004723,Time used 0.009974s\n",
      "batch 2869, train_loss 0.002981,Time used 0.008976s\n",
      "batch 2870, train_loss 0.003271,Time used 0.008976s\n",
      "batch 2871, train_loss 0.003713,Time used 0.007979s\n",
      "batch 2872, train_loss 0.003999,Time used 0.008976s\n",
      "batch 2873, train_loss 0.004393,Time used 0.008975s\n",
      "batch 2874, train_loss 0.002696,Time used 0.008976s\n",
      "batch 2875, train_loss 0.003655,Time used 0.008977s\n",
      "batch 2876, train_loss 0.003043,Time used 0.007979s\n",
      "batch 2877, train_loss 0.003631,Time used 0.008976s\n",
      "batch 2878, train_loss 0.002842,Time used 0.008976s\n",
      "batch 2879, train_loss 0.003530,Time used 0.008976s\n",
      "batch 2880, train_loss 0.004125,Time used 0.008976s\n",
      "batch 2881, train_loss 0.002632,Time used 0.009974s\n",
      "batch 2882, train_loss 0.003276,Time used 0.008976s\n",
      "batch 2883, train_loss 0.003926,Time used 0.008976s\n",
      "batch 2884, train_loss 0.003465,Time used 0.009974s\n",
      "batch 2885, train_loss 0.003614,Time used 0.009973s\n",
      "batch 2886, train_loss 0.005988,Time used 0.008976s\n",
      "batch 2887, train_loss 0.003625,Time used 0.009973s\n",
      "batch 2888, train_loss 0.003352,Time used 0.009974s\n",
      "batch 2889, train_loss 0.003552,Time used 0.008976s\n",
      "batch 2890, train_loss 0.003456,Time used 0.009973s\n",
      "batch 2891, train_loss 0.004341,Time used 0.009974s\n",
      "batch 2892, train_loss 0.003669,Time used 0.008976s\n",
      "batch 2893, train_loss 0.002985,Time used 0.008976s\n",
      "batch 2894, train_loss 0.005392,Time used 0.008976s\n",
      "batch 2895, train_loss 0.003531,Time used 0.008976s\n",
      "batch 2896, train_loss 0.004544,Time used 0.007979s\n",
      "batch 2897, train_loss 0.002685,Time used 0.008976s\n",
      "batch 2898, train_loss 0.004259,Time used 0.007979s\n",
      "batch 2899, train_loss 0.004779,Time used 0.008976s\n",
      "batch 2900, train_loss 0.003841,Time used 0.009973s\n",
      "***************************test_batch 2900, test_rmse_loss 0.060942,test_mae_loss 0.043477,test_mape_loss 13.111900,Time used 0.108709s\n",
      "batch 2901, train_loss 0.004135,Time used 0.007978s\n",
      "batch 2902, train_loss 0.004087,Time used 0.008976s\n",
      "batch 2903, train_loss 0.003664,Time used 0.008976s\n",
      "batch 2904, train_loss 0.004006,Time used 0.008976s\n",
      "batch 2905, train_loss 0.003414,Time used 0.007978s\n",
      "batch 2906, train_loss 0.002805,Time used 0.007979s\n",
      "batch 2907, train_loss 0.004231,Time used 0.008976s\n",
      "batch 2908, train_loss 0.003855,Time used 0.008977s\n",
      "batch 2909, train_loss 0.004005,Time used 0.007977s\n",
      "batch 2910, train_loss 0.003975,Time used 0.009974s\n",
      "batch 2911, train_loss 0.004612,Time used 0.017951s\n",
      "batch 2912, train_loss 0.003332,Time used 0.008976s\n",
      "batch 2913, train_loss 0.002653,Time used 0.008976s\n",
      "batch 2914, train_loss 0.003398,Time used 0.009973s\n",
      "batch 2915, train_loss 0.002271,Time used 0.008976s\n",
      "batch 2916, train_loss 0.005019,Time used 0.008976s\n",
      "batch 2917, train_loss 0.004141,Time used 0.009974s\n",
      "batch 2918, train_loss 0.003831,Time used 0.008975s\n",
      "batch 2919, train_loss 0.004586,Time used 0.009974s\n",
      "batch 2920, train_loss 0.003102,Time used 0.007979s\n",
      "batch 2921, train_loss 0.002477,Time used 0.008976s\n",
      "batch 2922, train_loss 0.002931,Time used 0.008977s\n",
      "batch 2923, train_loss 0.003186,Time used 0.009973s\n",
      "batch 2924, train_loss 0.003546,Time used 0.010971s\n",
      "batch 2925, train_loss 0.004371,Time used 0.009974s\n",
      "batch 2926, train_loss 0.003152,Time used 0.009973s\n",
      "batch 2927, train_loss 0.003683,Time used 0.009973s\n",
      "batch 2928, train_loss 0.002662,Time used 0.008975s\n",
      "batch 2929, train_loss 0.004034,Time used 0.008976s\n",
      "batch 2930, train_loss 0.003223,Time used 0.010968s\n",
      "batch 2931, train_loss 0.004208,Time used 0.008976s\n",
      "batch 2932, train_loss 0.004075,Time used 0.008976s\n",
      "batch 2933, train_loss 0.002912,Time used 0.009973s\n",
      "batch 2934, train_loss 0.003720,Time used 0.009974s\n",
      "batch 2935, train_loss 0.004113,Time used 0.008976s\n",
      "batch 2936, train_loss 0.004800,Time used 0.008976s\n",
      "batch 2937, train_loss 0.003270,Time used 0.007979s\n",
      "batch 2938, train_loss 0.005656,Time used 0.008976s\n",
      "batch 2939, train_loss 0.003398,Time used 0.007978s\n",
      "batch 2940, train_loss 0.003014,Time used 0.007978s\n",
      "batch 2941, train_loss 0.003042,Time used 0.006981s\n",
      "batch 2942, train_loss 0.004137,Time used 0.008976s\n",
      "batch 2943, train_loss 0.003229,Time used 0.008976s\n",
      "batch 2944, train_loss 0.003057,Time used 0.008976s\n",
      "batch 2945, train_loss 0.003932,Time used 0.009974s\n",
      "batch 2946, train_loss 0.004463,Time used 0.009973s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2947, train_loss 0.003319,Time used 0.009973s\n",
      "batch 2948, train_loss 0.003612,Time used 0.010971s\n",
      "batch 2949, train_loss 0.003293,Time used 0.008976s\n",
      "batch 2950, train_loss 0.004249,Time used 0.008977s\n",
      "batch 2951, train_loss 0.002886,Time used 0.008976s\n",
      "batch 2952, train_loss 0.003082,Time used 0.008977s\n",
      "batch 2953, train_loss 0.003243,Time used 0.008976s\n",
      "batch 2954, train_loss 0.004330,Time used 0.007978s\n",
      "batch 2955, train_loss 0.002580,Time used 0.009973s\n",
      "batch 2956, train_loss 0.002495,Time used 0.008976s\n",
      "batch 2957, train_loss 0.002971,Time used 0.008976s\n",
      "batch 2958, train_loss 0.003334,Time used 0.009027s\n",
      "batch 2959, train_loss 0.002771,Time used 0.009974s\n",
      "batch 2960, train_loss 0.006022,Time used 0.009973s\n",
      "batch 2961, train_loss 0.002815,Time used 0.008976s\n",
      "batch 2962, train_loss 0.002889,Time used 0.010971s\n",
      "batch 2963, train_loss 0.004306,Time used 0.009973s\n",
      "batch 2964, train_loss 0.004062,Time used 0.009974s\n",
      "batch 2965, train_loss 0.003948,Time used 0.009973s\n",
      "batch 2966, train_loss 0.003995,Time used 0.009974s\n",
      "batch 2967, train_loss 0.003899,Time used 0.008976s\n",
      "batch 2968, train_loss 0.003192,Time used 0.008977s\n",
      "batch 2969, train_loss 0.004081,Time used 0.008976s\n",
      "batch 2970, train_loss 0.003450,Time used 0.008975s\n",
      "batch 2971, train_loss 0.004510,Time used 0.007979s\n",
      "batch 2972, train_loss 0.003611,Time used 0.008976s\n",
      "batch 2973, train_loss 0.002947,Time used 0.008976s\n",
      "batch 2974, train_loss 0.003211,Time used 0.009973s\n",
      "batch 2975, train_loss 0.003144,Time used 0.008976s\n",
      "batch 2976, train_loss 0.002983,Time used 0.009973s\n",
      "batch 2977, train_loss 0.003793,Time used 0.009974s\n",
      "batch 2978, train_loss 0.003980,Time used 0.008976s\n",
      "batch 2979, train_loss 0.003649,Time used 0.009483s\n",
      "batch 2980, train_loss 0.003010,Time used 0.007978s\n",
      "batch 2981, train_loss 0.004098,Time used 0.009974s\n",
      "batch 2982, train_loss 0.003363,Time used 0.008976s\n",
      "batch 2983, train_loss 0.003385,Time used 0.009973s\n",
      "batch 2984, train_loss 0.005884,Time used 0.009974s\n",
      "batch 2985, train_loss 0.003405,Time used 0.010970s\n",
      "batch 2986, train_loss 0.003869,Time used 0.009974s\n",
      "batch 2987, train_loss 0.003430,Time used 0.008976s\n",
      "batch 2988, train_loss 0.003673,Time used 0.008976s\n",
      "batch 2989, train_loss 0.003134,Time used 0.009973s\n",
      "batch 2990, train_loss 0.003814,Time used 0.009974s\n",
      "batch 2991, train_loss 0.002638,Time used 0.008976s\n",
      "batch 2992, train_loss 0.003954,Time used 0.007978s\n",
      "batch 2993, train_loss 0.003723,Time used 0.007978s\n",
      "batch 2994, train_loss 0.003188,Time used 0.008976s\n",
      "batch 2995, train_loss 0.003407,Time used 0.008976s\n",
      "batch 2996, train_loss 0.003381,Time used 0.006981s\n",
      "batch 2997, train_loss 0.003390,Time used 0.007979s\n",
      "batch 2998, train_loss 0.004291,Time used 0.008976s\n",
      "batch 2999, train_loss 0.004005,Time used 0.008976s\n",
      "batch 3000, train_loss 0.005428,Time used 0.008976s\n",
      "***************************test_batch 3000, test_rmse_loss 0.060950,test_mae_loss 0.043484,test_mape_loss 12.875239,Time used 0.119680s\n",
      "batch 3001, train_loss 0.003352,Time used 0.009973s\n",
      "batch 3002, train_loss 0.003025,Time used 0.008976s\n",
      "batch 3003, train_loss 0.004072,Time used 0.008976s\n",
      "batch 3004, train_loss 0.003908,Time used 0.009974s\n",
      "batch 3005, train_loss 0.003901,Time used 0.010971s\n",
      "batch 3006, train_loss 0.003182,Time used 0.008975s\n",
      "batch 3007, train_loss 0.003485,Time used 0.008976s\n",
      "batch 3008, train_loss 0.004321,Time used 0.007979s\n",
      "batch 3009, train_loss 0.004390,Time used 0.008975s\n",
      "batch 3010, train_loss 0.003468,Time used 0.008977s\n",
      "batch 3011, train_loss 0.004440,Time used 0.007979s\n",
      "batch 3012, train_loss 0.003462,Time used 0.008976s\n",
      "batch 3013, train_loss 0.003916,Time used 0.008976s\n",
      "batch 3014, train_loss 0.003395,Time used 0.007979s\n",
      "batch 3015, train_loss 0.004393,Time used 0.007978s\n",
      "batch 3016, train_loss 0.003183,Time used 0.008976s\n",
      "batch 3017, train_loss 0.003637,Time used 0.008977s\n",
      "batch 3018, train_loss 0.002273,Time used 0.010971s\n",
      "batch 3019, train_loss 0.004285,Time used 0.008976s\n",
      "batch 3020, train_loss 0.004334,Time used 0.010970s\n",
      "batch 3021, train_loss 0.002128,Time used 0.010971s\n",
      "batch 3022, train_loss 0.003460,Time used 0.008975s\n",
      "batch 3023, train_loss 0.003037,Time used 0.008976s\n",
      "batch 3024, train_loss 0.002844,Time used 0.007979s\n",
      "batch 3025, train_loss 0.003542,Time used 0.007979s\n",
      "batch 3026, train_loss 0.003254,Time used 0.007979s\n",
      "batch 3027, train_loss 0.004452,Time used 0.007978s\n",
      "batch 3028, train_loss 0.004487,Time used 0.007978s\n",
      "batch 3029, train_loss 0.003377,Time used 0.007979s\n",
      "batch 3030, train_loss 0.002829,Time used 0.007979s\n",
      "batch 3031, train_loss 0.003397,Time used 0.007979s\n",
      "batch 3032, train_loss 0.004018,Time used 0.007979s\n",
      "batch 3033, train_loss 0.005251,Time used 0.007979s\n",
      "batch 3034, train_loss 0.004675,Time used 0.008976s\n",
      "batch 3035, train_loss 0.004603,Time used 0.007980s\n",
      "batch 3036, train_loss 0.002355,Time used 0.008976s\n",
      "batch 3037, train_loss 0.003450,Time used 0.007979s\n",
      "batch 3038, train_loss 0.003033,Time used 0.007979s\n",
      "batch 3039, train_loss 0.003718,Time used 0.007979s\n",
      "batch 3040, train_loss 0.002825,Time used 0.008975s\n",
      "batch 3041, train_loss 0.003156,Time used 0.009974s\n",
      "batch 3042, train_loss 0.005613,Time used 0.007979s\n",
      "batch 3043, train_loss 0.003490,Time used 0.007979s\n",
      "batch 3044, train_loss 0.004587,Time used 0.008976s\n",
      "batch 3045, train_loss 0.003641,Time used 0.007978s\n",
      "batch 3046, train_loss 0.004233,Time used 0.007979s\n",
      "batch 3047, train_loss 0.003931,Time used 0.007978s\n",
      "batch 3048, train_loss 0.004347,Time used 0.007979s\n",
      "batch 3049, train_loss 0.003783,Time used 0.008976s\n",
      "batch 3050, train_loss 0.003097,Time used 0.007978s\n",
      "batch 3051, train_loss 0.003667,Time used 0.007979s\n",
      "batch 3052, train_loss 0.003810,Time used 0.007979s\n",
      "batch 3053, train_loss 0.003789,Time used 0.007979s\n",
      "batch 3054, train_loss 0.005120,Time used 0.007979s\n",
      "batch 3055, train_loss 0.003548,Time used 0.008975s\n",
      "batch 3056, train_loss 0.004644,Time used 0.007979s\n",
      "batch 3057, train_loss 0.003582,Time used 0.007979s\n",
      "batch 3058, train_loss 0.002942,Time used 0.007978s\n",
      "batch 3059, train_loss 0.002893,Time used 0.007980s\n",
      "batch 3060, train_loss 0.004459,Time used 0.007979s\n",
      "batch 3061, train_loss 0.003046,Time used 0.007978s\n",
      "batch 3062, train_loss 0.004642,Time used 0.008976s\n",
      "batch 3063, train_loss 0.003136,Time used 0.007979s\n",
      "batch 3064, train_loss 0.004016,Time used 0.007978s\n",
      "batch 3065, train_loss 0.002837,Time used 0.007979s\n",
      "batch 3066, train_loss 0.004103,Time used 0.008977s\n",
      "batch 3067, train_loss 0.004526,Time used 0.007978s\n",
      "batch 3068, train_loss 0.002982,Time used 0.008976s\n",
      "batch 3069, train_loss 0.002629,Time used 0.008976s\n",
      "batch 3070, train_loss 0.003297,Time used 0.008976s\n",
      "batch 3071, train_loss 0.004087,Time used 0.007978s\n",
      "batch 3072, train_loss 0.002511,Time used 0.007979s\n",
      "batch 3073, train_loss 0.002701,Time used 0.007979s\n",
      "batch 3074, train_loss 0.003856,Time used 0.007978s\n",
      "batch 3075, train_loss 0.002561,Time used 0.008976s\n",
      "batch 3076, train_loss 0.003306,Time used 0.007978s\n",
      "batch 3077, train_loss 0.002422,Time used 0.007978s\n",
      "batch 3078, train_loss 0.003421,Time used 0.007978s\n",
      "batch 3079, train_loss 0.003460,Time used 0.008976s\n",
      "batch 3080, train_loss 0.003589,Time used 0.007979s\n",
      "batch 3081, train_loss 0.003993,Time used 0.008976s\n",
      "batch 3082, train_loss 0.005062,Time used 0.007979s\n",
      "batch 3083, train_loss 0.003933,Time used 0.008976s\n",
      "batch 3084, train_loss 0.003242,Time used 0.007979s\n",
      "batch 3085, train_loss 0.003415,Time used 0.007978s\n",
      "batch 3086, train_loss 0.002643,Time used 0.008976s\n",
      "batch 3087, train_loss 0.003790,Time used 0.007979s\n",
      "batch 3088, train_loss 0.003782,Time used 0.007978s\n",
      "batch 3089, train_loss 0.003486,Time used 0.007979s\n",
      "batch 3090, train_loss 0.003159,Time used 0.008977s\n",
      "batch 3091, train_loss 0.004947,Time used 0.009005s\n",
      "batch 3092, train_loss 0.002469,Time used 0.009484s\n",
      "batch 3093, train_loss 0.003800,Time used 0.008976s\n",
      "batch 3094, train_loss 0.004266,Time used 0.008976s\n",
      "batch 3095, train_loss 0.003500,Time used 0.008976s\n",
      "batch 3096, train_loss 0.003071,Time used 0.008976s\n",
      "batch 3097, train_loss 0.003250,Time used 0.007978s\n",
      "batch 3098, train_loss 0.003810,Time used 0.007979s\n",
      "batch 3099, train_loss 0.003600,Time used 0.007978s\n",
      "batch 3100, train_loss 0.004416,Time used 0.007979s\n",
      "***************************test_batch 3100, test_rmse_loss 0.060849,test_mae_loss 0.043391,test_mape_loss 12.931769,Time used 0.118683s\n",
      "batch 3101, train_loss 0.003353,Time used 0.008976s\n",
      "batch 3102, train_loss 0.003087,Time used 0.007978s\n",
      "batch 3103, train_loss 0.001541,Time used 0.007979s\n",
      "batch 3104, train_loss 0.002720,Time used 0.009973s\n",
      "batch 3105, train_loss 0.003943,Time used 0.008977s\n",
      "batch 3106, train_loss 0.003651,Time used 0.008975s\n",
      "batch 3107, train_loss 0.004584,Time used 0.008976s\n",
      "batch 3108, train_loss 0.004104,Time used 0.008975s\n",
      "batch 3109, train_loss 0.004423,Time used 0.008976s\n",
      "batch 3110, train_loss 0.003722,Time used 0.007978s\n",
      "batch 3111, train_loss 0.003158,Time used 0.007979s\n",
      "batch 3112, train_loss 0.002924,Time used 0.008976s\n",
      "batch 3113, train_loss 0.003467,Time used 0.008976s\n",
      "batch 3114, train_loss 0.003870,Time used 0.007978s\n",
      "batch 3115, train_loss 0.002169,Time used 0.008975s\n",
      "batch 3116, train_loss 0.003460,Time used 0.009973s\n",
      "batch 3117, train_loss 0.003721,Time used 0.008977s\n",
      "batch 3118, train_loss 0.003277,Time used 0.008976s\n",
      "batch 3119, train_loss 0.003823,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3120, train_loss 0.003113,Time used 0.008976s\n",
      "batch 3121, train_loss 0.004190,Time used 0.008976s\n",
      "batch 3122, train_loss 0.004455,Time used 0.007979s\n",
      "batch 3123, train_loss 0.004300,Time used 0.007979s\n",
      "batch 3124, train_loss 0.003407,Time used 0.007978s\n",
      "batch 3125, train_loss 0.002876,Time used 0.008976s\n",
      "batch 3126, train_loss 0.004257,Time used 0.007978s\n",
      "batch 3127, train_loss 0.003855,Time used 0.007979s\n",
      "batch 3128, train_loss 0.003390,Time used 0.008977s\n",
      "batch 3129, train_loss 0.003393,Time used 0.008975s\n",
      "batch 3130, train_loss 0.006165,Time used 0.008976s\n",
      "batch 3131, train_loss 0.002996,Time used 0.008976s\n",
      "batch 3132, train_loss 0.002197,Time used 0.008975s\n",
      "batch 3133, train_loss 0.003451,Time used 0.008976s\n",
      "batch 3134, train_loss 0.002528,Time used 0.008977s\n",
      "batch 3135, train_loss 0.003325,Time used 0.008976s\n",
      "batch 3136, train_loss 0.003011,Time used 0.007979s\n",
      "batch 3137, train_loss 0.003218,Time used 0.008976s\n",
      "batch 3138, train_loss 0.005155,Time used 0.007979s\n",
      "batch 3139, train_loss 0.003801,Time used 0.007978s\n",
      "batch 3140, train_loss 0.004843,Time used 0.007979s\n",
      "batch 3141, train_loss 0.005067,Time used 0.007979s\n",
      "batch 3142, train_loss 0.004110,Time used 0.008976s\n",
      "batch 3143, train_loss 0.004316,Time used 0.008976s\n",
      "batch 3144, train_loss 0.004311,Time used 0.008976s\n",
      "batch 3145, train_loss 0.003064,Time used 0.008975s\n",
      "batch 3146, train_loss 0.003096,Time used 0.008977s\n",
      "batch 3147, train_loss 0.002868,Time used 0.008975s\n",
      "batch 3148, train_loss 0.003138,Time used 0.009974s\n",
      "batch 3149, train_loss 0.005152,Time used 0.008976s\n",
      "batch 3150, train_loss 0.002136,Time used 0.008976s\n",
      "batch 3151, train_loss 0.003633,Time used 0.007979s\n",
      "batch 3152, train_loss 0.002977,Time used 0.007978s\n",
      "batch 3153, train_loss 0.003996,Time used 0.008977s\n",
      "batch 3154, train_loss 0.003632,Time used 0.007978s\n",
      "batch 3155, train_loss 0.003851,Time used 0.008977s\n",
      "batch 3156, train_loss 0.003228,Time used 0.008976s\n",
      "batch 3157, train_loss 0.004616,Time used 0.007979s\n",
      "batch 3158, train_loss 0.004250,Time used 0.008976s\n",
      "batch 3159, train_loss 0.003347,Time used 0.008976s\n",
      "batch 3160, train_loss 0.003401,Time used 0.007979s\n",
      "batch 3161, train_loss 0.003698,Time used 0.007978s\n",
      "batch 3162, train_loss 0.003118,Time used 0.008976s\n",
      "batch 3163, train_loss 0.003332,Time used 0.007979s\n",
      "batch 3164, train_loss 0.003009,Time used 0.008975s\n",
      "batch 3165, train_loss 0.003967,Time used 0.008976s\n",
      "batch 3166, train_loss 0.004109,Time used 0.008976s\n",
      "batch 3167, train_loss 0.003697,Time used 0.008977s\n",
      "batch 3168, train_loss 0.004086,Time used 0.007978s\n",
      "batch 3169, train_loss 0.002595,Time used 0.007979s\n",
      "batch 3170, train_loss 0.003083,Time used 0.006982s\n",
      "batch 3171, train_loss 0.005195,Time used 0.006981s\n",
      "batch 3172, train_loss 0.003515,Time used 0.007979s\n",
      "batch 3173, train_loss 0.003026,Time used 0.007978s\n",
      "batch 3174, train_loss 0.004031,Time used 0.008976s\n",
      "batch 3175, train_loss 0.002780,Time used 0.008977s\n",
      "batch 3176, train_loss 0.003361,Time used 0.008976s\n",
      "batch 3177, train_loss 0.004336,Time used 0.009974s\n",
      "batch 3178, train_loss 0.002891,Time used 0.009973s\n",
      "batch 3179, train_loss 0.003737,Time used 0.012044s\n",
      "batch 3180, train_loss 0.003719,Time used 0.009974s\n",
      "batch 3181, train_loss 0.003717,Time used 0.009973s\n",
      "batch 3182, train_loss 0.003609,Time used 0.008976s\n",
      "batch 3183, train_loss 0.002777,Time used 0.008977s\n",
      "batch 3184, train_loss 0.003519,Time used 0.007978s\n",
      "batch 3185, train_loss 0.004593,Time used 0.006981s\n",
      "batch 3186, train_loss 0.003838,Time used 0.007979s\n",
      "batch 3187, train_loss 0.003094,Time used 0.007978s\n",
      "batch 3188, train_loss 0.004355,Time used 0.007978s\n",
      "batch 3189, train_loss 0.002966,Time used 0.007978s\n",
      "batch 3190, train_loss 0.004218,Time used 0.007979s\n",
      "batch 3191, train_loss 0.004253,Time used 0.007978s\n",
      "batch 3192, train_loss 0.003665,Time used 0.007979s\n",
      "batch 3193, train_loss 0.003593,Time used 0.007979s\n",
      "batch 3194, train_loss 0.003420,Time used 0.008976s\n",
      "batch 3195, train_loss 0.003209,Time used 0.008976s\n",
      "batch 3196, train_loss 0.003022,Time used 0.008976s\n",
      "batch 3197, train_loss 0.003846,Time used 0.008976s\n",
      "batch 3198, train_loss 0.003697,Time used 0.007978s\n",
      "batch 3199, train_loss 0.005062,Time used 0.007979s\n",
      "batch 3200, train_loss 0.002757,Time used 0.008977s\n",
      "***************************test_batch 3200, test_rmse_loss 0.060856,test_mae_loss 0.043398,test_mape_loss 12.984704,Time used 0.105717s\n",
      "batch 3201, train_loss 0.003377,Time used 0.007978s\n",
      "batch 3202, train_loss 0.004456,Time used 0.007978s\n",
      "batch 3203, train_loss 0.004237,Time used 0.008487s\n",
      "batch 3204, train_loss 0.003504,Time used 0.008977s\n",
      "batch 3205, train_loss 0.003271,Time used 0.007978s\n",
      "batch 3206, train_loss 0.003743,Time used 0.007979s\n",
      "batch 3207, train_loss 0.003947,Time used 0.008976s\n",
      "batch 3208, train_loss 0.003451,Time used 0.008976s\n",
      "batch 3209, train_loss 0.003400,Time used 0.007978s\n",
      "batch 3210, train_loss 0.003831,Time used 0.006981s\n",
      "batch 3211, train_loss 0.003693,Time used 0.008976s\n",
      "batch 3212, train_loss 0.003242,Time used 0.007979s\n",
      "batch 3213, train_loss 0.004073,Time used 0.008975s\n",
      "batch 3214, train_loss 0.003108,Time used 0.007980s\n",
      "batch 3215, train_loss 0.003181,Time used 0.008487s\n",
      "batch 3216, train_loss 0.003421,Time used 0.008976s\n",
      "batch 3217, train_loss 0.004028,Time used 0.006981s\n",
      "batch 3218, train_loss 0.003755,Time used 0.008976s\n",
      "batch 3219, train_loss 0.003892,Time used 0.009974s\n",
      "batch 3220, train_loss 0.003286,Time used 0.008975s\n",
      "batch 3221, train_loss 0.002402,Time used 0.008976s\n",
      "batch 3222, train_loss 0.004841,Time used 0.007979s\n",
      "batch 3223, train_loss 0.004961,Time used 0.008976s\n",
      "batch 3224, train_loss 0.003822,Time used 0.007978s\n",
      "batch 3225, train_loss 0.003722,Time used 0.008976s\n",
      "batch 3226, train_loss 0.004753,Time used 0.007978s\n",
      "batch 3227, train_loss 0.002711,Time used 0.008976s\n",
      "batch 3228, train_loss 0.003126,Time used 0.008976s\n",
      "batch 3229, train_loss 0.003143,Time used 0.008976s\n",
      "batch 3230, train_loss 0.002910,Time used 0.008976s\n",
      "batch 3231, train_loss 0.003678,Time used 0.007979s\n",
      "batch 3232, train_loss 0.003444,Time used 0.006982s\n",
      "batch 3233, train_loss 0.005166,Time used 0.007979s\n",
      "batch 3234, train_loss 0.004191,Time used 0.008976s\n",
      "batch 3235, train_loss 0.003932,Time used 0.007978s\n",
      "batch 3236, train_loss 0.002637,Time used 0.007980s\n",
      "batch 3237, train_loss 0.002797,Time used 0.007979s\n",
      "batch 3238, train_loss 0.004884,Time used 0.008977s\n",
      "batch 3239, train_loss 0.003262,Time used 0.007978s\n",
      "batch 3240, train_loss 0.004858,Time used 0.007978s\n",
      "batch 3241, train_loss 0.004065,Time used 0.007979s\n",
      "batch 3242, train_loss 0.004300,Time used 0.008975s\n",
      "batch 3243, train_loss 0.003061,Time used 0.008977s\n",
      "batch 3244, train_loss 0.003719,Time used 0.007978s\n",
      "batch 3245, train_loss 0.002910,Time used 0.007980s\n",
      "batch 3246, train_loss 0.003252,Time used 0.008976s\n",
      "batch 3247, train_loss 0.003868,Time used 0.007978s\n",
      "batch 3248, train_loss 0.003487,Time used 0.007978s\n",
      "batch 3249, train_loss 0.004128,Time used 0.007979s\n",
      "batch 3250, train_loss 0.003805,Time used 0.007978s\n",
      "batch 3251, train_loss 0.003397,Time used 0.007979s\n",
      "batch 3252, train_loss 0.003197,Time used 0.007980s\n",
      "batch 3253, train_loss 0.003127,Time used 0.009973s\n",
      "batch 3254, train_loss 0.002620,Time used 0.009973s\n",
      "batch 3255, train_loss 0.002949,Time used 0.010971s\n",
      "batch 3256, train_loss 0.003269,Time used 0.009973s\n",
      "batch 3257, train_loss 0.003429,Time used 0.018950s\n",
      "batch 3258, train_loss 0.003465,Time used 0.011968s\n",
      "batch 3259, train_loss 0.003311,Time used 0.009973s\n",
      "batch 3260, train_loss 0.002500,Time used 0.009974s\n",
      "batch 3261, train_loss 0.004702,Time used 0.011968s\n",
      "batch 3262, train_loss 0.004177,Time used 0.008977s\n",
      "batch 3263, train_loss 0.003771,Time used 0.008975s\n",
      "batch 3264, train_loss 0.003319,Time used 0.009974s\n",
      "batch 3265, train_loss 0.003585,Time used 0.008976s\n",
      "batch 3266, train_loss 0.003773,Time used 0.008976s\n",
      "batch 3267, train_loss 0.003082,Time used 0.009974s\n",
      "batch 3268, train_loss 0.003414,Time used 0.008976s\n",
      "batch 3269, train_loss 0.003292,Time used 0.008976s\n",
      "batch 3270, train_loss 0.005167,Time used 0.008976s\n",
      "batch 3271, train_loss 0.004589,Time used 0.009973s\n",
      "batch 3272, train_loss 0.003449,Time used 0.009974s\n",
      "batch 3273, train_loss 0.003264,Time used 0.008976s\n",
      "batch 3274, train_loss 0.003990,Time used 0.008976s\n",
      "batch 3275, train_loss 0.004710,Time used 0.009974s\n",
      "batch 3276, train_loss 0.003045,Time used 0.009973s\n",
      "batch 3277, train_loss 0.002674,Time used 0.009974s\n",
      "batch 3278, train_loss 0.003644,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3279, train_loss 0.004502,Time used 0.008976s\n",
      "batch 3280, train_loss 0.003832,Time used 0.008976s\n",
      "batch 3281, train_loss 0.003029,Time used 0.008975s\n",
      "batch 3282, train_loss 0.003292,Time used 0.007979s\n",
      "batch 3283, train_loss 0.003045,Time used 0.007979s\n",
      "batch 3284, train_loss 0.002622,Time used 0.008975s\n",
      "batch 3285, train_loss 0.004198,Time used 0.008976s\n",
      "batch 3286, train_loss 0.003931,Time used 0.008976s\n",
      "batch 3287, train_loss 0.003901,Time used 0.008977s\n",
      "batch 3288, train_loss 0.002797,Time used 0.009974s\n",
      "batch 3289, train_loss 0.004121,Time used 0.008976s\n",
      "batch 3290, train_loss 0.003496,Time used 0.008976s\n",
      "batch 3291, train_loss 0.004662,Time used 0.007979s\n",
      "batch 3292, train_loss 0.004158,Time used 0.008976s\n",
      "batch 3293, train_loss 0.004018,Time used 0.009973s\n",
      "batch 3294, train_loss 0.005653,Time used 0.008976s\n",
      "batch 3295, train_loss 0.004139,Time used 0.008976s\n",
      "batch 3296, train_loss 0.003664,Time used 0.008976s\n",
      "batch 3297, train_loss 0.003572,Time used 0.008976s\n",
      "batch 3298, train_loss 0.003615,Time used 0.008976s\n",
      "batch 3299, train_loss 0.004793,Time used 0.008975s\n",
      "batch 3300, train_loss 0.003716,Time used 0.008975s\n",
      "***************************test_batch 3300, test_rmse_loss 0.060843,test_mae_loss 0.043398,test_mape_loss 12.913483,Time used 0.123670s\n",
      "batch 3301, train_loss 0.003238,Time used 0.008976s\n",
      "batch 3302, train_loss 0.003503,Time used 0.008976s\n",
      "batch 3303, train_loss 0.003484,Time used 0.008976s\n",
      "batch 3304, train_loss 0.003755,Time used 0.008975s\n",
      "batch 3305, train_loss 0.003016,Time used 0.008976s\n",
      "batch 3306, train_loss 0.003961,Time used 0.009973s\n",
      "batch 3307, train_loss 0.003100,Time used 0.009973s\n",
      "batch 3308, train_loss 0.003791,Time used 0.008976s\n",
      "batch 3309, train_loss 0.003214,Time used 0.008977s\n",
      "batch 3310, train_loss 0.004224,Time used 0.010970s\n",
      "batch 3311, train_loss 0.003455,Time used 0.009974s\n",
      "batch 3312, train_loss 0.003365,Time used 0.009972s\n",
      "batch 3313, train_loss 0.003897,Time used 0.009974s\n",
      "batch 3314, train_loss 0.002354,Time used 0.009973s\n",
      "batch 3315, train_loss 0.004905,Time used 0.009973s\n",
      "batch 3316, train_loss 0.003396,Time used 0.008975s\n",
      "batch 3317, train_loss 0.001516,Time used 0.007979s\n",
      "batch 3318, train_loss 0.003427,Time used 0.009973s\n",
      "batch 3319, train_loss 0.002190,Time used 0.009973s\n",
      "batch 3320, train_loss 0.003136,Time used 0.008975s\n",
      "batch 3321, train_loss 0.003605,Time used 0.008977s\n",
      "batch 3322, train_loss 0.003309,Time used 0.008975s\n",
      "batch 3323, train_loss 0.003797,Time used 0.008976s\n",
      "batch 3324, train_loss 0.002768,Time used 0.009974s\n",
      "batch 3325, train_loss 0.003199,Time used 0.008975s\n",
      "batch 3326, train_loss 0.004425,Time used 0.008977s\n",
      "batch 3327, train_loss 0.003053,Time used 0.008976s\n",
      "batch 3328, train_loss 0.003521,Time used 0.008977s\n",
      "batch 3329, train_loss 0.002692,Time used 0.008976s\n",
      "batch 3330, train_loss 0.002973,Time used 0.008976s\n",
      "batch 3331, train_loss 0.004336,Time used 0.008975s\n",
      "batch 3332, train_loss 0.005721,Time used 0.009974s\n",
      "batch 3333, train_loss 0.003431,Time used 0.008976s\n",
      "batch 3334, train_loss 0.003594,Time used 0.008976s\n",
      "batch 3335, train_loss 0.005654,Time used 0.008977s\n",
      "batch 3336, train_loss 0.004489,Time used 0.008975s\n",
      "batch 3337, train_loss 0.005711,Time used 0.008977s\n",
      "batch 3338, train_loss 0.002956,Time used 0.008976s\n",
      "batch 3339, train_loss 0.005464,Time used 0.008976s\n",
      "batch 3340, train_loss 0.003183,Time used 0.009974s\n",
      "batch 3341, train_loss 0.004062,Time used 0.008976s\n",
      "batch 3342, train_loss 0.003286,Time used 0.008976s\n",
      "batch 3343, train_loss 0.003829,Time used 0.009974s\n",
      "batch 3344, train_loss 0.003030,Time used 0.010481s\n",
      "batch 3345, train_loss 0.003245,Time used 0.007979s\n",
      "batch 3346, train_loss 0.003792,Time used 0.008976s\n",
      "batch 3347, train_loss 0.003757,Time used 0.008976s\n",
      "batch 3348, train_loss 0.002850,Time used 0.008976s\n",
      "batch 3349, train_loss 0.004342,Time used 0.008976s\n",
      "batch 3350, train_loss 0.003941,Time used 0.008976s\n",
      "batch 3351, train_loss 0.003661,Time used 0.008976s\n",
      "batch 3352, train_loss 0.003463,Time used 0.008976s\n",
      "batch 3353, train_loss 0.004880,Time used 0.009973s\n",
      "batch 3354, train_loss 0.006391,Time used 0.009973s\n",
      "batch 3355, train_loss 0.003899,Time used 0.009973s\n",
      "batch 3356, train_loss 0.002945,Time used 0.008976s\n",
      "batch 3357, train_loss 0.002752,Time used 0.009974s\n",
      "batch 3358, train_loss 0.003138,Time used 0.009973s\n",
      "batch 3359, train_loss 0.002437,Time used 0.008976s\n",
      "batch 3360, train_loss 0.003583,Time used 0.009974s\n",
      "batch 3361, train_loss 0.004888,Time used 0.008976s\n",
      "batch 3362, train_loss 0.003593,Time used 0.009974s\n",
      "batch 3363, train_loss 0.003823,Time used 0.009973s\n",
      "batch 3364, train_loss 0.004396,Time used 0.008976s\n",
      "batch 3365, train_loss 0.005602,Time used 0.009973s\n",
      "batch 3366, train_loss 0.002578,Time used 0.007979s\n",
      "batch 3367, train_loss 0.003661,Time used 0.009972s\n",
      "batch 3368, train_loss 0.003186,Time used 0.010972s\n",
      "batch 3369, train_loss 0.004017,Time used 0.010970s\n",
      "batch 3370, train_loss 0.003048,Time used 0.009973s\n",
      "batch 3371, train_loss 0.003565,Time used 0.009973s\n",
      "batch 3372, train_loss 0.004213,Time used 0.009974s\n",
      "batch 3373, train_loss 0.002768,Time used 0.009973s\n",
      "batch 3374, train_loss 0.004030,Time used 0.009974s\n",
      "batch 3375, train_loss 0.002950,Time used 0.009973s\n",
      "batch 3376, train_loss 0.003293,Time used 0.008976s\n",
      "batch 3377, train_loss 0.003137,Time used 0.009974s\n",
      "batch 3378, train_loss 0.003418,Time used 0.009974s\n",
      "batch 3379, train_loss 0.003748,Time used 0.009973s\n",
      "batch 3380, train_loss 0.004144,Time used 0.008976s\n",
      "batch 3381, train_loss 0.003960,Time used 0.009973s\n",
      "batch 3382, train_loss 0.003685,Time used 0.008975s\n",
      "batch 3383, train_loss 0.002114,Time used 0.008976s\n",
      "batch 3384, train_loss 0.003423,Time used 0.008976s\n",
      "batch 3385, train_loss 0.004288,Time used 0.008976s\n",
      "batch 3386, train_loss 0.002889,Time used 0.008974s\n",
      "batch 3387, train_loss 0.003597,Time used 0.008976s\n",
      "batch 3388, train_loss 0.002789,Time used 0.008976s\n",
      "batch 3389, train_loss 0.002555,Time used 0.008976s\n",
      "batch 3390, train_loss 0.004577,Time used 0.009974s\n",
      "batch 3391, train_loss 0.005173,Time used 0.008976s\n",
      "batch 3392, train_loss 0.003438,Time used 0.008976s\n",
      "batch 3393, train_loss 0.003555,Time used 0.008977s\n",
      "batch 3394, train_loss 0.003110,Time used 0.008977s\n",
      "batch 3395, train_loss 0.003416,Time used 0.008977s\n",
      "batch 3396, train_loss 0.004293,Time used 0.009973s\n",
      "batch 3397, train_loss 0.004164,Time used 0.008975s\n",
      "batch 3398, train_loss 0.002886,Time used 0.008976s\n",
      "batch 3399, train_loss 0.003332,Time used 0.008977s\n",
      "batch 3400, train_loss 0.003777,Time used 0.009973s\n",
      "***************************test_batch 3400, test_rmse_loss 0.060836,test_mae_loss 0.043379,test_mape_loss 12.948856,Time used 0.117686s\n",
      "batch 3401, train_loss 0.003700,Time used 0.009973s\n",
      "batch 3402, train_loss 0.003076,Time used 0.008976s\n",
      "batch 3403, train_loss 0.002789,Time used 0.008976s\n",
      "batch 3404, train_loss 0.003279,Time used 0.008977s\n",
      "batch 3405, train_loss 0.002970,Time used 0.008975s\n",
      "batch 3406, train_loss 0.004316,Time used 0.008976s\n",
      "batch 3407, train_loss 0.004294,Time used 0.010971s\n",
      "batch 3408, train_loss 0.004968,Time used 0.009974s\n",
      "batch 3409, train_loss 0.002159,Time used 0.007979s\n",
      "batch 3410, train_loss 0.003287,Time used 0.007977s\n",
      "batch 3411, train_loss 0.003206,Time used 0.008976s\n",
      "batch 3412, train_loss 0.003738,Time used 0.007978s\n",
      "batch 3413, train_loss 0.003081,Time used 0.007979s\n",
      "batch 3414, train_loss 0.003052,Time used 0.008975s\n",
      "batch 3415, train_loss 0.002874,Time used 0.008976s\n",
      "batch 3416, train_loss 0.003371,Time used 0.008976s\n",
      "batch 3417, train_loss 0.005800,Time used 0.008976s\n",
      "batch 3418, train_loss 0.004347,Time used 0.008976s\n",
      "batch 3419, train_loss 0.003986,Time used 0.008976s\n",
      "batch 3420, train_loss 0.003111,Time used 0.008976s\n",
      "batch 3421, train_loss 0.003128,Time used 0.008976s\n",
      "batch 3422, train_loss 0.003980,Time used 0.008976s\n",
      "batch 3423, train_loss 0.003797,Time used 0.008976s\n",
      "batch 3424, train_loss 0.003766,Time used 0.007978s\n",
      "batch 3425, train_loss 0.003251,Time used 0.008975s\n",
      "batch 3426, train_loss 0.004468,Time used 0.007979s\n",
      "batch 3427, train_loss 0.003660,Time used 0.008977s\n",
      "batch 3428, train_loss 0.003799,Time used 0.009973s\n",
      "batch 3429, train_loss 0.003071,Time used 0.009973s\n",
      "batch 3430, train_loss 0.004952,Time used 0.008485s\n",
      "batch 3431, train_loss 0.004914,Time used 0.007979s\n",
      "batch 3432, train_loss 0.003819,Time used 0.008976s\n",
      "batch 3433, train_loss 0.003248,Time used 0.008977s\n",
      "batch 3434, train_loss 0.003677,Time used 0.008976s\n",
      "batch 3435, train_loss 0.004068,Time used 0.008976s\n",
      "batch 3436, train_loss 0.003340,Time used 0.008976s\n",
      "batch 3437, train_loss 0.003709,Time used 0.008976s\n",
      "batch 3438, train_loss 0.002819,Time used 0.009973s\n",
      "batch 3439, train_loss 0.002618,Time used 0.009973s\n",
      "batch 3440, train_loss 0.004355,Time used 0.008976s\n",
      "batch 3441, train_loss 0.003379,Time used 0.009974s\n",
      "batch 3442, train_loss 0.003832,Time used 0.009973s\n",
      "batch 3443, train_loss 0.002805,Time used 0.009974s\n",
      "batch 3444, train_loss 0.004599,Time used 0.009973s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3445, train_loss 0.003455,Time used 0.009974s\n",
      "batch 3446, train_loss 0.003202,Time used 0.010971s\n",
      "batch 3447, train_loss 0.004058,Time used 0.008976s\n",
      "batch 3448, train_loss 0.003174,Time used 0.009973s\n",
      "batch 3449, train_loss 0.002971,Time used 0.009973s\n",
      "batch 3450, train_loss 0.003890,Time used 0.009974s\n",
      "batch 3451, train_loss 0.003409,Time used 0.008975s\n",
      "batch 3452, train_loss 0.002640,Time used 0.008977s\n",
      "batch 3453, train_loss 0.004802,Time used 0.009973s\n",
      "batch 3454, train_loss 0.002711,Time used 0.009974s\n",
      "batch 3455, train_loss 0.003549,Time used 0.008975s\n",
      "batch 3456, train_loss 0.003573,Time used 0.008976s\n",
      "batch 3457, train_loss 0.002644,Time used 0.008976s\n",
      "batch 3458, train_loss 0.004153,Time used 0.008976s\n",
      "batch 3459, train_loss 0.002367,Time used 0.008976s\n",
      "batch 3460, train_loss 0.004485,Time used 0.008976s\n",
      "batch 3461, train_loss 0.004037,Time used 0.008977s\n",
      "batch 3462, train_loss 0.003374,Time used 0.008976s\n",
      "batch 3463, train_loss 0.006708,Time used 0.009973s\n",
      "batch 3464, train_loss 0.002255,Time used 0.030939s\n",
      "batch 3465, train_loss 0.004154,Time used 0.011968s\n",
      "batch 3466, train_loss 0.002974,Time used 0.013963s\n",
      "batch 3467, train_loss 0.004589,Time used 0.019946s\n",
      "batch 3468, train_loss 0.003499,Time used 0.011968s\n",
      "batch 3469, train_loss 0.004061,Time used 0.011967s\n",
      "batch 3470, train_loss 0.003178,Time used 0.009973s\n",
      "batch 3471, train_loss 0.002667,Time used 0.012966s\n",
      "batch 3472, train_loss 0.003363,Time used 0.013963s\n",
      "batch 3473, train_loss 0.004068,Time used 0.011969s\n",
      "batch 3474, train_loss 0.004043,Time used 0.011969s\n",
      "batch 3475, train_loss 0.004833,Time used 0.012964s\n",
      "batch 3476, train_loss 0.002427,Time used 0.009974s\n",
      "batch 3477, train_loss 0.003260,Time used 0.010971s\n",
      "batch 3478, train_loss 0.004255,Time used 0.014959s\n",
      "batch 3479, train_loss 0.002696,Time used 0.011967s\n",
      "batch 3480, train_loss 0.003363,Time used 0.010971s\n",
      "batch 3481, train_loss 0.002822,Time used 0.008976s\n",
      "batch 3482, train_loss 0.003722,Time used 0.010971s\n",
      "batch 3483, train_loss 0.003132,Time used 0.009210s\n",
      "batch 3484, train_loss 0.003838,Time used 0.009973s\n",
      "batch 3485, train_loss 0.003183,Time used 0.008977s\n",
      "batch 3486, train_loss 0.003687,Time used 0.007978s\n",
      "batch 3487, train_loss 0.003161,Time used 0.009974s\n",
      "batch 3488, train_loss 0.003011,Time used 0.008976s\n",
      "batch 3489, train_loss 0.003123,Time used 0.008976s\n",
      "batch 3490, train_loss 0.003190,Time used 0.008976s\n",
      "batch 3491, train_loss 0.003205,Time used 0.008975s\n",
      "batch 3492, train_loss 0.003597,Time used 0.007979s\n",
      "batch 3493, train_loss 0.002441,Time used 0.007978s\n",
      "batch 3494, train_loss 0.002755,Time used 0.008977s\n",
      "batch 3495, train_loss 0.003619,Time used 0.008977s\n",
      "batch 3496, train_loss 0.004149,Time used 0.009973s\n",
      "batch 3497, train_loss 0.003802,Time used 0.009973s\n",
      "batch 3498, train_loss 0.002846,Time used 0.009974s\n",
      "batch 3499, train_loss 0.004089,Time used 0.008976s\n",
      "batch 3500, train_loss 0.003520,Time used 0.008975s\n",
      "***************************test_batch 3500, test_rmse_loss 0.060832,test_mae_loss 0.043380,test_mape_loss 12.941188,Time used 0.120677s\n",
      "batch 3501, train_loss 0.003360,Time used 0.008976s\n",
      "batch 3502, train_loss 0.004079,Time used 0.008976s\n",
      "batch 3503, train_loss 0.002918,Time used 0.008976s\n",
      "batch 3504, train_loss 0.005016,Time used 0.008976s\n",
      "batch 3505, train_loss 0.003783,Time used 0.007978s\n",
      "batch 3506, train_loss 0.005217,Time used 0.008976s\n",
      "batch 3507, train_loss 0.005143,Time used 0.008976s\n",
      "batch 3508, train_loss 0.004292,Time used 0.009973s\n",
      "batch 3509, train_loss 0.002950,Time used 0.008976s\n",
      "batch 3510, train_loss 0.004610,Time used 0.008976s\n",
      "batch 3511, train_loss 0.004207,Time used 0.008976s\n",
      "batch 3512, train_loss 0.003754,Time used 0.008976s\n",
      "batch 3513, train_loss 0.004092,Time used 0.007979s\n",
      "batch 3514, train_loss 0.003927,Time used 0.008976s\n",
      "batch 3515, train_loss 0.004138,Time used 0.008976s\n",
      "batch 3516, train_loss 0.003931,Time used 0.008976s\n",
      "batch 3517, train_loss 0.002635,Time used 0.007978s\n",
      "batch 3518, train_loss 0.005188,Time used 0.007979s\n",
      "batch 3519, train_loss 0.004990,Time used 0.008975s\n",
      "batch 3520, train_loss 0.003921,Time used 0.008977s\n",
      "batch 3521, train_loss 0.003245,Time used 0.008976s\n",
      "batch 3522, train_loss 0.003217,Time used 0.008976s\n",
      "batch 3523, train_loss 0.003966,Time used 0.008976s\n",
      "batch 3524, train_loss 0.002793,Time used 0.008976s\n",
      "batch 3525, train_loss 0.003695,Time used 0.009973s\n",
      "batch 3526, train_loss 0.004182,Time used 0.008976s\n",
      "batch 3527, train_loss 0.004720,Time used 0.008976s\n",
      "batch 3528, train_loss 0.003583,Time used 0.008977s\n",
      "batch 3529, train_loss 0.002929,Time used 0.008976s\n",
      "batch 3530, train_loss 0.003790,Time used 0.008976s\n",
      "batch 3531, train_loss 0.003085,Time used 0.006982s\n",
      "batch 3532, train_loss 0.004633,Time used 0.007979s\n",
      "batch 3533, train_loss 0.003726,Time used 0.008976s\n",
      "batch 3534, train_loss 0.002966,Time used 0.008976s\n",
      "batch 3535, train_loss 0.003332,Time used 0.007975s\n",
      "batch 3536, train_loss 0.002496,Time used 0.008977s\n",
      "batch 3537, train_loss 0.003504,Time used 0.008976s\n",
      "batch 3538, train_loss 0.005874,Time used 0.008977s\n",
      "batch 3539, train_loss 0.003929,Time used 0.008975s\n",
      "batch 3540, train_loss 0.004300,Time used 0.009974s\n",
      "batch 3541, train_loss 0.003541,Time used 0.008976s\n",
      "batch 3542, train_loss 0.003995,Time used 0.008976s\n",
      "batch 3543, train_loss 0.003461,Time used 0.010970s\n",
      "batch 3544, train_loss 0.003371,Time used 0.009973s\n",
      "batch 3545, train_loss 0.003506,Time used 0.008976s\n",
      "batch 3546, train_loss 0.005547,Time used 0.008976s\n",
      "batch 3547, train_loss 0.003135,Time used 0.008976s\n",
      "batch 3548, train_loss 0.003409,Time used 0.008977s\n",
      "batch 3549, train_loss 0.005678,Time used 0.008977s\n",
      "batch 3550, train_loss 0.003336,Time used 0.008976s\n",
      "batch 3551, train_loss 0.004522,Time used 0.008976s\n",
      "batch 3552, train_loss 0.002919,Time used 0.008976s\n",
      "batch 3553, train_loss 0.002930,Time used 0.009974s\n",
      "batch 3554, train_loss 0.002620,Time used 0.009973s\n",
      "batch 3555, train_loss 0.003743,Time used 0.008976s\n",
      "batch 3556, train_loss 0.004163,Time used 0.008977s\n",
      "batch 3557, train_loss 0.003876,Time used 0.009973s\n",
      "batch 3558, train_loss 0.003620,Time used 0.009973s\n",
      "batch 3559, train_loss 0.003764,Time used 0.009974s\n",
      "batch 3560, train_loss 0.004939,Time used 0.009973s\n",
      "batch 3561, train_loss 0.004208,Time used 0.009974s\n",
      "batch 3562, train_loss 0.004387,Time used 0.009974s\n",
      "batch 3563, train_loss 0.003675,Time used 0.010971s\n",
      "batch 3564, train_loss 0.002885,Time used 0.009973s\n",
      "batch 3565, train_loss 0.003760,Time used 0.009973s\n",
      "batch 3566, train_loss 0.004075,Time used 0.009974s\n",
      "batch 3567, train_loss 0.002853,Time used 0.008976s\n",
      "batch 3568, train_loss 0.003370,Time used 0.008976s\n",
      "batch 3569, train_loss 0.002744,Time used 0.008976s\n",
      "batch 3570, train_loss 0.002849,Time used 0.009974s\n",
      "batch 3571, train_loss 0.002862,Time used 0.008976s\n",
      "batch 3572, train_loss 0.003117,Time used 0.008977s\n",
      "batch 3573, train_loss 0.003374,Time used 0.009973s\n",
      "batch 3574, train_loss 0.004003,Time used 0.008976s\n",
      "batch 3575, train_loss 0.003753,Time used 0.008976s\n",
      "batch 3576, train_loss 0.003935,Time used 0.007979s\n",
      "batch 3577, train_loss 0.003851,Time used 0.008977s\n",
      "batch 3578, train_loss 0.003236,Time used 0.007979s\n",
      "batch 3579, train_loss 0.002360,Time used 0.008976s\n",
      "batch 3580, train_loss 0.004695,Time used 0.007978s\n",
      "batch 3581, train_loss 0.004301,Time used 0.008977s\n",
      "batch 3582, train_loss 0.003918,Time used 0.008976s\n",
      "batch 3583, train_loss 0.003708,Time used 0.008976s\n",
      "batch 3584, train_loss 0.003414,Time used 0.008976s\n",
      "batch 3585, train_loss 0.003548,Time used 0.007979s\n",
      "batch 3586, train_loss 0.002925,Time used 0.008976s\n",
      "batch 3587, train_loss 0.003932,Time used 0.007978s\n",
      "batch 3588, train_loss 0.002493,Time used 0.007978s\n",
      "batch 3589, train_loss 0.003727,Time used 0.008976s\n",
      "batch 3590, train_loss 0.003595,Time used 0.008976s\n",
      "batch 3591, train_loss 0.003013,Time used 0.008977s\n",
      "batch 3592, train_loss 0.003192,Time used 0.007979s\n",
      "batch 3593, train_loss 0.002809,Time used 0.008487s\n",
      "batch 3594, train_loss 0.003480,Time used 0.008976s\n",
      "batch 3595, train_loss 0.007028,Time used 0.007979s\n",
      "batch 3596, train_loss 0.003159,Time used 0.008976s\n",
      "batch 3597, train_loss 0.003702,Time used 0.008976s\n",
      "batch 3598, train_loss 0.002712,Time used 0.008976s\n",
      "batch 3599, train_loss 0.002584,Time used 0.008977s\n",
      "batch 3600, train_loss 0.003950,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************test_batch 3600, test_rmse_loss 0.061094,test_mae_loss 0.043598,test_mape_loss 12.788255,Time used 0.115690s\n",
      "batch 3601, train_loss 0.002820,Time used 0.008976s\n",
      "batch 3602, train_loss 0.004030,Time used 0.009974s\n",
      "batch 3603, train_loss 0.004671,Time used 0.009974s\n",
      "batch 3604, train_loss 0.004134,Time used 0.008976s\n",
      "batch 3605, train_loss 0.003631,Time used 0.008976s\n",
      "batch 3606, train_loss 0.003245,Time used 0.008977s\n",
      "batch 3607, train_loss 0.004341,Time used 0.009973s\n",
      "batch 3608, train_loss 0.003407,Time used 0.008975s\n",
      "batch 3609, train_loss 0.003090,Time used 0.008976s\n",
      "batch 3610, train_loss 0.003553,Time used 0.008976s\n",
      "batch 3611, train_loss 0.003121,Time used 0.009974s\n",
      "batch 3612, train_loss 0.003750,Time used 0.008976s\n",
      "batch 3613, train_loss 0.002864,Time used 0.008976s\n",
      "batch 3614, train_loss 0.002767,Time used 0.009974s\n",
      "batch 3615, train_loss 0.003326,Time used 0.008976s\n",
      "batch 3616, train_loss 0.003075,Time used 0.009973s\n",
      "batch 3617, train_loss 0.003286,Time used 0.009973s\n",
      "batch 3618, train_loss 0.003720,Time used 0.009974s\n",
      "batch 3619, train_loss 0.003249,Time used 0.010970s\n",
      "batch 3620, train_loss 0.004711,Time used 0.008976s\n",
      "batch 3621, train_loss 0.003848,Time used 0.009973s\n",
      "batch 3622, train_loss 0.005427,Time used 0.008977s\n",
      "batch 3623, train_loss 0.003284,Time used 0.008976s\n",
      "batch 3624, train_loss 0.003854,Time used 0.009972s\n",
      "batch 3625, train_loss 0.003579,Time used 0.008977s\n",
      "batch 3626, train_loss 0.004073,Time used 0.008976s\n",
      "batch 3627, train_loss 0.003456,Time used 0.008976s\n",
      "batch 3628, train_loss 0.004541,Time used 0.009974s\n",
      "batch 3629, train_loss 0.003172,Time used 0.008975s\n",
      "batch 3630, train_loss 0.003493,Time used 0.007979s\n",
      "batch 3631, train_loss 0.003405,Time used 0.008975s\n",
      "batch 3632, train_loss 0.003953,Time used 0.007978s\n",
      "batch 3633, train_loss 0.003269,Time used 0.007980s\n",
      "batch 3634, train_loss 0.004704,Time used 0.008976s\n",
      "batch 3635, train_loss 0.003032,Time used 0.008976s\n",
      "batch 3636, train_loss 0.003607,Time used 0.008976s\n",
      "batch 3637, train_loss 0.003649,Time used 0.007979s\n",
      "batch 3638, train_loss 0.003173,Time used 0.006980s\n",
      "batch 3639, train_loss 0.003099,Time used 0.008975s\n",
      "batch 3640, train_loss 0.004465,Time used 0.009973s\n",
      "batch 3641, train_loss 0.002147,Time used 0.007979s\n",
      "batch 3642, train_loss 0.002928,Time used 0.008486s\n",
      "batch 3643, train_loss 0.002543,Time used 0.008488s\n",
      "batch 3644, train_loss 0.003994,Time used 0.008976s\n",
      "batch 3645, train_loss 0.003767,Time used 0.007979s\n",
      "batch 3646, train_loss 0.003437,Time used 0.008976s\n",
      "batch 3647, train_loss 0.003679,Time used 0.008976s\n",
      "batch 3648, train_loss 0.004250,Time used 0.008977s\n",
      "batch 3649, train_loss 0.002883,Time used 0.008976s\n",
      "batch 3650, train_loss 0.003121,Time used 0.008976s\n",
      "batch 3651, train_loss 0.003859,Time used 0.008977s\n",
      "batch 3652, train_loss 0.003722,Time used 0.008976s\n",
      "batch 3653, train_loss 0.006151,Time used 0.009974s\n",
      "batch 3654, train_loss 0.003005,Time used 0.008976s\n",
      "batch 3655, train_loss 0.004079,Time used 0.009974s\n",
      "batch 3656, train_loss 0.003127,Time used 0.009972s\n",
      "batch 3657, train_loss 0.006059,Time used 0.011968s\n",
      "batch 3658, train_loss 0.004035,Time used 0.008976s\n",
      "batch 3659, train_loss 0.003792,Time used 0.008976s\n",
      "batch 3660, train_loss 0.003915,Time used 0.008976s\n",
      "batch 3661, train_loss 0.003624,Time used 0.008976s\n",
      "batch 3662, train_loss 0.004119,Time used 0.008977s\n",
      "batch 3663, train_loss 0.002233,Time used 0.009197s\n",
      "batch 3664, train_loss 0.003246,Time used 0.007979s\n",
      "batch 3665, train_loss 0.003541,Time used 0.008975s\n",
      "batch 3666, train_loss 0.003063,Time used 0.008976s\n",
      "batch 3667, train_loss 0.003487,Time used 0.009973s\n",
      "batch 3668, train_loss 0.004033,Time used 0.008976s\n",
      "batch 3669, train_loss 0.003084,Time used 0.007979s\n",
      "batch 3670, train_loss 0.003009,Time used 0.008975s\n",
      "batch 3671, train_loss 0.004536,Time used 0.009974s\n",
      "batch 3672, train_loss 0.005522,Time used 0.008976s\n",
      "batch 3673, train_loss 0.004660,Time used 0.008976s\n",
      "batch 3674, train_loss 0.003444,Time used 0.008976s\n",
      "batch 3675, train_loss 0.004546,Time used 0.008977s\n",
      "batch 3676, train_loss 0.004321,Time used 0.008975s\n",
      "batch 3677, train_loss 0.003240,Time used 0.010972s\n",
      "batch 3678, train_loss 0.003165,Time used 0.008977s\n",
      "batch 3679, train_loss 0.003428,Time used 0.009974s\n",
      "batch 3680, train_loss 0.004148,Time used 0.010970s\n",
      "batch 3681, train_loss 0.003628,Time used 0.009974s\n",
      "batch 3682, train_loss 0.003906,Time used 0.009973s\n",
      "batch 3683, train_loss 0.003793,Time used 0.008975s\n",
      "batch 3684, train_loss 0.002668,Time used 0.009974s\n",
      "batch 3685, train_loss 0.003322,Time used 0.009974s\n",
      "batch 3686, train_loss 0.003947,Time used 0.010971s\n",
      "batch 3687, train_loss 0.003758,Time used 0.008975s\n",
      "batch 3688, train_loss 0.004129,Time used 0.008977s\n",
      "batch 3689, train_loss 0.003421,Time used 0.008975s\n",
      "batch 3690, train_loss 0.005374,Time used 0.008976s\n",
      "batch 3691, train_loss 0.002269,Time used 0.008976s\n",
      "batch 3692, train_loss 0.003623,Time used 0.008976s\n",
      "batch 3693, train_loss 0.003893,Time used 0.008976s\n",
      "batch 3694, train_loss 0.002943,Time used 0.008975s\n",
      "batch 3695, train_loss 0.004610,Time used 0.008632s\n",
      "batch 3696, train_loss 0.002510,Time used 0.009973s\n",
      "batch 3697, train_loss 0.003882,Time used 0.008976s\n",
      "batch 3698, train_loss 0.004934,Time used 0.008976s\n",
      "batch 3699, train_loss 0.003249,Time used 0.008976s\n",
      "batch 3700, train_loss 0.003630,Time used 0.008976s\n",
      "***************************test_batch 3700, test_rmse_loss 0.061455,test_mae_loss 0.043865,test_mape_loss 12.758579,Time used 0.108709s\n",
      "batch 3701, train_loss 0.003830,Time used 0.008976s\n",
      "batch 3702, train_loss 0.003976,Time used 0.008976s\n",
      "batch 3703, train_loss 0.002945,Time used 0.008975s\n",
      "batch 3704, train_loss 0.003553,Time used 0.008976s\n",
      "batch 3705, train_loss 0.003363,Time used 0.007979s\n",
      "batch 3706, train_loss 0.003395,Time used 0.008976s\n",
      "batch 3707, train_loss 0.002681,Time used 0.008976s\n",
      "batch 3708, train_loss 0.004728,Time used 0.008976s\n",
      "batch 3709, train_loss 0.003076,Time used 0.007979s\n",
      "batch 3710, train_loss 0.003183,Time used 0.006981s\n",
      "batch 3711, train_loss 0.003870,Time used 0.006981s\n",
      "batch 3712, train_loss 0.003514,Time used 0.008976s\n",
      "batch 3713, train_loss 0.003816,Time used 0.008975s\n",
      "batch 3714, train_loss 0.003936,Time used 0.009974s\n",
      "batch 3715, train_loss 0.003615,Time used 0.009973s\n",
      "batch 3716, train_loss 0.005612,Time used 0.010969s\n",
      "batch 3717, train_loss 0.003172,Time used 0.009974s\n",
      "batch 3718, train_loss 0.003747,Time used 0.008976s\n",
      "batch 3719, train_loss 0.003064,Time used 0.008975s\n",
      "batch 3720, train_loss 0.004096,Time used 0.009974s\n",
      "batch 3721, train_loss 0.004073,Time used 0.007979s\n",
      "batch 3722, train_loss 0.004077,Time used 0.007979s\n",
      "batch 3723, train_loss 0.004837,Time used 0.007978s\n",
      "batch 3724, train_loss 0.002734,Time used 0.008976s\n",
      "batch 3725, train_loss 0.004014,Time used 0.008976s\n",
      "batch 3726, train_loss 0.003309,Time used 0.008976s\n",
      "batch 3727, train_loss 0.004306,Time used 0.009973s\n",
      "batch 3728, train_loss 0.003435,Time used 0.007979s\n",
      "batch 3729, train_loss 0.003193,Time used 0.007979s\n",
      "batch 3730, train_loss 0.003103,Time used 0.008976s\n",
      "batch 3731, train_loss 0.004406,Time used 0.008976s\n",
      "batch 3732, train_loss 0.002981,Time used 0.008976s\n",
      "batch 3733, train_loss 0.003923,Time used 0.009974s\n",
      "batch 3734, train_loss 0.004218,Time used 0.008976s\n",
      "batch 3735, train_loss 0.002839,Time used 0.007978s\n",
      "batch 3736, train_loss 0.003540,Time used 0.008977s\n",
      "batch 3737, train_loss 0.003408,Time used 0.008975s\n",
      "batch 3738, train_loss 0.003879,Time used 0.008976s\n",
      "batch 3739, train_loss 0.002635,Time used 0.008976s\n",
      "batch 3740, train_loss 0.002746,Time used 0.008976s\n",
      "batch 3741, train_loss 0.003942,Time used 0.008976s\n",
      "batch 3742, train_loss 0.004154,Time used 0.008976s\n",
      "batch 3743, train_loss 0.002693,Time used 0.007978s\n",
      "batch 3744, train_loss 0.003289,Time used 0.008976s\n",
      "batch 3745, train_loss 0.005609,Time used 0.006981s\n",
      "batch 3746, train_loss 0.002817,Time used 0.007980s\n",
      "batch 3747, train_loss 0.004826,Time used 0.008976s\n",
      "batch 3748, train_loss 0.003756,Time used 0.007980s\n",
      "batch 3749, train_loss 0.003339,Time used 0.007978s\n",
      "batch 3750, train_loss 0.002444,Time used 0.007979s\n",
      "batch 3751, train_loss 0.003217,Time used 0.008976s\n",
      "batch 3752, train_loss 0.003670,Time used 0.008976s\n",
      "batch 3753, train_loss 0.003585,Time used 0.007978s\n",
      "batch 3754, train_loss 0.003028,Time used 0.007979s\n",
      "batch 3755, train_loss 0.002515,Time used 0.008976s\n",
      "batch 3756, train_loss 0.003362,Time used 0.007979s\n",
      "batch 3757, train_loss 0.005057,Time used 0.007979s\n",
      "batch 3758, train_loss 0.002555,Time used 0.008976s\n",
      "batch 3759, train_loss 0.003199,Time used 0.007979s\n",
      "batch 3760, train_loss 0.003588,Time used 0.008976s\n",
      "batch 3761, train_loss 0.003077,Time used 0.007979s\n",
      "batch 3762, train_loss 0.003659,Time used 0.007979s\n",
      "batch 3763, train_loss 0.004645,Time used 0.007978s\n",
      "batch 3764, train_loss 0.002961,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3765, train_loss 0.004159,Time used 0.008977s\n",
      "batch 3766, train_loss 0.004601,Time used 0.008977s\n",
      "batch 3767, train_loss 0.002309,Time used 0.008975s\n",
      "batch 3768, train_loss 0.004420,Time used 0.008976s\n",
      "batch 3769, train_loss 0.003497,Time used 0.008977s\n",
      "batch 3770, train_loss 0.003112,Time used 0.008976s\n",
      "batch 3771, train_loss 0.003624,Time used 0.007978s\n",
      "batch 3772, train_loss 0.003183,Time used 0.007979s\n",
      "batch 3773, train_loss 0.003416,Time used 0.007979s\n",
      "batch 3774, train_loss 0.004788,Time used 0.007979s\n",
      "batch 3775, train_loss 0.004206,Time used 0.007978s\n",
      "batch 3776, train_loss 0.003205,Time used 0.007978s\n",
      "batch 3777, train_loss 0.003911,Time used 0.010970s\n",
      "batch 3778, train_loss 0.003354,Time used 0.007980s\n",
      "batch 3779, train_loss 0.005031,Time used 0.008975s\n",
      "batch 3780, train_loss 0.003494,Time used 0.008976s\n",
      "batch 3781, train_loss 0.003752,Time used 0.008976s\n",
      "batch 3782, train_loss 0.003884,Time used 0.008976s\n",
      "batch 3783, train_loss 0.003811,Time used 0.008976s\n",
      "batch 3784, train_loss 0.003016,Time used 0.008976s\n",
      "batch 3785, train_loss 0.002892,Time used 0.008976s\n",
      "batch 3786, train_loss 0.004113,Time used 0.008977s\n",
      "batch 3787, train_loss 0.004219,Time used 0.008977s\n",
      "batch 3788, train_loss 0.003606,Time used 0.008976s\n",
      "batch 3789, train_loss 0.004404,Time used 0.007978s\n",
      "batch 3790, train_loss 0.004053,Time used 0.008976s\n",
      "batch 3791, train_loss 0.003058,Time used 0.010970s\n",
      "batch 3792, train_loss 0.002930,Time used 0.008976s\n",
      "batch 3793, train_loss 0.003677,Time used 0.008975s\n",
      "batch 3794, train_loss 0.004331,Time used 0.008977s\n",
      "batch 3795, train_loss 0.001991,Time used 0.008976s\n",
      "batch 3796, train_loss 0.004582,Time used 0.009974s\n",
      "batch 3797, train_loss 0.002246,Time used 0.009973s\n",
      "batch 3798, train_loss 0.003944,Time used 0.008976s\n",
      "batch 3799, train_loss 0.003586,Time used 0.007978s\n",
      "batch 3800, train_loss 0.004200,Time used 0.008977s\n",
      "***************************test_batch 3800, test_rmse_loss 0.060917,test_mae_loss 0.043425,test_mape_loss 13.015471,Time used 0.122673s\n",
      "batch 3801, train_loss 0.003013,Time used 0.008976s\n",
      "batch 3802, train_loss 0.003022,Time used 0.008977s\n",
      "batch 3803, train_loss 0.002890,Time used 0.009972s\n",
      "batch 3804, train_loss 0.003091,Time used 0.009974s\n",
      "batch 3805, train_loss 0.003823,Time used 0.008976s\n",
      "batch 3806, train_loss 0.002956,Time used 0.008977s\n",
      "batch 3807, train_loss 0.004488,Time used 0.008976s\n",
      "batch 3808, train_loss 0.002940,Time used 0.008978s\n",
      "batch 3809, train_loss 0.002639,Time used 0.009972s\n",
      "batch 3810, train_loss 0.003630,Time used 0.009973s\n",
      "batch 3811, train_loss 0.002978,Time used 0.009974s\n",
      "batch 3812, train_loss 0.003403,Time used 0.008975s\n",
      "batch 3813, train_loss 0.004303,Time used 0.007979s\n",
      "batch 3814, train_loss 0.004912,Time used 0.009192s\n",
      "batch 3815, train_loss 0.002969,Time used 0.008977s\n",
      "batch 3816, train_loss 0.004382,Time used 0.009973s\n",
      "batch 3817, train_loss 0.005722,Time used 0.008976s\n",
      "batch 3818, train_loss 0.004097,Time used 0.007978s\n",
      "batch 3819, train_loss 0.003697,Time used 0.008976s\n",
      "batch 3820, train_loss 0.003267,Time used 0.008977s\n",
      "batch 3821, train_loss 0.002786,Time used 0.009974s\n",
      "batch 3822, train_loss 0.003798,Time used 0.008975s\n",
      "batch 3823, train_loss 0.003641,Time used 0.008977s\n",
      "batch 3824, train_loss 0.003560,Time used 0.008975s\n",
      "batch 3825, train_loss 0.003022,Time used 0.007978s\n",
      "batch 3826, train_loss 0.002952,Time used 0.008976s\n",
      "batch 3827, train_loss 0.002813,Time used 0.008977s\n",
      "batch 3828, train_loss 0.004908,Time used 0.008976s\n",
      "batch 3829, train_loss 0.003790,Time used 0.009974s\n",
      "batch 3830, train_loss 0.003664,Time used 0.008976s\n",
      "batch 3831, train_loss 0.002978,Time used 0.008976s\n",
      "batch 3832, train_loss 0.005904,Time used 0.008976s\n",
      "batch 3833, train_loss 0.003097,Time used 0.008976s\n",
      "batch 3834, train_loss 0.004448,Time used 0.008976s\n",
      "batch 3835, train_loss 0.003318,Time used 0.008976s\n",
      "batch 3836, train_loss 0.002727,Time used 0.008975s\n",
      "batch 3837, train_loss 0.004015,Time used 0.009974s\n",
      "batch 3838, train_loss 0.004056,Time used 0.007978s\n",
      "batch 3839, train_loss 0.004197,Time used 0.007979s\n",
      "batch 3840, train_loss 0.005256,Time used 0.008977s\n",
      "batch 3841, train_loss 0.003569,Time used 0.008975s\n",
      "batch 3842, train_loss 0.004182,Time used 0.008976s\n",
      "batch 3843, train_loss 0.004208,Time used 0.007978s\n",
      "batch 3844, train_loss 0.003637,Time used 0.008975s\n",
      "batch 3845, train_loss 0.005067,Time used 0.008976s\n",
      "batch 3846, train_loss 0.003680,Time used 0.007979s\n",
      "batch 3847, train_loss 0.003466,Time used 0.007978s\n",
      "batch 3848, train_loss 0.003414,Time used 0.008977s\n",
      "batch 3849, train_loss 0.004544,Time used 0.009973s\n",
      "batch 3850, train_loss 0.004237,Time used 0.008976s\n",
      "batch 3851, train_loss 0.003304,Time used 0.007978s\n",
      "batch 3852, train_loss 0.001904,Time used 0.007978s\n",
      "batch 3853, train_loss 0.002760,Time used 0.009973s\n",
      "batch 3854, train_loss 0.003825,Time used 0.009974s\n",
      "batch 3855, train_loss 0.004659,Time used 0.008976s\n",
      "batch 3856, train_loss 0.003079,Time used 0.009974s\n",
      "batch 3857, train_loss 0.004559,Time used 0.008975s\n",
      "batch 3858, train_loss 0.003670,Time used 0.008976s\n",
      "batch 3859, train_loss 0.003670,Time used 0.009974s\n",
      "batch 3860, train_loss 0.002515,Time used 0.010971s\n",
      "batch 3861, train_loss 0.003602,Time used 0.009974s\n",
      "batch 3862, train_loss 0.003207,Time used 0.008976s\n",
      "batch 3863, train_loss 0.004321,Time used 0.008976s\n",
      "batch 3864, train_loss 0.002641,Time used 0.008976s\n",
      "batch 3865, train_loss 0.003234,Time used 0.008977s\n",
      "batch 3866, train_loss 0.003683,Time used 0.008976s\n",
      "batch 3867, train_loss 0.003827,Time used 0.008976s\n",
      "batch 3868, train_loss 0.002960,Time used 0.007980s\n",
      "batch 3869, train_loss 0.003199,Time used 0.009974s\n",
      "batch 3870, train_loss 0.004522,Time used 0.008976s\n",
      "batch 3871, train_loss 0.003816,Time used 0.007979s\n",
      "batch 3872, train_loss 0.003662,Time used 0.009973s\n",
      "batch 3873, train_loss 0.003777,Time used 0.008976s\n",
      "batch 3874, train_loss 0.004515,Time used 0.008976s\n",
      "batch 3875, train_loss 0.003267,Time used 0.008976s\n",
      "batch 3876, train_loss 0.005011,Time used 0.008976s\n",
      "batch 3877, train_loss 0.006596,Time used 0.009974s\n",
      "batch 3878, train_loss 0.004094,Time used 0.008976s\n",
      "batch 3879, train_loss 0.003271,Time used 0.009974s\n",
      "batch 3880, train_loss 0.002712,Time used 0.008975s\n",
      "batch 3881, train_loss 0.003338,Time used 0.007979s\n",
      "batch 3882, train_loss 0.002779,Time used 0.008976s\n",
      "batch 3883, train_loss 0.005700,Time used 0.007978s\n",
      "batch 3884, train_loss 0.003905,Time used 0.007978s\n",
      "batch 3885, train_loss 0.003206,Time used 0.007979s\n",
      "batch 3886, train_loss 0.004119,Time used 0.007979s\n",
      "batch 3887, train_loss 0.003043,Time used 0.007979s\n",
      "batch 3888, train_loss 0.003529,Time used 0.008976s\n",
      "batch 3889, train_loss 0.003721,Time used 0.008977s\n",
      "batch 3890, train_loss 0.002952,Time used 0.008976s\n",
      "batch 3891, train_loss 0.004014,Time used 0.008976s\n",
      "batch 3892, train_loss 0.003410,Time used 0.008976s\n",
      "batch 3893, train_loss 0.003579,Time used 0.008975s\n",
      "batch 3894, train_loss 0.004135,Time used 0.008978s\n",
      "batch 3895, train_loss 0.003666,Time used 0.009972s\n",
      "batch 3896, train_loss 0.003265,Time used 0.009974s\n",
      "batch 3897, train_loss 0.003507,Time used 0.008976s\n",
      "batch 3898, train_loss 0.003340,Time used 0.009973s\n",
      "batch 3899, train_loss 0.003489,Time used 0.009973s\n",
      "batch 3900, train_loss 0.002437,Time used 0.008976s\n",
      "***************************test_batch 3900, test_rmse_loss 0.060994,test_mae_loss 0.043506,test_mape_loss 12.827465,Time used 0.115690s\n",
      "batch 3901, train_loss 0.004521,Time used 0.008976s\n",
      "batch 3902, train_loss 0.003800,Time used 0.007978s\n",
      "batch 3903, train_loss 0.003450,Time used 0.006981s\n",
      "batch 3904, train_loss 0.006455,Time used 0.007978s\n",
      "batch 3905, train_loss 0.003858,Time used 0.008976s\n",
      "batch 3906, train_loss 0.004729,Time used 0.007979s\n",
      "batch 3907, train_loss 0.003634,Time used 0.008976s\n",
      "batch 3908, train_loss 0.002702,Time used 0.008976s\n",
      "batch 3909, train_loss 0.003715,Time used 0.007977s\n",
      "batch 3910, train_loss 0.004343,Time used 0.008975s\n",
      "batch 3911, train_loss 0.002903,Time used 0.007979s\n",
      "batch 3912, train_loss 0.003446,Time used 0.007978s\n",
      "batch 3913, train_loss 0.002748,Time used 0.007979s\n",
      "batch 3914, train_loss 0.004125,Time used 0.008976s\n",
      "batch 3915, train_loss 0.003199,Time used 0.007979s\n",
      "batch 3916, train_loss 0.003500,Time used 0.007978s\n",
      "batch 3917, train_loss 0.002929,Time used 0.008977s\n",
      "batch 3918, train_loss 0.003758,Time used 0.008976s\n",
      "batch 3919, train_loss 0.004239,Time used 0.007978s\n",
      "batch 3920, train_loss 0.004205,Time used 0.007979s\n",
      "batch 3921, train_loss 0.003767,Time used 0.008975s\n",
      "batch 3922, train_loss 0.002960,Time used 0.007979s\n",
      "batch 3923, train_loss 0.002772,Time used 0.006981s\n",
      "batch 3924, train_loss 0.003846,Time used 0.007978s\n",
      "batch 3925, train_loss 0.002506,Time used 0.008976s\n",
      "batch 3926, train_loss 0.003045,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3927, train_loss 0.002975,Time used 0.007980s\n",
      "batch 3928, train_loss 0.004412,Time used 0.008976s\n",
      "batch 3929, train_loss 0.006211,Time used 0.007978s\n",
      "batch 3930, train_loss 0.003585,Time used 0.008976s\n",
      "batch 3931, train_loss 0.003601,Time used 0.008976s\n",
      "batch 3932, train_loss 0.003963,Time used 0.008975s\n",
      "batch 3933, train_loss 0.003505,Time used 0.008976s\n",
      "batch 3934, train_loss 0.003927,Time used 0.008976s\n",
      "batch 3935, train_loss 0.003262,Time used 0.007978s\n",
      "batch 3936, train_loss 0.003386,Time used 0.008975s\n",
      "batch 3937, train_loss 0.003373,Time used 0.008977s\n",
      "batch 3938, train_loss 0.003068,Time used 0.007979s\n",
      "batch 3939, train_loss 0.004292,Time used 0.007979s\n",
      "batch 3940, train_loss 0.003554,Time used 0.007978s\n",
      "batch 3941, train_loss 0.003479,Time used 0.008976s\n",
      "batch 3942, train_loss 0.004651,Time used 0.007979s\n",
      "batch 3943, train_loss 0.003430,Time used 0.008976s\n",
      "batch 3944, train_loss 0.003918,Time used 0.008976s\n",
      "batch 3945, train_loss 0.003027,Time used 0.008976s\n",
      "batch 3946, train_loss 0.003052,Time used 0.008976s\n",
      "batch 3947, train_loss 0.004004,Time used 0.009974s\n",
      "batch 3948, train_loss 0.003157,Time used 0.010971s\n",
      "batch 3949, train_loss 0.003392,Time used 0.009973s\n",
      "batch 3950, train_loss 0.004199,Time used 0.008975s\n",
      "batch 3951, train_loss 0.002367,Time used 0.008976s\n",
      "batch 3952, train_loss 0.002789,Time used 0.008976s\n",
      "batch 3953, train_loss 0.003772,Time used 0.008976s\n",
      "batch 3954, train_loss 0.003529,Time used 0.008976s\n",
      "batch 3955, train_loss 0.003137,Time used 0.008976s\n",
      "batch 3956, train_loss 0.003652,Time used 0.008976s\n",
      "batch 3957, train_loss 0.004093,Time used 0.008976s\n",
      "batch 3958, train_loss 0.003314,Time used 0.014960s\n",
      "batch 3959, train_loss 0.003567,Time used 0.007978s\n",
      "batch 3960, train_loss 0.003394,Time used 0.008975s\n",
      "batch 3961, train_loss 0.004538,Time used 0.008976s\n",
      "batch 3962, train_loss 0.003430,Time used 0.008976s\n",
      "batch 3963, train_loss 0.004013,Time used 0.007979s\n",
      "batch 3964, train_loss 0.003105,Time used 0.008976s\n",
      "batch 3965, train_loss 0.004600,Time used 0.009974s\n",
      "batch 3966, train_loss 0.005409,Time used 0.008976s\n",
      "batch 3967, train_loss 0.002490,Time used 0.008976s\n",
      "batch 3968, train_loss 0.002230,Time used 0.007978s\n",
      "batch 3969, train_loss 0.003019,Time used 0.007979s\n",
      "batch 3970, train_loss 0.002775,Time used 0.007979s\n",
      "batch 3971, train_loss 0.004785,Time used 0.008976s\n",
      "batch 3972, train_loss 0.003247,Time used 0.008976s\n",
      "batch 3973, train_loss 0.004307,Time used 0.007979s\n",
      "batch 3974, train_loss 0.003362,Time used 0.008975s\n",
      "batch 3975, train_loss 0.004724,Time used 0.007979s\n",
      "batch 3976, train_loss 0.004654,Time used 0.007978s\n",
      "batch 3977, train_loss 0.003304,Time used 0.008976s\n",
      "batch 3978, train_loss 0.003389,Time used 0.008976s\n",
      "batch 3979, train_loss 0.003174,Time used 0.007978s\n",
      "batch 3980, train_loss 0.004025,Time used 0.007979s\n",
      "batch 3981, train_loss 0.003193,Time used 0.007978s\n",
      "batch 3982, train_loss 0.003827,Time used 0.007979s\n",
      "batch 3983, train_loss 0.004280,Time used 0.008976s\n",
      "batch 3984, train_loss 0.003872,Time used 0.007979s\n",
      "batch 3985, train_loss 0.002954,Time used 0.008976s\n",
      "batch 3986, train_loss 0.003385,Time used 0.008976s\n",
      "batch 3987, train_loss 0.004105,Time used 0.008976s\n",
      "batch 3988, train_loss 0.004361,Time used 0.009973s\n",
      "batch 3989, train_loss 0.003590,Time used 0.008977s\n",
      "batch 3990, train_loss 0.004172,Time used 0.007979s\n",
      "batch 3991, train_loss 0.005808,Time used 0.008976s\n",
      "batch 3992, train_loss 0.004718,Time used 0.008975s\n",
      "batch 3993, train_loss 0.003848,Time used 0.008977s\n",
      "batch 3994, train_loss 0.003935,Time used 0.007979s\n",
      "batch 3995, train_loss 0.003604,Time used 0.007978s\n",
      "batch 3996, train_loss 0.003097,Time used 0.008976s\n",
      "batch 3997, train_loss 0.003142,Time used 0.007978s\n",
      "batch 3998, train_loss 0.003016,Time used 0.007978s\n",
      "batch 3999, train_loss 0.003297,Time used 0.008976s\n",
      "batch 4000, train_loss 0.002914,Time used 0.007978s\n",
      "***************************test_batch 4000, test_rmse_loss 0.060858,test_mae_loss 0.043395,test_mape_loss 12.958564,Time used 0.116690s\n",
      "batch 4001, train_loss 0.003732,Time used 0.021941s\n",
      "batch 4002, train_loss 0.003253,Time used 0.009974s\n",
      "batch 4003, train_loss 0.003152,Time used 0.008975s\n",
      "batch 4004, train_loss 0.005448,Time used 0.008976s\n",
      "batch 4005, train_loss 0.003942,Time used 0.008976s\n",
      "batch 4006, train_loss 0.003264,Time used 0.008976s\n",
      "batch 4007, train_loss 0.004358,Time used 0.008976s\n",
      "batch 4008, train_loss 0.003953,Time used 0.008976s\n",
      "batch 4009, train_loss 0.002853,Time used 0.007979s\n",
      "batch 4010, train_loss 0.004514,Time used 0.008976s\n",
      "batch 4011, train_loss 0.003250,Time used 0.008976s\n",
      "batch 4012, train_loss 0.002992,Time used 0.008977s\n",
      "batch 4013, train_loss 0.002987,Time used 0.007978s\n",
      "batch 4014, train_loss 0.002819,Time used 0.007979s\n",
      "batch 4015, train_loss 0.003761,Time used 0.008977s\n",
      "batch 4016, train_loss 0.003995,Time used 0.007978s\n",
      "batch 4017, train_loss 0.004336,Time used 0.007978s\n",
      "batch 4018, train_loss 0.005651,Time used 0.008687s\n",
      "batch 4019, train_loss 0.003251,Time used 0.007979s\n",
      "batch 4020, train_loss 0.003629,Time used 0.008975s\n",
      "batch 4021, train_loss 0.004052,Time used 0.007979s\n",
      "batch 4022, train_loss 0.003843,Time used 0.007978s\n",
      "batch 4023, train_loss 0.003471,Time used 0.007980s\n",
      "batch 4024, train_loss 0.003054,Time used 0.007978s\n",
      "batch 4025, train_loss 0.002843,Time used 0.008977s\n",
      "batch 4026, train_loss 0.003692,Time used 0.007978s\n",
      "batch 4027, train_loss 0.003264,Time used 0.008976s\n",
      "batch 4028, train_loss 0.003973,Time used 0.008976s\n",
      "batch 4029, train_loss 0.003487,Time used 0.008976s\n",
      "batch 4030, train_loss 0.002602,Time used 0.008976s\n",
      "batch 4031, train_loss 0.002498,Time used 0.009973s\n",
      "batch 4032, train_loss 0.003784,Time used 0.008976s\n",
      "batch 4033, train_loss 0.003271,Time used 0.008976s\n",
      "batch 4034, train_loss 0.003159,Time used 0.007979s\n",
      "batch 4035, train_loss 0.003086,Time used 0.008975s\n",
      "batch 4036, train_loss 0.003080,Time used 0.008977s\n",
      "batch 4037, train_loss 0.002832,Time used 0.007979s\n",
      "batch 4038, train_loss 0.002708,Time used 0.007979s\n",
      "batch 4039, train_loss 0.003765,Time used 0.008976s\n",
      "batch 4040, train_loss 0.003504,Time used 0.008976s\n",
      "batch 4041, train_loss 0.002381,Time used 0.008976s\n",
      "batch 4042, train_loss 0.003655,Time used 0.007979s\n",
      "batch 4043, train_loss 0.002579,Time used 0.008976s\n",
      "batch 4044, train_loss 0.003071,Time used 0.006981s\n",
      "batch 4045, train_loss 0.004789,Time used 0.007979s\n",
      "batch 4046, train_loss 0.004338,Time used 0.007978s\n",
      "batch 4047, train_loss 0.002580,Time used 0.007979s\n",
      "batch 4048, train_loss 0.003460,Time used 0.006980s\n",
      "batch 4049, train_loss 0.003770,Time used 0.007978s\n",
      "batch 4050, train_loss 0.004478,Time used 0.008976s\n",
      "batch 4051, train_loss 0.004460,Time used 0.007979s\n",
      "batch 4052, train_loss 0.003170,Time used 0.007979s\n",
      "batch 4053, train_loss 0.003011,Time used 0.008976s\n",
      "batch 4054, train_loss 0.003515,Time used 0.008488s\n",
      "batch 4055, train_loss 0.003709,Time used 0.007978s\n",
      "batch 4056, train_loss 0.006316,Time used 0.007978s\n",
      "batch 4057, train_loss 0.004032,Time used 0.007978s\n",
      "batch 4058, train_loss 0.004286,Time used 0.007979s\n",
      "batch 4059, train_loss 0.003972,Time used 0.008976s\n",
      "batch 4060, train_loss 0.003316,Time used 0.007978s\n",
      "batch 4061, train_loss 0.003498,Time used 0.008976s\n",
      "batch 4062, train_loss 0.005036,Time used 0.007979s\n",
      "batch 4063, train_loss 0.002195,Time used 0.008977s\n",
      "batch 4064, train_loss 0.003944,Time used 0.008976s\n",
      "batch 4065, train_loss 0.003515,Time used 0.007978s\n",
      "batch 4066, train_loss 0.002411,Time used 0.006981s\n",
      "batch 4067, train_loss 0.003368,Time used 0.007979s\n",
      "batch 4068, train_loss 0.004011,Time used 0.007978s\n",
      "batch 4069, train_loss 0.002648,Time used 0.007979s\n",
      "batch 4070, train_loss 0.004052,Time used 0.007979s\n",
      "batch 4071, train_loss 0.002729,Time used 0.007979s\n",
      "batch 4072, train_loss 0.004440,Time used 0.007978s\n",
      "batch 4073, train_loss 0.003779,Time used 0.007979s\n",
      "batch 4074, train_loss 0.004034,Time used 0.007980s\n",
      "batch 4075, train_loss 0.004585,Time used 0.008976s\n",
      "batch 4076, train_loss 0.002715,Time used 0.008976s\n",
      "batch 4077, train_loss 0.005654,Time used 0.008976s\n",
      "batch 4078, train_loss 0.002395,Time used 0.008976s\n",
      "batch 4079, train_loss 0.003295,Time used 0.008976s\n",
      "batch 4080, train_loss 0.003609,Time used 0.008976s\n",
      "batch 4081, train_loss 0.003755,Time used 0.008976s\n",
      "batch 4082, train_loss 0.004555,Time used 0.009973s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4083, train_loss 0.002806,Time used 0.008976s\n",
      "batch 4084, train_loss 0.003553,Time used 0.008976s\n",
      "batch 4085, train_loss 0.004439,Time used 0.008977s\n",
      "batch 4086, train_loss 0.003364,Time used 0.008976s\n",
      "batch 4087, train_loss 0.002536,Time used 0.008976s\n",
      "batch 4088, train_loss 0.004081,Time used 0.009975s\n",
      "batch 4089, train_loss 0.003744,Time used 0.010970s\n",
      "batch 4090, train_loss 0.002656,Time used 0.010971s\n",
      "batch 4091, train_loss 0.003789,Time used 0.009973s\n",
      "batch 4092, train_loss 0.003653,Time used 0.009973s\n",
      "batch 4093, train_loss 0.003190,Time used 0.008977s\n",
      "batch 4094, train_loss 0.004184,Time used 0.008975s\n",
      "batch 4095, train_loss 0.003246,Time used 0.008976s\n",
      "batch 4096, train_loss 0.005825,Time used 0.007978s\n",
      "batch 4097, train_loss 0.004428,Time used 0.008975s\n",
      "batch 4098, train_loss 0.002147,Time used 0.008976s\n",
      "batch 4099, train_loss 0.003406,Time used 0.008976s\n",
      "batch 4100, train_loss 0.002959,Time used 0.008975s\n",
      "***************************test_batch 4100, test_rmse_loss 0.060841,test_mae_loss 0.043381,test_mape_loss 12.881666,Time used 0.110705s\n",
      "batch 4101, train_loss 0.003982,Time used 0.008976s\n",
      "batch 4102, train_loss 0.004431,Time used 0.008976s\n",
      "batch 4103, train_loss 0.003762,Time used 0.007979s\n",
      "batch 4104, train_loss 0.003068,Time used 0.007979s\n",
      "batch 4105, train_loss 0.003525,Time used 0.008977s\n",
      "batch 4106, train_loss 0.004474,Time used 0.008975s\n",
      "batch 4107, train_loss 0.004354,Time used 0.008976s\n",
      "batch 4108, train_loss 0.004235,Time used 0.007978s\n",
      "batch 4109, train_loss 0.003136,Time used 0.007978s\n",
      "batch 4110, train_loss 0.003524,Time used 0.006981s\n",
      "batch 4111, train_loss 0.002920,Time used 0.007979s\n",
      "batch 4112, train_loss 0.003471,Time used 0.008976s\n",
      "batch 4113, train_loss 0.003616,Time used 0.008976s\n",
      "batch 4114, train_loss 0.004155,Time used 0.007979s\n",
      "batch 4115, train_loss 0.003428,Time used 0.007979s\n",
      "batch 4116, train_loss 0.005167,Time used 0.008976s\n",
      "batch 4117, train_loss 0.003031,Time used 0.007978s\n",
      "batch 4118, train_loss 0.003892,Time used 0.008976s\n",
      "batch 4119, train_loss 0.004838,Time used 0.007979s\n",
      "batch 4120, train_loss 0.004102,Time used 0.008976s\n",
      "batch 4121, train_loss 0.003803,Time used 0.008976s\n",
      "batch 4122, train_loss 0.003207,Time used 0.008976s\n",
      "batch 4123, train_loss 0.003062,Time used 0.008976s\n",
      "batch 4124, train_loss 0.004807,Time used 0.009973s\n",
      "batch 4125, train_loss 0.003027,Time used 0.008976s\n",
      "batch 4126, train_loss 0.004119,Time used 0.007979s\n",
      "batch 4127, train_loss 0.004437,Time used 0.008976s\n",
      "batch 4128, train_loss 0.004060,Time used 0.008976s\n",
      "batch 4129, train_loss 0.003312,Time used 0.008976s\n",
      "batch 4130, train_loss 0.004101,Time used 0.008976s\n",
      "batch 4131, train_loss 0.003574,Time used 0.008976s\n",
      "batch 4132, train_loss 0.004069,Time used 0.007979s\n",
      "batch 4133, train_loss 0.003922,Time used 0.007978s\n",
      "batch 4134, train_loss 0.005815,Time used 0.008977s\n",
      "batch 4135, train_loss 0.004047,Time used 0.008975s\n",
      "batch 4136, train_loss 0.002896,Time used 0.008977s\n",
      "batch 4137, train_loss 0.005050,Time used 0.007978s\n",
      "batch 4138, train_loss 0.003193,Time used 0.008977s\n",
      "batch 4139, train_loss 0.003802,Time used 0.008976s\n",
      "batch 4140, train_loss 0.003505,Time used 0.008977s\n",
      "batch 4141, train_loss 0.003890,Time used 0.008976s\n",
      "batch 4142, train_loss 0.003532,Time used 0.008976s\n",
      "batch 4143, train_loss 0.003548,Time used 0.009974s\n",
      "batch 4144, train_loss 0.003109,Time used 0.009974s\n",
      "batch 4145, train_loss 0.003290,Time used 0.008976s\n",
      "batch 4146, train_loss 0.003271,Time used 0.008975s\n",
      "batch 4147, train_loss 0.004209,Time used 0.008976s\n",
      "batch 4148, train_loss 0.003543,Time used 0.008975s\n",
      "batch 4149, train_loss 0.003640,Time used 0.008977s\n",
      "batch 4150, train_loss 0.003012,Time used 0.008976s\n",
      "batch 4151, train_loss 0.003289,Time used 0.009974s\n",
      "batch 4152, train_loss 0.003476,Time used 0.009972s\n",
      "batch 4153, train_loss 0.003034,Time used 0.008975s\n",
      "batch 4154, train_loss 0.003519,Time used 0.008975s\n",
      "batch 4155, train_loss 0.004484,Time used 0.008976s\n",
      "batch 4156, train_loss 0.002302,Time used 0.009973s\n",
      "batch 4157, train_loss 0.002675,Time used 0.009974s\n",
      "batch 4158, train_loss 0.003463,Time used 0.010971s\n",
      "batch 4159, train_loss 0.005187,Time used 0.010970s\n",
      "batch 4160, train_loss 0.002406,Time used 0.009974s\n",
      "batch 4161, train_loss 0.004039,Time used 0.009973s\n",
      "batch 4162, train_loss 0.002148,Time used 0.007979s\n",
      "batch 4163, train_loss 0.003229,Time used 0.008975s\n",
      "batch 4164, train_loss 0.002711,Time used 0.008977s\n",
      "batch 4165, train_loss 0.004077,Time used 0.007978s\n",
      "batch 4166, train_loss 0.003536,Time used 0.007979s\n",
      "batch 4167, train_loss 0.004154,Time used 0.008976s\n",
      "batch 4168, train_loss 0.003397,Time used 0.008976s\n",
      "batch 4169, train_loss 0.002736,Time used 0.008975s\n",
      "batch 4170, train_loss 0.002936,Time used 0.008976s\n",
      "batch 4171, train_loss 0.003252,Time used 0.008976s\n",
      "batch 4172, train_loss 0.003490,Time used 0.008976s\n",
      "batch 4173, train_loss 0.001956,Time used 0.006982s\n",
      "batch 4174, train_loss 0.003609,Time used 0.007979s\n",
      "batch 4175, train_loss 0.003449,Time used 0.009485s\n",
      "batch 4176, train_loss 0.002031,Time used 0.008976s\n",
      "batch 4177, train_loss 0.004377,Time used 0.009973s\n",
      "batch 4178, train_loss 0.004201,Time used 0.009973s\n",
      "batch 4179, train_loss 0.003724,Time used 0.008977s\n",
      "batch 4180, train_loss 0.002412,Time used 0.009974s\n",
      "batch 4181, train_loss 0.003132,Time used 0.008976s\n",
      "batch 4182, train_loss 0.003026,Time used 0.008977s\n",
      "batch 4183, train_loss 0.006503,Time used 0.008976s\n",
      "batch 4184, train_loss 0.004381,Time used 0.009974s\n",
      "batch 4185, train_loss 0.003062,Time used 0.008976s\n",
      "batch 4186, train_loss 0.003096,Time used 0.008976s\n",
      "batch 4187, train_loss 0.004363,Time used 0.008976s\n",
      "batch 4188, train_loss 0.003172,Time used 0.008976s\n",
      "batch 4189, train_loss 0.003135,Time used 0.008977s\n",
      "batch 4190, train_loss 0.002657,Time used 0.008976s\n",
      "batch 4191, train_loss 0.002918,Time used 0.008976s\n",
      "batch 4192, train_loss 0.006748,Time used 0.008975s\n",
      "batch 4193, train_loss 0.004348,Time used 0.008976s\n",
      "batch 4194, train_loss 0.003707,Time used 0.008976s\n",
      "batch 4195, train_loss 0.004790,Time used 0.009974s\n",
      "batch 4196, train_loss 0.004800,Time used 0.008976s\n",
      "batch 4197, train_loss 0.003000,Time used 0.008976s\n",
      "batch 4198, train_loss 0.002900,Time used 0.008976s\n",
      "batch 4199, train_loss 0.003270,Time used 0.009973s\n",
      "batch 4200, train_loss 0.004142,Time used 0.009973s\n",
      "***************************test_batch 4200, test_rmse_loss 0.060935,test_mae_loss 0.043506,test_mape_loss 12.800090,Time used 0.119680s\n",
      "batch 4201, train_loss 0.004137,Time used 0.008976s\n",
      "batch 4202, train_loss 0.003214,Time used 0.008976s\n",
      "batch 4203, train_loss 0.003232,Time used 0.008976s\n",
      "batch 4204, train_loss 0.003606,Time used 0.009973s\n",
      "batch 4205, train_loss 0.003078,Time used 0.009973s\n",
      "batch 4206, train_loss 0.003733,Time used 0.009974s\n",
      "batch 4207, train_loss 0.003087,Time used 0.010969s\n",
      "batch 4208, train_loss 0.004459,Time used 0.010972s\n",
      "batch 4209, train_loss 0.003587,Time used 0.023936s\n",
      "batch 4210, train_loss 0.003024,Time used 0.010970s\n",
      "batch 4211, train_loss 0.005080,Time used 0.010971s\n",
      "batch 4212, train_loss 0.003696,Time used 0.009973s\n",
      "batch 4213, train_loss 0.003329,Time used 0.010971s\n",
      "batch 4214, train_loss 0.003151,Time used 0.009973s\n",
      "batch 4215, train_loss 0.004175,Time used 0.009973s\n",
      "batch 4216, train_loss 0.003250,Time used 0.012966s\n",
      "batch 4217, train_loss 0.003997,Time used 0.010970s\n",
      "batch 4218, train_loss 0.002595,Time used 0.009973s\n",
      "batch 4219, train_loss 0.003870,Time used 0.010972s\n",
      "batch 4220, train_loss 0.002767,Time used 0.009973s\n",
      "batch 4221, train_loss 0.003175,Time used 0.008977s\n",
      "batch 4222, train_loss 0.002613,Time used 0.009974s\n",
      "batch 4223, train_loss 0.003598,Time used 0.009972s\n",
      "batch 4224, train_loss 0.004503,Time used 0.009974s\n",
      "batch 4225, train_loss 0.003617,Time used 0.009974s\n",
      "batch 4226, train_loss 0.005903,Time used 0.009973s\n",
      "batch 4227, train_loss 0.003636,Time used 0.008975s\n",
      "batch 4228, train_loss 0.003572,Time used 0.008977s\n",
      "batch 4229, train_loss 0.003225,Time used 0.008976s\n",
      "batch 4230, train_loss 0.002835,Time used 0.007978s\n",
      "batch 4231, train_loss 0.003776,Time used 0.008976s\n",
      "batch 4232, train_loss 0.003333,Time used 0.009973s\n",
      "batch 4233, train_loss 0.003226,Time used 0.008976s\n",
      "batch 4234, train_loss 0.003984,Time used 0.008976s\n",
      "batch 4235, train_loss 0.003828,Time used 0.009973s\n",
      "batch 4236, train_loss 0.004155,Time used 0.008976s\n",
      "batch 4237, train_loss 0.004082,Time used 0.007978s\n",
      "batch 4238, train_loss 0.003220,Time used 0.008976s\n",
      "batch 4239, train_loss 0.003740,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4240, train_loss 0.005422,Time used 0.007978s\n",
      "batch 4241, train_loss 0.004624,Time used 0.008976s\n",
      "batch 4242, train_loss 0.003526,Time used 0.007979s\n",
      "batch 4243, train_loss 0.003965,Time used 0.007979s\n",
      "batch 4244, train_loss 0.002825,Time used 0.008976s\n",
      "batch 4245, train_loss 0.004180,Time used 0.010970s\n",
      "batch 4246, train_loss 0.002537,Time used 0.007979s\n",
      "batch 4247, train_loss 0.004838,Time used 0.007979s\n",
      "batch 4248, train_loss 0.003747,Time used 0.008976s\n",
      "batch 4249, train_loss 0.003925,Time used 0.007979s\n",
      "batch 4250, train_loss 0.004212,Time used 0.008977s\n",
      "batch 4251, train_loss 0.003991,Time used 0.008977s\n",
      "batch 4252, train_loss 0.003305,Time used 0.008975s\n",
      "batch 4253, train_loss 0.003473,Time used 0.007978s\n",
      "batch 4254, train_loss 0.003192,Time used 0.007979s\n",
      "batch 4255, train_loss 0.003536,Time used 0.007978s\n",
      "batch 4256, train_loss 0.002936,Time used 0.007978s\n",
      "batch 4257, train_loss 0.003982,Time used 0.008976s\n",
      "batch 4258, train_loss 0.002478,Time used 0.006983s\n",
      "batch 4259, train_loss 0.003924,Time used 0.007979s\n",
      "batch 4260, train_loss 0.003525,Time used 0.008976s\n",
      "batch 4261, train_loss 0.002614,Time used 0.007979s\n",
      "batch 4262, train_loss 0.003265,Time used 0.008976s\n",
      "batch 4263, train_loss 0.002901,Time used 0.008976s\n",
      "batch 4264, train_loss 0.002235,Time used 0.007979s\n",
      "batch 4265, train_loss 0.002858,Time used 0.006982s\n",
      "batch 4266, train_loss 0.002760,Time used 0.009972s\n",
      "batch 4267, train_loss 0.004032,Time used 0.007980s\n",
      "batch 4268, train_loss 0.004398,Time used 0.009973s\n",
      "batch 4269, train_loss 0.003585,Time used 0.007978s\n",
      "batch 4270, train_loss 0.004282,Time used 0.008975s\n",
      "batch 4271, train_loss 0.003747,Time used 0.008976s\n",
      "batch 4272, train_loss 0.004113,Time used 0.009973s\n",
      "batch 4273, train_loss 0.004164,Time used 0.008976s\n",
      "batch 4274, train_loss 0.003588,Time used 0.008976s\n",
      "batch 4275, train_loss 0.003193,Time used 0.008976s\n",
      "batch 4276, train_loss 0.004127,Time used 0.009973s\n",
      "batch 4277, train_loss 0.004255,Time used 0.008976s\n",
      "batch 4278, train_loss 0.004369,Time used 0.008976s\n",
      "batch 4279, train_loss 0.002448,Time used 0.007978s\n",
      "batch 4280, train_loss 0.001891,Time used 0.006980s\n",
      "batch 4281, train_loss 0.003845,Time used 0.010972s\n",
      "batch 4282, train_loss 0.002694,Time used 0.008975s\n",
      "batch 4283, train_loss 0.005595,Time used 0.008975s\n",
      "batch 4284, train_loss 0.003771,Time used 0.007979s\n",
      "batch 4285, train_loss 0.003444,Time used 0.007979s\n",
      "batch 4286, train_loss 0.002472,Time used 0.008976s\n",
      "batch 4287, train_loss 0.002484,Time used 0.008976s\n",
      "batch 4288, train_loss 0.004158,Time used 0.007979s\n",
      "batch 4289, train_loss 0.003202,Time used 0.008976s\n",
      "batch 4290, train_loss 0.003149,Time used 0.008976s\n",
      "batch 4291, train_loss 0.002482,Time used 0.008975s\n",
      "batch 4292, train_loss 0.003950,Time used 0.008977s\n",
      "batch 4293, train_loss 0.003315,Time used 0.008976s\n",
      "batch 4294, train_loss 0.004899,Time used 0.008977s\n",
      "batch 4295, train_loss 0.003853,Time used 0.008976s\n",
      "batch 4296, train_loss 0.003500,Time used 0.008976s\n",
      "batch 4297, train_loss 0.004070,Time used 0.008976s\n",
      "batch 4298, train_loss 0.003332,Time used 0.009973s\n",
      "batch 4299, train_loss 0.003690,Time used 0.008976s\n",
      "batch 4300, train_loss 0.003254,Time used 0.008976s\n",
      "***************************test_batch 4300, test_rmse_loss 0.060802,test_mae_loss 0.043350,test_mape_loss 12.922854,Time used 0.118684s\n",
      "batch 4301, train_loss 0.003238,Time used 0.008976s\n",
      "batch 4302, train_loss 0.003036,Time used 0.007980s\n",
      "batch 4303, train_loss 0.003629,Time used 0.008976s\n",
      "batch 4304, train_loss 0.003361,Time used 0.008975s\n",
      "batch 4305, train_loss 0.002554,Time used 0.007979s\n",
      "batch 4306, train_loss 0.003606,Time used 0.008976s\n",
      "batch 4307, train_loss 0.003332,Time used 0.008977s\n",
      "batch 4308, train_loss 0.005236,Time used 0.008976s\n",
      "batch 4309, train_loss 0.003001,Time used 0.008975s\n",
      "batch 4310, train_loss 0.002418,Time used 0.008977s\n",
      "batch 4311, train_loss 0.004691,Time used 0.008975s\n",
      "batch 4312, train_loss 0.003487,Time used 0.009973s\n",
      "batch 4313, train_loss 0.005389,Time used 0.008976s\n",
      "batch 4314, train_loss 0.004201,Time used 0.008977s\n",
      "batch 4315, train_loss 0.003589,Time used 0.008976s\n",
      "batch 4316, train_loss 0.004245,Time used 0.008976s\n",
      "batch 4317, train_loss 0.002606,Time used 0.008975s\n",
      "batch 4318, train_loss 0.003403,Time used 0.008977s\n",
      "batch 4319, train_loss 0.002952,Time used 0.008976s\n",
      "batch 4320, train_loss 0.003849,Time used 0.007979s\n",
      "batch 4321, train_loss 0.003053,Time used 0.008976s\n",
      "batch 4322, train_loss 0.003686,Time used 0.007978s\n",
      "batch 4323, train_loss 0.003250,Time used 0.007979s\n",
      "batch 4324, train_loss 0.002540,Time used 0.007979s\n",
      "batch 4325, train_loss 0.005233,Time used 0.008976s\n",
      "batch 4326, train_loss 0.004459,Time used 0.006980s\n",
      "batch 4327, train_loss 0.003097,Time used 0.007979s\n",
      "batch 4328, train_loss 0.003804,Time used 0.006981s\n",
      "batch 4329, train_loss 0.003498,Time used 0.006981s\n",
      "batch 4330, train_loss 0.003570,Time used 0.007978s\n",
      "batch 4331, train_loss 0.003421,Time used 0.007979s\n",
      "batch 4332, train_loss 0.003642,Time used 0.006981s\n",
      "batch 4333, train_loss 0.004047,Time used 0.007979s\n",
      "batch 4334, train_loss 0.003477,Time used 0.007978s\n",
      "batch 4335, train_loss 0.003108,Time used 0.008976s\n",
      "batch 4336, train_loss 0.005333,Time used 0.007979s\n",
      "batch 4337, train_loss 0.004555,Time used 0.006981s\n",
      "batch 4338, train_loss 0.003312,Time used 0.007978s\n",
      "batch 4339, train_loss 0.004617,Time used 0.007979s\n",
      "batch 4340, train_loss 0.003043,Time used 0.007979s\n",
      "batch 4341, train_loss 0.003645,Time used 0.007979s\n",
      "batch 4342, train_loss 0.003175,Time used 0.006982s\n",
      "batch 4343, train_loss 0.004503,Time used 0.009973s\n",
      "batch 4344, train_loss 0.002956,Time used 0.008976s\n",
      "batch 4345, train_loss 0.003483,Time used 0.008448s\n",
      "batch 4346, train_loss 0.004061,Time used 0.007980s\n",
      "batch 4347, train_loss 0.003512,Time used 0.006982s\n",
      "batch 4348, train_loss 0.003548,Time used 0.008976s\n",
      "batch 4349, train_loss 0.004713,Time used 0.007978s\n",
      "batch 4350, train_loss 0.004564,Time used 0.007979s\n",
      "batch 4351, train_loss 0.003148,Time used 0.007979s\n",
      "batch 4352, train_loss 0.005292,Time used 0.007979s\n",
      "batch 4353, train_loss 0.002661,Time used 0.007978s\n",
      "batch 4354, train_loss 0.004137,Time used 0.007979s\n",
      "batch 4355, train_loss 0.005256,Time used 0.007978s\n",
      "batch 4356, train_loss 0.003239,Time used 0.007978s\n",
      "batch 4357, train_loss 0.003239,Time used 0.007979s\n",
      "batch 4358, train_loss 0.004018,Time used 0.007979s\n",
      "batch 4359, train_loss 0.003526,Time used 0.008976s\n",
      "batch 4360, train_loss 0.003272,Time used 0.008976s\n",
      "batch 4361, train_loss 0.003593,Time used 0.008976s\n",
      "batch 4362, train_loss 0.003441,Time used 0.008975s\n",
      "batch 4363, train_loss 0.004564,Time used 0.007979s\n",
      "batch 4364, train_loss 0.005125,Time used 0.006981s\n",
      "batch 4365, train_loss 0.002421,Time used 0.009974s\n",
      "batch 4366, train_loss 0.003206,Time used 0.008975s\n",
      "batch 4367, train_loss 0.002840,Time used 0.007978s\n",
      "batch 4368, train_loss 0.003229,Time used 0.007979s\n",
      "batch 4369, train_loss 0.002768,Time used 0.007978s\n",
      "batch 4370, train_loss 0.004344,Time used 0.008976s\n",
      "batch 4371, train_loss 0.002943,Time used 0.008976s\n",
      "batch 4372, train_loss 0.003399,Time used 0.008976s\n",
      "batch 4373, train_loss 0.003500,Time used 0.007979s\n",
      "batch 4374, train_loss 0.003512,Time used 0.007980s\n",
      "batch 4375, train_loss 0.003311,Time used 0.007978s\n",
      "batch 4376, train_loss 0.003312,Time used 0.007979s\n",
      "batch 4377, train_loss 0.003828,Time used 0.007978s\n",
      "batch 4378, train_loss 0.004707,Time used 0.007980s\n",
      "batch 4379, train_loss 0.003138,Time used 0.008976s\n",
      "batch 4380, train_loss 0.003548,Time used 0.007978s\n",
      "batch 4381, train_loss 0.003181,Time used 0.007979s\n",
      "batch 4382, train_loss 0.003009,Time used 0.008976s\n",
      "batch 4383, train_loss 0.004415,Time used 0.008977s\n",
      "batch 4384, train_loss 0.003510,Time used 0.007978s\n",
      "batch 4385, train_loss 0.003147,Time used 0.007980s\n",
      "batch 4386, train_loss 0.004129,Time used 0.008975s\n",
      "batch 4387, train_loss 0.002808,Time used 0.006982s\n",
      "batch 4388, train_loss 0.003308,Time used 0.008976s\n",
      "batch 4389, train_loss 0.003805,Time used 0.007979s\n",
      "batch 4390, train_loss 0.004224,Time used 0.007980s\n",
      "batch 4391, train_loss 0.003111,Time used 0.007978s\n",
      "batch 4392, train_loss 0.003258,Time used 0.007979s\n",
      "batch 4393, train_loss 0.002485,Time used 0.007978s\n",
      "batch 4394, train_loss 0.003302,Time used 0.007979s\n",
      "batch 4395, train_loss 0.003501,Time used 0.007979s\n",
      "batch 4396, train_loss 0.003781,Time used 0.008975s\n",
      "batch 4397, train_loss 0.003587,Time used 0.007979s\n",
      "batch 4398, train_loss 0.003795,Time used 0.007979s\n",
      "batch 4399, train_loss 0.002705,Time used 0.008975s\n",
      "batch 4400, train_loss 0.004868,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************test_batch 4400, test_rmse_loss 0.060971,test_mae_loss 0.043473,test_mape_loss 12.775923,Time used 0.113758s\n",
      "batch 4401, train_loss 0.003269,Time used 0.007978s\n",
      "batch 4402, train_loss 0.005564,Time used 0.007978s\n",
      "batch 4403, train_loss 0.003551,Time used 0.008976s\n",
      "batch 4404, train_loss 0.004923,Time used 0.008976s\n",
      "batch 4405, train_loss 0.004493,Time used 0.008976s\n",
      "batch 4406, train_loss 0.002773,Time used 0.008976s\n",
      "batch 4407, train_loss 0.003704,Time used 0.009973s\n",
      "batch 4408, train_loss 0.002800,Time used 0.009973s\n",
      "batch 4409, train_loss 0.002692,Time used 0.008976s\n",
      "batch 4410, train_loss 0.003755,Time used 0.008976s\n",
      "batch 4411, train_loss 0.004147,Time used 0.008976s\n",
      "batch 4412, train_loss 0.002278,Time used 0.009973s\n",
      "batch 4413, train_loss 0.003417,Time used 0.008977s\n",
      "batch 4414, train_loss 0.003312,Time used 0.007979s\n",
      "batch 4415, train_loss 0.004467,Time used 0.007979s\n",
      "batch 4416, train_loss 0.002933,Time used 0.007979s\n",
      "batch 4417, train_loss 0.003644,Time used 0.007979s\n",
      "batch 4418, train_loss 0.003176,Time used 0.008976s\n",
      "batch 4419, train_loss 0.004251,Time used 0.008976s\n",
      "batch 4420, train_loss 0.003419,Time used 0.008976s\n",
      "batch 4421, train_loss 0.004463,Time used 0.009972s\n",
      "batch 4422, train_loss 0.002769,Time used 0.008977s\n",
      "batch 4423, train_loss 0.003641,Time used 0.009973s\n",
      "batch 4424, train_loss 0.003476,Time used 0.008976s\n",
      "batch 4425, train_loss 0.004795,Time used 0.009973s\n",
      "batch 4426, train_loss 0.003921,Time used 0.008977s\n",
      "batch 4427, train_loss 0.002936,Time used 0.008976s\n",
      "batch 4428, train_loss 0.003589,Time used 0.009133s\n",
      "batch 4429, train_loss 0.003968,Time used 0.008977s\n",
      "batch 4430, train_loss 0.004073,Time used 0.008976s\n",
      "batch 4431, train_loss 0.003756,Time used 0.009973s\n",
      "batch 4432, train_loss 0.004189,Time used 0.010971s\n",
      "batch 4433, train_loss 0.003598,Time used 0.009974s\n",
      "batch 4434, train_loss 0.002924,Time used 0.009972s\n",
      "batch 4435, train_loss 0.002651,Time used 0.010971s\n",
      "batch 4436, train_loss 0.003445,Time used 0.009974s\n",
      "batch 4437, train_loss 0.003435,Time used 0.009973s\n",
      "batch 4438, train_loss 0.003795,Time used 0.010972s\n",
      "batch 4439, train_loss 0.003863,Time used 0.010971s\n",
      "batch 4440, train_loss 0.004183,Time used 0.010970s\n",
      "batch 4441, train_loss 0.003974,Time used 0.010971s\n",
      "batch 4442, train_loss 0.004772,Time used 0.008977s\n",
      "batch 4443, train_loss 0.003715,Time used 0.008976s\n",
      "batch 4444, train_loss 0.002389,Time used 0.008976s\n",
      "batch 4445, train_loss 0.003833,Time used 0.008976s\n",
      "batch 4446, train_loss 0.003797,Time used 0.009974s\n",
      "batch 4447, train_loss 0.003892,Time used 0.008976s\n",
      "batch 4448, train_loss 0.003805,Time used 0.008976s\n",
      "batch 4449, train_loss 0.003888,Time used 0.007979s\n",
      "batch 4450, train_loss 0.003343,Time used 0.007978s\n",
      "batch 4451, train_loss 0.003626,Time used 0.008976s\n",
      "batch 4452, train_loss 0.003075,Time used 0.008976s\n",
      "batch 4453, train_loss 0.003075,Time used 0.008976s\n",
      "batch 4454, train_loss 0.003980,Time used 0.007979s\n",
      "batch 4455, train_loss 0.003941,Time used 0.007979s\n",
      "batch 4456, train_loss 0.003711,Time used 0.007979s\n",
      "batch 4457, train_loss 0.004063,Time used 0.007979s\n",
      "batch 4458, train_loss 0.003262,Time used 0.007979s\n",
      "batch 4459, train_loss 0.002707,Time used 0.007979s\n",
      "batch 4460, train_loss 0.003413,Time used 0.009974s\n",
      "batch 4461, train_loss 0.005744,Time used 0.008976s\n",
      "batch 4462, train_loss 0.004097,Time used 0.008976s\n",
      "batch 4463, train_loss 0.002968,Time used 0.007980s\n",
      "batch 4464, train_loss 0.004222,Time used 0.007978s\n",
      "batch 4465, train_loss 0.002722,Time used 0.007978s\n",
      "batch 4466, train_loss 0.003918,Time used 0.007980s\n",
      "batch 4467, train_loss 0.003040,Time used 0.007979s\n",
      "batch 4468, train_loss 0.003112,Time used 0.008975s\n",
      "batch 4469, train_loss 0.003072,Time used 0.008977s\n",
      "batch 4470, train_loss 0.003437,Time used 0.008976s\n",
      "batch 4471, train_loss 0.003027,Time used 0.008976s\n",
      "batch 4472, train_loss 0.004149,Time used 0.008976s\n",
      "batch 4473, train_loss 0.003346,Time used 0.007978s\n",
      "batch 4474, train_loss 0.003862,Time used 0.007979s\n",
      "batch 4475, train_loss 0.003757,Time used 0.008976s\n",
      "batch 4476, train_loss 0.002921,Time used 0.007978s\n",
      "batch 4477, train_loss 0.004368,Time used 0.007979s\n",
      "batch 4478, train_loss 0.004215,Time used 0.007978s\n",
      "batch 4479, train_loss 0.006427,Time used 0.007979s\n",
      "batch 4480, train_loss 0.003777,Time used 0.008976s\n",
      "batch 4481, train_loss 0.003625,Time used 0.008976s\n",
      "batch 4482, train_loss 0.002450,Time used 0.007979s\n",
      "batch 4483, train_loss 0.005349,Time used 0.007978s\n",
      "batch 4484, train_loss 0.003428,Time used 0.007979s\n",
      "batch 4485, train_loss 0.003001,Time used 0.008976s\n",
      "batch 4486, train_loss 0.002551,Time used 0.007979s\n",
      "batch 4487, train_loss 0.003645,Time used 0.007978s\n",
      "batch 4488, train_loss 0.005444,Time used 0.007978s\n",
      "batch 4489, train_loss 0.003584,Time used 0.007979s\n",
      "batch 4490, train_loss 0.003365,Time used 0.007978s\n",
      "batch 4491, train_loss 0.002398,Time used 0.007979s\n",
      "batch 4492, train_loss 0.003253,Time used 0.007979s\n",
      "batch 4493, train_loss 0.003778,Time used 0.007979s\n",
      "batch 4494, train_loss 0.002498,Time used 0.006982s\n",
      "batch 4495, train_loss 0.002690,Time used 0.008976s\n",
      "batch 4496, train_loss 0.003521,Time used 0.007979s\n",
      "batch 4497, train_loss 0.003203,Time used 0.007978s\n",
      "batch 4498, train_loss 0.004617,Time used 0.007979s\n",
      "batch 4499, train_loss 0.004296,Time used 0.008975s\n",
      "batch 4500, train_loss 0.004497,Time used 0.008977s\n",
      "***************************test_batch 4500, test_rmse_loss 0.060816,test_mae_loss 0.043359,test_mape_loss 12.826448,Time used 0.113697s\n",
      "batch 4501, train_loss 0.003771,Time used 0.008974s\n",
      "batch 4502, train_loss 0.002264,Time used 0.008977s\n",
      "batch 4503, train_loss 0.004382,Time used 0.007979s\n",
      "batch 4504, train_loss 0.004112,Time used 0.007978s\n",
      "batch 4505, train_loss 0.003073,Time used 0.008977s\n",
      "batch 4506, train_loss 0.004224,Time used 0.008975s\n",
      "batch 4507, train_loss 0.002835,Time used 0.007978s\n",
      "batch 4508, train_loss 0.002986,Time used 0.007978s\n",
      "batch 4509, train_loss 0.003469,Time used 0.008976s\n",
      "batch 4510, train_loss 0.002447,Time used 0.008976s\n",
      "batch 4511, train_loss 0.003551,Time used 0.007979s\n",
      "batch 4512, train_loss 0.002515,Time used 0.007979s\n",
      "batch 4513, train_loss 0.003960,Time used 0.007978s\n",
      "batch 4514, train_loss 0.002700,Time used 0.007979s\n",
      "batch 4515, train_loss 0.004333,Time used 0.007979s\n",
      "batch 4516, train_loss 0.003709,Time used 0.007980s\n",
      "batch 4517, train_loss 0.003116,Time used 0.008975s\n",
      "batch 4518, train_loss 0.003075,Time used 0.007979s\n",
      "batch 4519, train_loss 0.003866,Time used 0.007979s\n",
      "batch 4520, train_loss 0.003552,Time used 0.008976s\n",
      "batch 4521, train_loss 0.003599,Time used 0.009974s\n",
      "batch 4522, train_loss 0.002976,Time used 0.008976s\n",
      "batch 4523, train_loss 0.004147,Time used 0.008975s\n",
      "batch 4524, train_loss 0.004225,Time used 0.007979s\n",
      "batch 4525, train_loss 0.002361,Time used 0.008976s\n",
      "batch 4526, train_loss 0.003620,Time used 0.008977s\n",
      "batch 4527, train_loss 0.003636,Time used 0.007978s\n",
      "batch 4528, train_loss 0.004964,Time used 0.007978s\n",
      "batch 4529, train_loss 0.004009,Time used 0.007978s\n",
      "batch 4530, train_loss 0.003366,Time used 0.008977s\n",
      "batch 4531, train_loss 0.003329,Time used 0.008975s\n",
      "batch 4532, train_loss 0.003792,Time used 0.007978s\n",
      "batch 4533, train_loss 0.004173,Time used 0.007979s\n",
      "batch 4534, train_loss 0.002173,Time used 0.008976s\n",
      "batch 4535, train_loss 0.003876,Time used 0.007979s\n",
      "batch 4536, train_loss 0.002928,Time used 0.006981s\n",
      "batch 4537, train_loss 0.003879,Time used 0.007979s\n",
      "batch 4538, train_loss 0.003479,Time used 0.007978s\n",
      "batch 4539, train_loss 0.004463,Time used 0.007978s\n",
      "batch 4540, train_loss 0.003886,Time used 0.008977s\n",
      "batch 4541, train_loss 0.003653,Time used 0.008975s\n",
      "batch 4542, train_loss 0.003065,Time used 0.007979s\n",
      "batch 4543, train_loss 0.004820,Time used 0.007978s\n",
      "batch 4544, train_loss 0.003312,Time used 0.008976s\n",
      "batch 4545, train_loss 0.002532,Time used 0.007979s\n",
      "batch 4546, train_loss 0.005117,Time used 0.008975s\n",
      "batch 4547, train_loss 0.003521,Time used 0.008976s\n",
      "batch 4548, train_loss 0.003318,Time used 0.007978s\n",
      "batch 4549, train_loss 0.002952,Time used 0.008976s\n",
      "batch 4550, train_loss 0.002755,Time used 0.007979s\n",
      "batch 4551, train_loss 0.003983,Time used 0.008976s\n",
      "batch 4552, train_loss 0.004275,Time used 0.007979s\n",
      "batch 4553, train_loss 0.003959,Time used 0.007979s\n",
      "batch 4554, train_loss 0.003245,Time used 0.007978s\n",
      "batch 4555, train_loss 0.003894,Time used 0.007979s\n",
      "batch 4556, train_loss 0.004167,Time used 0.008976s\n",
      "batch 4557, train_loss 0.003241,Time used 0.007979s\n",
      "batch 4558, train_loss 0.003601,Time used 0.006982s\n",
      "batch 4559, train_loss 0.003139,Time used 0.008976s\n",
      "batch 4560, train_loss 0.003112,Time used 0.008975s\n",
      "batch 4561, train_loss 0.003167,Time used 0.008977s\n",
      "batch 4562, train_loss 0.003165,Time used 0.008976s\n",
      "batch 4563, train_loss 0.004433,Time used 0.008977s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4564, train_loss 0.003252,Time used 0.008976s\n",
      "batch 4565, train_loss 0.003270,Time used 0.009974s\n",
      "batch 4566, train_loss 0.003553,Time used 0.008976s\n",
      "batch 4567, train_loss 0.003330,Time used 0.008976s\n",
      "batch 4568, train_loss 0.003284,Time used 0.009974s\n",
      "batch 4569, train_loss 0.002667,Time used 0.008976s\n",
      "batch 4570, train_loss 0.003975,Time used 0.008976s\n",
      "batch 4571, train_loss 0.003694,Time used 0.008976s\n",
      "batch 4572, train_loss 0.003829,Time used 0.007978s\n",
      "batch 4573, train_loss 0.003495,Time used 0.008976s\n",
      "batch 4574, train_loss 0.005158,Time used 0.007978s\n",
      "batch 4575, train_loss 0.002976,Time used 0.008977s\n",
      "batch 4576, train_loss 0.003127,Time used 0.008976s\n",
      "batch 4577, train_loss 0.004192,Time used 0.008976s\n",
      "batch 4578, train_loss 0.006831,Time used 0.007979s\n",
      "batch 4579, train_loss 0.003493,Time used 0.007979s\n",
      "batch 4580, train_loss 0.004096,Time used 0.008976s\n",
      "batch 4581, train_loss 0.004234,Time used 0.007979s\n",
      "batch 4582, train_loss 0.002335,Time used 0.007979s\n",
      "batch 4583, train_loss 0.005163,Time used 0.007979s\n",
      "batch 4584, train_loss 0.002933,Time used 0.007979s\n",
      "batch 4585, train_loss 0.004327,Time used 0.007979s\n",
      "batch 4586, train_loss 0.004929,Time used 0.008976s\n",
      "batch 4587, train_loss 0.004039,Time used 0.007979s\n",
      "batch 4588, train_loss 0.004077,Time used 0.007979s\n",
      "batch 4589, train_loss 0.002880,Time used 0.007980s\n",
      "batch 4590, train_loss 0.003520,Time used 0.007979s\n",
      "batch 4591, train_loss 0.003266,Time used 0.007979s\n",
      "batch 4592, train_loss 0.003499,Time used 0.007978s\n",
      "batch 4593, train_loss 0.003909,Time used 0.008976s\n",
      "batch 4594, train_loss 0.003826,Time used 0.007979s\n",
      "batch 4595, train_loss 0.002860,Time used 0.007979s\n",
      "batch 4596, train_loss 0.003719,Time used 0.007978s\n",
      "batch 4597, train_loss 0.005112,Time used 0.007978s\n",
      "batch 4598, train_loss 0.003612,Time used 0.008977s\n",
      "batch 4599, train_loss 0.003991,Time used 0.008976s\n",
      "batch 4600, train_loss 0.003609,Time used 0.008976s\n",
      "***************************test_batch 4600, test_rmse_loss 0.060790,test_mae_loss 0.043334,test_mape_loss 12.876160,Time used 0.109708s\n",
      "batch 4601, train_loss 0.002701,Time used 0.006980s\n",
      "batch 4602, train_loss 0.003880,Time used 0.007979s\n",
      "batch 4603, train_loss 0.003162,Time used 0.007979s\n",
      "batch 4604, train_loss 0.004276,Time used 0.007978s\n",
      "batch 4605, train_loss 0.004020,Time used 0.008977s\n",
      "batch 4606, train_loss 0.003490,Time used 0.007978s\n",
      "batch 4607, train_loss 0.005855,Time used 0.007978s\n",
      "batch 4608, train_loss 0.003066,Time used 0.008976s\n",
      "batch 4609, train_loss 0.003574,Time used 0.008976s\n",
      "batch 4610, train_loss 0.003521,Time used 0.007978s\n",
      "batch 4611, train_loss 0.003107,Time used 0.007979s\n",
      "batch 4612, train_loss 0.003312,Time used 0.007978s\n",
      "batch 4613, train_loss 0.004429,Time used 0.007978s\n",
      "batch 4614, train_loss 0.002375,Time used 0.007978s\n",
      "batch 4615, train_loss 0.003548,Time used 0.007979s\n",
      "batch 4616, train_loss 0.003531,Time used 0.007978s\n",
      "batch 4617, train_loss 0.003518,Time used 0.009974s\n",
      "batch 4618, train_loss 0.005355,Time used 0.008976s\n",
      "batch 4619, train_loss 0.004600,Time used 0.008976s\n",
      "batch 4620, train_loss 0.003579,Time used 0.008976s\n",
      "batch 4621, train_loss 0.003816,Time used 0.008976s\n",
      "batch 4622, train_loss 0.002840,Time used 0.009974s\n",
      "batch 4623, train_loss 0.003542,Time used 0.008976s\n",
      "batch 4624, train_loss 0.002920,Time used 0.009973s\n",
      "batch 4625, train_loss 0.003826,Time used 0.017464s\n",
      "batch 4626, train_loss 0.003410,Time used 0.012966s\n",
      "batch 4627, train_loss 0.003976,Time used 0.009974s\n",
      "batch 4628, train_loss 0.002876,Time used 0.010971s\n",
      "batch 4629, train_loss 0.005221,Time used 0.010971s\n",
      "batch 4630, train_loss 0.003265,Time used 0.008977s\n",
      "batch 4631, train_loss 0.004462,Time used 0.008976s\n",
      "batch 4632, train_loss 0.004080,Time used 0.009973s\n",
      "batch 4633, train_loss 0.002569,Time used 0.009974s\n",
      "batch 4634, train_loss 0.003198,Time used 0.009973s\n",
      "batch 4635, train_loss 0.003501,Time used 0.008977s\n",
      "batch 4636, train_loss 0.004950,Time used 0.008977s\n",
      "batch 4637, train_loss 0.003872,Time used 0.010971s\n",
      "batch 4638, train_loss 0.004826,Time used 0.008977s\n",
      "batch 4639, train_loss 0.003050,Time used 0.009974s\n",
      "batch 4640, train_loss 0.003104,Time used 0.008975s\n",
      "batch 4641, train_loss 0.003903,Time used 0.008976s\n",
      "batch 4642, train_loss 0.003224,Time used 0.009973s\n",
      "batch 4643, train_loss 0.003759,Time used 0.008976s\n",
      "batch 4644, train_loss 0.003864,Time used 0.008976s\n",
      "batch 4645, train_loss 0.003868,Time used 0.008976s\n",
      "batch 4646, train_loss 0.004923,Time used 0.007979s\n",
      "batch 4647, train_loss 0.005365,Time used 0.007978s\n",
      "batch 4648, train_loss 0.003260,Time used 0.007979s\n",
      "batch 4649, train_loss 0.002921,Time used 0.007978s\n",
      "batch 4650, train_loss 0.003855,Time used 0.007979s\n",
      "batch 4651, train_loss 0.002631,Time used 0.008976s\n",
      "batch 4652, train_loss 0.003939,Time used 0.008488s\n",
      "batch 4653, train_loss 0.004538,Time used 0.008976s\n",
      "batch 4654, train_loss 0.003251,Time used 0.007978s\n",
      "batch 4655, train_loss 0.005201,Time used 0.008976s\n",
      "batch 4656, train_loss 0.003522,Time used 0.008976s\n",
      "batch 4657, train_loss 0.003665,Time used 0.008976s\n",
      "batch 4658, train_loss 0.004235,Time used 0.008976s\n",
      "batch 4659, train_loss 0.003159,Time used 0.008976s\n",
      "batch 4660, train_loss 0.003640,Time used 0.008975s\n",
      "batch 4661, train_loss 0.002725,Time used 0.008976s\n",
      "batch 4662, train_loss 0.002907,Time used 0.008977s\n",
      "batch 4663, train_loss 0.003239,Time used 0.008976s\n",
      "batch 4664, train_loss 0.004407,Time used 0.008976s\n",
      "batch 4665, train_loss 0.002678,Time used 0.007979s\n",
      "batch 4666, train_loss 0.004256,Time used 0.008975s\n",
      "batch 4667, train_loss 0.003306,Time used 0.008977s\n",
      "batch 4668, train_loss 0.003794,Time used 0.008976s\n",
      "batch 4669, train_loss 0.003309,Time used 0.007979s\n",
      "batch 4670, train_loss 0.006360,Time used 0.007979s\n",
      "batch 4671, train_loss 0.003136,Time used 0.008976s\n",
      "batch 4672, train_loss 0.004015,Time used 0.008977s\n",
      "batch 4673, train_loss 0.002963,Time used 0.008975s\n",
      "batch 4674, train_loss 0.002888,Time used 0.008977s\n",
      "batch 4675, train_loss 0.003273,Time used 0.007978s\n",
      "batch 4676, train_loss 0.003552,Time used 0.007978s\n",
      "batch 4677, train_loss 0.002961,Time used 0.007980s\n",
      "batch 4678, train_loss 0.004810,Time used 0.008975s\n",
      "batch 4679, train_loss 0.003165,Time used 0.007979s\n",
      "batch 4680, train_loss 0.003494,Time used 0.009973s\n",
      "batch 4681, train_loss 0.003080,Time used 0.008977s\n",
      "batch 4682, train_loss 0.003785,Time used 0.008975s\n",
      "batch 4683, train_loss 0.003556,Time used 0.008976s\n",
      "batch 4684, train_loss 0.002754,Time used 0.008977s\n",
      "batch 4685, train_loss 0.002880,Time used 0.007979s\n",
      "batch 4686, train_loss 0.003786,Time used 0.007979s\n",
      "batch 4687, train_loss 0.003292,Time used 0.007978s\n",
      "batch 4688, train_loss 0.004086,Time used 0.007979s\n",
      "batch 4689, train_loss 0.003847,Time used 0.007980s\n",
      "batch 4690, train_loss 0.003291,Time used 0.008976s\n",
      "batch 4691, train_loss 0.003770,Time used 0.008976s\n",
      "batch 4692, train_loss 0.003156,Time used 0.008976s\n",
      "batch 4693, train_loss 0.003653,Time used 0.008977s\n",
      "batch 4694, train_loss 0.003258,Time used 0.007979s\n",
      "batch 4695, train_loss 0.002651,Time used 0.007979s\n",
      "batch 4696, train_loss 0.003438,Time used 0.008976s\n",
      "batch 4697, train_loss 0.004129,Time used 0.008976s\n",
      "batch 4698, train_loss 0.003656,Time used 0.009973s\n",
      "batch 4699, train_loss 0.002422,Time used 0.008977s\n",
      "batch 4700, train_loss 0.002764,Time used 0.009974s\n",
      "***************************test_batch 4700, test_rmse_loss 0.060838,test_mae_loss 0.043385,test_mape_loss 12.802387,Time used 0.106714s\n",
      "batch 4701, train_loss 0.003323,Time used 0.008976s\n",
      "batch 4702, train_loss 0.003645,Time used 0.007979s\n",
      "batch 4703, train_loss 0.004547,Time used 0.006981s\n",
      "batch 4704, train_loss 0.004093,Time used 0.007978s\n",
      "batch 4705, train_loss 0.002765,Time used 0.007978s\n",
      "batch 4706, train_loss 0.003524,Time used 0.007978s\n",
      "batch 4707, train_loss 0.002788,Time used 0.007978s\n",
      "batch 4708, train_loss 0.008727,Time used 0.006982s\n",
      "batch 4709, train_loss 0.004166,Time used 0.008977s\n",
      "batch 4710, train_loss 0.003386,Time used 0.008977s\n",
      "batch 4711, train_loss 0.002601,Time used 0.008976s\n",
      "batch 4712, train_loss 0.003983,Time used 0.008976s\n",
      "batch 4713, train_loss 0.002476,Time used 0.007979s\n",
      "batch 4714, train_loss 0.004186,Time used 0.008487s\n",
      "batch 4715, train_loss 0.003084,Time used 0.008976s\n",
      "batch 4716, train_loss 0.004018,Time used 0.007978s\n",
      "batch 4717, train_loss 0.003922,Time used 0.008975s\n",
      "batch 4718, train_loss 0.002489,Time used 0.008976s\n",
      "batch 4719, train_loss 0.004115,Time used 0.008976s\n",
      "batch 4720, train_loss 0.002785,Time used 0.008976s\n",
      "batch 4721, train_loss 0.003145,Time used 0.008976s\n",
      "batch 4722, train_loss 0.003363,Time used 0.007979s\n",
      "batch 4723, train_loss 0.003415,Time used 0.007979s\n",
      "batch 4724, train_loss 0.003791,Time used 0.007979s\n",
      "batch 4725, train_loss 0.004176,Time used 0.007979s\n",
      "batch 4726, train_loss 0.004813,Time used 0.007978s\n",
      "batch 4727, train_loss 0.004033,Time used 0.007978s\n",
      "batch 4728, train_loss 0.004020,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4729, train_loss 0.002577,Time used 0.007978s\n",
      "batch 4730, train_loss 0.003587,Time used 0.008976s\n",
      "batch 4731, train_loss 0.003294,Time used 0.008976s\n",
      "batch 4732, train_loss 0.003561,Time used 0.008976s\n",
      "batch 4733, train_loss 0.002583,Time used 0.007978s\n",
      "batch 4734, train_loss 0.004463,Time used 0.007979s\n",
      "batch 4735, train_loss 0.004833,Time used 0.007979s\n",
      "batch 4736, train_loss 0.003285,Time used 0.008977s\n",
      "batch 4737, train_loss 0.004040,Time used 0.007978s\n",
      "batch 4738, train_loss 0.004839,Time used 0.007980s\n",
      "batch 4739, train_loss 0.003788,Time used 0.007978s\n",
      "batch 4740, train_loss 0.003204,Time used 0.007979s\n",
      "batch 4741, train_loss 0.003440,Time used 0.008976s\n",
      "batch 4742, train_loss 0.002972,Time used 0.008976s\n",
      "batch 4743, train_loss 0.003212,Time used 0.007978s\n",
      "batch 4744, train_loss 0.003142,Time used 0.007978s\n",
      "batch 4745, train_loss 0.003709,Time used 0.007979s\n",
      "batch 4746, train_loss 0.004528,Time used 0.007979s\n",
      "batch 4747, train_loss 0.002803,Time used 0.007979s\n",
      "batch 4748, train_loss 0.004105,Time used 0.007979s\n",
      "batch 4749, train_loss 0.003395,Time used 0.007980s\n",
      "batch 4750, train_loss 0.003955,Time used 0.007979s\n",
      "batch 4751, train_loss 0.002751,Time used 0.008976s\n",
      "batch 4752, train_loss 0.004324,Time used 0.008984s\n",
      "batch 4753, train_loss 0.003421,Time used 0.007970s\n",
      "batch 4754, train_loss 0.002973,Time used 0.007978s\n",
      "batch 4755, train_loss 0.004265,Time used 0.007979s\n",
      "batch 4756, train_loss 0.003623,Time used 0.007979s\n",
      "batch 4757, train_loss 0.003836,Time used 0.007979s\n",
      "batch 4758, train_loss 0.003756,Time used 0.007979s\n",
      "batch 4759, train_loss 0.003605,Time used 0.008976s\n",
      "batch 4760, train_loss 0.002590,Time used 0.008976s\n",
      "batch 4761, train_loss 0.003369,Time used 0.007979s\n",
      "batch 4762, train_loss 0.003219,Time used 0.007979s\n",
      "batch 4763, train_loss 0.002842,Time used 0.008975s\n",
      "batch 4764, train_loss 0.003359,Time used 0.007979s\n",
      "batch 4765, train_loss 0.003248,Time used 0.007979s\n",
      "batch 4766, train_loss 0.003638,Time used 0.007979s\n",
      "batch 4767, train_loss 0.003956,Time used 0.008976s\n",
      "batch 4768, train_loss 0.006182,Time used 0.007978s\n",
      "batch 4769, train_loss 0.003245,Time used 0.007979s\n",
      "batch 4770, train_loss 0.003774,Time used 0.008976s\n",
      "batch 4771, train_loss 0.002880,Time used 0.007979s\n",
      "batch 4772, train_loss 0.003455,Time used 0.007978s\n",
      "batch 4773, train_loss 0.003871,Time used 0.008976s\n",
      "batch 4774, train_loss 0.003319,Time used 0.007978s\n",
      "batch 4775, train_loss 0.004536,Time used 0.007979s\n",
      "batch 4776, train_loss 0.005081,Time used 0.007979s\n",
      "batch 4777, train_loss 0.004813,Time used 0.007979s\n",
      "batch 4778, train_loss 0.003850,Time used 0.007979s\n",
      "batch 4779, train_loss 0.003780,Time used 0.008976s\n",
      "batch 4780, train_loss 0.003047,Time used 0.007979s\n",
      "batch 4781, train_loss 0.003802,Time used 0.007979s\n",
      "batch 4782, train_loss 0.003085,Time used 0.007978s\n",
      "batch 4783, train_loss 0.004390,Time used 0.008976s\n",
      "batch 4784, train_loss 0.003454,Time used 0.007979s\n",
      "batch 4785, train_loss 0.003136,Time used 0.008976s\n",
      "batch 4786, train_loss 0.002829,Time used 0.007978s\n",
      "batch 4787, train_loss 0.006051,Time used 0.007978s\n",
      "batch 4788, train_loss 0.005062,Time used 0.007979s\n",
      "batch 4789, train_loss 0.003824,Time used 0.008976s\n",
      "batch 4790, train_loss 0.003375,Time used 0.007978s\n",
      "batch 4791, train_loss 0.004115,Time used 0.007979s\n",
      "batch 4792, train_loss 0.003223,Time used 0.007979s\n",
      "batch 4793, train_loss 0.002716,Time used 0.007979s\n",
      "batch 4794, train_loss 0.003432,Time used 0.007978s\n",
      "batch 4795, train_loss 0.002864,Time used 0.009973s\n",
      "batch 4796, train_loss 0.002401,Time used 0.009974s\n",
      "batch 4797, train_loss 0.002669,Time used 0.008975s\n",
      "batch 4798, train_loss 0.003551,Time used 0.008976s\n",
      "batch 4799, train_loss 0.004856,Time used 0.007979s\n",
      "batch 4800, train_loss 0.001875,Time used 0.008976s\n",
      "***************************test_batch 4800, test_rmse_loss 0.060825,test_mae_loss 0.043368,test_mape_loss 12.817120,Time used 0.116689s\n",
      "batch 4801, train_loss 0.003839,Time used 0.008976s\n",
      "batch 4802, train_loss 0.002982,Time used 0.009974s\n",
      "batch 4803, train_loss 0.003880,Time used 0.007979s\n",
      "batch 4804, train_loss 0.004208,Time used 0.008976s\n",
      "batch 4805, train_loss 0.003279,Time used 0.007978s\n",
      "batch 4806, train_loss 0.005129,Time used 0.008976s\n",
      "batch 4807, train_loss 0.003316,Time used 0.008976s\n",
      "batch 4808, train_loss 0.003421,Time used 0.008976s\n",
      "batch 4809, train_loss 0.003371,Time used 0.007979s\n",
      "batch 4810, train_loss 0.003967,Time used 0.008976s\n",
      "batch 4811, train_loss 0.003443,Time used 0.008976s\n",
      "batch 4812, train_loss 0.003275,Time used 0.008976s\n",
      "batch 4813, train_loss 0.004192,Time used 0.009974s\n",
      "batch 4814, train_loss 0.005528,Time used 0.008976s\n",
      "batch 4815, train_loss 0.007364,Time used 0.007979s\n",
      "batch 4816, train_loss 0.003310,Time used 0.009974s\n",
      "batch 4817, train_loss 0.003577,Time used 0.009973s\n",
      "batch 4818, train_loss 0.003285,Time used 0.009973s\n",
      "batch 4819, train_loss 0.003424,Time used 0.008977s\n",
      "batch 4820, train_loss 0.003823,Time used 0.008976s\n",
      "batch 4821, train_loss 0.004407,Time used 0.007979s\n",
      "batch 4822, train_loss 0.002827,Time used 0.008976s\n",
      "batch 4823, train_loss 0.003290,Time used 0.008976s\n",
      "batch 4824, train_loss 0.002755,Time used 0.007978s\n",
      "batch 4825, train_loss 0.003498,Time used 0.007978s\n",
      "batch 4826, train_loss 0.002920,Time used 0.008976s\n",
      "batch 4827, train_loss 0.004755,Time used 0.008976s\n",
      "batch 4828, train_loss 0.003521,Time used 0.008977s\n",
      "batch 4829, train_loss 0.003795,Time used 0.007978s\n",
      "batch 4830, train_loss 0.005225,Time used 0.007980s\n",
      "batch 4831, train_loss 0.005203,Time used 0.008976s\n",
      "batch 4832, train_loss 0.002979,Time used 0.008975s\n",
      "batch 4833, train_loss 0.003113,Time used 0.007979s\n",
      "batch 4834, train_loss 0.003037,Time used 0.007978s\n",
      "batch 4835, train_loss 0.003504,Time used 0.007979s\n",
      "batch 4836, train_loss 0.004954,Time used 0.007978s\n",
      "batch 4837, train_loss 0.005033,Time used 0.008976s\n",
      "batch 4838, train_loss 0.002685,Time used 0.008976s\n",
      "batch 4839, train_loss 0.004211,Time used 0.008977s\n",
      "batch 4840, train_loss 0.003617,Time used 0.007978s\n",
      "batch 4841, train_loss 0.003600,Time used 0.007978s\n",
      "batch 4842, train_loss 0.003248,Time used 0.008976s\n",
      "batch 4843, train_loss 0.003379,Time used 0.008976s\n",
      "batch 4844, train_loss 0.002929,Time used 0.009973s\n",
      "batch 4845, train_loss 0.002611,Time used 0.008977s\n",
      "batch 4846, train_loss 0.003332,Time used 0.008976s\n",
      "batch 4847, train_loss 0.003826,Time used 0.007978s\n",
      "batch 4848, train_loss 0.005293,Time used 0.008976s\n",
      "batch 4849, train_loss 0.004544,Time used 0.007979s\n",
      "batch 4850, train_loss 0.004125,Time used 0.006982s\n",
      "batch 4851, train_loss 0.003614,Time used 0.007978s\n",
      "batch 4852, train_loss 0.003107,Time used 0.007979s\n",
      "batch 4853, train_loss 0.004691,Time used 0.007979s\n",
      "batch 4854, train_loss 0.003762,Time used 0.007978s\n",
      "batch 4855, train_loss 0.003050,Time used 0.008976s\n",
      "batch 4856, train_loss 0.002786,Time used 0.008975s\n",
      "batch 4857, train_loss 0.004719,Time used 0.006981s\n",
      "batch 4858, train_loss 0.002911,Time used 0.008976s\n",
      "batch 4859, train_loss 0.003353,Time used 0.007978s\n",
      "batch 4860, train_loss 0.002766,Time used 0.007979s\n",
      "batch 4861, train_loss 0.005709,Time used 0.007979s\n",
      "batch 4862, train_loss 0.003932,Time used 0.008977s\n",
      "batch 4863, train_loss 0.004087,Time used 0.007978s\n",
      "batch 4864, train_loss 0.003755,Time used 0.007979s\n",
      "batch 4865, train_loss 0.002649,Time used 0.008976s\n",
      "batch 4866, train_loss 0.002610,Time used 0.008977s\n",
      "batch 4867, train_loss 0.002453,Time used 0.006981s\n",
      "batch 4868, train_loss 0.003097,Time used 0.008976s\n",
      "batch 4869, train_loss 0.003244,Time used 0.008976s\n",
      "batch 4870, train_loss 0.002964,Time used 0.008976s\n",
      "batch 4871, train_loss 0.004831,Time used 0.008976s\n",
      "batch 4872, train_loss 0.003473,Time used 0.006981s\n",
      "batch 4873, train_loss 0.003900,Time used 0.008976s\n",
      "batch 4874, train_loss 0.002499,Time used 0.007978s\n",
      "batch 4875, train_loss 0.003151,Time used 0.007979s\n",
      "batch 4876, train_loss 0.002287,Time used 0.008975s\n",
      "batch 4877, train_loss 0.004098,Time used 0.007979s\n",
      "batch 4878, train_loss 0.004443,Time used 0.007978s\n",
      "batch 4879, train_loss 0.003348,Time used 0.007977s\n",
      "batch 4880, train_loss 0.003528,Time used 0.007979s\n",
      "batch 4881, train_loss 0.002887,Time used 0.006982s\n",
      "batch 4882, train_loss 0.003191,Time used 0.007979s\n",
      "batch 4883, train_loss 0.003256,Time used 0.007978s\n",
      "batch 4884, train_loss 0.004153,Time used 0.007979s\n",
      "batch 4885, train_loss 0.003844,Time used 0.007980s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4886, train_loss 0.003083,Time used 0.006982s\n",
      "batch 4887, train_loss 0.004523,Time used 0.008976s\n",
      "batch 4888, train_loss 0.003597,Time used 0.008976s\n",
      "batch 4889, train_loss 0.003417,Time used 0.008976s\n",
      "batch 4890, train_loss 0.003765,Time used 0.008976s\n",
      "batch 4891, train_loss 0.002635,Time used 0.007978s\n",
      "batch 4892, train_loss 0.003534,Time used 0.007980s\n",
      "batch 4893, train_loss 0.003519,Time used 0.008976s\n",
      "batch 4894, train_loss 0.002811,Time used 0.008976s\n",
      "batch 4895, train_loss 0.003153,Time used 0.007978s\n",
      "batch 4896, train_loss 0.005890,Time used 0.009973s\n",
      "batch 4897, train_loss 0.003330,Time used 0.008976s\n",
      "batch 4898, train_loss 0.002835,Time used 0.008976s\n",
      "batch 4899, train_loss 0.003733,Time used 0.009973s\n",
      "batch 4900, train_loss 0.002848,Time used 0.008976s\n",
      "***************************test_batch 4900, test_rmse_loss 0.060905,test_mae_loss 0.043429,test_mape_loss 12.774273,Time used 0.110704s\n",
      "batch 4901, train_loss 0.004549,Time used 0.008977s\n",
      "batch 4902, train_loss 0.004094,Time used 0.008975s\n",
      "batch 4903, train_loss 0.003382,Time used 0.007978s\n",
      "batch 4904, train_loss 0.004972,Time used 0.007979s\n",
      "batch 4905, train_loss 0.003196,Time used 0.007978s\n",
      "batch 4906, train_loss 0.003139,Time used 0.007979s\n",
      "batch 4907, train_loss 0.004164,Time used 0.008977s\n",
      "batch 4908, train_loss 0.004629,Time used 0.008976s\n",
      "batch 4909, train_loss 0.003470,Time used 0.008976s\n",
      "batch 4910, train_loss 0.005347,Time used 0.008976s\n",
      "batch 4911, train_loss 0.004021,Time used 0.008976s\n",
      "batch 4912, train_loss 0.003619,Time used 0.008976s\n",
      "batch 4913, train_loss 0.004176,Time used 0.008975s\n",
      "batch 4914, train_loss 0.004059,Time used 0.008977s\n",
      "batch 4915, train_loss 0.003531,Time used 0.008976s\n",
      "batch 4916, train_loss 0.003851,Time used 0.008976s\n",
      "batch 4917, train_loss 0.003325,Time used 0.008975s\n",
      "batch 4918, train_loss 0.004304,Time used 0.008976s\n",
      "batch 4919, train_loss 0.003349,Time used 0.007978s\n",
      "batch 4920, train_loss 0.003868,Time used 0.008976s\n",
      "batch 4921, train_loss 0.003137,Time used 0.007979s\n",
      "batch 4922, train_loss 0.010589,Time used 0.006981s\n",
      "batch 4923, train_loss 0.003532,Time used 0.008976s\n",
      "batch 4924, train_loss 0.002744,Time used 0.008976s\n",
      "batch 4925, train_loss 0.002440,Time used 0.009974s\n",
      "batch 4926, train_loss 0.004013,Time used 0.009973s\n",
      "batch 4927, train_loss 0.004739,Time used 0.009973s\n",
      "batch 4928, train_loss 0.003893,Time used 0.009974s\n",
      "batch 4929, train_loss 0.003615,Time used 0.009973s\n",
      "batch 4930, train_loss 0.003925,Time used 0.008976s\n",
      "batch 4931, train_loss 0.004459,Time used 0.008977s\n",
      "batch 4932, train_loss 0.004456,Time used 0.008976s\n",
      "batch 4933, train_loss 0.003188,Time used 0.009973s\n",
      "batch 4934, train_loss 0.002904,Time used 0.009974s\n",
      "batch 4935, train_loss 0.003264,Time used 0.009974s\n",
      "batch 4936, train_loss 0.002885,Time used 0.008976s\n",
      "batch 4937, train_loss 0.003272,Time used 0.009973s\n",
      "batch 4938, train_loss 0.003127,Time used 0.008977s\n",
      "batch 4939, train_loss 0.003517,Time used 0.009973s\n",
      "batch 4940, train_loss 0.004266,Time used 0.009973s\n",
      "batch 4941, train_loss 0.003157,Time used 0.008976s\n",
      "batch 4942, train_loss 0.003599,Time used 0.008976s\n",
      "batch 4943, train_loss 0.003700,Time used 0.008977s\n",
      "batch 4944, train_loss 0.004305,Time used 0.008975s\n",
      "batch 4945, train_loss 0.004213,Time used 0.008977s\n",
      "batch 4946, train_loss 0.003071,Time used 0.007979s\n",
      "batch 4947, train_loss 0.003390,Time used 0.007978s\n",
      "batch 4948, train_loss 0.003548,Time used 0.007978s\n",
      "batch 4949, train_loss 0.003595,Time used 0.007978s\n",
      "batch 4950, train_loss 0.003647,Time used 0.007978s\n",
      "batch 4951, train_loss 0.003214,Time used 0.007978s\n",
      "batch 4952, train_loss 0.002857,Time used 0.008977s\n",
      "batch 4953, train_loss 0.002856,Time used 0.008976s\n",
      "batch 4954, train_loss 0.002158,Time used 0.008976s\n",
      "batch 4955, train_loss 0.003048,Time used 0.007979s\n",
      "batch 4956, train_loss 0.003996,Time used 0.007979s\n",
      "batch 4957, train_loss 0.002886,Time used 0.008976s\n",
      "batch 4958, train_loss 0.004980,Time used 0.007979s\n",
      "batch 4959, train_loss 0.006659,Time used 0.008976s\n",
      "batch 4960, train_loss 0.003056,Time used 0.007979s\n",
      "batch 4961, train_loss 0.002425,Time used 0.007978s\n",
      "batch 4962, train_loss 0.003223,Time used 0.008976s\n",
      "batch 4963, train_loss 0.004474,Time used 0.008976s\n",
      "batch 4964, train_loss 0.003738,Time used 0.008976s\n",
      "batch 4965, train_loss 0.003998,Time used 0.007979s\n",
      "batch 4966, train_loss 0.003884,Time used 0.007979s\n",
      "batch 4967, train_loss 0.003548,Time used 0.007979s\n",
      "batch 4968, train_loss 0.004275,Time used 0.007978s\n",
      "batch 4969, train_loss 0.003065,Time used 0.007979s\n",
      "batch 4970, train_loss 0.003805,Time used 0.008976s\n",
      "batch 4971, train_loss 0.003508,Time used 0.007978s\n",
      "batch 4972, train_loss 0.003709,Time used 0.007979s\n",
      "batch 4973, train_loss 0.003675,Time used 0.008975s\n",
      "batch 4974, train_loss 0.003694,Time used 0.008976s\n",
      "batch 4975, train_loss 0.002996,Time used 0.007979s\n",
      "batch 4976, train_loss 0.004342,Time used 0.008976s\n",
      "batch 4977, train_loss 0.003738,Time used 0.007979s\n",
      "batch 4978, train_loss 0.003878,Time used 0.008976s\n",
      "batch 4979, train_loss 0.003898,Time used 0.007978s\n",
      "batch 4980, train_loss 0.003001,Time used 0.008977s\n",
      "batch 4981, train_loss 0.003393,Time used 0.008975s\n",
      "batch 4982, train_loss 0.003662,Time used 0.008977s\n",
      "batch 4983, train_loss 0.005266,Time used 0.008976s\n",
      "batch 4984, train_loss 0.003483,Time used 0.008976s\n",
      "batch 4985, train_loss 0.004203,Time used 0.008976s\n",
      "batch 4986, train_loss 0.004071,Time used 0.008977s\n",
      "batch 4987, train_loss 0.005341,Time used 0.007979s\n",
      "batch 4988, train_loss 0.002800,Time used 0.008976s\n",
      "batch 4989, train_loss 0.003507,Time used 0.008976s\n",
      "batch 4990, train_loss 0.003664,Time used 0.008976s\n",
      "batch 4991, train_loss 0.003538,Time used 0.007978s\n",
      "batch 4992, train_loss 0.003765,Time used 0.007979s\n",
      "batch 4993, train_loss 0.004869,Time used 0.007978s\n",
      "batch 4994, train_loss 0.004158,Time used 0.007979s\n",
      "batch 4995, train_loss 0.003759,Time used 0.007978s\n",
      "batch 4996, train_loss 0.003980,Time used 0.007979s\n",
      "batch 4997, train_loss 0.004326,Time used 0.008976s\n",
      "batch 4998, train_loss 0.004080,Time used 0.008976s\n",
      "batch 4999, train_loss 0.002353,Time used 0.007978s\n",
      "batch 5000, train_loss 0.006139,Time used 0.007978s\n",
      "***************************test_batch 5000, test_rmse_loss 0.060828,test_mae_loss 0.043380,test_mape_loss 13.022490,Time used 0.109707s\n",
      "batch 5001, train_loss 0.003872,Time used 0.008975s\n",
      "batch 5002, train_loss 0.003377,Time used 0.007979s\n",
      "batch 5003, train_loss 0.004459,Time used 0.007979s\n",
      "batch 5004, train_loss 0.003182,Time used 0.007979s\n",
      "batch 5005, train_loss 0.003345,Time used 0.007979s\n",
      "batch 5006, train_loss 0.006407,Time used 0.008976s\n",
      "batch 5007, train_loss 0.003404,Time used 0.007979s\n",
      "batch 5008, train_loss 0.002908,Time used 0.007978s\n",
      "batch 5009, train_loss 0.003436,Time used 0.007978s\n",
      "batch 5010, train_loss 0.002728,Time used 0.008977s\n",
      "batch 5011, train_loss 0.002776,Time used 0.007979s\n",
      "batch 5012, train_loss 0.003117,Time used 0.007978s\n",
      "batch 5013, train_loss 0.003050,Time used 0.007979s\n",
      "batch 5014, train_loss 0.003454,Time used 0.007979s\n",
      "batch 5015, train_loss 0.003210,Time used 0.007978s\n",
      "batch 5016, train_loss 0.002672,Time used 0.007979s\n",
      "batch 5017, train_loss 0.003945,Time used 0.006981s\n",
      "batch 5018, train_loss 0.004530,Time used 0.007979s\n",
      "batch 5019, train_loss 0.003327,Time used 0.007979s\n",
      "batch 5020, train_loss 0.002491,Time used 0.007978s\n",
      "batch 5021, train_loss 0.005138,Time used 0.007979s\n",
      "batch 5022, train_loss 0.003688,Time used 0.008976s\n",
      "batch 5023, train_loss 0.004729,Time used 0.007979s\n",
      "batch 5024, train_loss 0.003244,Time used 0.006982s\n",
      "batch 5025, train_loss 0.003335,Time used 0.007978s\n",
      "batch 5026, train_loss 0.004866,Time used 0.008977s\n",
      "batch 5027, train_loss 0.002577,Time used 0.007978s\n",
      "batch 5028, train_loss 0.002451,Time used 0.007979s\n",
      "batch 5029, train_loss 0.001076,Time used 0.006981s\n",
      "batch 5030, train_loss 0.003032,Time used 0.007978s\n",
      "batch 5031, train_loss 0.004261,Time used 0.007979s\n",
      "batch 5032, train_loss 0.004124,Time used 0.009974s\n",
      "batch 5033, train_loss 0.002985,Time used 0.008975s\n",
      "batch 5034, train_loss 0.003502,Time used 0.007980s\n",
      "batch 5035, train_loss 0.004914,Time used 0.008976s\n",
      "batch 5036, train_loss 0.003640,Time used 0.007978s\n",
      "batch 5037, train_loss 0.003079,Time used 0.007979s\n",
      "batch 5038, train_loss 0.002958,Time used 0.007979s\n",
      "batch 5039, train_loss 0.004319,Time used 0.008975s\n",
      "batch 5040, train_loss 0.003727,Time used 0.008977s\n",
      "batch 5041, train_loss 0.006281,Time used 0.008975s\n",
      "batch 5042, train_loss 0.003181,Time used 0.008976s\n",
      "batch 5043, train_loss 0.005434,Time used 0.008976s\n",
      "batch 5044, train_loss 0.003310,Time used 0.008976s\n",
      "batch 5045, train_loss 0.003909,Time used 0.007978s\n",
      "batch 5046, train_loss 0.004112,Time used 0.007979s\n",
      "batch 5047, train_loss 0.003230,Time used 0.007979s\n",
      "batch 5048, train_loss 0.003378,Time used 0.007978s\n",
      "batch 5049, train_loss 0.002998,Time used 0.007978s\n",
      "batch 5050, train_loss 0.002288,Time used 0.007979s\n",
      "batch 5051, train_loss 0.002537,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5052, train_loss 0.004716,Time used 0.008976s\n",
      "batch 5053, train_loss 0.004085,Time used 0.008976s\n",
      "batch 5054, train_loss 0.003981,Time used 0.007979s\n",
      "batch 5055, train_loss 0.005477,Time used 0.008976s\n",
      "batch 5056, train_loss 0.003312,Time used 0.007979s\n",
      "batch 5057, train_loss 0.002906,Time used 0.007980s\n",
      "batch 5058, train_loss 0.003827,Time used 0.008975s\n",
      "batch 5059, train_loss 0.003719,Time used 0.007979s\n",
      "batch 5060, train_loss 0.003023,Time used 0.008976s\n",
      "batch 5061, train_loss 0.004474,Time used 0.008976s\n",
      "batch 5062, train_loss 0.002799,Time used 0.007979s\n",
      "batch 5063, train_loss 0.002842,Time used 0.008976s\n",
      "batch 5064, train_loss 0.003474,Time used 0.007978s\n",
      "batch 5065, train_loss 0.004028,Time used 0.008976s\n",
      "batch 5066, train_loss 0.004030,Time used 0.008976s\n",
      "batch 5067, train_loss 0.003959,Time used 0.008976s\n",
      "batch 5068, train_loss 0.003761,Time used 0.008975s\n",
      "batch 5069, train_loss 0.003350,Time used 0.008977s\n",
      "batch 5070, train_loss 0.003434,Time used 0.008975s\n",
      "batch 5071, train_loss 0.003248,Time used 0.007980s\n",
      "batch 5072, train_loss 0.003900,Time used 0.007978s\n",
      "batch 5073, train_loss 0.003514,Time used 0.007979s\n",
      "batch 5074, train_loss 0.003343,Time used 0.008975s\n",
      "batch 5075, train_loss 0.003575,Time used 0.007980s\n",
      "batch 5076, train_loss 0.003277,Time used 0.007979s\n",
      "batch 5077, train_loss 0.003427,Time used 0.007978s\n",
      "batch 5078, train_loss 0.003370,Time used 0.007979s\n",
      "batch 5079, train_loss 0.005227,Time used 0.007978s\n",
      "batch 5080, train_loss 0.003708,Time used 0.008033s\n",
      "batch 5081, train_loss 0.003291,Time used 0.007979s\n",
      "batch 5082, train_loss 0.003646,Time used 0.008976s\n",
      "batch 5083, train_loss 0.002495,Time used 0.008976s\n",
      "batch 5084, train_loss 0.002538,Time used 0.008976s\n",
      "batch 5085, train_loss 0.003729,Time used 0.007978s\n",
      "batch 5086, train_loss 0.003266,Time used 0.008975s\n",
      "batch 5087, train_loss 0.004231,Time used 0.008977s\n",
      "batch 5088, train_loss 0.003938,Time used 0.007979s\n",
      "batch 5089, train_loss 0.003168,Time used 0.009974s\n",
      "batch 5090, train_loss 0.002745,Time used 0.008976s\n",
      "batch 5091, train_loss 0.003237,Time used 0.008977s\n",
      "batch 5092, train_loss 0.002966,Time used 0.008977s\n",
      "batch 5093, train_loss 0.003732,Time used 0.008976s\n",
      "batch 5094, train_loss 0.003482,Time used 0.010971s\n",
      "batch 5095, train_loss 0.003268,Time used 0.008976s\n",
      "batch 5096, train_loss 0.003399,Time used 0.008976s\n",
      "batch 5097, train_loss 0.004495,Time used 0.008975s\n",
      "batch 5098, train_loss 0.003676,Time used 0.009974s\n",
      "batch 5099, train_loss 0.003047,Time used 0.009973s\n",
      "batch 5100, train_loss 0.003338,Time used 0.008975s\n",
      "***************************test_batch 5100, test_rmse_loss 0.060916,test_mae_loss 0.043423,test_mape_loss 12.770636,Time used 0.114695s\n",
      "batch 5101, train_loss 0.003812,Time used 0.008975s\n",
      "batch 5102, train_loss 0.005095,Time used 0.008976s\n",
      "batch 5103, train_loss 0.004173,Time used 0.007980s\n",
      "batch 5104, train_loss 0.003678,Time used 0.007980s\n",
      "batch 5105, train_loss 0.002997,Time used 0.007978s\n",
      "batch 5106, train_loss 0.004291,Time used 0.008976s\n",
      "batch 5107, train_loss 0.003325,Time used 0.008976s\n",
      "batch 5108, train_loss 0.002904,Time used 0.008977s\n",
      "batch 5109, train_loss 0.004605,Time used 0.007978s\n",
      "batch 5110, train_loss 0.004249,Time used 0.007980s\n",
      "batch 5111, train_loss 0.003223,Time used 0.007978s\n",
      "batch 5112, train_loss 0.002929,Time used 0.007979s\n",
      "batch 5113, train_loss 0.003866,Time used 0.007978s\n",
      "batch 5114, train_loss 0.003456,Time used 0.007980s\n",
      "batch 5115, train_loss 0.002852,Time used 0.007979s\n",
      "batch 5116, train_loss 0.004424,Time used 0.007978s\n",
      "batch 5117, train_loss 0.004100,Time used 0.007980s\n",
      "batch 5118, train_loss 0.003058,Time used 0.007978s\n",
      "batch 5119, train_loss 0.004580,Time used 0.007978s\n",
      "batch 5120, train_loss 0.003716,Time used 0.007979s\n",
      "batch 5121, train_loss 0.003627,Time used 0.007979s\n",
      "batch 5122, train_loss 0.004130,Time used 0.008976s\n",
      "batch 5123, train_loss 0.002933,Time used 0.008976s\n",
      "batch 5124, train_loss 0.003367,Time used 0.007492s\n",
      "batch 5125, train_loss 0.003879,Time used 0.006981s\n",
      "batch 5126, train_loss 0.003627,Time used 0.008977s\n",
      "batch 5127, train_loss 0.003683,Time used 0.007979s\n",
      "batch 5128, train_loss 0.003062,Time used 0.007978s\n",
      "batch 5129, train_loss 0.002759,Time used 0.008976s\n",
      "batch 5130, train_loss 0.003744,Time used 0.008976s\n",
      "batch 5131, train_loss 0.003554,Time used 0.007978s\n",
      "batch 5132, train_loss 0.003661,Time used 0.009974s\n",
      "batch 5133, train_loss 0.004245,Time used 0.008976s\n",
      "batch 5134, train_loss 0.003833,Time used 0.007979s\n",
      "batch 5135, train_loss 0.003817,Time used 0.008977s\n",
      "batch 5136, train_loss 0.001912,Time used 0.005984s\n",
      "batch 5137, train_loss 0.004064,Time used 0.008976s\n",
      "batch 5138, train_loss 0.006087,Time used 0.007979s\n",
      "batch 5139, train_loss 0.004345,Time used 0.007978s\n",
      "batch 5140, train_loss 0.003896,Time used 0.007978s\n",
      "batch 5141, train_loss 0.003667,Time used 0.007979s\n",
      "batch 5142, train_loss 0.003988,Time used 0.006982s\n",
      "batch 5143, train_loss 0.003619,Time used 0.006981s\n",
      "batch 5144, train_loss 0.003190,Time used 0.009973s\n",
      "batch 5145, train_loss 0.003352,Time used 0.007979s\n",
      "batch 5146, train_loss 0.003557,Time used 0.008977s\n",
      "batch 5147, train_loss 0.005051,Time used 0.009016s\n",
      "batch 5148, train_loss 0.003005,Time used 0.008976s\n",
      "batch 5149, train_loss 0.004594,Time used 0.007978s\n",
      "batch 5150, train_loss 0.003449,Time used 0.008976s\n",
      "batch 5151, train_loss 0.004927,Time used 0.008976s\n",
      "batch 5152, train_loss 0.003085,Time used 0.008976s\n",
      "batch 5153, train_loss 0.004331,Time used 0.008976s\n",
      "batch 5154, train_loss 0.002383,Time used 0.007979s\n",
      "batch 5155, train_loss 0.003088,Time used 0.008976s\n",
      "batch 5156, train_loss 0.003954,Time used 0.007978s\n",
      "batch 5157, train_loss 0.003887,Time used 0.008976s\n",
      "batch 5158, train_loss 0.003369,Time used 0.008976s\n",
      "batch 5159, train_loss 0.004009,Time used 0.007979s\n",
      "batch 5160, train_loss 0.002754,Time used 0.007979s\n",
      "batch 5161, train_loss 0.002823,Time used 0.008976s\n",
      "batch 5162, train_loss 0.003813,Time used 0.007979s\n",
      "batch 5163, train_loss 0.003379,Time used 0.008976s\n",
      "batch 5164, train_loss 0.003643,Time used 0.007978s\n",
      "batch 5165, train_loss 0.004278,Time used 0.008977s\n",
      "batch 5166, train_loss 0.005160,Time used 0.008976s\n",
      "batch 5167, train_loss 0.003997,Time used 0.007978s\n",
      "batch 5168, train_loss 0.004003,Time used 0.007978s\n",
      "batch 5169, train_loss 0.003420,Time used 0.007979s\n",
      "batch 5170, train_loss 0.004459,Time used 0.007979s\n",
      "batch 5171, train_loss 0.003504,Time used 0.007979s\n",
      "batch 5172, train_loss 0.002680,Time used 0.007978s\n",
      "batch 5173, train_loss 0.003574,Time used 0.008976s\n",
      "batch 5174, train_loss 0.003416,Time used 0.008976s\n",
      "batch 5175, train_loss 0.003522,Time used 0.007978s\n",
      "batch 5176, train_loss 0.005181,Time used 0.007979s\n",
      "batch 5177, train_loss 0.003542,Time used 0.008976s\n",
      "batch 5178, train_loss 0.002531,Time used 0.007978s\n",
      "batch 5179, train_loss 0.003790,Time used 0.007979s\n",
      "batch 5180, train_loss 0.004361,Time used 0.008976s\n",
      "batch 5181, train_loss 0.002884,Time used 0.007979s\n",
      "batch 5182, train_loss 0.003677,Time used 0.008976s\n",
      "batch 5183, train_loss 0.004151,Time used 0.008976s\n",
      "batch 5184, train_loss 0.004326,Time used 0.008975s\n",
      "batch 5185, train_loss 0.002749,Time used 0.009974s\n",
      "batch 5186, train_loss 0.003355,Time used 0.010970s\n",
      "batch 5187, train_loss 0.004607,Time used 0.008976s\n",
      "batch 5188, train_loss 0.002444,Time used 0.009975s\n",
      "batch 5189, train_loss 0.004408,Time used 0.009973s\n",
      "batch 5190, train_loss 0.004095,Time used 0.011968s\n",
      "batch 5191, train_loss 0.002841,Time used 0.008986s\n",
      "batch 5192, train_loss 0.003515,Time used 0.008966s\n",
      "batch 5193, train_loss 0.002103,Time used 0.009973s\n",
      "batch 5194, train_loss 0.003587,Time used 0.007978s\n",
      "batch 5195, train_loss 0.003017,Time used 0.007978s\n",
      "batch 5196, train_loss 0.004129,Time used 0.007979s\n",
      "batch 5197, train_loss 0.003219,Time used 0.008975s\n",
      "batch 5198, train_loss 0.003910,Time used 0.007978s\n",
      "batch 5199, train_loss 0.004985,Time used 0.007979s\n",
      "batch 5200, train_loss 0.005743,Time used 0.006981s\n",
      "***************************test_batch 5200, test_rmse_loss 0.060820,test_mae_loss 0.043366,test_mape_loss 12.850164,Time used 0.109706s\n",
      "batch 5201, train_loss 0.003427,Time used 0.008977s\n",
      "batch 5202, train_loss 0.003583,Time used 0.006982s\n",
      "batch 5203, train_loss 0.003489,Time used 0.009973s\n",
      "batch 5204, train_loss 0.004227,Time used 0.008976s\n",
      "batch 5205, train_loss 0.003928,Time used 0.008976s\n",
      "batch 5206, train_loss 0.002979,Time used 0.007979s\n",
      "batch 5207, train_loss 0.003323,Time used 0.008975s\n",
      "batch 5208, train_loss 0.003610,Time used 0.008976s\n",
      "batch 5209, train_loss 0.003049,Time used 0.008976s\n",
      "batch 5210, train_loss 0.003495,Time used 0.008976s\n",
      "batch 5211, train_loss 0.004085,Time used 0.007980s\n",
      "batch 5212, train_loss 0.002852,Time used 0.007978s\n",
      "batch 5213, train_loss 0.002988,Time used 0.008976s\n",
      "batch 5214, train_loss 0.002858,Time used 0.007978s\n",
      "batch 5215, train_loss 0.004154,Time used 0.008975s\n",
      "batch 5216, train_loss 0.002919,Time used 0.008977s\n",
      "batch 5217, train_loss 0.002333,Time used 0.007978s\n",
      "batch 5218, train_loss 0.002740,Time used 0.008976s\n",
      "batch 5219, train_loss 0.003246,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5220, train_loss 0.004379,Time used 0.008976s\n",
      "batch 5221, train_loss 0.003655,Time used 0.009974s\n",
      "batch 5222, train_loss 0.003678,Time used 0.007979s\n",
      "batch 5223, train_loss 0.003509,Time used 0.007978s\n",
      "batch 5224, train_loss 0.003315,Time used 0.007979s\n",
      "batch 5225, train_loss 0.003090,Time used 0.008976s\n",
      "batch 5226, train_loss 0.003864,Time used 0.008976s\n",
      "batch 5227, train_loss 0.004218,Time used 0.008976s\n",
      "batch 5228, train_loss 0.002589,Time used 0.008976s\n",
      "batch 5229, train_loss 0.003774,Time used 0.008976s\n",
      "batch 5230, train_loss 0.003910,Time used 0.009973s\n",
      "batch 5231, train_loss 0.004392,Time used 0.008976s\n",
      "batch 5232, train_loss 0.004541,Time used 0.008975s\n",
      "batch 5233, train_loss 0.002781,Time used 0.008976s\n",
      "batch 5234, train_loss 0.003729,Time used 0.008976s\n",
      "batch 5235, train_loss 0.003620,Time used 0.008975s\n",
      "batch 5236, train_loss 0.003791,Time used 0.007978s\n",
      "batch 5237, train_loss 0.002777,Time used 0.007978s\n",
      "batch 5238, train_loss 0.002482,Time used 0.007978s\n",
      "batch 5239, train_loss 0.003341,Time used 0.008976s\n",
      "batch 5240, train_loss 0.002254,Time used 0.008976s\n",
      "batch 5241, train_loss 0.003779,Time used 0.008976s\n",
      "batch 5242, train_loss 0.004903,Time used 0.008976s\n",
      "batch 5243, train_loss 0.003317,Time used 0.006981s\n",
      "batch 5244, train_loss 0.003129,Time used 0.008975s\n",
      "batch 5245, train_loss 0.002887,Time used 0.008976s\n",
      "batch 5246, train_loss 0.003280,Time used 0.008976s\n",
      "batch 5247, train_loss 0.004220,Time used 0.008976s\n",
      "batch 5248, train_loss 0.003897,Time used 0.008976s\n",
      "batch 5249, train_loss 0.004491,Time used 0.009974s\n",
      "batch 5250, train_loss 0.003134,Time used 0.008976s\n",
      "batch 5251, train_loss 0.003329,Time used 0.008976s\n",
      "batch 5252, train_loss 0.003321,Time used 0.008976s\n",
      "batch 5253, train_loss 0.003140,Time used 0.008977s\n",
      "batch 5254, train_loss 0.003476,Time used 0.008976s\n",
      "batch 5255, train_loss 0.003225,Time used 0.008976s\n",
      "batch 5256, train_loss 0.005510,Time used 0.009974s\n",
      "batch 5257, train_loss 0.002868,Time used 0.008975s\n",
      "batch 5258, train_loss 0.002903,Time used 0.009974s\n",
      "batch 5259, train_loss 0.003230,Time used 0.009974s\n",
      "batch 5260, train_loss 0.003697,Time used 0.010969s\n",
      "batch 5261, train_loss 0.003996,Time used 0.008975s\n",
      "batch 5262, train_loss 0.004122,Time used 0.008976s\n",
      "batch 5263, train_loss 0.003832,Time used 0.007979s\n",
      "batch 5264, train_loss 0.005298,Time used 0.008976s\n",
      "batch 5265, train_loss 0.002910,Time used 0.008976s\n",
      "batch 5266, train_loss 0.002749,Time used 0.009973s\n",
      "batch 5267, train_loss 0.002710,Time used 0.009485s\n",
      "batch 5268, train_loss 0.003012,Time used 0.009973s\n",
      "batch 5269, train_loss 0.004649,Time used 0.009973s\n",
      "batch 5270, train_loss 0.002742,Time used 0.009974s\n",
      "batch 5271, train_loss 0.003207,Time used 0.008976s\n",
      "batch 5272, train_loss 0.003220,Time used 0.009973s\n",
      "batch 5273, train_loss 0.001850,Time used 0.009974s\n",
      "batch 5274, train_loss 0.003581,Time used 0.008977s\n",
      "batch 5275, train_loss 0.003609,Time used 0.009973s\n",
      "batch 5276, train_loss 0.004113,Time used 0.009974s\n",
      "batch 5277, train_loss 0.003441,Time used 0.008976s\n",
      "batch 5278, train_loss 0.005200,Time used 0.008976s\n",
      "batch 5279, train_loss 0.002845,Time used 0.009973s\n",
      "batch 5280, train_loss 0.004317,Time used 0.009973s\n",
      "batch 5281, train_loss 0.002422,Time used 0.010971s\n",
      "batch 5282, train_loss 0.003607,Time used 0.009974s\n",
      "batch 5283, train_loss 0.003901,Time used 0.010970s\n",
      "batch 5284, train_loss 0.004584,Time used 0.010971s\n",
      "batch 5285, train_loss 0.002762,Time used 0.009973s\n",
      "batch 5286, train_loss 0.004835,Time used 0.009974s\n",
      "batch 5287, train_loss 0.005082,Time used 0.009974s\n",
      "batch 5288, train_loss 0.003533,Time used 0.008975s\n",
      "batch 5289, train_loss 0.002409,Time used 0.008976s\n",
      "batch 5290, train_loss 0.003375,Time used 0.008976s\n",
      "batch 5291, train_loss 0.003013,Time used 0.008975s\n",
      "batch 5292, train_loss 0.003093,Time used 0.008975s\n",
      "batch 5293, train_loss 0.003218,Time used 0.008976s\n",
      "batch 5294, train_loss 0.003230,Time used 0.008975s\n",
      "batch 5295, train_loss 0.003640,Time used 0.008977s\n",
      "batch 5296, train_loss 0.004302,Time used 0.008976s\n",
      "batch 5297, train_loss 0.003145,Time used 0.009974s\n",
      "batch 5298, train_loss 0.002907,Time used 0.008977s\n",
      "batch 5299, train_loss 0.003865,Time used 0.008976s\n",
      "batch 5300, train_loss 0.002402,Time used 0.008975s\n",
      "***************************test_batch 5300, test_rmse_loss 0.060815,test_mae_loss 0.043356,test_mape_loss 12.846065,Time used 0.130652s\n",
      "batch 5301, train_loss 0.004485,Time used 0.010970s\n",
      "batch 5302, train_loss 0.003882,Time used 0.009973s\n",
      "batch 5303, train_loss 0.003593,Time used 0.009974s\n",
      "batch 5304, train_loss 0.004234,Time used 0.008976s\n",
      "batch 5305, train_loss 0.003938,Time used 0.008977s\n",
      "batch 5306, train_loss 0.003839,Time used 0.008975s\n",
      "batch 5307, train_loss 0.003581,Time used 0.009973s\n",
      "batch 5308, train_loss 0.003685,Time used 0.009974s\n",
      "batch 5309, train_loss 0.003538,Time used 0.008976s\n",
      "batch 5310, train_loss 0.004032,Time used 0.009973s\n",
      "batch 5311, train_loss 0.002832,Time used 0.008976s\n",
      "batch 5312, train_loss 0.003027,Time used 0.008976s\n",
      "batch 5313, train_loss 0.003422,Time used 0.008975s\n",
      "batch 5314, train_loss 0.003223,Time used 0.008976s\n",
      "batch 5315, train_loss 0.004203,Time used 0.008976s\n",
      "batch 5316, train_loss 0.003931,Time used 0.008976s\n",
      "batch 5317, train_loss 0.002745,Time used 0.008976s\n",
      "batch 5318, train_loss 0.004120,Time used 0.007978s\n",
      "batch 5319, train_loss 0.002781,Time used 0.009974s\n",
      "batch 5320, train_loss 0.003778,Time used 0.009973s\n",
      "batch 5321, train_loss 0.005852,Time used 0.008977s\n",
      "batch 5322, train_loss 0.003488,Time used 0.008976s\n",
      "batch 5323, train_loss 0.005263,Time used 0.007978s\n",
      "batch 5324, train_loss 0.003141,Time used 0.007979s\n",
      "batch 5325, train_loss 0.004106,Time used 0.007979s\n",
      "batch 5326, train_loss 0.005301,Time used 0.007978s\n",
      "batch 5327, train_loss 0.003970,Time used 0.008976s\n",
      "batch 5328, train_loss 0.003057,Time used 0.008976s\n",
      "batch 5329, train_loss 0.003186,Time used 0.008975s\n",
      "batch 5330, train_loss 0.002802,Time used 0.008977s\n",
      "batch 5331, train_loss 0.003708,Time used 0.008976s\n",
      "batch 5332, train_loss 0.003362,Time used 0.008976s\n",
      "batch 5333, train_loss 0.002525,Time used 0.007979s\n",
      "batch 5334, train_loss 0.005254,Time used 0.007978s\n",
      "batch 5335, train_loss 0.003242,Time used 0.007978s\n",
      "batch 5336, train_loss 0.002783,Time used 0.007979s\n",
      "batch 5337, train_loss 0.003226,Time used 0.007979s\n",
      "batch 5338, train_loss 0.003423,Time used 0.008975s\n",
      "batch 5339, train_loss 0.003506,Time used 0.008976s\n",
      "batch 5340, train_loss 0.004181,Time used 0.008976s\n",
      "batch 5341, train_loss 0.005189,Time used 0.008976s\n",
      "batch 5342, train_loss 0.007087,Time used 0.008976s\n",
      "batch 5343, train_loss 0.004078,Time used 0.008975s\n",
      "batch 5344, train_loss 0.003941,Time used 0.008976s\n",
      "batch 5345, train_loss 0.003710,Time used 0.008976s\n",
      "batch 5346, train_loss 0.003826,Time used 0.008977s\n",
      "batch 5347, train_loss 0.004165,Time used 0.008976s\n",
      "batch 5348, train_loss 0.002402,Time used 0.008976s\n",
      "batch 5349, train_loss 0.003233,Time used 0.008976s\n",
      "batch 5350, train_loss 0.006792,Time used 0.006982s\n",
      "batch 5351, train_loss 0.003266,Time used 0.008976s\n",
      "batch 5352, train_loss 0.003707,Time used 0.008976s\n",
      "batch 5353, train_loss 0.003124,Time used 0.008976s\n",
      "batch 5354, train_loss 0.002716,Time used 0.008976s\n",
      "batch 5355, train_loss 0.004619,Time used 0.007979s\n",
      "batch 5356, train_loss 0.002630,Time used 0.007978s\n",
      "batch 5357, train_loss 0.002786,Time used 0.007979s\n",
      "batch 5358, train_loss 0.003798,Time used 0.008976s\n",
      "batch 5359, train_loss 0.004198,Time used 0.008976s\n",
      "batch 5360, train_loss 0.004752,Time used 0.008976s\n",
      "batch 5361, train_loss 0.003727,Time used 0.009974s\n",
      "batch 5362, train_loss 0.002960,Time used 0.008975s\n",
      "batch 5363, train_loss 0.004154,Time used 0.009973s\n",
      "batch 5364, train_loss 0.003048,Time used 0.008977s\n",
      "batch 5365, train_loss 0.003245,Time used 0.007978s\n",
      "batch 5366, train_loss 0.003689,Time used 0.007980s\n",
      "batch 5367, train_loss 0.003990,Time used 0.007978s\n",
      "batch 5368, train_loss 0.003666,Time used 0.008975s\n",
      "batch 5369, train_loss 0.003859,Time used 0.008976s\n",
      "batch 5370, train_loss 0.003756,Time used 0.007979s\n",
      "batch 5371, train_loss 0.003584,Time used 0.008976s\n",
      "batch 5372, train_loss 0.005751,Time used 0.008976s\n",
      "batch 5373, train_loss 0.003967,Time used 0.008976s\n",
      "batch 5374, train_loss 0.003987,Time used 0.008975s\n",
      "batch 5375, train_loss 0.003098,Time used 0.007980s\n",
      "batch 5376, train_loss 0.003841,Time used 0.009974s\n",
      "batch 5377, train_loss 0.003793,Time used 0.009972s\n",
      "batch 5378, train_loss 0.003518,Time used 0.008976s\n",
      "batch 5379, train_loss 0.003385,Time used 0.008976s\n",
      "batch 5380, train_loss 0.004422,Time used 0.008976s\n",
      "batch 5381, train_loss 0.002403,Time used 0.008976s\n",
      "batch 5382, train_loss 0.004220,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5383, train_loss 0.003371,Time used 0.008976s\n",
      "batch 5384, train_loss 0.003619,Time used 0.008976s\n",
      "batch 5385, train_loss 0.003256,Time used 0.008977s\n",
      "batch 5386, train_loss 0.003193,Time used 0.008976s\n",
      "batch 5387, train_loss 0.003787,Time used 0.009973s\n",
      "batch 5388, train_loss 0.004047,Time used 0.009973s\n",
      "batch 5389, train_loss 0.004439,Time used 0.009974s\n",
      "batch 5390, train_loss 0.003936,Time used 0.009974s\n",
      "batch 5391, train_loss 0.004078,Time used 0.008975s\n",
      "batch 5392, train_loss 0.002989,Time used 0.007978s\n",
      "batch 5393, train_loss 0.003183,Time used 0.007978s\n",
      "batch 5394, train_loss 0.004928,Time used 0.009973s\n",
      "batch 5395, train_loss 0.004064,Time used 0.023936s\n",
      "batch 5396, train_loss 0.003872,Time used 0.010971s\n",
      "batch 5397, train_loss 0.003028,Time used 0.011968s\n",
      "batch 5398, train_loss 0.004009,Time used 0.023498s\n",
      "batch 5399, train_loss 0.003888,Time used 0.016467s\n",
      "batch 5400, train_loss 0.002864,Time used 0.015958s\n",
      "***************************test_batch 5400, test_rmse_loss 0.060851,test_mae_loss 0.043369,test_mape_loss 12.820447,Time used 0.134641s\n",
      "batch 5401, train_loss 0.004396,Time used 0.009973s\n",
      "batch 5402, train_loss 0.004542,Time used 0.008976s\n",
      "batch 5403, train_loss 0.002706,Time used 0.008977s\n",
      "batch 5404, train_loss 0.003007,Time used 0.008977s\n",
      "batch 5405, train_loss 0.003210,Time used 0.010971s\n",
      "batch 5406, train_loss 0.004014,Time used 0.009973s\n",
      "batch 5407, train_loss 0.002958,Time used 0.010971s\n",
      "batch 5408, train_loss 0.003511,Time used 0.010971s\n",
      "batch 5409, train_loss 0.004010,Time used 0.009974s\n",
      "batch 5410, train_loss 0.003021,Time used 0.009973s\n",
      "batch 5411, train_loss 0.004747,Time used 0.009973s\n",
      "batch 5412, train_loss 0.004515,Time used 0.009974s\n",
      "batch 5413, train_loss 0.002862,Time used 0.009973s\n",
      "batch 5414, train_loss 0.003595,Time used 0.008976s\n",
      "batch 5415, train_loss 0.003443,Time used 0.008977s\n",
      "batch 5416, train_loss 0.002705,Time used 0.007979s\n",
      "batch 5417, train_loss 0.004078,Time used 0.008977s\n",
      "batch 5418, train_loss 0.003602,Time used 0.008976s\n",
      "batch 5419, train_loss 0.005491,Time used 0.009974s\n",
      "batch 5420, train_loss 0.003302,Time used 0.009973s\n",
      "batch 5421, train_loss 0.003183,Time used 0.009973s\n",
      "batch 5422, train_loss 0.003568,Time used 0.009974s\n",
      "batch 5423, train_loss 0.004930,Time used 0.011968s\n",
      "batch 5424, train_loss 0.003896,Time used 0.008977s\n",
      "batch 5425, train_loss 0.003769,Time used 0.008976s\n",
      "batch 5426, train_loss 0.003450,Time used 0.008977s\n",
      "batch 5427, train_loss 0.003573,Time used 0.009512s\n",
      "batch 5428, train_loss 0.003488,Time used 0.008976s\n",
      "batch 5429, train_loss 0.004653,Time used 0.007978s\n",
      "batch 5430, train_loss 0.003635,Time used 0.008977s\n",
      "batch 5431, train_loss 0.002816,Time used 0.007978s\n",
      "batch 5432, train_loss 0.002624,Time used 0.007978s\n",
      "batch 5433, train_loss 0.003586,Time used 0.007979s\n",
      "batch 5434, train_loss 0.003487,Time used 0.007979s\n",
      "batch 5435, train_loss 0.003037,Time used 0.008976s\n",
      "batch 5436, train_loss 0.003188,Time used 0.008976s\n",
      "batch 5437, train_loss 0.003165,Time used 0.008976s\n",
      "batch 5438, train_loss 0.003360,Time used 0.007978s\n",
      "batch 5439, train_loss 0.002813,Time used 0.008977s\n",
      "batch 5440, train_loss 0.003183,Time used 0.008976s\n",
      "batch 5441, train_loss 0.004597,Time used 0.008976s\n",
      "batch 5442, train_loss 0.004191,Time used 0.007978s\n",
      "batch 5443, train_loss 0.003141,Time used 0.007979s\n",
      "batch 5444, train_loss 0.003935,Time used 0.008976s\n",
      "batch 5445, train_loss 0.003200,Time used 0.007978s\n",
      "batch 5446, train_loss 0.003605,Time used 0.007979s\n",
      "batch 5447, train_loss 0.003461,Time used 0.007978s\n",
      "batch 5448, train_loss 0.002563,Time used 0.007979s\n",
      "batch 5449, train_loss 0.005257,Time used 0.008976s\n",
      "batch 5450, train_loss 0.003499,Time used 0.008976s\n",
      "batch 5451, train_loss 0.003959,Time used 0.008976s\n",
      "batch 5452, train_loss 0.003192,Time used 0.007978s\n",
      "batch 5453, train_loss 0.003842,Time used 0.007979s\n",
      "batch 5454, train_loss 0.003140,Time used 0.007979s\n",
      "batch 5455, train_loss 0.003147,Time used 0.007978s\n",
      "batch 5456, train_loss 0.004400,Time used 0.007979s\n",
      "batch 5457, train_loss 0.000520,Time used 0.005984s\n",
      "batch 5458, train_loss 0.004336,Time used 0.007978s\n",
      "batch 5459, train_loss 0.003590,Time used 0.007979s\n",
      "batch 5460, train_loss 0.004654,Time used 0.007979s\n",
      "batch 5461, train_loss 0.004803,Time used 0.007978s\n",
      "batch 5462, train_loss 0.002771,Time used 0.007979s\n",
      "batch 5463, train_loss 0.004813,Time used 0.007979s\n",
      "batch 5464, train_loss 0.003327,Time used 0.006981s\n",
      "batch 5465, train_loss 0.003334,Time used 0.007979s\n",
      "batch 5466, train_loss 0.003824,Time used 0.007979s\n",
      "batch 5467, train_loss 0.003342,Time used 0.007980s\n",
      "batch 5468, train_loss 0.003089,Time used 0.007978s\n",
      "batch 5469, train_loss 0.003376,Time used 0.007978s\n",
      "batch 5470, train_loss 0.002953,Time used 0.007978s\n",
      "batch 5471, train_loss 0.003899,Time used 0.008976s\n",
      "batch 5472, train_loss 0.004401,Time used 0.008977s\n",
      "batch 5473, train_loss 0.002247,Time used 0.007978s\n",
      "batch 5474, train_loss 0.004328,Time used 0.007979s\n",
      "batch 5475, train_loss 0.002603,Time used 0.008976s\n",
      "batch 5476, train_loss 0.003917,Time used 0.007979s\n",
      "batch 5477, train_loss 0.002118,Time used 0.007978s\n",
      "batch 5478, train_loss 0.003839,Time used 0.008976s\n",
      "batch 5479, train_loss 0.003999,Time used 0.008976s\n",
      "batch 5480, train_loss 0.005108,Time used 0.009973s\n",
      "batch 5481, train_loss 0.003467,Time used 0.008977s\n",
      "batch 5482, train_loss 0.003105,Time used 0.009973s\n",
      "batch 5483, train_loss 0.003638,Time used 0.009973s\n",
      "batch 5484, train_loss 0.003976,Time used 0.008976s\n",
      "batch 5485, train_loss 0.002475,Time used 0.008977s\n",
      "batch 5486, train_loss 0.003535,Time used 0.010971s\n",
      "batch 5487, train_loss 0.004728,Time used 0.008976s\n",
      "batch 5488, train_loss 0.003936,Time used 0.009974s\n",
      "batch 5489, train_loss 0.003939,Time used 0.008975s\n",
      "batch 5490, train_loss 0.003062,Time used 0.009974s\n",
      "batch 5491, train_loss 0.002908,Time used 0.008976s\n",
      "batch 5492, train_loss 0.002857,Time used 0.008976s\n",
      "batch 5493, train_loss 0.003768,Time used 0.009975s\n",
      "batch 5494, train_loss 0.003265,Time used 0.008976s\n",
      "batch 5495, train_loss 0.003225,Time used 0.009974s\n",
      "batch 5496, train_loss 0.004002,Time used 0.008977s\n",
      "batch 5497, train_loss 0.002789,Time used 0.009973s\n",
      "batch 5498, train_loss 0.002467,Time used 0.008976s\n",
      "batch 5499, train_loss 0.004279,Time used 0.008976s\n",
      "batch 5500, train_loss 0.003924,Time used 0.008976s\n",
      "***************************test_batch 5500, test_rmse_loss 0.060805,test_mae_loss 0.043359,test_mape_loss 12.913633,Time used 0.114692s\n",
      "batch 5501, train_loss 0.002905,Time used 0.008976s\n",
      "batch 5502, train_loss 0.002785,Time used 0.008976s\n",
      "batch 5503, train_loss 0.003231,Time used 0.009973s\n",
      "batch 5504, train_loss 0.004318,Time used 0.008976s\n",
      "batch 5505, train_loss 0.003907,Time used 0.009974s\n",
      "batch 5506, train_loss 0.003978,Time used 0.008976s\n",
      "batch 5507, train_loss 0.004137,Time used 0.009973s\n",
      "batch 5508, train_loss 0.003204,Time used 0.007978s\n",
      "batch 5509, train_loss 0.004289,Time used 0.009974s\n",
      "batch 5510, train_loss 0.004358,Time used 0.008976s\n",
      "batch 5511, train_loss 0.003652,Time used 0.009974s\n",
      "batch 5512, train_loss 0.002389,Time used 0.009973s\n",
      "batch 5513, train_loss 0.003655,Time used 0.011968s\n",
      "batch 5514, train_loss 0.003873,Time used 0.012966s\n",
      "batch 5515, train_loss 0.003779,Time used 0.010971s\n",
      "batch 5516, train_loss 0.003994,Time used 0.010971s\n",
      "batch 5517, train_loss 0.004125,Time used 0.015957s\n",
      "batch 5518, train_loss 0.003230,Time used 0.009973s\n",
      "batch 5519, train_loss 0.003573,Time used 0.010972s\n",
      "batch 5520, train_loss 0.003995,Time used 0.010970s\n",
      "batch 5521, train_loss 0.003910,Time used 0.010971s\n",
      "batch 5522, train_loss 0.003895,Time used 0.010971s\n",
      "batch 5523, train_loss 0.002902,Time used 0.010970s\n",
      "batch 5524, train_loss 0.002623,Time used 0.011968s\n",
      "batch 5525, train_loss 0.003339,Time used 0.008976s\n",
      "batch 5526, train_loss 0.004810,Time used 0.009973s\n",
      "batch 5527, train_loss 0.004167,Time used 0.010970s\n",
      "batch 5528, train_loss 0.004897,Time used 0.009973s\n",
      "batch 5529, train_loss 0.005026,Time used 0.010971s\n",
      "batch 5530, train_loss 0.003421,Time used 0.009973s\n",
      "batch 5531, train_loss 0.003274,Time used 0.008976s\n",
      "batch 5532, train_loss 0.003706,Time used 0.009973s\n",
      "batch 5533, train_loss 0.006449,Time used 0.010045s\n",
      "batch 5534, train_loss 0.003144,Time used 0.008976s\n",
      "batch 5535, train_loss 0.003531,Time used 0.008977s\n",
      "batch 5536, train_loss 0.002666,Time used 0.008976s\n",
      "batch 5537, train_loss 0.003068,Time used 0.008976s\n",
      "batch 5538, train_loss 0.004308,Time used 0.009973s\n",
      "batch 5539, train_loss 0.003227,Time used 0.008976s\n",
      "batch 5540, train_loss 0.002936,Time used 0.008977s\n",
      "batch 5541, train_loss 0.003574,Time used 0.009973s\n",
      "batch 5542, train_loss 0.003413,Time used 0.009973s\n",
      "batch 5543, train_loss 0.004166,Time used 0.053856s\n",
      "batch 5544, train_loss 0.004358,Time used 0.010970s\n",
      "batch 5545, train_loss 0.003818,Time used 0.009974s\n",
      "batch 5546, train_loss 0.002585,Time used 0.010971s\n",
      "batch 5547, train_loss 0.006743,Time used 0.009974s\n",
      "batch 5548, train_loss 0.002334,Time used 0.010970s\n",
      "batch 5549, train_loss 0.003286,Time used 0.010482s\n",
      "batch 5550, train_loss 0.002910,Time used 0.012966s\n",
      "batch 5551, train_loss 0.003461,Time used 0.010970s\n",
      "batch 5552, train_loss 0.002963,Time used 0.010972s\n",
      "batch 5553, train_loss 0.005353,Time used 0.011967s\n",
      "batch 5554, train_loss 0.002469,Time used 0.011969s\n",
      "batch 5555, train_loss 0.003907,Time used 0.009974s\n",
      "batch 5556, train_loss 0.002831,Time used 0.013963s\n",
      "batch 5557, train_loss 0.003074,Time used 0.010971s\n",
      "batch 5558, train_loss 0.005143,Time used 0.011967s\n",
      "batch 5559, train_loss 0.002972,Time used 0.010027s\n",
      "batch 5560, train_loss 0.003662,Time used 0.010971s\n",
      "batch 5561, train_loss 0.003062,Time used 0.009973s\n",
      "batch 5562, train_loss 0.003362,Time used 0.009974s\n",
      "batch 5563, train_loss 0.003594,Time used 0.009974s\n",
      "batch 5564, train_loss 0.006995,Time used 0.006981s\n",
      "batch 5565, train_loss 0.002889,Time used 0.008976s\n",
      "batch 5566, train_loss 0.004119,Time used 0.009973s\n",
      "batch 5567, train_loss 0.003566,Time used 0.008976s\n",
      "batch 5568, train_loss 0.003602,Time used 0.009974s\n",
      "batch 5569, train_loss 0.004322,Time used 0.009979s\n",
      "batch 5570, train_loss 0.003813,Time used 0.009968s\n",
      "batch 5571, train_loss 0.002902,Time used 0.009974s\n",
      "batch 5572, train_loss 0.002780,Time used 0.007978s\n",
      "batch 5573, train_loss 0.003443,Time used 0.008976s\n",
      "batch 5574, train_loss 0.003606,Time used 0.008976s\n",
      "batch 5575, train_loss 0.004080,Time used 0.008976s\n",
      "batch 5576, train_loss 0.003393,Time used 0.009974s\n",
      "batch 5577, train_loss 0.002477,Time used 0.008976s\n",
      "batch 5578, train_loss 0.002486,Time used 0.009973s\n",
      "batch 5579, train_loss 0.006250,Time used 0.008976s\n",
      "batch 5580, train_loss 0.004188,Time used 0.009012s\n",
      "batch 5581, train_loss 0.004312,Time used 0.008976s\n",
      "batch 5582, train_loss 0.003094,Time used 0.008976s\n",
      "batch 5583, train_loss 0.004279,Time used 0.008975s\n",
      "batch 5584, train_loss 0.003615,Time used 0.009974s\n",
      "batch 5585, train_loss 0.002391,Time used 0.010970s\n",
      "batch 5586, train_loss 0.003397,Time used 0.007978s\n",
      "batch 5587, train_loss 0.003007,Time used 0.008977s\n",
      "batch 5588, train_loss 0.003323,Time used 0.008976s\n",
      "batch 5589, train_loss 0.003210,Time used 0.009974s\n",
      "batch 5590, train_loss 0.004552,Time used 0.008975s\n",
      "batch 5591, train_loss 0.005701,Time used 0.007979s\n",
      "batch 5592, train_loss 0.002656,Time used 0.008976s\n",
      "batch 5593, train_loss 0.004918,Time used 0.008976s\n",
      "batch 5594, train_loss 0.003691,Time used 0.009974s\n",
      "batch 5595, train_loss 0.002763,Time used 0.007979s\n",
      "batch 5596, train_loss 0.003035,Time used 0.008976s\n",
      "batch 5597, train_loss 0.003766,Time used 0.008976s\n",
      "batch 5598, train_loss 0.004794,Time used 0.008976s\n",
      "batch 5599, train_loss 0.003088,Time used 0.008977s\n",
      "batch 5600, train_loss 0.002801,Time used 0.007979s\n",
      "***************************test_batch 5600, test_rmse_loss 0.060816,test_mae_loss 0.043324,test_mape_loss 12.900787,Time used 0.116710s\n",
      "batch 5601, train_loss 0.003165,Time used 0.008975s\n",
      "batch 5602, train_loss 0.003426,Time used 0.007978s\n",
      "batch 5603, train_loss 0.003887,Time used 0.007979s\n",
      "batch 5604, train_loss 0.003336,Time used 0.008976s\n",
      "batch 5605, train_loss 0.003743,Time used 0.009973s\n",
      "batch 5606, train_loss 0.003697,Time used 0.008975s\n",
      "batch 5607, train_loss 0.004535,Time used 0.008976s\n",
      "batch 5608, train_loss 0.002806,Time used 0.008976s\n",
      "batch 5609, train_loss 0.004296,Time used 0.008976s\n",
      "batch 5610, train_loss 0.003949,Time used 0.008976s\n",
      "batch 5611, train_loss 0.002478,Time used 0.007978s\n",
      "batch 5612, train_loss 0.003983,Time used 0.007979s\n",
      "batch 5613, train_loss 0.003715,Time used 0.007978s\n",
      "batch 5614, train_loss 0.003700,Time used 0.007980s\n",
      "batch 5615, train_loss 0.003673,Time used 0.007978s\n",
      "batch 5616, train_loss 0.004387,Time used 0.007978s\n",
      "batch 5617, train_loss 0.004312,Time used 0.008977s\n",
      "batch 5618, train_loss 0.002721,Time used 0.008976s\n",
      "batch 5619, train_loss 0.003879,Time used 0.007978s\n",
      "batch 5620, train_loss 0.003612,Time used 0.007979s\n",
      "batch 5621, train_loss 0.003355,Time used 0.007978s\n",
      "batch 5622, train_loss 0.002909,Time used 0.008976s\n",
      "batch 5623, train_loss 0.002349,Time used 0.007979s\n",
      "batch 5624, train_loss 0.003684,Time used 0.008976s\n",
      "batch 5625, train_loss 0.003050,Time used 0.007979s\n",
      "batch 5626, train_loss 0.004294,Time used 0.007979s\n",
      "batch 5627, train_loss 0.003793,Time used 0.006981s\n",
      "batch 5628, train_loss 0.003601,Time used 0.007979s\n",
      "batch 5629, train_loss 0.003850,Time used 0.007978s\n",
      "batch 5630, train_loss 0.003777,Time used 0.006982s\n",
      "batch 5631, train_loss 0.004885,Time used 0.006981s\n",
      "batch 5632, train_loss 0.003956,Time used 0.007981s\n",
      "batch 5633, train_loss 0.003101,Time used 0.007979s\n",
      "batch 5634, train_loss 0.003115,Time used 0.007978s\n",
      "batch 5635, train_loss 0.004570,Time used 0.006981s\n",
      "batch 5636, train_loss 0.003520,Time used 0.007978s\n",
      "batch 5637, train_loss 0.003561,Time used 0.007979s\n",
      "batch 5638, train_loss 0.003372,Time used 0.007979s\n",
      "batch 5639, train_loss 0.003120,Time used 0.007979s\n",
      "batch 5640, train_loss 0.003056,Time used 0.007978s\n",
      "batch 5641, train_loss 0.003450,Time used 0.006981s\n",
      "batch 5642, train_loss 0.002825,Time used 0.006981s\n",
      "batch 5643, train_loss 0.003366,Time used 0.006981s\n",
      "batch 5644, train_loss 0.004934,Time used 0.008977s\n",
      "batch 5645, train_loss 0.003575,Time used 0.008975s\n",
      "batch 5646, train_loss 0.005692,Time used 0.008977s\n",
      "batch 5647, train_loss 0.004910,Time used 0.008976s\n",
      "batch 5648, train_loss 0.003344,Time used 0.007979s\n",
      "batch 5649, train_loss 0.003556,Time used 0.007979s\n",
      "batch 5650, train_loss 0.003487,Time used 0.006981s\n",
      "batch 5651, train_loss 0.003948,Time used 0.007978s\n",
      "batch 5652, train_loss 0.003326,Time used 0.007978s\n",
      "batch 5653, train_loss 0.002821,Time used 0.007979s\n",
      "batch 5654, train_loss 0.004278,Time used 0.007978s\n",
      "batch 5655, train_loss 0.005639,Time used 0.007979s\n",
      "batch 5656, train_loss 0.002509,Time used 0.007979s\n",
      "batch 5657, train_loss 0.005413,Time used 0.007978s\n",
      "batch 5658, train_loss 0.003291,Time used 0.006980s\n",
      "batch 5659, train_loss 0.003606,Time used 0.007979s\n",
      "batch 5660, train_loss 0.003908,Time used 0.007978s\n",
      "batch 5661, train_loss 0.003167,Time used 0.008976s\n",
      "batch 5662, train_loss 0.002191,Time used 0.007979s\n",
      "batch 5663, train_loss 0.004769,Time used 0.007979s\n",
      "batch 5664, train_loss 0.003892,Time used 0.007979s\n",
      "batch 5665, train_loss 0.002834,Time used 0.007977s\n",
      "batch 5666, train_loss 0.003827,Time used 0.008976s\n",
      "batch 5667, train_loss 0.002844,Time used 0.007979s\n",
      "batch 5668, train_loss 0.003467,Time used 0.008976s\n",
      "batch 5669, train_loss 0.003463,Time used 0.007979s\n",
      "batch 5670, train_loss 0.003602,Time used 0.008975s\n",
      "batch 5671, train_loss 0.003316,Time used 0.005985s\n",
      "batch 5672, train_loss 0.005778,Time used 0.007979s\n",
      "batch 5673, train_loss 0.002726,Time used 0.007978s\n",
      "batch 5674, train_loss 0.002973,Time used 0.007978s\n",
      "batch 5675, train_loss 0.003887,Time used 0.007978s\n",
      "batch 5676, train_loss 0.003952,Time used 0.007978s\n",
      "batch 5677, train_loss 0.007064,Time used 0.009973s\n",
      "batch 5678, train_loss 0.003191,Time used 0.008976s\n",
      "batch 5679, train_loss 0.003342,Time used 0.008976s\n",
      "batch 5680, train_loss 0.002698,Time used 0.008976s\n",
      "batch 5681, train_loss 0.004041,Time used 0.008976s\n",
      "batch 5682, train_loss 0.003534,Time used 0.008976s\n",
      "batch 5683, train_loss 0.004655,Time used 0.008976s\n",
      "batch 5684, train_loss 0.004020,Time used 0.008976s\n",
      "batch 5685, train_loss 0.004040,Time used 0.008976s\n",
      "batch 5686, train_loss 0.003121,Time used 0.008976s\n",
      "batch 5687, train_loss 0.003225,Time used 0.009973s\n",
      "batch 5688, train_loss 0.004403,Time used 0.009974s\n",
      "batch 5689, train_loss 0.003608,Time used 0.008976s\n",
      "batch 5690, train_loss 0.003073,Time used 0.008976s\n",
      "batch 5691, train_loss 0.003762,Time used 0.008976s\n",
      "batch 5692, train_loss 0.003453,Time used 0.007979s\n",
      "batch 5693, train_loss 0.004191,Time used 0.007979s\n",
      "batch 5694, train_loss 0.003271,Time used 0.007979s\n",
      "batch 5695, train_loss 0.003187,Time used 0.008976s\n",
      "batch 5696, train_loss 0.003022,Time used 0.008976s\n",
      "batch 5697, train_loss 0.003636,Time used 0.007979s\n",
      "batch 5698, train_loss 0.005136,Time used 0.007979s\n",
      "batch 5699, train_loss 0.003099,Time used 0.007979s\n",
      "batch 5700, train_loss 0.003835,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************test_batch 5700, test_rmse_loss 0.061182,test_mae_loss 0.043685,test_mape_loss 12.739527,Time used 0.110704s\n",
      "batch 5701, train_loss 0.003784,Time used 0.007979s\n",
      "batch 5702, train_loss 0.004745,Time used 0.007979s\n",
      "batch 5703, train_loss 0.003989,Time used 0.008976s\n",
      "batch 5704, train_loss 0.004078,Time used 0.007979s\n",
      "batch 5705, train_loss 0.003262,Time used 0.007978s\n",
      "batch 5706, train_loss 0.003833,Time used 0.007979s\n",
      "batch 5707, train_loss 0.005610,Time used 0.008976s\n",
      "batch 5708, train_loss 0.002704,Time used 0.007979s\n",
      "batch 5709, train_loss 0.003372,Time used 0.007979s\n",
      "batch 5710, train_loss 0.002210,Time used 0.008977s\n",
      "batch 5711, train_loss 0.002855,Time used 0.007978s\n",
      "batch 5712, train_loss 0.005676,Time used 0.007979s\n",
      "batch 5713, train_loss 0.004456,Time used 0.007980s\n",
      "batch 5714, train_loss 0.003575,Time used 0.007979s\n",
      "batch 5715, train_loss 0.003787,Time used 0.007979s\n",
      "batch 5716, train_loss 0.003772,Time used 0.007978s\n",
      "batch 5717, train_loss 0.003804,Time used 0.007978s\n",
      "batch 5718, train_loss 0.002963,Time used 0.007978s\n",
      "batch 5719, train_loss 0.003743,Time used 0.007979s\n",
      "batch 5720, train_loss 0.003356,Time used 0.008975s\n",
      "batch 5721, train_loss 0.004806,Time used 0.007979s\n",
      "batch 5722, train_loss 0.003909,Time used 0.007979s\n",
      "batch 5723, train_loss 0.004768,Time used 0.008976s\n",
      "batch 5724, train_loss 0.004522,Time used 0.007979s\n",
      "batch 5725, train_loss 0.003616,Time used 0.008976s\n",
      "batch 5726, train_loss 0.002668,Time used 0.008976s\n",
      "batch 5727, train_loss 0.002550,Time used 0.008976s\n",
      "batch 5728, train_loss 0.002527,Time used 0.007979s\n",
      "batch 5729, train_loss 0.003808,Time used 0.007979s\n",
      "batch 5730, train_loss 0.002967,Time used 0.007979s\n",
      "batch 5731, train_loss 0.003256,Time used 0.008976s\n",
      "batch 5732, train_loss 0.002627,Time used 0.008976s\n",
      "batch 5733, train_loss 0.003329,Time used 0.007978s\n",
      "batch 5734, train_loss 0.003931,Time used 0.008976s\n",
      "batch 5735, train_loss 0.003282,Time used 0.009974s\n",
      "batch 5736, train_loss 0.002330,Time used 0.009973s\n",
      "batch 5737, train_loss 0.002619,Time used 0.008975s\n",
      "batch 5738, train_loss 0.003094,Time used 0.007979s\n",
      "batch 5739, train_loss 0.003462,Time used 0.007979s\n",
      "batch 5740, train_loss 0.003887,Time used 0.008976s\n",
      "batch 5741, train_loss 0.003278,Time used 0.007979s\n",
      "batch 5742, train_loss 0.003239,Time used 0.007979s\n",
      "batch 5743, train_loss 0.003487,Time used 0.008975s\n",
      "batch 5744, train_loss 0.003790,Time used 0.008976s\n",
      "batch 5745, train_loss 0.002765,Time used 0.008977s\n",
      "batch 5746, train_loss 0.003267,Time used 0.008976s\n",
      "batch 5747, train_loss 0.003758,Time used 0.008975s\n",
      "batch 5748, train_loss 0.004244,Time used 0.007979s\n",
      "batch 5749, train_loss 0.003528,Time used 0.007979s\n",
      "batch 5750, train_loss 0.002739,Time used 0.007978s\n",
      "batch 5751, train_loss 0.002637,Time used 0.007979s\n",
      "batch 5752, train_loss 0.003632,Time used 0.007978s\n",
      "batch 5753, train_loss 0.004949,Time used 0.007978s\n",
      "batch 5754, train_loss 0.002677,Time used 0.007979s\n",
      "batch 5755, train_loss 0.003399,Time used 0.008977s\n",
      "batch 5756, train_loss 0.003629,Time used 0.008975s\n",
      "batch 5757, train_loss 0.004801,Time used 0.010970s\n",
      "batch 5758, train_loss 0.004518,Time used 0.008976s\n",
      "batch 5759, train_loss 0.002750,Time used 0.007979s\n",
      "batch 5760, train_loss 0.005132,Time used 0.007979s\n",
      "batch 5761, train_loss 0.003395,Time used 0.007980s\n",
      "batch 5762, train_loss 0.004407,Time used 0.008976s\n",
      "batch 5763, train_loss 0.003107,Time used 0.007979s\n",
      "batch 5764, train_loss 0.004313,Time used 0.008976s\n",
      "batch 5765, train_loss 0.002534,Time used 0.008976s\n",
      "batch 5766, train_loss 0.003702,Time used 0.008975s\n",
      "batch 5767, train_loss 0.003671,Time used 0.008976s\n",
      "batch 5768, train_loss 0.004698,Time used 0.009974s\n",
      "batch 5769, train_loss 0.003679,Time used 0.007979s\n",
      "batch 5770, train_loss 0.003722,Time used 0.007978s\n",
      "batch 5771, train_loss 0.002637,Time used 0.007978s\n",
      "batch 5772, train_loss 0.004132,Time used 0.007978s\n",
      "batch 5773, train_loss 0.003230,Time used 0.008976s\n",
      "batch 5774, train_loss 0.002925,Time used 0.008976s\n",
      "batch 5775, train_loss 0.002503,Time used 0.008975s\n",
      "batch 5776, train_loss 0.004343,Time used 0.008976s\n",
      "batch 5777, train_loss 0.003699,Time used 0.008976s\n",
      "batch 5778, train_loss 0.009324,Time used 0.006982s\n",
      "batch 5779, train_loss 0.003217,Time used 0.008975s\n",
      "batch 5780, train_loss 0.003731,Time used 0.008976s\n",
      "batch 5781, train_loss 0.002936,Time used 0.008977s\n",
      "batch 5782, train_loss 0.002938,Time used 0.008975s\n",
      "batch 5783, train_loss 0.004082,Time used 0.007979s\n",
      "batch 5784, train_loss 0.003474,Time used 0.008976s\n",
      "batch 5785, train_loss 0.003279,Time used 0.007979s\n",
      "batch 5786, train_loss 0.002883,Time used 0.008976s\n",
      "batch 5787, train_loss 0.003397,Time used 0.007979s\n",
      "batch 5788, train_loss 0.003219,Time used 0.007980s\n",
      "batch 5789, train_loss 0.003589,Time used 0.007978s\n",
      "batch 5790, train_loss 0.003857,Time used 0.007979s\n",
      "batch 5791, train_loss 0.003752,Time used 0.007979s\n",
      "batch 5792, train_loss 0.004692,Time used 0.008976s\n",
      "batch 5793, train_loss 0.003246,Time used 0.007979s\n",
      "batch 5794, train_loss 0.003077,Time used 0.007978s\n",
      "batch 5795, train_loss 0.003996,Time used 0.009974s\n",
      "batch 5796, train_loss 0.002352,Time used 0.008976s\n",
      "batch 5797, train_loss 0.004090,Time used 0.008976s\n",
      "batch 5798, train_loss 0.003931,Time used 0.008976s\n",
      "batch 5799, train_loss 0.003389,Time used 0.008487s\n",
      "batch 5800, train_loss 0.003011,Time used 0.007979s\n",
      "***************************test_batch 5800, test_rmse_loss 0.060784,test_mae_loss 0.043325,test_mape_loss 12.828353,Time used 0.112700s\n",
      "batch 5801, train_loss 0.002910,Time used 0.008976s\n",
      "batch 5802, train_loss 0.002892,Time used 0.007978s\n",
      "batch 5803, train_loss 0.003028,Time used 0.007979s\n",
      "batch 5804, train_loss 0.003758,Time used 0.007978s\n",
      "batch 5805, train_loss 0.004825,Time used 0.007979s\n",
      "batch 5806, train_loss 0.003846,Time used 0.007978s\n",
      "batch 5807, train_loss 0.003803,Time used 0.007979s\n",
      "batch 5808, train_loss 0.004599,Time used 0.007979s\n",
      "batch 5809, train_loss 0.002999,Time used 0.007979s\n",
      "batch 5810, train_loss 0.003741,Time used 0.007979s\n",
      "batch 5811, train_loss 0.003900,Time used 0.007978s\n",
      "batch 5812, train_loss 0.003241,Time used 0.007978s\n",
      "batch 5813, train_loss 0.003416,Time used 0.008976s\n",
      "batch 5814, train_loss 0.002796,Time used 0.008976s\n",
      "batch 5815, train_loss 0.003116,Time used 0.008976s\n",
      "batch 5816, train_loss 0.003692,Time used 0.008976s\n",
      "batch 5817, train_loss 0.002911,Time used 0.008976s\n",
      "batch 5818, train_loss 0.003944,Time used 0.008976s\n",
      "batch 5819, train_loss 0.003863,Time used 0.007979s\n",
      "batch 5820, train_loss 0.002736,Time used 0.008977s\n",
      "batch 5821, train_loss 0.004133,Time used 0.007978s\n",
      "batch 5822, train_loss 0.003187,Time used 0.008976s\n",
      "batch 5823, train_loss 0.004553,Time used 0.008976s\n",
      "batch 5824, train_loss 0.005427,Time used 0.008975s\n",
      "batch 5825, train_loss 0.002587,Time used 0.007979s\n",
      "batch 5826, train_loss 0.003663,Time used 0.008976s\n",
      "batch 5827, train_loss 0.003000,Time used 0.007978s\n",
      "batch 5828, train_loss 0.004560,Time used 0.007978s\n",
      "batch 5829, train_loss 0.003575,Time used 0.007978s\n",
      "batch 5830, train_loss 0.004214,Time used 0.008977s\n",
      "batch 5831, train_loss 0.003486,Time used 0.007978s\n",
      "batch 5832, train_loss 0.003524,Time used 0.007979s\n",
      "batch 5833, train_loss 0.003874,Time used 0.007980s\n",
      "batch 5834, train_loss 0.004685,Time used 0.007979s\n",
      "batch 5835, train_loss 0.005091,Time used 0.008976s\n",
      "batch 5836, train_loss 0.003840,Time used 0.007979s\n",
      "batch 5837, train_loss 0.003470,Time used 0.007978s\n",
      "batch 5838, train_loss 0.004248,Time used 0.008976s\n",
      "batch 5839, train_loss 0.004995,Time used 0.008976s\n",
      "batch 5840, train_loss 0.003610,Time used 0.007979s\n",
      "batch 5841, train_loss 0.003759,Time used 0.007979s\n",
      "batch 5842, train_loss 0.002826,Time used 0.007978s\n",
      "batch 5843, train_loss 0.003379,Time used 0.008976s\n",
      "batch 5844, train_loss 0.003358,Time used 0.008976s\n",
      "batch 5845, train_loss 0.003249,Time used 0.009973s\n",
      "batch 5846, train_loss 0.002934,Time used 0.008977s\n",
      "batch 5847, train_loss 0.004829,Time used 0.008975s\n",
      "batch 5848, train_loss 0.003872,Time used 0.007979s\n",
      "batch 5849, train_loss 0.003447,Time used 0.008976s\n",
      "batch 5850, train_loss 0.002752,Time used 0.008976s\n",
      "batch 5851, train_loss 0.002694,Time used 0.008976s\n",
      "batch 5852, train_loss 0.003073,Time used 0.008976s\n",
      "batch 5853, train_loss 0.003543,Time used 0.008975s\n",
      "batch 5854, train_loss 0.003784,Time used 0.008977s\n",
      "batch 5855, train_loss 0.003329,Time used 0.008976s\n",
      "batch 5856, train_loss 0.003536,Time used 0.008976s\n",
      "batch 5857, train_loss 0.003653,Time used 0.007979s\n",
      "batch 5858, train_loss 0.003586,Time used 0.007978s\n",
      "batch 5859, train_loss 0.004313,Time used 0.007978s\n",
      "batch 5860, train_loss 0.004000,Time used 0.007978s\n",
      "batch 5861, train_loss 0.003980,Time used 0.007979s\n",
      "batch 5862, train_loss 0.004386,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5863, train_loss 0.007307,Time used 0.007978s\n",
      "batch 5864, train_loss 0.002745,Time used 0.008976s\n",
      "batch 5865, train_loss 0.002503,Time used 0.007978s\n",
      "batch 5866, train_loss 0.004206,Time used 0.007980s\n",
      "batch 5867, train_loss 0.004427,Time used 0.006981s\n",
      "batch 5868, train_loss 0.004658,Time used 0.007979s\n",
      "batch 5869, train_loss 0.003445,Time used 0.008976s\n",
      "batch 5870, train_loss 0.003791,Time used 0.007979s\n",
      "batch 5871, train_loss 0.004097,Time used 0.007978s\n",
      "batch 5872, train_loss 0.003499,Time used 0.007979s\n",
      "batch 5873, train_loss 0.003350,Time used 0.007979s\n",
      "batch 5874, train_loss 0.003220,Time used 0.007979s\n",
      "batch 5875, train_loss 0.002788,Time used 0.007978s\n",
      "batch 5876, train_loss 0.003431,Time used 0.007978s\n",
      "batch 5877, train_loss 0.003202,Time used 0.007978s\n",
      "batch 5878, train_loss 0.003685,Time used 0.008977s\n",
      "batch 5879, train_loss 0.003894,Time used 0.008976s\n",
      "batch 5880, train_loss 0.003571,Time used 0.008975s\n",
      "batch 5881, train_loss 0.003409,Time used 0.008977s\n",
      "batch 5882, train_loss 0.005318,Time used 0.008975s\n",
      "batch 5883, train_loss 0.003070,Time used 0.008976s\n",
      "batch 5884, train_loss 0.003732,Time used 0.007978s\n",
      "batch 5885, train_loss 0.001950,Time used 0.007979s\n",
      "batch 5886, train_loss 0.004428,Time used 0.008976s\n",
      "batch 5887, train_loss 0.003616,Time used 0.008976s\n",
      "batch 5888, train_loss 0.004080,Time used 0.007978s\n",
      "batch 5889, train_loss 0.004091,Time used 0.008976s\n",
      "batch 5890, train_loss 0.003438,Time used 0.007979s\n",
      "batch 5891, train_loss 0.003909,Time used 0.007978s\n",
      "batch 5892, train_loss 0.004969,Time used 0.008976s\n",
      "batch 5893, train_loss 0.003630,Time used 0.007977s\n",
      "batch 5894, train_loss 0.003440,Time used 0.009974s\n",
      "batch 5895, train_loss 0.003894,Time used 0.007978s\n",
      "batch 5896, train_loss 0.003338,Time used 0.008975s\n",
      "batch 5897, train_loss 0.003428,Time used 0.008977s\n",
      "batch 5898, train_loss 0.004643,Time used 0.009973s\n",
      "batch 5899, train_loss 0.002916,Time used 0.009973s\n",
      "batch 5900, train_loss 0.003558,Time used 0.008976s\n",
      "***************************test_batch 5900, test_rmse_loss 0.060778,test_mae_loss 0.043338,test_mape_loss 12.959563,Time used 0.117685s\n",
      "batch 5901, train_loss 0.003045,Time used 0.009973s\n",
      "batch 5902, train_loss 0.003568,Time used 0.008975s\n",
      "batch 5903, train_loss 0.003636,Time used 0.008976s\n",
      "batch 5904, train_loss 0.002491,Time used 0.008976s\n",
      "batch 5905, train_loss 0.003181,Time used 0.008976s\n",
      "batch 5906, train_loss 0.003568,Time used 0.008976s\n",
      "batch 5907, train_loss 0.003296,Time used 0.008976s\n",
      "batch 5908, train_loss 0.003000,Time used 0.008975s\n",
      "batch 5909, train_loss 0.003488,Time used 0.008977s\n",
      "batch 5910, train_loss 0.003516,Time used 0.007978s\n",
      "batch 5911, train_loss 0.004307,Time used 0.007979s\n",
      "batch 5912, train_loss 0.003850,Time used 0.008976s\n",
      "batch 5913, train_loss 0.003985,Time used 0.014960s\n",
      "batch 5914, train_loss 0.003104,Time used 0.014959s\n",
      "batch 5915, train_loss 0.004696,Time used 0.010971s\n",
      "batch 5916, train_loss 0.002614,Time used 0.008976s\n",
      "batch 5917, train_loss 0.003096,Time used 0.008976s\n",
      "batch 5918, train_loss 0.005349,Time used 0.009973s\n",
      "batch 5919, train_loss 0.004980,Time used 0.008976s\n",
      "batch 5920, train_loss 0.003795,Time used 0.009974s\n",
      "batch 5921, train_loss 0.003122,Time used 0.009972s\n",
      "batch 5922, train_loss 0.003498,Time used 0.009974s\n",
      "batch 5923, train_loss 0.002853,Time used 0.009972s\n",
      "batch 5924, train_loss 0.003823,Time used 0.008977s\n",
      "batch 5925, train_loss 0.003207,Time used 0.008976s\n",
      "batch 5926, train_loss 0.002973,Time used 0.009974s\n",
      "batch 5927, train_loss 0.003831,Time used 0.009973s\n",
      "batch 5928, train_loss 0.003666,Time used 0.008976s\n",
      "batch 5929, train_loss 0.002735,Time used 0.008976s\n",
      "batch 5930, train_loss 0.003255,Time used 0.009974s\n",
      "batch 5931, train_loss 0.003371,Time used 0.009973s\n",
      "batch 5932, train_loss 0.002479,Time used 0.008976s\n",
      "batch 5933, train_loss 0.004575,Time used 0.008976s\n",
      "batch 5934, train_loss 0.003064,Time used 0.008977s\n",
      "batch 5935, train_loss 0.003778,Time used 0.008975s\n",
      "batch 5936, train_loss 0.003749,Time used 0.008977s\n",
      "batch 5937, train_loss 0.002533,Time used 0.009973s\n",
      "batch 5938, train_loss 0.003885,Time used 0.007979s\n",
      "batch 5939, train_loss 0.004863,Time used 0.008976s\n",
      "batch 5940, train_loss 0.004014,Time used 0.008976s\n",
      "batch 5941, train_loss 0.003744,Time used 0.008975s\n",
      "batch 5942, train_loss 0.004333,Time used 0.009974s\n",
      "batch 5943, train_loss 0.003531,Time used 0.008976s\n",
      "batch 5944, train_loss 0.004027,Time used 0.008976s\n",
      "batch 5945, train_loss 0.005612,Time used 0.007978s\n",
      "batch 5946, train_loss 0.002944,Time used 0.008977s\n",
      "batch 5947, train_loss 0.002769,Time used 0.008975s\n",
      "batch 5948, train_loss 0.003119,Time used 0.006981s\n",
      "batch 5949, train_loss 0.004034,Time used 0.007979s\n",
      "batch 5950, train_loss 0.004005,Time used 0.008976s\n",
      "batch 5951, train_loss 0.002683,Time used 0.009974s\n",
      "batch 5952, train_loss 0.003006,Time used 0.008976s\n",
      "batch 5953, train_loss 0.003852,Time used 0.008975s\n",
      "batch 5954, train_loss 0.002873,Time used 0.008976s\n",
      "batch 5955, train_loss 0.003417,Time used 0.008976s\n",
      "batch 5956, train_loss 0.004916,Time used 0.007979s\n",
      "batch 5957, train_loss 0.002659,Time used 0.007978s\n",
      "batch 5958, train_loss 0.004024,Time used 0.007978s\n",
      "batch 5959, train_loss 0.003897,Time used 0.009974s\n",
      "batch 5960, train_loss 0.002827,Time used 0.008976s\n",
      "batch 5961, train_loss 0.003285,Time used 0.008976s\n",
      "batch 5962, train_loss 0.003868,Time used 0.007979s\n",
      "batch 5963, train_loss 0.003012,Time used 0.007978s\n",
      "batch 5964, train_loss 0.003447,Time used 0.008976s\n",
      "batch 5965, train_loss 0.002898,Time used 0.008976s\n",
      "batch 5966, train_loss 0.003436,Time used 0.008976s\n",
      "batch 5967, train_loss 0.003337,Time used 0.007978s\n",
      "batch 5968, train_loss 0.004500,Time used 0.008978s\n",
      "batch 5969, train_loss 0.004769,Time used 0.008975s\n",
      "batch 5970, train_loss 0.002950,Time used 0.008976s\n",
      "batch 5971, train_loss 0.002769,Time used 0.008975s\n",
      "batch 5972, train_loss 0.003389,Time used 0.020944s\n",
      "batch 5973, train_loss 0.004211,Time used 0.009973s\n",
      "batch 5974, train_loss 0.003666,Time used 0.009974s\n",
      "batch 5975, train_loss 0.004115,Time used 0.008976s\n",
      "batch 5976, train_loss 0.004722,Time used 0.008976s\n",
      "batch 5977, train_loss 0.003537,Time used 0.008977s\n",
      "batch 5978, train_loss 0.003136,Time used 0.008977s\n",
      "batch 5979, train_loss 0.003213,Time used 0.008975s\n",
      "batch 5980, train_loss 0.003486,Time used 0.008976s\n",
      "batch 5981, train_loss 0.004756,Time used 0.008976s\n",
      "batch 5982, train_loss 0.002699,Time used 0.009974s\n",
      "batch 5983, train_loss 0.004825,Time used 0.008976s\n",
      "batch 5984, train_loss 0.004898,Time used 0.008976s\n",
      "batch 5985, train_loss 0.003420,Time used 0.009973s\n",
      "batch 5986, train_loss 0.003623,Time used 0.008977s\n",
      "batch 5987, train_loss 0.003736,Time used 0.008976s\n",
      "batch 5988, train_loss 0.003519,Time used 0.007980s\n",
      "batch 5989, train_loss 0.003165,Time used 0.008976s\n",
      "batch 5990, train_loss 0.002244,Time used 0.008976s\n",
      "batch 5991, train_loss 0.005472,Time used 0.007979s\n",
      "batch 5992, train_loss 0.002480,Time used 0.006981s\n",
      "batch 5993, train_loss 0.003352,Time used 0.007978s\n",
      "batch 5994, train_loss 0.004819,Time used 0.008975s\n",
      "batch 5995, train_loss 0.004553,Time used 0.008976s\n",
      "batch 5996, train_loss 0.003837,Time used 0.008976s\n",
      "batch 5997, train_loss 0.004929,Time used 0.007979s\n",
      "batch 5998, train_loss 0.003100,Time used 0.009974s\n",
      "batch 5999, train_loss 0.003308,Time used 0.008975s\n",
      "batch 6000, train_loss 0.004227,Time used 0.008976s\n",
      "***************************test_batch 6000, test_rmse_loss 0.060829,test_mae_loss 0.043393,test_mape_loss 12.789818,Time used 0.107712s\n",
      "batch 6001, train_loss 0.002838,Time used 0.008976s\n",
      "batch 6002, train_loss 0.003100,Time used 0.008976s\n",
      "batch 6003, train_loss 0.002648,Time used 0.007979s\n",
      "batch 6004, train_loss 0.004007,Time used 0.006981s\n",
      "batch 6005, train_loss 0.002255,Time used 0.006981s\n",
      "batch 6006, train_loss 0.004324,Time used 0.006981s\n",
      "batch 6007, train_loss 0.003088,Time used 0.008975s\n",
      "batch 6008, train_loss 0.002948,Time used 0.007980s\n",
      "batch 6009, train_loss 0.004647,Time used 0.007979s\n",
      "batch 6010, train_loss 0.003532,Time used 0.007979s\n",
      "batch 6011, train_loss 0.003298,Time used 0.007979s\n",
      "batch 6012, train_loss 0.004689,Time used 0.008976s\n",
      "batch 6013, train_loss 0.003755,Time used 0.008976s\n",
      "batch 6014, train_loss 0.004739,Time used 0.007979s\n",
      "batch 6015, train_loss 0.003138,Time used 0.007979s\n",
      "batch 6016, train_loss 0.003486,Time used 0.008977s\n",
      "batch 6017, train_loss 0.003309,Time used 0.007979s\n",
      "batch 6018, train_loss 0.004201,Time used 0.007979s\n",
      "batch 6019, train_loss 0.003891,Time used 0.007978s\n",
      "batch 6020, train_loss 0.002707,Time used 0.007979s\n",
      "batch 6021, train_loss 0.005954,Time used 0.008976s\n",
      "batch 6022, train_loss 0.003665,Time used 0.008976s\n",
      "batch 6023, train_loss 0.003095,Time used 0.007979s\n",
      "batch 6024, train_loss 0.004169,Time used 0.007979s\n",
      "batch 6025, train_loss 0.003392,Time used 0.007979s\n",
      "batch 6026, train_loss 0.002997,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 6027, train_loss 0.004437,Time used 0.008976s\n",
      "batch 6028, train_loss 0.003555,Time used 0.008976s\n",
      "batch 6029, train_loss 0.005888,Time used 0.007978s\n",
      "batch 6030, train_loss 0.003423,Time used 0.006982s\n",
      "batch 6031, train_loss 0.004012,Time used 0.008976s\n",
      "batch 6032, train_loss 0.005031,Time used 0.007979s\n",
      "batch 6033, train_loss 0.002755,Time used 0.008976s\n",
      "batch 6034, train_loss 0.003607,Time used 0.007978s\n",
      "batch 6035, train_loss 0.003264,Time used 0.007979s\n",
      "batch 6036, train_loss 0.004093,Time used 0.008976s\n",
      "batch 6037, train_loss 0.004582,Time used 0.008976s\n",
      "batch 6038, train_loss 0.004312,Time used 0.008977s\n",
      "batch 6039, train_loss 0.004137,Time used 0.008975s\n",
      "batch 6040, train_loss 0.002191,Time used 0.007979s\n",
      "batch 6041, train_loss 0.002670,Time used 0.007978s\n",
      "batch 6042, train_loss 0.002882,Time used 0.008975s\n",
      "batch 6043, train_loss 0.003422,Time used 0.008977s\n",
      "batch 6044, train_loss 0.004048,Time used 0.007977s\n",
      "batch 6045, train_loss 0.003389,Time used 0.007979s\n",
      "batch 6046, train_loss 0.004651,Time used 0.008976s\n",
      "batch 6047, train_loss 0.004799,Time used 0.008976s\n",
      "batch 6048, train_loss 0.003259,Time used 0.008976s\n",
      "batch 6049, train_loss 0.004161,Time used 0.008976s\n",
      "batch 6050, train_loss 0.003126,Time used 0.007978s\n",
      "batch 6051, train_loss 0.003189,Time used 0.007979s\n",
      "batch 6052, train_loss 0.002747,Time used 0.007978s\n",
      "batch 6053, train_loss 0.004789,Time used 0.007979s\n",
      "batch 6054, train_loss 0.002823,Time used 0.007979s\n",
      "batch 6055, train_loss 0.003780,Time used 0.007978s\n",
      "batch 6056, train_loss 0.004858,Time used 0.007995s\n",
      "batch 6057, train_loss 0.003476,Time used 0.008487s\n",
      "batch 6058, train_loss 0.002058,Time used 0.007978s\n",
      "batch 6059, train_loss 0.002890,Time used 0.007979s\n",
      "batch 6060, train_loss 0.003393,Time used 0.007979s\n",
      "batch 6061, train_loss 0.003634,Time used 0.007978s\n",
      "batch 6062, train_loss 0.002834,Time used 0.007979s\n",
      "batch 6063, train_loss 0.005165,Time used 0.007978s\n",
      "batch 6064, train_loss 0.003408,Time used 0.007979s\n",
      "batch 6065, train_loss 0.003448,Time used 0.007978s\n",
      "batch 6066, train_loss 0.004320,Time used 0.007979s\n",
      "batch 6067, train_loss 0.003479,Time used 0.007978s\n",
      "batch 6068, train_loss 0.003198,Time used 0.008976s\n",
      "batch 6069, train_loss 0.003091,Time used 0.007979s\n",
      "batch 6070, train_loss 0.003025,Time used 0.008976s\n",
      "batch 6071, train_loss 0.003519,Time used 0.007979s\n",
      "batch 6072, train_loss 0.005031,Time used 0.008976s\n",
      "batch 6073, train_loss 0.003691,Time used 0.008975s\n",
      "batch 6074, train_loss 0.003165,Time used 0.008976s\n",
      "batch 6075, train_loss 0.002504,Time used 0.008977s\n",
      "batch 6076, train_loss 0.002856,Time used 0.007979s\n",
      "batch 6077, train_loss 0.003934,Time used 0.007979s\n",
      "batch 6078, train_loss 0.003024,Time used 0.007979s\n",
      "batch 6079, train_loss 0.003011,Time used 0.008976s\n",
      "batch 6080, train_loss 0.003029,Time used 0.008976s\n",
      "batch 6081, train_loss 0.003539,Time used 0.007978s\n",
      "batch 6082, train_loss 0.003891,Time used 0.007978s\n",
      "batch 6083, train_loss 0.004473,Time used 0.009973s\n",
      "batch 6084, train_loss 0.002567,Time used 0.007978s\n",
      "batch 6085, train_loss 0.002447,Time used 0.009974s\n",
      "batch 6086, train_loss 0.003817,Time used 0.007978s\n",
      "batch 6087, train_loss 0.004626,Time used 0.008976s\n",
      "batch 6088, train_loss 0.002722,Time used 0.007979s\n",
      "batch 6089, train_loss 0.004199,Time used 0.007978s\n",
      "batch 6090, train_loss 0.004576,Time used 0.008977s\n",
      "batch 6091, train_loss 0.002994,Time used 0.008976s\n",
      "batch 6092, train_loss 0.002972,Time used 0.007979s\n",
      "batch 6093, train_loss 0.003265,Time used 0.007978s\n",
      "batch 6094, train_loss 0.003111,Time used 0.007979s\n",
      "batch 6095, train_loss 0.003229,Time used 0.008977s\n",
      "batch 6096, train_loss 0.004006,Time used 0.008975s\n",
      "batch 6097, train_loss 0.004780,Time used 0.008977s\n",
      "batch 6098, train_loss 0.003268,Time used 0.009973s\n",
      "batch 6099, train_loss 0.001859,Time used 0.007978s\n",
      "batch 6100, train_loss 0.003511,Time used 0.009973s\n",
      "***************************test_batch 6100, test_rmse_loss 0.060786,test_mae_loss 0.043329,test_mape_loss 12.824403,Time used 0.120732s\n",
      "batch 6101, train_loss 0.003833,Time used 0.008976s\n",
      "batch 6102, train_loss 0.003447,Time used 0.008975s\n",
      "batch 6103, train_loss 0.003014,Time used 0.008976s\n",
      "batch 6104, train_loss 0.004363,Time used 0.008976s\n",
      "batch 6105, train_loss 0.003271,Time used 0.008976s\n",
      "batch 6106, train_loss 0.003356,Time used 0.009973s\n",
      "batch 6107, train_loss 0.003754,Time used 0.008976s\n",
      "batch 6108, train_loss 0.003326,Time used 0.008976s\n",
      "batch 6109, train_loss 0.003822,Time used 0.006981s\n",
      "batch 6110, train_loss 0.003369,Time used 0.007979s\n",
      "batch 6111, train_loss 0.003802,Time used 0.008976s\n",
      "batch 6112, train_loss 0.005026,Time used 0.007979s\n",
      "batch 6113, train_loss 0.004950,Time used 0.007979s\n",
      "batch 6114, train_loss 0.003456,Time used 0.008976s\n",
      "batch 6115, train_loss 0.004734,Time used 0.007979s\n",
      "batch 6116, train_loss 0.004148,Time used 0.008976s\n",
      "batch 6117, train_loss 0.003326,Time used 0.007978s\n",
      "batch 6118, train_loss 0.005263,Time used 0.008976s\n",
      "batch 6119, train_loss 0.003348,Time used 0.008975s\n",
      "batch 6120, train_loss 0.003597,Time used 0.008976s\n",
      "batch 6121, train_loss 0.003413,Time used 0.009385s\n",
      "batch 6122, train_loss 0.005534,Time used 0.007979s\n",
      "batch 6123, train_loss 0.004115,Time used 0.007978s\n",
      "batch 6124, train_loss 0.003084,Time used 0.007979s\n",
      "batch 6125, train_loss 0.002490,Time used 0.008976s\n",
      "batch 6126, train_loss 0.003827,Time used 0.008976s\n",
      "batch 6127, train_loss 0.003951,Time used 0.008976s\n",
      "batch 6128, train_loss 0.003908,Time used 0.007979s\n",
      "batch 6129, train_loss 0.002629,Time used 0.008976s\n",
      "batch 6130, train_loss 0.003421,Time used 0.007979s\n",
      "batch 6131, train_loss 0.002686,Time used 0.007979s\n",
      "batch 6132, train_loss 0.004151,Time used 0.007979s\n",
      "batch 6133, train_loss 0.003669,Time used 0.007979s\n",
      "batch 6134, train_loss 0.003407,Time used 0.008976s\n",
      "batch 6135, train_loss 0.003889,Time used 0.008976s\n",
      "batch 6136, train_loss 0.003303,Time used 0.007979s\n",
      "batch 6137, train_loss 0.003054,Time used 0.008976s\n",
      "batch 6138, train_loss 0.003972,Time used 0.008976s\n",
      "batch 6139, train_loss 0.005820,Time used 0.008976s\n",
      "batch 6140, train_loss 0.003453,Time used 0.007978s\n",
      "batch 6141, train_loss 0.002999,Time used 0.007979s\n",
      "batch 6142, train_loss 0.003763,Time used 0.007979s\n",
      "batch 6143, train_loss 0.003908,Time used 0.009973s\n",
      "batch 6144, train_loss 0.003898,Time used 0.007978s\n",
      "batch 6145, train_loss 0.003718,Time used 0.008977s\n",
      "batch 6146, train_loss 0.002642,Time used 0.008209s\n",
      "batch 6147, train_loss 0.002693,Time used 0.007979s\n",
      "batch 6148, train_loss 0.002988,Time used 0.008976s\n",
      "batch 6149, train_loss 0.002597,Time used 0.007978s\n",
      "batch 6150, train_loss 0.003468,Time used 0.008976s\n",
      "batch 6151, train_loss 0.002944,Time used 0.008976s\n",
      "batch 6152, train_loss 0.003744,Time used 0.008977s\n",
      "batch 6153, train_loss 0.002936,Time used 0.008976s\n",
      "batch 6154, train_loss 0.003920,Time used 0.008975s\n",
      "batch 6155, train_loss 0.004688,Time used 0.008975s\n",
      "batch 6156, train_loss 0.004965,Time used 0.008975s\n",
      "batch 6157, train_loss 0.002633,Time used 0.008977s\n",
      "batch 6158, train_loss 0.003044,Time used 0.009973s\n",
      "batch 6159, train_loss 0.003205,Time used 0.008976s\n",
      "batch 6160, train_loss 0.004737,Time used 0.008977s\n",
      "batch 6161, train_loss 0.004148,Time used 0.009974s\n",
      "batch 6162, train_loss 0.003402,Time used 0.009973s\n",
      "batch 6163, train_loss 0.002928,Time used 0.008976s\n",
      "batch 6164, train_loss 0.001697,Time used 0.008976s\n",
      "batch 6165, train_loss 0.002707,Time used 0.009973s\n",
      "batch 6166, train_loss 0.002969,Time used 0.008976s\n",
      "batch 6167, train_loss 0.003519,Time used 0.008976s\n",
      "batch 6168, train_loss 0.003983,Time used 0.007979s\n",
      "batch 6169, train_loss 0.002864,Time used 0.008975s\n",
      "batch 6170, train_loss 0.004348,Time used 0.008977s\n",
      "batch 6171, train_loss 0.005253,Time used 0.007978s\n",
      "batch 6172, train_loss 0.003224,Time used 0.008976s\n",
      "batch 6173, train_loss 0.005139,Time used 0.008976s\n",
      "batch 6174, train_loss 0.003262,Time used 0.009974s\n",
      "batch 6175, train_loss 0.003619,Time used 0.008976s\n",
      "batch 6176, train_loss 0.003259,Time used 0.008976s\n",
      "batch 6177, train_loss 0.004009,Time used 0.008976s\n",
      "batch 6178, train_loss 0.004265,Time used 0.007979s\n",
      "batch 6179, train_loss 0.003242,Time used 0.007978s\n",
      "batch 6180, train_loss 0.004494,Time used 0.008976s\n",
      "batch 6181, train_loss 0.004843,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 6182, train_loss 0.002125,Time used 0.007979s\n",
      "batch 6183, train_loss 0.003749,Time used 0.008977s\n",
      "batch 6184, train_loss 0.002680,Time used 0.008975s\n",
      "batch 6185, train_loss 0.004170,Time used 0.008976s\n",
      "batch 6186, train_loss 0.003174,Time used 0.007979s\n",
      "batch 6187, train_loss 0.003632,Time used 0.008976s\n",
      "batch 6188, train_loss 0.003930,Time used 0.008976s\n",
      "batch 6189, train_loss 0.003836,Time used 0.008976s\n",
      "batch 6190, train_loss 0.002840,Time used 0.007979s\n",
      "batch 6191, train_loss 0.003655,Time used 0.008976s\n",
      "batch 6192, train_loss 0.003097,Time used 0.008976s\n",
      "batch 6193, train_loss 0.002763,Time used 0.008975s\n",
      "batch 6194, train_loss 0.004529,Time used 0.008976s\n",
      "batch 6195, train_loss 0.003974,Time used 0.008976s\n",
      "batch 6196, train_loss 0.002760,Time used 0.015958s\n",
      "batch 6197, train_loss 0.004247,Time used 0.008976s\n",
      "batch 6198, train_loss 0.003367,Time used 0.008977s\n",
      "batch 6199, train_loss 0.003778,Time used 0.008977s\n",
      "batch 6200, train_loss 0.003296,Time used 0.008976s\n",
      "***************************test_batch 6200, test_rmse_loss 0.060796,test_mae_loss 0.043332,test_mape_loss 12.839150,Time used 0.124668s\n",
      "batch 6201, train_loss 0.004678,Time used 0.007978s\n",
      "batch 6202, train_loss 0.002921,Time used 0.008977s\n",
      "batch 6203, train_loss 0.003448,Time used 0.008975s\n",
      "batch 6204, train_loss 0.004817,Time used 0.009973s\n",
      "batch 6205, train_loss 0.003650,Time used 0.009973s\n",
      "batch 6206, train_loss 0.001638,Time used 0.007979s\n",
      "batch 6207, train_loss 0.003221,Time used 0.008976s\n",
      "batch 6208, train_loss 0.003415,Time used 0.009973s\n",
      "batch 6209, train_loss 0.004832,Time used 0.009974s\n",
      "batch 6210, train_loss 0.004478,Time used 0.009974s\n",
      "batch 6211, train_loss 0.003065,Time used 0.009974s\n",
      "batch 6212, train_loss 0.004517,Time used 0.009973s\n",
      "batch 6213, train_loss 0.002931,Time used 0.009973s\n",
      "batch 6214, train_loss 0.002827,Time used 0.009973s\n",
      "batch 6215, train_loss 0.003802,Time used 0.008976s\n",
      "batch 6216, train_loss 0.001999,Time used 0.009974s\n",
      "batch 6217, train_loss 0.003709,Time used 0.008976s\n",
      "batch 6218, train_loss 0.004016,Time used 0.008975s\n",
      "batch 6219, train_loss 0.003686,Time used 0.008976s\n",
      "batch 6220, train_loss 0.004011,Time used 0.009973s\n",
      "batch 6221, train_loss 0.003434,Time used 0.008976s\n",
      "batch 6222, train_loss 0.002457,Time used 0.008977s\n",
      "batch 6223, train_loss 0.003283,Time used 0.009972s\n",
      "batch 6224, train_loss 0.002202,Time used 0.009973s\n",
      "batch 6225, train_loss 0.004139,Time used 0.008976s\n",
      "batch 6226, train_loss 0.004261,Time used 0.009973s\n",
      "batch 6227, train_loss 0.003858,Time used 0.008976s\n",
      "batch 6228, train_loss 0.003890,Time used 0.009972s\n",
      "batch 6229, train_loss 0.003541,Time used 0.008976s\n",
      "batch 6230, train_loss 0.002984,Time used 0.008976s\n",
      "batch 6231, train_loss 0.003241,Time used 0.008976s\n",
      "batch 6232, train_loss 0.003356,Time used 0.007979s\n",
      "batch 6233, train_loss 0.003430,Time used 0.008976s\n",
      "batch 6234, train_loss 0.003297,Time used 0.007979s\n",
      "batch 6235, train_loss 0.003289,Time used 0.007979s\n",
      "batch 6236, train_loss 0.002547,Time used 0.008977s\n",
      "batch 6237, train_loss 0.002021,Time used 0.008976s\n",
      "batch 6238, train_loss 0.002675,Time used 0.007979s\n",
      "batch 6239, train_loss 0.003598,Time used 0.008976s\n",
      "batch 6240, train_loss 0.003903,Time used 0.008976s\n",
      "batch 6241, train_loss 0.002670,Time used 0.008977s\n",
      "batch 6242, train_loss 0.005223,Time used 0.007979s\n",
      "batch 6243, train_loss 0.004709,Time used 0.007979s\n",
      "batch 6244, train_loss 0.003857,Time used 0.007979s\n",
      "batch 6245, train_loss 0.003872,Time used 0.008977s\n",
      "batch 6246, train_loss 0.005610,Time used 0.008975s\n",
      "batch 6247, train_loss 0.003760,Time used 0.007980s\n",
      "batch 6248, train_loss 0.003164,Time used 0.008976s\n",
      "batch 6249, train_loss 0.003416,Time used 0.007978s\n",
      "batch 6250, train_loss 0.004134,Time used 0.008977s\n",
      "batch 6251, train_loss 0.002815,Time used 0.008975s\n",
      "batch 6252, train_loss 0.003169,Time used 0.008976s\n",
      "batch 6253, train_loss 0.002980,Time used 0.008977s\n",
      "batch 6254, train_loss 0.004915,Time used 0.008975s\n",
      "batch 6255, train_loss 0.005420,Time used 0.008976s\n",
      "batch 6256, train_loss 0.003872,Time used 0.008976s\n",
      "batch 6257, train_loss 0.004135,Time used 0.007978s\n",
      "batch 6258, train_loss 0.004341,Time used 0.008977s\n",
      "batch 6259, train_loss 0.004291,Time used 0.008975s\n",
      "batch 6260, train_loss 0.004855,Time used 0.008976s\n",
      "batch 6261, train_loss 0.004492,Time used 0.007979s\n",
      "batch 6262, train_loss 0.004398,Time used 0.008976s\n",
      "batch 6263, train_loss 0.003594,Time used 0.008975s\n",
      "batch 6264, train_loss 0.003938,Time used 0.008977s\n",
      "batch 6265, train_loss 0.003172,Time used 0.008976s\n",
      "batch 6266, train_loss 0.003312,Time used 0.007978s\n",
      "batch 6267, train_loss 0.003829,Time used 0.007978s\n",
      "batch 6268, train_loss 0.003569,Time used 0.008976s\n",
      "batch 6269, train_loss 0.004184,Time used 0.008977s\n",
      "batch 6270, train_loss 0.002829,Time used 0.008976s\n",
      "batch 6271, train_loss 0.003368,Time used 0.007977s\n",
      "batch 6272, train_loss 0.003317,Time used 0.008976s\n",
      "batch 6273, train_loss 0.003667,Time used 0.008976s\n",
      "batch 6274, train_loss 0.003340,Time used 0.008976s\n",
      "batch 6275, train_loss 0.003565,Time used 0.007979s\n",
      "batch 6276, train_loss 0.002666,Time used 0.008976s\n",
      "batch 6277, train_loss 0.003308,Time used 0.008977s\n",
      "batch 6278, train_loss 0.003605,Time used 0.007978s\n",
      "batch 6279, train_loss 0.003935,Time used 0.008976s\n",
      "batch 6280, train_loss 0.003983,Time used 0.009973s\n",
      "batch 6281, train_loss 0.003724,Time used 0.009973s\n",
      "batch 6282, train_loss 0.003292,Time used 0.008977s\n",
      "batch 6283, train_loss 0.002904,Time used 0.008976s\n",
      "batch 6284, train_loss 0.002929,Time used 0.009973s\n",
      "batch 6285, train_loss 0.004149,Time used 0.008976s\n",
      "batch 6286, train_loss 0.003501,Time used 0.007978s\n",
      "batch 6287, train_loss 0.003334,Time used 0.007979s\n",
      "batch 6288, train_loss 0.003283,Time used 0.008976s\n",
      "batch 6289, train_loss 0.004355,Time used 0.008976s\n",
      "batch 6290, train_loss 0.004901,Time used 0.008976s\n",
      "batch 6291, train_loss 0.003227,Time used 0.008976s\n",
      "batch 6292, train_loss 0.002186,Time used 0.008976s\n",
      "batch 6293, train_loss 0.006466,Time used 0.008977s\n",
      "batch 6294, train_loss 0.004453,Time used 0.009973s\n",
      "batch 6295, train_loss 0.002594,Time used 0.009974s\n",
      "batch 6296, train_loss 0.003190,Time used 0.009974s\n",
      "batch 6297, train_loss 0.003564,Time used 0.008976s\n",
      "batch 6298, train_loss 0.003035,Time used 0.009974s\n",
      "batch 6299, train_loss 0.004022,Time used 0.010971s\n",
      "batch 6300, train_loss 0.003604,Time used 0.008976s\n",
      "***************************test_batch 6300, test_rmse_loss 0.060793,test_mae_loss 0.043326,test_mape_loss 12.866367,Time used 0.131649s\n",
      "batch 6301, train_loss 0.003459,Time used 0.009973s\n",
      "batch 6302, train_loss 0.003527,Time used 0.008976s\n",
      "batch 6303, train_loss 0.003104,Time used 0.009973s\n",
      "batch 6304, train_loss 0.002611,Time used 0.009974s\n",
      "batch 6305, train_loss 0.004560,Time used 0.009974s\n",
      "batch 6306, train_loss 0.002906,Time used 0.009973s\n",
      "batch 6307, train_loss 0.004183,Time used 0.009008s\n",
      "batch 6308, train_loss 0.003764,Time used 0.008975s\n",
      "batch 6309, train_loss 0.004429,Time used 0.008976s\n",
      "batch 6310, train_loss 0.003897,Time used 0.008977s\n",
      "batch 6311, train_loss 0.003459,Time used 0.008976s\n",
      "batch 6312, train_loss 0.003082,Time used 0.008976s\n",
      "batch 6313, train_loss 0.006506,Time used 0.007979s\n",
      "batch 6314, train_loss 0.003648,Time used 0.009974s\n",
      "batch 6315, train_loss 0.003454,Time used 0.009974s\n",
      "batch 6316, train_loss 0.005274,Time used 0.008976s\n",
      "batch 6317, train_loss 0.003795,Time used 0.009973s\n",
      "batch 6318, train_loss 0.003704,Time used 0.009973s\n",
      "batch 6319, train_loss 0.004098,Time used 0.009973s\n",
      "batch 6320, train_loss 0.005113,Time used 0.008976s\n",
      "batch 6321, train_loss 0.003548,Time used 0.008976s\n",
      "batch 6322, train_loss 0.003632,Time used 0.007979s\n",
      "batch 6323, train_loss 0.003266,Time used 0.010970s\n",
      "batch 6324, train_loss 0.003819,Time used 0.009974s\n",
      "batch 6325, train_loss 0.004563,Time used 0.008975s\n",
      "batch 6326, train_loss 0.004360,Time used 0.008975s\n",
      "batch 6327, train_loss 0.002869,Time used 0.008977s\n",
      "batch 6328, train_loss 0.003015,Time used 0.008976s\n",
      "batch 6329, train_loss 0.005130,Time used 0.009974s\n",
      "batch 6330, train_loss 0.002855,Time used 0.008975s\n",
      "batch 6331, train_loss 0.003500,Time used 0.008977s\n",
      "batch 6332, train_loss 0.004974,Time used 0.008975s\n",
      "batch 6333, train_loss 0.003939,Time used 0.009974s\n",
      "batch 6334, train_loss 0.003154,Time used 0.008976s\n",
      "batch 6335, train_loss 0.002441,Time used 0.008976s\n",
      "batch 6336, train_loss 0.004151,Time used 0.009974s\n",
      "batch 6337, train_loss 0.002737,Time used 0.009973s\n",
      "batch 6338, train_loss 0.003249,Time used 0.008975s\n",
      "batch 6339, train_loss 0.005064,Time used 0.008976s\n",
      "batch 6340, train_loss 0.003681,Time used 0.009973s\n",
      "batch 6341, train_loss 0.003265,Time used 0.010971s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 6342, train_loss 0.002351,Time used 0.009973s\n",
      "batch 6343, train_loss 0.003599,Time used 0.008976s\n",
      "batch 6344, train_loss 0.003697,Time used 0.008978s\n",
      "batch 6345, train_loss 0.002975,Time used 0.008976s\n",
      "batch 6346, train_loss 0.004043,Time used 0.009972s\n",
      "batch 6347, train_loss 0.003125,Time used 0.008975s\n",
      "batch 6348, train_loss 0.003058,Time used 0.009973s\n",
      "batch 6349, train_loss 0.003472,Time used 0.009973s\n",
      "batch 6350, train_loss 0.002933,Time used 0.009974s\n",
      "batch 6351, train_loss 0.003166,Time used 0.011969s\n",
      "batch 6352, train_loss 0.003312,Time used 0.009972s\n",
      "batch 6353, train_loss 0.003382,Time used 0.009974s\n",
      "batch 6354, train_loss 0.003367,Time used 0.009974s\n",
      "batch 6355, train_loss 0.002616,Time used 0.009972s\n",
      "batch 6356, train_loss 0.003515,Time used 0.008977s\n",
      "batch 6357, train_loss 0.003982,Time used 0.008976s\n",
      "batch 6358, train_loss 0.004059,Time used 0.008976s\n",
      "batch 6359, train_loss 0.004510,Time used 0.008976s\n",
      "batch 6360, train_loss 0.004560,Time used 0.009973s\n",
      "batch 6361, train_loss 0.004377,Time used 0.009973s\n",
      "batch 6362, train_loss 0.003225,Time used 0.010970s\n",
      "batch 6363, train_loss 0.002931,Time used 0.008976s\n",
      "batch 6364, train_loss 0.003429,Time used 0.008976s\n",
      "batch 6365, train_loss 0.003734,Time used 0.009974s\n",
      "batch 6366, train_loss 0.003913,Time used 0.008976s\n",
      "batch 6367, train_loss 0.003789,Time used 0.008976s\n",
      "batch 6368, train_loss 0.005095,Time used 0.008976s\n",
      "batch 6369, train_loss 0.004361,Time used 0.008977s\n",
      "batch 6370, train_loss 0.002826,Time used 0.008976s\n",
      "batch 6371, train_loss 0.003110,Time used 0.008976s\n",
      "batch 6372, train_loss 0.002736,Time used 0.009973s\n",
      "batch 6373, train_loss 0.004167,Time used 0.009974s\n",
      "batch 6374, train_loss 0.003826,Time used 0.017952s\n",
      "batch 6375, train_loss 0.003145,Time used 0.010971s\n",
      "batch 6376, train_loss 0.003183,Time used 0.011968s\n",
      "batch 6377, train_loss 0.005245,Time used 0.008975s\n",
      "batch 6378, train_loss 0.003088,Time used 0.009973s\n",
      "batch 6379, train_loss 0.003773,Time used 0.009973s\n",
      "batch 6380, train_loss 0.004548,Time used 0.008977s\n",
      "batch 6381, train_loss 0.003746,Time used 0.008976s\n",
      "batch 6382, train_loss 0.003980,Time used 0.008976s\n",
      "batch 6383, train_loss 0.003565,Time used 0.009973s\n",
      "batch 6384, train_loss 0.003572,Time used 0.009975s\n",
      "batch 6385, train_loss 0.004015,Time used 0.008976s\n",
      "batch 6386, train_loss 0.004367,Time used 0.009973s\n",
      "batch 6387, train_loss 0.004375,Time used 0.008976s\n",
      "batch 6388, train_loss 0.004001,Time used 0.009973s\n",
      "batch 6389, train_loss 0.004866,Time used 0.009973s\n",
      "batch 6390, train_loss 0.002346,Time used 0.008976s\n",
      "batch 6391, train_loss 0.003939,Time used 0.009974s\n",
      "batch 6392, train_loss 0.003671,Time used 0.008976s\n",
      "batch 6393, train_loss 0.003683,Time used 0.008976s\n",
      "batch 6394, train_loss 0.005704,Time used 0.009973s\n",
      "batch 6395, train_loss 0.005325,Time used 0.008976s\n",
      "batch 6396, train_loss 0.003894,Time used 0.009973s\n",
      "batch 6397, train_loss 0.003295,Time used 0.010971s\n",
      "batch 6398, train_loss 0.002748,Time used 0.009974s\n",
      "batch 6399, train_loss 0.003158,Time used 0.010970s\n",
      "batch 6400, train_loss 0.003671,Time used 0.008976s\n",
      "***************************test_batch 6400, test_rmse_loss 0.060796,test_mae_loss 0.043325,test_mape_loss 12.835156,Time used 0.116689s\n",
      "batch 6401, train_loss 0.002601,Time used 0.008976s\n",
      "batch 6402, train_loss 0.002821,Time used 0.008976s\n",
      "batch 6403, train_loss 0.003629,Time used 0.008976s\n",
      "batch 6404, train_loss 0.002986,Time used 0.009973s\n",
      "batch 6405, train_loss 0.003391,Time used 0.008976s\n",
      "batch 6406, train_loss 0.003574,Time used 0.009973s\n",
      "batch 6407, train_loss 0.003529,Time used 0.008977s\n",
      "batch 6408, train_loss 0.003530,Time used 0.008976s\n",
      "batch 6409, train_loss 0.003977,Time used 0.008976s\n",
      "batch 6410, train_loss 0.002795,Time used 0.008976s\n",
      "batch 6411, train_loss 0.002923,Time used 0.009973s\n",
      "batch 6412, train_loss 0.002722,Time used 0.009974s\n",
      "batch 6413, train_loss 0.003812,Time used 0.008976s\n",
      "batch 6414, train_loss 0.004060,Time used 0.009973s\n",
      "batch 6415, train_loss 0.002999,Time used 0.008977s\n",
      "batch 6416, train_loss 0.002867,Time used 0.009973s\n",
      "batch 6417, train_loss 0.002534,Time used 0.008976s\n",
      "batch 6418, train_loss 0.003499,Time used 0.007978s\n",
      "batch 6419, train_loss 0.003553,Time used 0.007979s\n",
      "batch 6420, train_loss 0.003579,Time used 0.006980s\n",
      "batch 6421, train_loss 0.003657,Time used 0.009973s\n",
      "batch 6422, train_loss 0.002802,Time used 0.008976s\n",
      "batch 6423, train_loss 0.003602,Time used 0.009973s\n",
      "batch 6424, train_loss 0.003821,Time used 0.008976s\n",
      "batch 6425, train_loss 0.003734,Time used 0.007979s\n",
      "batch 6426, train_loss 0.005235,Time used 0.008976s\n",
      "batch 6427, train_loss 0.003723,Time used 0.008976s\n",
      "batch 6428, train_loss 0.004073,Time used 0.007978s\n",
      "batch 6429, train_loss 0.002929,Time used 0.008976s\n",
      "batch 6430, train_loss 0.003473,Time used 0.008976s\n",
      "batch 6431, train_loss 0.003342,Time used 0.008976s\n",
      "batch 6432, train_loss 0.003456,Time used 0.008976s\n",
      "batch 6433, train_loss 0.003714,Time used 0.007979s\n",
      "batch 6434, train_loss 0.003900,Time used 0.008977s\n",
      "batch 6435, train_loss 0.003458,Time used 0.008975s\n",
      "batch 6436, train_loss 0.004598,Time used 0.008977s\n",
      "batch 6437, train_loss 0.003020,Time used 0.008975s\n",
      "batch 6438, train_loss 0.003081,Time used 0.008975s\n",
      "batch 6439, train_loss 0.003203,Time used 0.009974s\n",
      "batch 6440, train_loss 0.003585,Time used 0.008976s\n",
      "batch 6441, train_loss 0.003859,Time used 0.008976s\n",
      "batch 6442, train_loss 0.003953,Time used 0.007979s\n",
      "batch 6443, train_loss 0.003071,Time used 0.008976s\n",
      "batch 6444, train_loss 0.003613,Time used 0.008976s\n",
      "batch 6445, train_loss 0.003607,Time used 0.007978s\n",
      "batch 6446, train_loss 0.003884,Time used 0.007978s\n",
      "batch 6447, train_loss 0.005196,Time used 0.008976s\n",
      "batch 6448, train_loss 0.003747,Time used 0.008976s\n",
      "batch 6449, train_loss 0.003586,Time used 0.008974s\n",
      "batch 6450, train_loss 0.003591,Time used 0.008977s\n",
      "batch 6451, train_loss 0.003754,Time used 0.007978s\n",
      "batch 6452, train_loss 0.003960,Time used 0.009973s\n",
      "batch 6453, train_loss 0.003229,Time used 0.010007s\n",
      "batch 6454, train_loss 0.002653,Time used 0.008976s\n",
      "batch 6455, train_loss 0.004850,Time used 0.009974s\n",
      "batch 6456, train_loss 0.003303,Time used 0.008976s\n",
      "batch 6457, train_loss 0.003077,Time used 0.008976s\n",
      "batch 6458, train_loss 0.003444,Time used 0.008976s\n",
      "batch 6459, train_loss 0.004106,Time used 0.008977s\n",
      "batch 6460, train_loss 0.003375,Time used 0.010970s\n",
      "batch 6461, train_loss 0.002977,Time used 0.009973s\n",
      "batch 6462, train_loss 0.002716,Time used 0.008976s\n",
      "batch 6463, train_loss 0.003271,Time used 0.009974s\n",
      "batch 6464, train_loss 0.004239,Time used 0.009974s\n",
      "batch 6465, train_loss 0.003450,Time used 0.008976s\n",
      "batch 6466, train_loss 0.003952,Time used 0.010971s\n",
      "batch 6467, train_loss 0.004268,Time used 0.009974s\n",
      "batch 6468, train_loss 0.004103,Time used 0.009974s\n",
      "batch 6469, train_loss 0.003671,Time used 0.009974s\n",
      "batch 6470, train_loss 0.004211,Time used 0.008976s\n",
      "batch 6471, train_loss 0.003321,Time used 0.007978s\n",
      "batch 6472, train_loss 0.003114,Time used 0.008975s\n",
      "batch 6473, train_loss 0.004505,Time used 0.009974s\n",
      "batch 6474, train_loss 0.003861,Time used 0.008976s\n",
      "batch 6475, train_loss 0.002894,Time used 0.008977s\n",
      "batch 6476, train_loss 0.003619,Time used 0.008976s\n",
      "batch 6477, train_loss 0.003457,Time used 0.008976s\n",
      "batch 6478, train_loss 0.002966,Time used 0.008976s\n",
      "batch 6479, train_loss 0.003417,Time used 0.007979s\n",
      "batch 6480, train_loss 0.005668,Time used 0.008977s\n",
      "batch 6481, train_loss 0.005255,Time used 0.008975s\n",
      "batch 6482, train_loss 0.004329,Time used 0.008975s\n",
      "batch 6483, train_loss 0.003764,Time used 0.007980s\n",
      "batch 6484, train_loss 0.002657,Time used 0.008976s\n",
      "batch 6485, train_loss 0.003424,Time used 0.008976s\n",
      "batch 6486, train_loss 0.003669,Time used 0.008977s\n",
      "batch 6487, train_loss 0.003614,Time used 0.008975s\n",
      "batch 6488, train_loss 0.005028,Time used 0.008976s\n",
      "batch 6489, train_loss 0.005964,Time used 0.008976s\n",
      "batch 6490, train_loss 0.002959,Time used 0.007979s\n",
      "batch 6491, train_loss 0.003192,Time used 0.007979s\n",
      "batch 6492, train_loss 0.003624,Time used 0.007980s\n",
      "batch 6493, train_loss 0.004162,Time used 0.007980s\n",
      "batch 6494, train_loss 0.004108,Time used 0.008976s\n",
      "batch 6495, train_loss 0.002631,Time used 0.007979s\n",
      "batch 6496, train_loss 0.003193,Time used 0.007978s\n",
      "batch 6497, train_loss 0.002681,Time used 0.007979s\n",
      "batch 6498, train_loss 0.003975,Time used 0.008976s\n",
      "batch 6499, train_loss 0.003843,Time used 0.007979s\n",
      "batch 6500, train_loss 0.003592,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************test_batch 6500, test_rmse_loss 0.060925,test_mae_loss 0.043425,test_mape_loss 12.751349,Time used 0.110705s\n",
      "batch 6501, train_loss 0.004131,Time used 0.008976s\n",
      "batch 6502, train_loss 0.003692,Time used 0.008976s\n",
      "batch 6503, train_loss 0.003700,Time used 0.007979s\n",
      "batch 6504, train_loss 0.002621,Time used 0.007979s\n",
      "batch 6505, train_loss 0.003899,Time used 0.007978s\n",
      "batch 6506, train_loss 0.004158,Time used 0.007978s\n",
      "batch 6507, train_loss 0.003501,Time used 0.007978s\n",
      "batch 6508, train_loss 0.002731,Time used 0.007979s\n",
      "batch 6509, train_loss 0.003062,Time used 0.006981s\n",
      "batch 6510, train_loss 0.002933,Time used 0.007979s\n",
      "batch 6511, train_loss 0.002606,Time used 0.007979s\n",
      "batch 6512, train_loss 0.003737,Time used 0.007979s\n",
      "batch 6513, train_loss 0.003639,Time used 0.007979s\n",
      "batch 6514, train_loss 0.002564,Time used 0.007979s\n",
      "batch 6515, train_loss 0.003317,Time used 0.007979s\n",
      "batch 6516, train_loss 0.005191,Time used 0.008975s\n",
      "batch 6517, train_loss 0.004306,Time used 0.008976s\n",
      "batch 6518, train_loss 0.003263,Time used 0.008976s\n",
      "batch 6519, train_loss 0.003168,Time used 0.008976s\n",
      "batch 6520, train_loss 0.003551,Time used 0.008975s\n",
      "batch 6521, train_loss 0.003507,Time used 0.008977s\n",
      "batch 6522, train_loss 0.004555,Time used 0.009973s\n",
      "batch 6523, train_loss 0.002874,Time used 0.008976s\n",
      "batch 6524, train_loss 0.003471,Time used 0.008976s\n",
      "batch 6525, train_loss 0.003915,Time used 0.008976s\n",
      "batch 6526, train_loss 0.002682,Time used 0.008976s\n",
      "batch 6527, train_loss 0.002236,Time used 0.007979s\n",
      "batch 6528, train_loss 0.002568,Time used 0.008975s\n",
      "batch 6529, train_loss 0.006871,Time used 0.008977s\n",
      "batch 6530, train_loss 0.003002,Time used 0.007978s\n",
      "batch 6531, train_loss 0.004083,Time used 0.007979s\n",
      "batch 6532, train_loss 0.004547,Time used 0.006981s\n",
      "batch 6533, train_loss 0.003329,Time used 0.007979s\n",
      "batch 6534, train_loss 0.004488,Time used 0.007978s\n",
      "batch 6535, train_loss 0.003995,Time used 0.007980s\n",
      "batch 6536, train_loss 0.006398,Time used 0.007978s\n",
      "batch 6537, train_loss 0.004661,Time used 0.007979s\n",
      "batch 6538, train_loss 0.003331,Time used 0.007979s\n",
      "batch 6539, train_loss 0.003633,Time used 0.007978s\n",
      "batch 6540, train_loss 0.003064,Time used 0.007978s\n",
      "batch 6541, train_loss 0.002495,Time used 0.007979s\n",
      "batch 6542, train_loss 0.002725,Time used 0.007977s\n",
      "batch 6543, train_loss 0.003677,Time used 0.008977s\n",
      "batch 6544, train_loss 0.003670,Time used 0.009974s\n",
      "batch 6545, train_loss 0.003275,Time used 0.007979s\n",
      "batch 6546, train_loss 0.003302,Time used 0.007979s\n",
      "batch 6547, train_loss 0.003193,Time used 0.007980s\n",
      "batch 6548, train_loss 0.003522,Time used 0.008975s\n",
      "batch 6549, train_loss 0.003429,Time used 0.008976s\n",
      "batch 6550, train_loss 0.004581,Time used 0.009973s\n",
      "batch 6551, train_loss 0.002844,Time used 0.008976s\n",
      "batch 6552, train_loss 0.004014,Time used 0.008977s\n",
      "batch 6553, train_loss 0.003939,Time used 0.008976s\n",
      "batch 6554, train_loss 0.004414,Time used 0.008975s\n",
      "batch 6555, train_loss 0.004661,Time used 0.008977s\n",
      "batch 6556, train_loss 0.004025,Time used 0.009974s\n",
      "batch 6557, train_loss 0.003178,Time used 0.008976s\n",
      "batch 6558, train_loss 0.004343,Time used 0.008977s\n",
      "batch 6559, train_loss 0.002532,Time used 0.008976s\n",
      "batch 6560, train_loss 0.004323,Time used 0.008976s\n",
      "batch 6561, train_loss 0.002988,Time used 0.008976s\n",
      "batch 6562, train_loss 0.003263,Time used 0.008976s\n",
      "batch 6563, train_loss 0.004417,Time used 0.009973s\n",
      "batch 6564, train_loss 0.005345,Time used 0.008976s\n",
      "batch 6565, train_loss 0.003140,Time used 0.008976s\n",
      "batch 6566, train_loss 0.002946,Time used 0.008976s\n",
      "batch 6567, train_loss 0.004661,Time used 0.008976s\n",
      "batch 6568, train_loss 0.002719,Time used 0.007978s\n",
      "batch 6569, train_loss 0.002946,Time used 0.008975s\n",
      "batch 6570, train_loss 0.005381,Time used 0.008977s\n",
      "batch 6571, train_loss 0.002695,Time used 0.007978s\n",
      "batch 6572, train_loss 0.003322,Time used 0.007980s\n",
      "batch 6573, train_loss 0.003415,Time used 0.007977s\n",
      "batch 6574, train_loss 0.006330,Time used 0.006981s\n",
      "batch 6575, train_loss 0.003264,Time used 0.007979s\n",
      "batch 6576, train_loss 0.003407,Time used 0.008976s\n",
      "batch 6577, train_loss 0.003075,Time used 0.007979s\n",
      "batch 6578, train_loss 0.003837,Time used 0.007979s\n",
      "batch 6579, train_loss 0.003497,Time used 0.008977s\n",
      "batch 6580, train_loss 0.004371,Time used 0.007978s\n",
      "batch 6581, train_loss 0.003973,Time used 0.007978s\n",
      "batch 6582, train_loss 0.003879,Time used 0.007979s\n",
      "batch 6583, train_loss 0.003171,Time used 0.007979s\n",
      "batch 6584, train_loss 0.003041,Time used 0.007979s\n",
      "batch 6585, train_loss 0.002765,Time used 0.008976s\n",
      "batch 6586, train_loss 0.003931,Time used 0.007978s\n",
      "batch 6587, train_loss 0.003302,Time used 0.007978s\n",
      "batch 6588, train_loss 0.003883,Time used 0.007978s\n",
      "batch 6589, train_loss 0.003536,Time used 0.007978s\n",
      "batch 6590, train_loss 0.002827,Time used 0.007978s\n",
      "batch 6591, train_loss 0.003758,Time used 0.007979s\n",
      "batch 6592, train_loss 0.003615,Time used 0.008976s\n",
      "batch 6593, train_loss 0.002809,Time used 0.008976s\n",
      "batch 6594, train_loss 0.003175,Time used 0.008976s\n",
      "batch 6595, train_loss 0.002825,Time used 0.007979s\n",
      "batch 6596, train_loss 0.002568,Time used 0.008976s\n",
      "batch 6597, train_loss 0.003840,Time used 0.007979s\n",
      "batch 6598, train_loss 0.004615,Time used 0.007978s\n",
      "batch 6599, train_loss 0.003373,Time used 0.007978s\n",
      "batch 6600, train_loss 0.003131,Time used 0.007979s\n",
      "***************************test_batch 6600, test_rmse_loss 0.061161,test_mae_loss 0.043696,test_mape_loss 13.287082,Time used 0.115692s\n",
      "batch 6601, train_loss 0.003693,Time used 0.008976s\n",
      "batch 6602, train_loss 0.003298,Time used 0.008976s\n",
      "batch 6603, train_loss 0.003276,Time used 0.008486s\n",
      "batch 6604, train_loss 0.003630,Time used 0.008487s\n",
      "batch 6605, train_loss 0.003282,Time used 0.007979s\n",
      "batch 6606, train_loss 0.003280,Time used 0.007979s\n",
      "batch 6607, train_loss 0.003295,Time used 0.007978s\n",
      "batch 6608, train_loss 0.003607,Time used 0.007978s\n",
      "batch 6609, train_loss 0.003709,Time used 0.008976s\n",
      "batch 6610, train_loss 0.003256,Time used 0.007978s\n",
      "batch 6611, train_loss 0.004748,Time used 0.008976s\n",
      "batch 6612, train_loss 0.003356,Time used 0.007978s\n",
      "batch 6613, train_loss 0.003384,Time used 0.007978s\n",
      "batch 6614, train_loss 0.002820,Time used 0.007979s\n",
      "batch 6615, train_loss 0.002979,Time used 0.007979s\n",
      "batch 6616, train_loss 0.003504,Time used 0.007978s\n",
      "batch 6617, train_loss 0.003214,Time used 0.007979s\n",
      "batch 6618, train_loss 0.003679,Time used 0.007978s\n",
      "batch 6619, train_loss 0.003586,Time used 0.007979s\n",
      "batch 6620, train_loss 0.003843,Time used 0.007979s\n",
      "batch 6621, train_loss 0.003698,Time used 0.007979s\n",
      "batch 6622, train_loss 0.004066,Time used 0.007978s\n",
      "batch 6623, train_loss 0.003732,Time used 0.008976s\n",
      "batch 6624, train_loss 0.004379,Time used 0.007978s\n",
      "batch 6625, train_loss 0.002650,Time used 0.007977s\n",
      "batch 6626, train_loss 0.003151,Time used 0.007979s\n",
      "batch 6627, train_loss 0.003781,Time used 0.008976s\n",
      "batch 6628, train_loss 0.002503,Time used 0.007979s\n",
      "batch 6629, train_loss 0.003862,Time used 0.007979s\n",
      "batch 6630, train_loss 0.004071,Time used 0.007979s\n",
      "batch 6631, train_loss 0.003745,Time used 0.007978s\n",
      "batch 6632, train_loss 0.004531,Time used 0.008977s\n",
      "batch 6633, train_loss 0.003165,Time used 0.007978s\n",
      "batch 6634, train_loss 0.001747,Time used 0.006982s\n",
      "batch 6635, train_loss 0.003024,Time used 0.008976s\n",
      "batch 6636, train_loss 0.003720,Time used 0.007978s\n",
      "batch 6637, train_loss 0.003920,Time used 0.007979s\n",
      "batch 6638, train_loss 0.002627,Time used 0.008976s\n",
      "batch 6639, train_loss 0.003841,Time used 0.007979s\n",
      "batch 6640, train_loss 0.003009,Time used 0.006981s\n",
      "batch 6641, train_loss 0.002226,Time used 0.007979s\n",
      "batch 6642, train_loss 0.003445,Time used 0.008976s\n",
      "batch 6643, train_loss 0.003856,Time used 0.007979s\n",
      "batch 6644, train_loss 0.006536,Time used 0.007979s\n",
      "batch 6645, train_loss 0.004639,Time used 0.007979s\n",
      "batch 6646, train_loss 0.004121,Time used 0.009973s\n",
      "batch 6647, train_loss 0.003758,Time used 0.009973s\n",
      "batch 6648, train_loss 0.003280,Time used 0.007979s\n",
      "batch 6649, train_loss 0.003073,Time used 0.007978s\n",
      "batch 6650, train_loss 0.003721,Time used 0.008976s\n",
      "batch 6651, train_loss 0.003304,Time used 0.007978s\n",
      "batch 6652, train_loss 0.002798,Time used 0.007979s\n",
      "batch 6653, train_loss 0.003827,Time used 0.007978s\n",
      "batch 6654, train_loss 0.004400,Time used 0.007979s\n",
      "batch 6655, train_loss 0.004171,Time used 0.008976s\n",
      "batch 6656, train_loss 0.003400,Time used 0.008975s\n",
      "batch 6657, train_loss 0.003625,Time used 0.008976s\n",
      "batch 6658, train_loss 0.003932,Time used 0.006981s\n",
      "batch 6659, train_loss 0.002940,Time used 0.007978s\n",
      "batch 6660, train_loss 0.002626,Time used 0.007978s\n",
      "batch 6661, train_loss 0.003364,Time used 0.007979s\n",
      "batch 6662, train_loss 0.003721,Time used 0.007979s\n",
      "batch 6663, train_loss 0.003041,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 6664, train_loss 0.004008,Time used 0.007978s\n",
      "batch 6665, train_loss 0.003047,Time used 0.009974s\n",
      "batch 6666, train_loss 0.003778,Time used 0.008975s\n",
      "batch 6667, train_loss 0.003550,Time used 0.008976s\n",
      "batch 6668, train_loss 0.003361,Time used 0.011968s\n",
      "batch 6669, train_loss 0.004156,Time used 0.009973s\n",
      "batch 6670, train_loss 0.003433,Time used 0.007978s\n",
      "batch 6671, train_loss 0.002703,Time used 0.007978s\n",
      "batch 6672, train_loss 0.003122,Time used 0.007979s\n",
      "batch 6673, train_loss 0.003710,Time used 0.006982s\n",
      "batch 6674, train_loss 0.003028,Time used 0.006982s\n",
      "batch 6675, train_loss 0.003889,Time used 0.007979s\n",
      "batch 6676, train_loss 0.002859,Time used 0.008975s\n",
      "batch 6677, train_loss 0.003475,Time used 0.006982s\n",
      "batch 6678, train_loss 0.003278,Time used 0.008976s\n",
      "batch 6679, train_loss 0.003144,Time used 0.008976s\n",
      "batch 6680, train_loss 0.003957,Time used 0.007979s\n",
      "batch 6681, train_loss 0.003240,Time used 0.007979s\n",
      "batch 6682, train_loss 0.003270,Time used 0.006981s\n",
      "batch 6683, train_loss 0.003221,Time used 0.007978s\n",
      "batch 6684, train_loss 0.004403,Time used 0.008976s\n",
      "batch 6685, train_loss 0.004348,Time used 0.008976s\n",
      "batch 6686, train_loss 0.004489,Time used 0.008977s\n",
      "batch 6687, train_loss 0.003113,Time used 0.007978s\n",
      "batch 6688, train_loss 0.003214,Time used 0.007978s\n",
      "batch 6689, train_loss 0.005776,Time used 0.007978s\n",
      "batch 6690, train_loss 0.003768,Time used 0.007979s\n",
      "batch 6691, train_loss 0.003373,Time used 0.007979s\n",
      "batch 6692, train_loss 0.004796,Time used 0.008976s\n",
      "batch 6693, train_loss 0.003826,Time used 0.008976s\n",
      "batch 6694, train_loss 0.004393,Time used 0.008976s\n",
      "batch 6695, train_loss 0.004900,Time used 0.008976s\n",
      "batch 6696, train_loss 0.005011,Time used 0.008976s\n",
      "batch 6697, train_loss 0.003673,Time used 0.008976s\n",
      "batch 6698, train_loss 0.002341,Time used 0.007977s\n",
      "batch 6699, train_loss 0.003133,Time used 0.007979s\n",
      "batch 6700, train_loss 0.003456,Time used 0.007978s\n",
      "***************************test_batch 6700, test_rmse_loss 0.060793,test_mae_loss 0.043321,test_mape_loss 12.956610,Time used 0.113238s\n",
      "batch 6701, train_loss 0.003450,Time used 0.008976s\n",
      "batch 6702, train_loss 0.003288,Time used 0.008976s\n",
      "batch 6703, train_loss 0.003551,Time used 0.008975s\n",
      "batch 6704, train_loss 0.003394,Time used 0.007979s\n",
      "batch 6705, train_loss 0.002974,Time used 0.008976s\n",
      "batch 6706, train_loss 0.002280,Time used 0.007979s\n",
      "batch 6707, train_loss 0.002752,Time used 0.007978s\n",
      "batch 6708, train_loss 0.004892,Time used 0.007980s\n",
      "batch 6709, train_loss 0.003747,Time used 0.008976s\n",
      "batch 6710, train_loss 0.004115,Time used 0.028922s\n",
      "batch 6711, train_loss 0.004453,Time used 0.009973s\n",
      "batch 6712, train_loss 0.003292,Time used 0.008976s\n",
      "batch 6713, train_loss 0.003595,Time used 0.011968s\n",
      "batch 6714, train_loss 0.005511,Time used 0.014959s\n",
      "batch 6715, train_loss 0.004738,Time used 0.010971s\n",
      "batch 6716, train_loss 0.002897,Time used 0.008976s\n",
      "batch 6717, train_loss 0.004016,Time used 0.008975s\n",
      "batch 6718, train_loss 0.003759,Time used 0.009973s\n",
      "batch 6719, train_loss 0.003166,Time used 0.012966s\n",
      "batch 6720, train_loss 0.002286,Time used 0.009973s\n",
      "batch 6721, train_loss 0.003305,Time used 0.010971s\n",
      "batch 6722, train_loss 0.002642,Time used 0.011967s\n",
      "batch 6723, train_loss 0.002567,Time used 0.009971s\n",
      "batch 6724, train_loss 0.003745,Time used 0.010970s\n",
      "batch 6725, train_loss 0.002384,Time used 0.009972s\n",
      "batch 6726, train_loss 0.004282,Time used 0.009973s\n",
      "batch 6727, train_loss 0.003972,Time used 0.009973s\n",
      "batch 6728, train_loss 0.003456,Time used 0.008976s\n",
      "batch 6729, train_loss 0.004472,Time used 0.008975s\n",
      "batch 6730, train_loss 0.004814,Time used 0.009973s\n",
      "batch 6731, train_loss 0.002610,Time used 0.008976s\n",
      "batch 6732, train_loss 0.004053,Time used 0.008977s\n",
      "batch 6733, train_loss 0.003979,Time used 0.008975s\n",
      "batch 6734, train_loss 0.003184,Time used 0.007977s\n",
      "batch 6735, train_loss 0.004678,Time used 0.009974s\n",
      "batch 6736, train_loss 0.003871,Time used 0.008975s\n",
      "batch 6737, train_loss 0.003199,Time used 0.008976s\n",
      "batch 6738, train_loss 0.004101,Time used 0.008977s\n",
      "batch 6739, train_loss 0.004434,Time used 0.007978s\n",
      "batch 6740, train_loss 0.004260,Time used 0.008977s\n",
      "batch 6741, train_loss 0.001581,Time used 0.006980s\n",
      "batch 6742, train_loss 0.002891,Time used 0.008976s\n",
      "batch 6743, train_loss 0.005240,Time used 0.009973s\n",
      "batch 6744, train_loss 0.002546,Time used 0.007979s\n",
      "batch 6745, train_loss 0.003743,Time used 0.008976s\n",
      "batch 6746, train_loss 0.002970,Time used 0.007979s\n",
      "batch 6747, train_loss 0.002340,Time used 0.007978s\n",
      "batch 6748, train_loss 0.002699,Time used 0.007979s\n",
      "batch 6749, train_loss 0.003003,Time used 0.008976s\n",
      "batch 6750, train_loss 0.003429,Time used 0.008976s\n",
      "batch 6751, train_loss 0.003853,Time used 0.008976s\n",
      "batch 6752, train_loss 0.003860,Time used 0.008976s\n",
      "batch 6753, train_loss 0.003047,Time used 0.008975s\n",
      "batch 6754, train_loss 0.004284,Time used 0.007979s\n",
      "batch 6755, train_loss 0.004113,Time used 0.008976s\n",
      "batch 6756, train_loss 0.003913,Time used 0.007979s\n",
      "batch 6757, train_loss 0.003141,Time used 0.007978s\n",
      "batch 6758, train_loss 0.002747,Time used 0.007979s\n",
      "batch 6759, train_loss 0.003763,Time used 0.008976s\n",
      "batch 6760, train_loss 0.002601,Time used 0.008976s\n",
      "batch 6761, train_loss 0.004211,Time used 0.008976s\n",
      "batch 6762, train_loss 0.004024,Time used 0.008976s\n",
      "batch 6763, train_loss 0.004902,Time used 0.008976s\n",
      "batch 6764, train_loss 0.003469,Time used 0.008976s\n",
      "batch 6765, train_loss 0.005909,Time used 0.008976s\n",
      "batch 6766, train_loss 0.002867,Time used 0.008976s\n",
      "batch 6767, train_loss 0.003897,Time used 0.007978s\n",
      "batch 6768, train_loss 0.003267,Time used 0.008976s\n",
      "batch 6769, train_loss 0.003576,Time used 0.007979s\n",
      "batch 6770, train_loss 0.003445,Time used 0.007978s\n",
      "batch 6771, train_loss 0.003416,Time used 0.007978s\n",
      "batch 6772, train_loss 0.002995,Time used 0.007979s\n",
      "batch 6773, train_loss 0.003942,Time used 0.007980s\n",
      "batch 6774, train_loss 0.004182,Time used 0.007977s\n",
      "batch 6775, train_loss 0.005470,Time used 0.007979s\n",
      "batch 6776, train_loss 0.002889,Time used 0.008976s\n",
      "batch 6777, train_loss 0.003362,Time used 0.007978s\n",
      "batch 6778, train_loss 0.002552,Time used 0.007979s\n",
      "batch 6779, train_loss 0.003275,Time used 0.007979s\n",
      "batch 6780, train_loss 0.003418,Time used 0.007979s\n",
      "batch 6781, train_loss 0.003700,Time used 0.007979s\n",
      "batch 6782, train_loss 0.003952,Time used 0.007979s\n",
      "batch 6783, train_loss 0.003712,Time used 0.007978s\n",
      "batch 6784, train_loss 0.003158,Time used 0.007979s\n",
      "batch 6785, train_loss 0.003532,Time used 0.008976s\n",
      "batch 6786, train_loss 0.004582,Time used 0.008977s\n",
      "batch 6787, train_loss 0.004282,Time used 0.008976s\n",
      "batch 6788, train_loss 0.003684,Time used 0.008976s\n",
      "batch 6789, train_loss 0.004582,Time used 0.008976s\n",
      "batch 6790, train_loss 0.003907,Time used 0.008975s\n",
      "batch 6791, train_loss 0.002776,Time used 0.008976s\n",
      "batch 6792, train_loss 0.004036,Time used 0.008977s\n",
      "batch 6793, train_loss 0.003649,Time used 0.007979s\n",
      "batch 6794, train_loss 0.002994,Time used 0.008977s\n",
      "batch 6795, train_loss 0.002630,Time used 0.008975s\n",
      "batch 6796, train_loss 0.004045,Time used 0.008976s\n",
      "batch 6797, train_loss 0.003372,Time used 0.009973s\n",
      "batch 6798, train_loss 0.004073,Time used 0.008976s\n",
      "batch 6799, train_loss 0.003560,Time used 0.007978s\n",
      "batch 6800, train_loss 0.004689,Time used 0.008976s\n",
      "***************************test_batch 6800, test_rmse_loss 0.060829,test_mae_loss 0.043368,test_mape_loss 12.992870,Time used 0.102725s\n",
      "batch 6801, train_loss 0.003032,Time used 0.009974s\n",
      "batch 6802, train_loss 0.004163,Time used 0.008975s\n",
      "batch 6803, train_loss 0.002800,Time used 0.009973s\n",
      "batch 6804, train_loss 0.004256,Time used 0.009974s\n",
      "batch 6805, train_loss 0.004359,Time used 0.009973s\n",
      "batch 6806, train_loss 0.002349,Time used 0.009973s\n",
      "batch 6807, train_loss 0.003752,Time used 0.008976s\n",
      "batch 6808, train_loss 0.004130,Time used 0.008976s\n",
      "batch 6809, train_loss 0.003894,Time used 0.008976s\n",
      "batch 6810, train_loss 0.003077,Time used 0.008977s\n",
      "batch 6811, train_loss 0.003305,Time used 0.008976s\n",
      "batch 6812, train_loss 0.004139,Time used 0.007979s\n",
      "batch 6813, train_loss 0.002858,Time used 0.007979s\n",
      "batch 6814, train_loss 0.003131,Time used 0.007978s\n",
      "batch 6815, train_loss 0.003340,Time used 0.007978s\n",
      "batch 6816, train_loss 0.003519,Time used 0.007979s\n",
      "batch 6817, train_loss 0.004088,Time used 0.007979s\n",
      "batch 6818, train_loss 0.003101,Time used 0.007978s\n",
      "batch 6819, train_loss 0.004525,Time used 0.008976s\n",
      "batch 6820, train_loss 0.004171,Time used 0.008975s\n",
      "batch 6821, train_loss 0.002685,Time used 0.008977s\n",
      "batch 6822, train_loss 0.003687,Time used 0.007979s\n",
      "batch 6823, train_loss 0.003097,Time used 0.007979s\n",
      "batch 6824, train_loss 0.002571,Time used 0.008976s\n",
      "batch 6825, train_loss 0.002470,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 6826, train_loss 0.003387,Time used 0.008976s\n",
      "batch 6827, train_loss 0.004657,Time used 0.008976s\n",
      "batch 6828, train_loss 0.003495,Time used 0.007952s\n",
      "batch 6829, train_loss 0.003513,Time used 0.007979s\n",
      "batch 6830, train_loss 0.004897,Time used 0.007978s\n",
      "batch 6831, train_loss 0.003354,Time used 0.008976s\n",
      "batch 6832, train_loss 0.004163,Time used 0.008976s\n",
      "batch 6833, train_loss 0.004162,Time used 0.008976s\n",
      "batch 6834, train_loss 0.003755,Time used 0.008976s\n",
      "batch 6835, train_loss 0.005320,Time used 0.007979s\n",
      "batch 6836, train_loss 0.003290,Time used 0.007979s\n",
      "batch 6837, train_loss 0.003877,Time used 0.008976s\n",
      "batch 6838, train_loss 0.003432,Time used 0.007979s\n",
      "batch 6839, train_loss 0.003291,Time used 0.007979s\n",
      "batch 6840, train_loss 0.003886,Time used 0.008976s\n",
      "batch 6841, train_loss 0.004184,Time used 0.008976s\n",
      "batch 6842, train_loss 0.003476,Time used 0.007979s\n",
      "batch 6843, train_loss 0.003413,Time used 0.009974s\n",
      "batch 6844, train_loss 0.003526,Time used 0.007979s\n",
      "batch 6845, train_loss 0.003426,Time used 0.007980s\n",
      "batch 6846, train_loss 0.005529,Time used 0.007979s\n",
      "batch 6847, train_loss 0.002890,Time used 0.007979s\n",
      "batch 6848, train_loss 0.003724,Time used 0.006981s\n",
      "batch 6849, train_loss 0.002725,Time used 0.007978s\n",
      "batch 6850, train_loss 0.004023,Time used 0.008488s\n",
      "batch 6851, train_loss 0.002899,Time used 0.008976s\n",
      "batch 6852, train_loss 0.003387,Time used 0.007979s\n",
      "batch 6853, train_loss 0.003743,Time used 0.007979s\n",
      "batch 6854, train_loss 0.006174,Time used 0.007980s\n",
      "batch 6855, train_loss 0.003495,Time used 0.007979s\n",
      "batch 6856, train_loss 0.003665,Time used 0.007979s\n",
      "batch 6857, train_loss 0.003910,Time used 0.007978s\n",
      "batch 6858, train_loss 0.003986,Time used 0.008976s\n",
      "batch 6859, train_loss 0.003958,Time used 0.008976s\n",
      "batch 6860, train_loss 0.004453,Time used 0.008976s\n",
      "batch 6861, train_loss 0.002867,Time used 0.008975s\n",
      "batch 6862, train_loss 0.002832,Time used 0.008977s\n",
      "batch 6863, train_loss 0.003250,Time used 0.009974s\n",
      "batch 6864, train_loss 0.003806,Time used 0.008976s\n",
      "batch 6865, train_loss 0.003771,Time used 0.007980s\n",
      "batch 6866, train_loss 0.004915,Time used 0.008976s\n",
      "batch 6867, train_loss 0.003688,Time used 0.008976s\n",
      "batch 6868, train_loss 0.003946,Time used 0.010971s\n",
      "batch 6869, train_loss 0.002943,Time used 0.009974s\n",
      "batch 6870, train_loss 0.003931,Time used 0.010971s\n",
      "batch 6871, train_loss 0.002845,Time used 0.008976s\n",
      "batch 6872, train_loss 0.004130,Time used 0.008976s\n",
      "batch 6873, train_loss 0.003163,Time used 0.008975s\n",
      "batch 6874, train_loss 0.003950,Time used 0.007979s\n",
      "batch 6875, train_loss 0.003532,Time used 0.008976s\n",
      "batch 6876, train_loss 0.002626,Time used 0.008977s\n",
      "batch 6877, train_loss 0.004366,Time used 0.006981s\n",
      "batch 6878, train_loss 0.003865,Time used 0.008976s\n",
      "batch 6879, train_loss 0.003936,Time used 0.008976s\n",
      "batch 6880, train_loss 0.004189,Time used 0.008977s\n",
      "batch 6881, train_loss 0.003605,Time used 0.007978s\n",
      "batch 6882, train_loss 0.003728,Time used 0.008976s\n",
      "batch 6883, train_loss 0.003283,Time used 0.008976s\n",
      "batch 6884, train_loss 0.005771,Time used 0.009974s\n",
      "batch 6885, train_loss 0.002795,Time used 0.009974s\n",
      "batch 6886, train_loss 0.003007,Time used 0.008976s\n",
      "batch 6887, train_loss 0.003436,Time used 0.008975s\n",
      "batch 6888, train_loss 0.003602,Time used 0.007979s\n",
      "batch 6889, train_loss 0.004393,Time used 0.007978s\n",
      "batch 6890, train_loss 0.003183,Time used 0.007979s\n",
      "batch 6891, train_loss 0.003144,Time used 0.007979s\n",
      "batch 6892, train_loss 0.007142,Time used 0.008975s\n",
      "batch 6893, train_loss 0.003111,Time used 0.008976s\n",
      "batch 6894, train_loss 0.004526,Time used 0.008976s\n",
      "batch 6895, train_loss 0.003496,Time used 0.008976s\n",
      "batch 6896, train_loss 0.003815,Time used 0.008976s\n",
      "batch 6897, train_loss 0.003526,Time used 0.007978s\n",
      "batch 6898, train_loss 0.003717,Time used 0.008976s\n",
      "batch 6899, train_loss 0.005445,Time used 0.008976s\n",
      "batch 6900, train_loss 0.003496,Time used 0.009973s\n",
      "***************************test_batch 6900, test_rmse_loss 0.060896,test_mae_loss 0.043416,test_mape_loss 12.756152,Time used 0.116688s\n",
      "batch 6901, train_loss 0.003360,Time used 0.008976s\n",
      "batch 6902, train_loss 0.002406,Time used 0.008976s\n",
      "batch 6903, train_loss 0.003363,Time used 0.007978s\n",
      "batch 6904, train_loss 0.002751,Time used 0.007979s\n",
      "batch 6905, train_loss 0.003567,Time used 0.006982s\n",
      "batch 6906, train_loss 0.002839,Time used 0.007979s\n",
      "batch 6907, train_loss 0.002980,Time used 0.008976s\n",
      "batch 6908, train_loss 0.002826,Time used 0.007979s\n",
      "batch 6909, train_loss 0.004357,Time used 0.008976s\n",
      "batch 6910, train_loss 0.003606,Time used 0.009973s\n",
      "batch 6911, train_loss 0.002967,Time used 0.009973s\n",
      "batch 6912, train_loss 0.003335,Time used 0.008976s\n",
      "batch 6913, train_loss 0.004453,Time used 0.008977s\n",
      "batch 6914, train_loss 0.004256,Time used 0.007978s\n",
      "batch 6915, train_loss 0.002609,Time used 0.007978s\n",
      "batch 6916, train_loss 0.003415,Time used 0.007978s\n",
      "batch 6917, train_loss 0.003112,Time used 0.008976s\n",
      "batch 6918, train_loss 0.003215,Time used 0.007981s\n",
      "batch 6919, train_loss 0.002623,Time used 0.010969s\n",
      "batch 6920, train_loss 0.004600,Time used 0.008976s\n",
      "batch 6921, train_loss 0.003526,Time used 0.009973s\n",
      "batch 6922, train_loss 0.003948,Time used 0.008976s\n",
      "batch 6923, train_loss 0.004150,Time used 0.007979s\n",
      "batch 6924, train_loss 0.003128,Time used 0.007978s\n",
      "batch 6925, train_loss 0.003933,Time used 0.007978s\n",
      "batch 6926, train_loss 0.003063,Time used 0.008977s\n",
      "batch 6927, train_loss 0.003396,Time used 0.008975s\n",
      "batch 6928, train_loss 0.003849,Time used 0.007979s\n",
      "batch 6929, train_loss 0.002947,Time used 0.007979s\n",
      "batch 6930, train_loss 0.003576,Time used 0.007978s\n",
      "batch 6931, train_loss 0.003811,Time used 0.008977s\n",
      "batch 6932, train_loss 0.003353,Time used 0.007978s\n",
      "batch 6933, train_loss 0.003057,Time used 0.008976s\n",
      "batch 6934, train_loss 0.005643,Time used 0.007978s\n",
      "batch 6935, train_loss 0.003972,Time used 0.008976s\n",
      "batch 6936, train_loss 0.003244,Time used 0.007980s\n",
      "batch 6937, train_loss 0.003265,Time used 0.008976s\n",
      "batch 6938, train_loss 0.003722,Time used 0.008977s\n",
      "batch 6939, train_loss 0.003031,Time used 0.008976s\n",
      "batch 6940, train_loss 0.004095,Time used 0.008976s\n",
      "batch 6941, train_loss 0.002481,Time used 0.008976s\n",
      "batch 6942, train_loss 0.003772,Time used 0.008976s\n",
      "batch 6943, train_loss 0.003967,Time used 0.008976s\n",
      "batch 6944, train_loss 0.003565,Time used 0.008976s\n",
      "batch 6945, train_loss 0.004248,Time used 0.008977s\n",
      "batch 6946, train_loss 0.004580,Time used 0.008977s\n",
      "batch 6947, train_loss 0.003155,Time used 0.008975s\n",
      "batch 6948, train_loss 0.002599,Time used 0.008977s\n",
      "batch 6949, train_loss 0.002494,Time used 0.008975s\n",
      "batch 6950, train_loss 0.004062,Time used 0.007978s\n",
      "batch 6951, train_loss 0.003509,Time used 0.008976s\n",
      "batch 6952, train_loss 0.002997,Time used 0.007979s\n",
      "batch 6953, train_loss 0.004008,Time used 0.007979s\n",
      "batch 6954, train_loss 0.003905,Time used 0.008975s\n",
      "batch 6955, train_loss 0.003584,Time used 0.006981s\n",
      "batch 6956, train_loss 0.004188,Time used 0.008976s\n",
      "batch 6957, train_loss 0.003927,Time used 0.008976s\n",
      "batch 6958, train_loss 0.003494,Time used 0.008975s\n",
      "batch 6959, train_loss 0.004932,Time used 0.008976s\n",
      "batch 6960, train_loss 0.002864,Time used 0.008976s\n",
      "batch 6961, train_loss 0.002316,Time used 0.009973s\n",
      "batch 6962, train_loss 0.003613,Time used 0.008976s\n",
      "batch 6963, train_loss 0.002945,Time used 0.009973s\n",
      "batch 6964, train_loss 0.004019,Time used 0.008976s\n",
      "batch 6965, train_loss 0.002568,Time used 0.008976s\n",
      "batch 6966, train_loss 0.003928,Time used 0.008977s\n",
      "batch 6967, train_loss 0.004828,Time used 0.008976s\n",
      "batch 6968, train_loss 0.002994,Time used 0.008977s\n",
      "batch 6969, train_loss 0.003593,Time used 0.008976s\n",
      "batch 6970, train_loss 0.002505,Time used 0.009973s\n",
      "batch 6971, train_loss 0.003224,Time used 0.009974s\n",
      "batch 6972, train_loss 0.002607,Time used 0.008976s\n",
      "batch 6973, train_loss 0.005256,Time used 0.009973s\n",
      "batch 6974, train_loss 0.004576,Time used 0.009973s\n",
      "batch 6975, train_loss 0.003623,Time used 0.009973s\n",
      "batch 6976, train_loss 0.004573,Time used 0.009974s\n",
      "batch 6977, train_loss 0.004172,Time used 0.008975s\n",
      "batch 6978, train_loss 0.002925,Time used 0.007978s\n",
      "batch 6979, train_loss 0.004278,Time used 0.008977s\n",
      "batch 6980, train_loss 0.002957,Time used 0.008976s\n",
      "batch 6981, train_loss 0.002915,Time used 0.008976s\n",
      "batch 6982, train_loss 0.003417,Time used 0.008975s\n",
      "batch 6983, train_loss 0.003796,Time used 0.009485s\n",
      "batch 6984, train_loss 0.004464,Time used 0.008975s\n",
      "batch 6985, train_loss 0.002728,Time used 0.008977s\n",
      "batch 6986, train_loss 0.004526,Time used 0.008976s\n",
      "batch 6987, train_loss 0.003234,Time used 0.008976s\n",
      "batch 6988, train_loss 0.003473,Time used 0.008976s\n",
      "batch 6989, train_loss 0.004838,Time used 0.008976s\n",
      "batch 6990, train_loss 0.003464,Time used 0.009973s\n",
      "batch 6991, train_loss 0.002724,Time used 0.008975s\n",
      "batch 6992, train_loss 0.002972,Time used 0.008977s\n",
      "batch 6993, train_loss 0.003134,Time used 0.008975s\n",
      "batch 6994, train_loss 0.002442,Time used 0.008976s\n",
      "batch 6995, train_loss 0.006199,Time used 0.008977s\n",
      "batch 6996, train_loss 0.003262,Time used 0.009972s\n",
      "batch 6997, train_loss 0.003816,Time used 0.009974s\n",
      "batch 6998, train_loss 0.003799,Time used 0.008977s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 6999, train_loss 0.003438,Time used 0.008976s\n",
      "batch 7000, train_loss 0.003668,Time used 0.007978s\n",
      "***************************test_batch 7000, test_rmse_loss 0.061078,test_mae_loss 0.043541,test_mape_loss 12.721672,Time used 0.102726s\n",
      "batch 7001, train_loss 0.003274,Time used 0.008976s\n",
      "batch 7002, train_loss 0.004280,Time used 0.008976s\n",
      "batch 7003, train_loss 0.003810,Time used 0.008975s\n",
      "batch 7004, train_loss 0.006212,Time used 0.008977s\n",
      "batch 7005, train_loss 0.003139,Time used 0.008977s\n",
      "batch 7006, train_loss 0.003398,Time used 0.008975s\n",
      "batch 7007, train_loss 0.004580,Time used 0.008976s\n",
      "batch 7008, train_loss 0.003955,Time used 0.008976s\n",
      "batch 7009, train_loss 0.002756,Time used 0.009974s\n",
      "batch 7010, train_loss 0.002648,Time used 0.007978s\n",
      "batch 7011, train_loss 0.002967,Time used 0.008976s\n",
      "batch 7012, train_loss 0.003882,Time used 0.008976s\n",
      "batch 7013, train_loss 0.003610,Time used 0.007978s\n",
      "batch 7014, train_loss 0.004437,Time used 0.008976s\n",
      "batch 7015, train_loss 0.004540,Time used 0.008976s\n",
      "batch 7016, train_loss 0.003320,Time used 0.008976s\n",
      "batch 7017, train_loss 0.003191,Time used 0.007979s\n",
      "batch 7018, train_loss 0.003643,Time used 0.008976s\n",
      "batch 7019, train_loss 0.003846,Time used 0.007978s\n",
      "batch 7020, train_loss 0.004589,Time used 0.007979s\n",
      "batch 7021, train_loss 0.003279,Time used 0.007978s\n",
      "batch 7022, train_loss 0.003801,Time used 0.007978s\n",
      "batch 7023, train_loss 0.002815,Time used 0.007979s\n",
      "batch 7024, train_loss 0.004242,Time used 0.007979s\n",
      "batch 7025, train_loss 0.003127,Time used 0.008976s\n",
      "batch 7026, train_loss 0.003235,Time used 0.008975s\n",
      "batch 7027, train_loss 0.003889,Time used 0.008977s\n",
      "batch 7028, train_loss 0.003087,Time used 0.007979s\n",
      "batch 7029, train_loss 0.003281,Time used 0.008976s\n",
      "batch 7030, train_loss 0.003128,Time used 0.008977s\n",
      "batch 7031, train_loss 0.004018,Time used 0.006981s\n",
      "batch 7032, train_loss 0.003260,Time used 0.008976s\n",
      "batch 7033, train_loss 0.003418,Time used 0.007979s\n",
      "batch 7034, train_loss 0.003722,Time used 0.008977s\n",
      "batch 7035, train_loss 0.002682,Time used 0.008976s\n",
      "batch 7036, train_loss 0.003176,Time used 0.007979s\n",
      "batch 7037, train_loss 0.003980,Time used 0.007979s\n",
      "batch 7038, train_loss 0.003113,Time used 0.008976s\n",
      "batch 7039, train_loss 0.003084,Time used 0.008976s\n",
      "batch 7040, train_loss 0.003353,Time used 0.008976s\n",
      "batch 7041, train_loss 0.003157,Time used 0.008977s\n",
      "batch 7042, train_loss 0.003500,Time used 0.007978s\n",
      "batch 7043, train_loss 0.003845,Time used 0.008976s\n",
      "batch 7044, train_loss 0.004630,Time used 0.007979s\n",
      "batch 7045, train_loss 0.003239,Time used 0.008976s\n",
      "batch 7046, train_loss 0.003822,Time used 0.007978s\n",
      "batch 7047, train_loss 0.003220,Time used 0.006982s\n",
      "batch 7048, train_loss 0.003812,Time used 0.006981s\n",
      "batch 7049, train_loss 0.003375,Time used 0.007979s\n",
      "batch 7050, train_loss 0.002709,Time used 0.008976s\n",
      "batch 7051, train_loss 0.002693,Time used 0.007978s\n",
      "batch 7052, train_loss 0.004493,Time used 0.008976s\n",
      "batch 7053, train_loss 0.005432,Time used 0.008976s\n",
      "batch 7054, train_loss 0.004822,Time used 0.007979s\n",
      "batch 7055, train_loss 0.002788,Time used 0.008976s\n",
      "batch 7056, train_loss 0.003185,Time used 0.008976s\n",
      "batch 7057, train_loss 0.002987,Time used 0.006981s\n",
      "batch 7058, train_loss 0.002812,Time used 0.006981s\n",
      "batch 7059, train_loss 0.003622,Time used 0.007978s\n",
      "batch 7060, train_loss 0.003774,Time used 0.007979s\n",
      "batch 7061, train_loss 0.005734,Time used 0.007978s\n",
      "batch 7062, train_loss 0.009005,Time used 0.005983s\n",
      "batch 7063, train_loss 0.005492,Time used 0.007979s\n",
      "batch 7064, train_loss 0.003373,Time used 0.008976s\n",
      "batch 7065, train_loss 0.003709,Time used 0.007979s\n",
      "batch 7066, train_loss 0.003664,Time used 0.007978s\n",
      "batch 7067, train_loss 0.003822,Time used 0.007979s\n",
      "batch 7068, train_loss 0.003008,Time used 0.007979s\n",
      "batch 7069, train_loss 0.002367,Time used 0.007978s\n",
      "batch 7070, train_loss 0.004540,Time used 0.008976s\n",
      "batch 7071, train_loss 0.002829,Time used 0.007979s\n",
      "batch 7072, train_loss 0.002992,Time used 0.009973s\n",
      "batch 7073, train_loss 0.003966,Time used 0.008976s\n",
      "batch 7074, train_loss 0.003717,Time used 0.008976s\n",
      "batch 7075, train_loss 0.003671,Time used 0.007979s\n",
      "batch 7076, train_loss 0.003560,Time used 0.007978s\n",
      "batch 7077, train_loss 0.003032,Time used 0.007978s\n",
      "batch 7078, train_loss 0.004193,Time used 0.007979s\n",
      "batch 7079, train_loss 0.004461,Time used 0.007979s\n",
      "batch 7080, train_loss 0.003167,Time used 0.007978s\n",
      "batch 7081, train_loss 0.004185,Time used 0.007979s\n",
      "batch 7082, train_loss 0.004765,Time used 0.007979s\n",
      "batch 7083, train_loss 0.003099,Time used 0.008976s\n",
      "batch 7084, train_loss 0.004706,Time used 0.009973s\n",
      "batch 7085, train_loss 0.003105,Time used 0.008976s\n",
      "batch 7086, train_loss 0.003546,Time used 0.008976s\n",
      "batch 7087, train_loss 0.005900,Time used 0.008976s\n",
      "batch 7088, train_loss 0.004133,Time used 0.007978s\n",
      "batch 7089, train_loss 0.002417,Time used 0.008976s\n",
      "batch 7090, train_loss 0.003475,Time used 0.007979s\n",
      "batch 7091, train_loss 0.004473,Time used 0.008976s\n",
      "batch 7092, train_loss 0.002799,Time used 0.008976s\n",
      "batch 7093, train_loss 0.003125,Time used 0.009974s\n",
      "batch 7094, train_loss 0.003116,Time used 0.007979s\n",
      "batch 7095, train_loss 0.003867,Time used 0.007978s\n",
      "batch 7096, train_loss 0.003143,Time used 0.009974s\n",
      "batch 7097, train_loss 0.003431,Time used 0.008976s\n",
      "batch 7098, train_loss 0.003976,Time used 0.007979s\n",
      "batch 7099, train_loss 0.002857,Time used 0.008013s\n",
      "batch 7100, train_loss 0.004398,Time used 0.008487s\n",
      "***************************test_batch 7100, test_rmse_loss 0.060763,test_mae_loss 0.043324,test_mape_loss 12.940772,Time used 0.103735s\n",
      "batch 7101, train_loss 0.004894,Time used 0.008975s\n",
      "batch 7102, train_loss 0.002999,Time used 0.008977s\n",
      "batch 7103, train_loss 0.003412,Time used 0.008975s\n",
      "batch 7104, train_loss 0.003281,Time used 0.007979s\n",
      "batch 7105, train_loss 0.003088,Time used 0.007978s\n",
      "batch 7106, train_loss 0.003824,Time used 0.007979s\n",
      "batch 7107, train_loss 0.003677,Time used 0.007978s\n",
      "batch 7108, train_loss 0.003626,Time used 0.007978s\n",
      "batch 7109, train_loss 0.003550,Time used 0.007979s\n",
      "batch 7110, train_loss 0.003489,Time used 0.007979s\n",
      "batch 7111, train_loss 0.002850,Time used 0.008976s\n",
      "batch 7112, train_loss 0.004476,Time used 0.008976s\n",
      "batch 7113, train_loss 0.003296,Time used 0.008976s\n",
      "batch 7114, train_loss 0.004153,Time used 0.008976s\n",
      "batch 7115, train_loss 0.003134,Time used 0.007979s\n",
      "batch 7116, train_loss 0.003983,Time used 0.008977s\n",
      "batch 7117, train_loss 0.003156,Time used 0.008976s\n",
      "batch 7118, train_loss 0.005827,Time used 0.008976s\n",
      "batch 7119, train_loss 0.003111,Time used 0.008975s\n",
      "batch 7120, train_loss 0.003331,Time used 0.008977s\n",
      "batch 7121, train_loss 0.004100,Time used 0.008976s\n",
      "batch 7122, train_loss 0.003069,Time used 0.008976s\n",
      "batch 7123, train_loss 0.002776,Time used 0.008977s\n",
      "batch 7124, train_loss 0.004003,Time used 0.008975s\n",
      "batch 7125, train_loss 0.002558,Time used 0.007979s\n",
      "batch 7126, train_loss 0.003652,Time used 0.006981s\n",
      "batch 7127, train_loss 0.003523,Time used 0.007979s\n",
      "batch 7128, train_loss 0.002737,Time used 0.007978s\n",
      "batch 7129, train_loss 0.002713,Time used 0.008976s\n",
      "batch 7130, train_loss 0.003692,Time used 0.007979s\n",
      "batch 7131, train_loss 0.003657,Time used 0.007979s\n",
      "batch 7132, train_loss 0.003136,Time used 0.008975s\n",
      "batch 7133, train_loss 0.004555,Time used 0.007979s\n",
      "batch 7134, train_loss 0.003174,Time used 0.007979s\n",
      "batch 7135, train_loss 0.003481,Time used 0.007978s\n",
      "batch 7136, train_loss 0.003358,Time used 0.007979s\n",
      "batch 7137, train_loss 0.004894,Time used 0.008976s\n",
      "batch 7138, train_loss 0.002966,Time used 0.009974s\n",
      "batch 7139, train_loss 0.003223,Time used 0.008975s\n",
      "batch 7140, train_loss 0.003735,Time used 0.009973s\n",
      "batch 7141, train_loss 0.003544,Time used 0.008976s\n",
      "batch 7142, train_loss 0.003050,Time used 0.008976s\n",
      "batch 7143, train_loss 0.003422,Time used 0.008977s\n",
      "batch 7144, train_loss 0.004319,Time used 0.007978s\n",
      "batch 7145, train_loss 0.003592,Time used 0.007979s\n",
      "batch 7146, train_loss 0.003980,Time used 0.008975s\n",
      "batch 7147, train_loss 0.005123,Time used 0.008976s\n",
      "batch 7148, train_loss 0.003036,Time used 0.008976s\n",
      "batch 7149, train_loss 0.005650,Time used 0.008976s\n",
      "batch 7150, train_loss 0.003135,Time used 0.008976s\n",
      "batch 7151, train_loss 0.003203,Time used 0.012966s\n",
      "batch 7152, train_loss 0.003572,Time used 0.011968s\n",
      "batch 7153, train_loss 0.003078,Time used 0.007978s\n",
      "batch 7154, train_loss 0.003383,Time used 0.008976s\n",
      "batch 7155, train_loss 0.002762,Time used 0.007979s\n",
      "batch 7156, train_loss 0.003407,Time used 0.007979s\n",
      "batch 7157, train_loss 0.004339,Time used 0.008977s\n",
      "batch 7158, train_loss 0.003568,Time used 0.009973s\n",
      "batch 7159, train_loss 0.004799,Time used 0.010971s\n",
      "batch 7160, train_loss 0.003454,Time used 0.009460s\n",
      "batch 7161, train_loss 0.002673,Time used 0.010971s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 7162, train_loss 0.002891,Time used 0.008976s\n",
      "batch 7163, train_loss 0.003296,Time used 0.008976s\n",
      "batch 7164, train_loss 0.003950,Time used 0.009973s\n",
      "batch 7165, train_loss 0.003339,Time used 0.008976s\n",
      "batch 7166, train_loss 0.004188,Time used 0.008976s\n",
      "batch 7167, train_loss 0.004061,Time used 0.007978s\n",
      "batch 7168, train_loss 0.004528,Time used 0.007978s\n",
      "batch 7169, train_loss 0.002579,Time used 0.006981s\n",
      "batch 7170, train_loss 0.003460,Time used 0.009973s\n",
      "batch 7171, train_loss 0.003429,Time used 0.010971s\n",
      "batch 7172, train_loss 0.004824,Time used 0.011968s\n",
      "batch 7173, train_loss 0.006752,Time used 0.010971s\n",
      "batch 7174, train_loss 0.004825,Time used 0.010971s\n",
      "batch 7175, train_loss 0.003156,Time used 0.010970s\n",
      "batch 7176, train_loss 0.003604,Time used 0.009973s\n",
      "batch 7177, train_loss 0.004153,Time used 0.009974s\n",
      "batch 7178, train_loss 0.002554,Time used 0.007978s\n",
      "batch 7179, train_loss 0.003694,Time used 0.008976s\n",
      "batch 7180, train_loss 0.003325,Time used 0.008976s\n",
      "batch 7181, train_loss 0.003310,Time used 0.009973s\n",
      "batch 7182, train_loss 0.003327,Time used 0.009974s\n",
      "batch 7183, train_loss 0.003789,Time used 0.009974s\n",
      "batch 7184, train_loss 0.003369,Time used 0.010971s\n",
      "batch 7185, train_loss 0.004534,Time used 0.010970s\n",
      "batch 7186, train_loss 0.004339,Time used 0.008976s\n",
      "batch 7187, train_loss 0.003215,Time used 0.008977s\n",
      "batch 7188, train_loss 0.003609,Time used 0.008976s\n",
      "batch 7189, train_loss 0.003187,Time used 0.008976s\n",
      "batch 7190, train_loss 0.004125,Time used 0.009974s\n",
      "batch 7191, train_loss 0.003290,Time used 0.008975s\n",
      "batch 7192, train_loss 0.004325,Time used 0.009974s\n",
      "batch 7193, train_loss 0.003259,Time used 0.008976s\n",
      "batch 7194, train_loss 0.003336,Time used 0.008976s\n",
      "batch 7195, train_loss 0.006771,Time used 0.007978s\n",
      "batch 7196, train_loss 0.003026,Time used 0.007979s\n",
      "batch 7197, train_loss 0.003650,Time used 0.008976s\n",
      "batch 7198, train_loss 0.003244,Time used 0.007978s\n",
      "batch 7199, train_loss 0.002764,Time used 0.008976s\n",
      "batch 7200, train_loss 0.002631,Time used 0.008976s\n",
      "***************************test_batch 7200, test_rmse_loss 0.060929,test_mae_loss 0.043461,test_mape_loss 13.081439,Time used 0.112698s\n",
      "batch 7201, train_loss 0.003480,Time used 0.010972s\n",
      "batch 7202, train_loss 0.003461,Time used 0.008976s\n",
      "batch 7203, train_loss 0.003400,Time used 0.007978s\n",
      "batch 7204, train_loss 0.002873,Time used 0.008976s\n",
      "batch 7205, train_loss 0.003790,Time used 0.008976s\n",
      "batch 7206, train_loss 0.003182,Time used 0.008022s\n",
      "batch 7207, train_loss 0.004178,Time used 0.008961s\n",
      "batch 7208, train_loss 0.005707,Time used 0.008976s\n",
      "batch 7209, train_loss 0.004053,Time used 0.008975s\n",
      "batch 7210, train_loss 0.002922,Time used 0.008976s\n",
      "batch 7211, train_loss 0.002884,Time used 0.007978s\n",
      "batch 7212, train_loss 0.003389,Time used 0.008977s\n",
      "batch 7213, train_loss 0.004599,Time used 0.007978s\n",
      "batch 7214, train_loss 0.003516,Time used 0.006981s\n",
      "batch 7215, train_loss 0.003708,Time used 0.007978s\n",
      "batch 7216, train_loss 0.003958,Time used 0.007979s\n",
      "batch 7217, train_loss 0.002891,Time used 0.008976s\n",
      "batch 7218, train_loss 0.003267,Time used 0.006981s\n",
      "batch 7219, train_loss 0.003972,Time used 0.007979s\n",
      "batch 7220, train_loss 0.003331,Time used 0.007978s\n",
      "batch 7221, train_loss 0.003399,Time used 0.006981s\n",
      "batch 7222, train_loss 0.003231,Time used 0.007978s\n",
      "batch 7223, train_loss 0.003526,Time used 0.007979s\n",
      "batch 7224, train_loss 0.002555,Time used 0.007978s\n",
      "batch 7225, train_loss 0.004525,Time used 0.007979s\n",
      "batch 7226, train_loss 0.004796,Time used 0.007978s\n",
      "batch 7227, train_loss 0.002700,Time used 0.008976s\n",
      "batch 7228, train_loss 0.003735,Time used 0.007979s\n",
      "batch 7229, train_loss 0.002683,Time used 0.007978s\n",
      "batch 7230, train_loss 0.003562,Time used 0.008976s\n",
      "batch 7231, train_loss 0.003905,Time used 0.008976s\n",
      "batch 7232, train_loss 0.002476,Time used 0.008976s\n",
      "batch 7233, train_loss 0.003273,Time used 0.008976s\n",
      "batch 7234, train_loss 0.004044,Time used 0.007979s\n",
      "batch 7235, train_loss 0.003323,Time used 0.007978s\n",
      "batch 7236, train_loss 0.002657,Time used 0.008975s\n",
      "batch 7237, train_loss 0.003836,Time used 0.007979s\n",
      "batch 7238, train_loss 0.004484,Time used 0.007978s\n",
      "batch 7239, train_loss 0.002762,Time used 0.007979s\n",
      "batch 7240, train_loss 0.004009,Time used 0.007978s\n",
      "batch 7241, train_loss 0.003291,Time used 0.007979s\n",
      "batch 7242, train_loss 0.003248,Time used 0.007979s\n",
      "batch 7243, train_loss 0.004122,Time used 0.007979s\n",
      "batch 7244, train_loss 0.003223,Time used 0.007979s\n",
      "batch 7245, train_loss 0.003947,Time used 0.007979s\n",
      "batch 7246, train_loss 0.004291,Time used 0.007980s\n",
      "batch 7247, train_loss 0.002770,Time used 0.007980s\n",
      "batch 7248, train_loss 0.003574,Time used 0.008976s\n",
      "batch 7249, train_loss 0.003409,Time used 0.007978s\n",
      "batch 7250, train_loss 0.002811,Time used 0.007978s\n",
      "batch 7251, train_loss 0.004168,Time used 0.008976s\n",
      "batch 7252, train_loss 0.003561,Time used 0.008976s\n",
      "batch 7253, train_loss 0.003747,Time used 0.007979s\n",
      "batch 7254, train_loss 0.003360,Time used 0.007979s\n",
      "batch 7255, train_loss 0.002873,Time used 0.007979s\n",
      "batch 7256, train_loss 0.003528,Time used 0.007979s\n",
      "batch 7257, train_loss 0.003526,Time used 0.007979s\n",
      "batch 7258, train_loss 0.004131,Time used 0.008976s\n",
      "batch 7259, train_loss 0.003041,Time used 0.008976s\n",
      "batch 7260, train_loss 0.004280,Time used 0.007978s\n",
      "batch 7261, train_loss 0.003822,Time used 0.007979s\n",
      "batch 7262, train_loss 0.004027,Time used 0.008976s\n",
      "batch 7263, train_loss 0.003617,Time used 0.009974s\n",
      "batch 7264, train_loss 0.002856,Time used 0.008976s\n",
      "batch 7265, train_loss 0.003660,Time used 0.009974s\n",
      "batch 7266, train_loss 0.003474,Time used 0.008975s\n",
      "batch 7267, train_loss 0.003826,Time used 0.007978s\n",
      "batch 7268, train_loss 0.004028,Time used 0.008976s\n",
      "batch 7269, train_loss 0.003657,Time used 0.007978s\n",
      "batch 7270, train_loss 0.004274,Time used 0.008976s\n",
      "batch 7271, train_loss 0.003763,Time used 0.007978s\n",
      "batch 7272, train_loss 0.003302,Time used 0.008976s\n",
      "batch 7273, train_loss 0.003391,Time used 0.008977s\n",
      "batch 7274, train_loss 0.004962,Time used 0.008976s\n",
      "batch 7275, train_loss 0.003818,Time used 0.008976s\n",
      "batch 7276, train_loss 0.000840,Time used 0.006981s\n",
      "batch 7277, train_loss 0.003259,Time used 0.007979s\n",
      "batch 7278, train_loss 0.002884,Time used 0.008976s\n",
      "batch 7279, train_loss 0.003412,Time used 0.008976s\n",
      "batch 7280, train_loss 0.003208,Time used 0.006980s\n",
      "batch 7281, train_loss 0.002729,Time used 0.006982s\n",
      "batch 7282, train_loss 0.003974,Time used 0.008976s\n",
      "batch 7283, train_loss 0.003690,Time used 0.006981s\n",
      "batch 7284, train_loss 0.002835,Time used 0.007979s\n",
      "batch 7285, train_loss 0.004021,Time used 0.008976s\n",
      "batch 7286, train_loss 0.003602,Time used 0.008025s\n",
      "batch 7287, train_loss 0.004797,Time used 0.006981s\n",
      "batch 7288, train_loss 0.002531,Time used 0.007979s\n",
      "batch 7289, train_loss 0.002762,Time used 0.008976s\n",
      "batch 7290, train_loss 0.003451,Time used 0.006982s\n",
      "batch 7291, train_loss 0.003155,Time used 0.006982s\n",
      "batch 7292, train_loss 0.004174,Time used 0.007979s\n",
      "batch 7293, train_loss 0.003066,Time used 0.008976s\n",
      "batch 7294, train_loss 0.003687,Time used 0.006981s\n",
      "batch 7295, train_loss 0.004366,Time used 0.007979s\n",
      "batch 7296, train_loss 0.004283,Time used 0.006981s\n",
      "batch 7297, train_loss 0.003242,Time used 0.008976s\n",
      "batch 7298, train_loss 0.003433,Time used 0.008976s\n",
      "batch 7299, train_loss 0.003274,Time used 0.008977s\n",
      "batch 7300, train_loss 0.003356,Time used 0.007979s\n",
      "***************************test_batch 7300, test_rmse_loss 0.061030,test_mae_loss 0.043539,test_mape_loss 13.142493,Time used 0.111702s\n",
      "batch 7301, train_loss 0.002645,Time used 0.007978s\n",
      "batch 7302, train_loss 0.003883,Time used 0.008976s\n",
      "batch 7303, train_loss 0.002977,Time used 0.007978s\n",
      "batch 7304, train_loss 0.004989,Time used 0.007978s\n",
      "batch 7305, train_loss 0.003336,Time used 0.008976s\n",
      "batch 7306, train_loss 0.003635,Time used 0.008976s\n",
      "batch 7307, train_loss 0.004625,Time used 0.008976s\n",
      "batch 7308, train_loss 0.002654,Time used 0.009974s\n",
      "batch 7309, train_loss 0.003847,Time used 0.008976s\n",
      "batch 7310, train_loss 0.003483,Time used 0.009973s\n",
      "batch 7311, train_loss 0.002546,Time used 0.007978s\n",
      "batch 7312, train_loss 0.002176,Time used 0.008975s\n",
      "batch 7313, train_loss 0.004302,Time used 0.007979s\n",
      "batch 7314, train_loss 0.003435,Time used 0.007979s\n",
      "batch 7315, train_loss 0.003238,Time used 0.007980s\n",
      "batch 7316, train_loss 0.003347,Time used 0.007979s\n",
      "batch 7317, train_loss 0.004394,Time used 0.008977s\n",
      "batch 7318, train_loss 0.004346,Time used 0.007978s\n",
      "batch 7319, train_loss 0.003354,Time used 0.007978s\n",
      "batch 7320, train_loss 0.003985,Time used 0.008976s\n",
      "batch 7321, train_loss 0.004205,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 7322, train_loss 0.003782,Time used 0.007978s\n",
      "batch 7323, train_loss 0.002936,Time used 0.008977s\n",
      "batch 7324, train_loss 0.005823,Time used 0.007978s\n",
      "batch 7325, train_loss 0.004079,Time used 0.007979s\n",
      "batch 7326, train_loss 0.004166,Time used 0.008976s\n",
      "batch 7327, train_loss 0.004625,Time used 0.007979s\n",
      "batch 7328, train_loss 0.004713,Time used 0.007979s\n",
      "batch 7329, train_loss 0.003224,Time used 0.007980s\n",
      "batch 7330, train_loss 0.002866,Time used 0.007977s\n",
      "batch 7331, train_loss 0.002504,Time used 0.008976s\n",
      "batch 7332, train_loss 0.005023,Time used 0.008976s\n",
      "batch 7333, train_loss 0.003492,Time used 0.007979s\n",
      "batch 7334, train_loss 0.003480,Time used 0.007979s\n",
      "batch 7335, train_loss 0.004205,Time used 0.008977s\n",
      "batch 7336, train_loss 0.003682,Time used 0.008976s\n",
      "batch 7337, train_loss 0.003338,Time used 0.008976s\n",
      "batch 7338, train_loss 0.003067,Time used 0.009973s\n",
      "batch 7339, train_loss 0.003058,Time used 0.008976s\n",
      "batch 7340, train_loss 0.003447,Time used 0.008976s\n",
      "batch 7341, train_loss 0.002527,Time used 0.007980s\n",
      "batch 7342, train_loss 0.003622,Time used 0.007979s\n",
      "batch 7343, train_loss 0.004278,Time used 0.009974s\n",
      "batch 7344, train_loss 0.005929,Time used 0.008976s\n",
      "batch 7345, train_loss 0.003973,Time used 0.008976s\n",
      "batch 7346, train_loss 0.003602,Time used 0.008976s\n",
      "batch 7347, train_loss 0.003079,Time used 0.009973s\n",
      "batch 7348, train_loss 0.003504,Time used 0.009974s\n",
      "batch 7349, train_loss 0.002995,Time used 0.009974s\n",
      "batch 7350, train_loss 0.003445,Time used 0.008976s\n",
      "batch 7351, train_loss 0.003498,Time used 0.008976s\n",
      "batch 7352, train_loss 0.003306,Time used 0.008976s\n",
      "batch 7353, train_loss 0.005359,Time used 0.008976s\n",
      "batch 7354, train_loss 0.003801,Time used 0.008976s\n",
      "batch 7355, train_loss 0.003315,Time used 0.007980s\n",
      "batch 7356, train_loss 0.003253,Time used 0.007978s\n",
      "batch 7357, train_loss 0.003649,Time used 0.007979s\n",
      "batch 7358, train_loss 0.003232,Time used 0.008976s\n",
      "batch 7359, train_loss 0.004387,Time used 0.008976s\n",
      "batch 7360, train_loss 0.002790,Time used 0.008976s\n",
      "batch 7361, train_loss 0.003408,Time used 0.009000s\n",
      "batch 7362, train_loss 0.004713,Time used 0.008977s\n",
      "batch 7363, train_loss 0.003994,Time used 0.009974s\n",
      "batch 7364, train_loss 0.004176,Time used 0.007978s\n",
      "batch 7365, train_loss 0.004188,Time used 0.007979s\n",
      "batch 7366, train_loss 0.006024,Time used 0.008976s\n",
      "batch 7367, train_loss 0.002948,Time used 0.008976s\n",
      "batch 7368, train_loss 0.004608,Time used 0.008975s\n",
      "batch 7369, train_loss 0.003081,Time used 0.008977s\n",
      "batch 7370, train_loss 0.001787,Time used 0.008976s\n",
      "batch 7371, train_loss 0.003027,Time used 0.007978s\n",
      "batch 7372, train_loss 0.002539,Time used 0.007979s\n",
      "batch 7373, train_loss 0.003928,Time used 0.007979s\n",
      "batch 7374, train_loss 0.004147,Time used 0.008976s\n",
      "batch 7375, train_loss 0.003899,Time used 0.008977s\n",
      "batch 7376, train_loss 0.003828,Time used 0.008975s\n",
      "batch 7377, train_loss 0.004218,Time used 0.008977s\n",
      "batch 7378, train_loss 0.003885,Time used 0.008976s\n",
      "batch 7379, train_loss 0.003819,Time used 0.007978s\n",
      "batch 7380, train_loss 0.003374,Time used 0.007979s\n",
      "batch 7381, train_loss 0.003558,Time used 0.008976s\n",
      "batch 7382, train_loss 0.002924,Time used 0.007978s\n",
      "batch 7383, train_loss 0.001563,Time used 0.006205s\n",
      "batch 7384, train_loss 0.003462,Time used 0.008975s\n",
      "batch 7385, train_loss 0.003588,Time used 0.007980s\n",
      "batch 7386, train_loss 0.002539,Time used 0.007979s\n",
      "batch 7387, train_loss 0.003814,Time used 0.008976s\n",
      "batch 7388, train_loss 0.003102,Time used 0.008976s\n",
      "batch 7389, train_loss 0.003129,Time used 0.009972s\n",
      "batch 7390, train_loss 0.003586,Time used 0.008977s\n",
      "batch 7391, train_loss 0.005033,Time used 0.007978s\n",
      "batch 7392, train_loss 0.003194,Time used 0.008977s\n",
      "batch 7393, train_loss 0.002575,Time used 0.008976s\n",
      "batch 7394, train_loss 0.002730,Time used 0.008976s\n",
      "batch 7395, train_loss 0.002549,Time used 0.007979s\n",
      "batch 7396, train_loss 0.003570,Time used 0.008976s\n",
      "batch 7397, train_loss 0.004297,Time used 0.008976s\n",
      "batch 7398, train_loss 0.002745,Time used 0.009973s\n",
      "batch 7399, train_loss 0.003504,Time used 0.008976s\n",
      "batch 7400, train_loss 0.002956,Time used 0.007978s\n",
      "***************************test_batch 7400, test_rmse_loss 0.060832,test_mae_loss 0.043385,test_mape_loss 13.047317,Time used 0.113698s\n",
      "batch 7401, train_loss 0.002890,Time used 0.008975s\n",
      "batch 7402, train_loss 0.003163,Time used 0.006981s\n",
      "batch 7403, train_loss 0.003640,Time used 0.007978s\n",
      "batch 7404, train_loss 0.004448,Time used 0.007979s\n",
      "batch 7405, train_loss 0.004191,Time used 0.008976s\n",
      "batch 7406, train_loss 0.002589,Time used 0.007979s\n",
      "batch 7407, train_loss 0.003806,Time used 0.008976s\n",
      "batch 7408, train_loss 0.003427,Time used 0.008977s\n",
      "batch 7409, train_loss 0.003364,Time used 0.007978s\n",
      "batch 7410, train_loss 0.002886,Time used 0.007978s\n",
      "batch 7411, train_loss 0.003535,Time used 0.007979s\n",
      "batch 7412, train_loss 0.003916,Time used 0.007979s\n",
      "batch 7413, train_loss 0.003280,Time used 0.007979s\n",
      "batch 7414, train_loss 0.003441,Time used 0.007979s\n",
      "batch 7415, train_loss 0.004316,Time used 0.007979s\n",
      "batch 7416, train_loss 0.003718,Time used 0.007979s\n",
      "batch 7417, train_loss 0.003593,Time used 0.007978s\n",
      "batch 7418, train_loss 0.003502,Time used 0.007979s\n",
      "batch 7419, train_loss 0.004366,Time used 0.008975s\n",
      "batch 7420, train_loss 0.003843,Time used 0.008976s\n",
      "batch 7421, train_loss 0.004272,Time used 0.008976s\n",
      "batch 7422, train_loss 0.002883,Time used 0.008976s\n",
      "batch 7423, train_loss 0.003771,Time used 0.008976s\n",
      "batch 7424, train_loss 0.003546,Time used 0.009973s\n",
      "batch 7425, train_loss 0.003054,Time used 0.008977s\n",
      "batch 7426, train_loss 0.005054,Time used 0.008976s\n",
      "batch 7427, train_loss 0.003662,Time used 0.008976s\n",
      "batch 7428, train_loss 0.004105,Time used 0.008976s\n",
      "batch 7429, train_loss 0.003526,Time used 0.009973s\n",
      "batch 7430, train_loss 0.004850,Time used 0.009973s\n",
      "batch 7431, train_loss 0.003607,Time used 0.008977s\n",
      "batch 7432, train_loss 0.003516,Time used 0.008977s\n",
      "batch 7433, train_loss 0.004222,Time used 0.008975s\n",
      "batch 7434, train_loss 0.003180,Time used 0.007979s\n",
      "batch 7435, train_loss 0.004415,Time used 0.008977s\n",
      "batch 7436, train_loss 0.004585,Time used 0.009973s\n",
      "batch 7437, train_loss 0.003477,Time used 0.008976s\n",
      "batch 7438, train_loss 0.003122,Time used 0.008977s\n",
      "batch 7439, train_loss 0.003637,Time used 0.008975s\n",
      "batch 7440, train_loss 0.003801,Time used 0.008976s\n",
      "batch 7441, train_loss 0.002968,Time used 0.008975s\n",
      "batch 7442, train_loss 0.003062,Time used 0.009974s\n",
      "batch 7443, train_loss 0.002716,Time used 0.008976s\n",
      "batch 7444, train_loss 0.003338,Time used 0.008976s\n",
      "batch 7445, train_loss 0.003445,Time used 0.007978s\n",
      "batch 7446, train_loss 0.002979,Time used 0.008977s\n",
      "batch 7447, train_loss 0.004976,Time used 0.008976s\n",
      "batch 7448, train_loss 0.004592,Time used 0.008976s\n",
      "batch 7449, train_loss 0.003620,Time used 0.008976s\n",
      "batch 7450, train_loss 0.003398,Time used 0.008976s\n",
      "batch 7451, train_loss 0.003686,Time used 0.008976s\n",
      "batch 7452, train_loss 0.004315,Time used 0.007979s\n",
      "batch 7453, train_loss 0.002351,Time used 0.008976s\n",
      "batch 7454, train_loss 0.003819,Time used 0.006981s\n",
      "batch 7455, train_loss 0.004234,Time used 0.007979s\n",
      "batch 7456, train_loss 0.006360,Time used 0.006981s\n",
      "batch 7457, train_loss 0.003222,Time used 0.008977s\n",
      "batch 7458, train_loss 0.005005,Time used 0.008976s\n",
      "batch 7459, train_loss 0.002526,Time used 0.007978s\n",
      "batch 7460, train_loss 0.002846,Time used 0.006981s\n",
      "batch 7461, train_loss 0.003827,Time used 0.007979s\n",
      "batch 7462, train_loss 0.003387,Time used 0.006981s\n",
      "batch 7463, train_loss 0.004060,Time used 0.007978s\n",
      "batch 7464, train_loss 0.003564,Time used 0.007978s\n",
      "batch 7465, train_loss 0.004366,Time used 0.007979s\n",
      "batch 7466, train_loss 0.006474,Time used 0.007979s\n",
      "batch 7467, train_loss 0.003373,Time used 0.006982s\n",
      "batch 7468, train_loss 0.005666,Time used 0.007978s\n",
      "batch 7469, train_loss 0.003433,Time used 0.007979s\n",
      "batch 7470, train_loss 0.004205,Time used 0.007979s\n",
      "batch 7471, train_loss 0.002071,Time used 0.007979s\n",
      "batch 7472, train_loss 0.003766,Time used 0.006981s\n",
      "batch 7473, train_loss 0.003117,Time used 0.007978s\n",
      "batch 7474, train_loss 0.003052,Time used 0.007979s\n",
      "batch 7475, train_loss 0.003720,Time used 0.007979s\n",
      "batch 7476, train_loss 0.003151,Time used 0.007979s\n",
      "batch 7477, train_loss 0.003878,Time used 0.007977s\n",
      "batch 7478, train_loss 0.003230,Time used 0.007979s\n",
      "batch 7479, train_loss 0.002863,Time used 0.007979s\n",
      "batch 7480, train_loss 0.004032,Time used 0.007978s\n",
      "batch 7481, train_loss 0.003800,Time used 0.007979s\n",
      "batch 7482, train_loss 0.004863,Time used 0.007978s\n",
      "batch 7483, train_loss 0.003201,Time used 0.008977s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 7484, train_loss 0.003021,Time used 0.008976s\n",
      "batch 7485, train_loss 0.004033,Time used 0.008976s\n",
      "batch 7486, train_loss 0.003375,Time used 0.008976s\n",
      "batch 7487, train_loss 0.003709,Time used 0.007979s\n",
      "batch 7488, train_loss 0.002471,Time used 0.009973s\n",
      "batch 7489, train_loss 0.005198,Time used 0.008976s\n",
      "batch 7490, train_loss 0.002810,Time used 0.006982s\n",
      "batch 7491, train_loss 0.003602,Time used 0.007979s\n",
      "batch 7492, train_loss 0.004442,Time used 0.007979s\n",
      "batch 7493, train_loss 0.003798,Time used 0.007979s\n",
      "batch 7494, train_loss 0.003288,Time used 0.007979s\n",
      "batch 7495, train_loss 0.003989,Time used 0.007978s\n",
      "batch 7496, train_loss 0.003588,Time used 0.007978s\n",
      "batch 7497, train_loss 0.002559,Time used 0.007979s\n",
      "batch 7498, train_loss 0.003862,Time used 0.007979s\n",
      "batch 7499, train_loss 0.002845,Time used 0.008976s\n",
      "batch 7500, train_loss 0.003450,Time used 0.009974s\n",
      "***************************test_batch 7500, test_rmse_loss 0.060876,test_mae_loss 0.043433,test_mape_loss 13.093659,Time used 0.113697s\n",
      "batch 7501, train_loss 0.003262,Time used 0.008975s\n",
      "batch 7502, train_loss 0.004335,Time used 0.008976s\n",
      "batch 7503, train_loss 0.003878,Time used 0.007978s\n",
      "batch 7504, train_loss 0.003630,Time used 0.007979s\n",
      "batch 7505, train_loss 0.002860,Time used 0.007978s\n",
      "batch 7506, train_loss 0.003118,Time used 0.007979s\n",
      "batch 7507, train_loss 0.003174,Time used 0.007979s\n",
      "batch 7508, train_loss 0.003144,Time used 0.007979s\n",
      "batch 7509, train_loss 0.004110,Time used 0.007979s\n",
      "batch 7510, train_loss 0.005470,Time used 0.007979s\n",
      "batch 7511, train_loss 0.003413,Time used 0.007979s\n",
      "batch 7512, train_loss 0.002925,Time used 0.007978s\n",
      "batch 7513, train_loss 0.003504,Time used 0.007978s\n",
      "batch 7514, train_loss 0.004177,Time used 0.008976s\n",
      "batch 7515, train_loss 0.003139,Time used 0.008976s\n",
      "batch 7516, train_loss 0.004093,Time used 0.007979s\n",
      "batch 7517, train_loss 0.002997,Time used 0.007979s\n",
      "batch 7518, train_loss 0.004316,Time used 0.008977s\n",
      "batch 7519, train_loss 0.003938,Time used 0.008975s\n",
      "batch 7520, train_loss 0.005019,Time used 0.007978s\n",
      "batch 7521, train_loss 0.002541,Time used 0.007979s\n",
      "batch 7522, train_loss 0.003904,Time used 0.007978s\n",
      "batch 7523, train_loss 0.003860,Time used 0.009974s\n",
      "batch 7524, train_loss 0.003062,Time used 0.008976s\n",
      "batch 7525, train_loss 0.003827,Time used 0.007978s\n",
      "batch 7526, train_loss 0.002346,Time used 0.007980s\n",
      "batch 7527, train_loss 0.005113,Time used 0.008976s\n",
      "batch 7528, train_loss 0.003295,Time used 0.007978s\n",
      "batch 7529, train_loss 0.004063,Time used 0.009974s\n",
      "batch 7530, train_loss 0.003588,Time used 0.008976s\n",
      "batch 7531, train_loss 0.003436,Time used 0.008975s\n",
      "batch 7532, train_loss 0.003690,Time used 0.007979s\n",
      "batch 7533, train_loss 0.003971,Time used 0.007979s\n",
      "batch 7534, train_loss 0.004898,Time used 0.007979s\n",
      "batch 7535, train_loss 0.003212,Time used 0.007978s\n",
      "batch 7536, train_loss 0.002527,Time used 0.007978s\n",
      "batch 7537, train_loss 0.003147,Time used 0.007979s\n",
      "batch 7538, train_loss 0.003232,Time used 0.007979s\n",
      "batch 7539, train_loss 0.002780,Time used 0.007979s\n",
      "batch 7540, train_loss 0.002795,Time used 0.007978s\n",
      "batch 7541, train_loss 0.002773,Time used 0.007979s\n",
      "batch 7542, train_loss 0.003188,Time used 0.007980s\n",
      "batch 7543, train_loss 0.003114,Time used 0.007978s\n",
      "batch 7544, train_loss 0.003138,Time used 0.008976s\n",
      "batch 7545, train_loss 0.004511,Time used 0.007978s\n",
      "batch 7546, train_loss 0.003533,Time used 0.007979s\n",
      "batch 7547, train_loss 0.003605,Time used 0.007978s\n",
      "batch 7548, train_loss 0.005065,Time used 0.007978s\n",
      "batch 7549, train_loss 0.004326,Time used 0.008977s\n",
      "batch 7550, train_loss 0.003170,Time used 0.008976s\n",
      "batch 7551, train_loss 0.003460,Time used 0.008976s\n",
      "batch 7552, train_loss 0.004543,Time used 0.008976s\n",
      "batch 7553, train_loss 0.003104,Time used 0.008976s\n",
      "batch 7554, train_loss 0.003569,Time used 0.007979s\n",
      "batch 7555, train_loss 0.003477,Time used 0.007979s\n",
      "batch 7556, train_loss 0.002263,Time used 0.007979s\n",
      "batch 7557, train_loss 0.003701,Time used 0.008976s\n",
      "batch 7558, train_loss 0.004517,Time used 0.008975s\n",
      "batch 7559, train_loss 0.002316,Time used 0.008977s\n",
      "batch 7560, train_loss 0.002169,Time used 0.007979s\n",
      "batch 7561, train_loss 0.004536,Time used 0.007980s\n",
      "batch 7562, train_loss 0.004539,Time used 0.008976s\n",
      "batch 7563, train_loss 0.003443,Time used 0.008976s\n",
      "batch 7564, train_loss 0.002672,Time used 0.008977s\n",
      "batch 7565, train_loss 0.003856,Time used 0.008976s\n",
      "batch 7566, train_loss 0.003584,Time used 0.007978s\n",
      "batch 7567, train_loss 0.004209,Time used 0.007979s\n",
      "batch 7568, train_loss 0.003959,Time used 0.008976s\n",
      "batch 7569, train_loss 0.003050,Time used 0.008976s\n",
      "batch 7570, train_loss 0.002806,Time used 0.008976s\n",
      "batch 7571, train_loss 0.003602,Time used 0.008976s\n",
      "batch 7572, train_loss 0.004468,Time used 0.007978s\n",
      "batch 7573, train_loss 0.002222,Time used 0.007980s\n",
      "batch 7574, train_loss 0.002843,Time used 0.007979s\n",
      "batch 7575, train_loss 0.003448,Time used 0.008976s\n",
      "batch 7576, train_loss 0.003959,Time used 0.007979s\n",
      "batch 7577, train_loss 0.003237,Time used 0.008976s\n",
      "batch 7578, train_loss 0.004285,Time used 0.007978s\n",
      "batch 7579, train_loss 0.004823,Time used 0.007979s\n",
      "batch 7580, train_loss 0.004077,Time used 0.007978s\n",
      "batch 7581, train_loss 0.004629,Time used 0.007978s\n",
      "batch 7582, train_loss 0.003472,Time used 0.007980s\n",
      "batch 7583, train_loss 0.003412,Time used 0.007979s\n",
      "batch 7584, train_loss 0.004759,Time used 0.008976s\n",
      "batch 7585, train_loss 0.003581,Time used 0.008976s\n",
      "batch 7586, train_loss 0.003612,Time used 0.008976s\n",
      "batch 7587, train_loss 0.003084,Time used 0.007979s\n",
      "batch 7588, train_loss 0.003502,Time used 0.007979s\n",
      "batch 7589, train_loss 0.004824,Time used 0.007979s\n",
      "batch 7590, train_loss 0.008329,Time used 0.007978s\n",
      "batch 7591, train_loss 0.004012,Time used 0.007979s\n",
      "batch 7592, train_loss 0.003375,Time used 0.008976s\n",
      "batch 7593, train_loss 0.002961,Time used 0.007979s\n",
      "batch 7594, train_loss 0.002964,Time used 0.008977s\n",
      "batch 7595, train_loss 0.004908,Time used 0.007978s\n",
      "batch 7596, train_loss 0.002553,Time used 0.007979s\n",
      "batch 7597, train_loss 0.002572,Time used 0.006982s\n",
      "batch 7598, train_loss 0.003343,Time used 0.008001s\n",
      "batch 7599, train_loss 0.003467,Time used 0.007979s\n",
      "batch 7600, train_loss 0.004382,Time used 0.007978s\n",
      "***************************test_batch 7600, test_rmse_loss 0.060840,test_mae_loss 0.043358,test_mape_loss 12.765841,Time used 0.111701s\n",
      "batch 7601, train_loss 0.002913,Time used 0.009974s\n",
      "batch 7602, train_loss 0.003613,Time used 0.008976s\n",
      "batch 7603, train_loss 0.003407,Time used 0.008976s\n",
      "batch 7604, train_loss 0.003994,Time used 0.008977s\n",
      "batch 7605, train_loss 0.003738,Time used 0.008976s\n",
      "batch 7606, train_loss 0.004158,Time used 0.008977s\n",
      "batch 7607, train_loss 0.005355,Time used 0.008976s\n",
      "batch 7608, train_loss 0.003889,Time used 0.008976s\n",
      "batch 7609, train_loss 0.003530,Time used 0.007978s\n",
      "batch 7610, train_loss 0.004210,Time used 0.007979s\n",
      "batch 7611, train_loss 0.002450,Time used 0.007979s\n",
      "batch 7612, train_loss 0.002751,Time used 0.007979s\n",
      "batch 7613, train_loss 0.003526,Time used 0.007978s\n",
      "batch 7614, train_loss 0.003604,Time used 0.007979s\n",
      "batch 7615, train_loss 0.003009,Time used 0.007979s\n",
      "batch 7616, train_loss 0.002406,Time used 0.007978s\n",
      "batch 7617, train_loss 0.003370,Time used 0.008976s\n",
      "batch 7618, train_loss 0.003523,Time used 0.007979s\n",
      "batch 7619, train_loss 0.003014,Time used 0.008976s\n",
      "batch 7620, train_loss 0.003645,Time used 0.007979s\n",
      "batch 7621, train_loss 0.003576,Time used 0.007978s\n",
      "batch 7622, train_loss 0.003936,Time used 0.008976s\n",
      "batch 7623, train_loss 0.003783,Time used 0.007978s\n",
      "batch 7624, train_loss 0.002965,Time used 0.007979s\n",
      "batch 7625, train_loss 0.003125,Time used 0.008976s\n",
      "batch 7626, train_loss 0.003286,Time used 0.007978s\n",
      "batch 7627, train_loss 0.002869,Time used 0.007979s\n",
      "batch 7628, train_loss 0.003093,Time used 0.007980s\n",
      "batch 7629, train_loss 0.004733,Time used 0.007978s\n",
      "batch 7630, train_loss 0.003766,Time used 0.007979s\n",
      "batch 7631, train_loss 0.005312,Time used 0.007979s\n",
      "batch 7632, train_loss 0.003477,Time used 0.007979s\n",
      "batch 7633, train_loss 0.003591,Time used 0.007978s\n",
      "batch 7634, train_loss 0.003273,Time used 0.007978s\n",
      "batch 7635, train_loss 0.004260,Time used 0.007979s\n",
      "batch 7636, train_loss 0.003606,Time used 0.007979s\n",
      "batch 7637, train_loss 0.004112,Time used 0.007979s\n",
      "batch 7638, train_loss 0.003645,Time used 0.007979s\n",
      "batch 7639, train_loss 0.003293,Time used 0.007979s\n",
      "batch 7640, train_loss 0.003772,Time used 0.007978s\n",
      "batch 7641, train_loss 0.004973,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 7642, train_loss 0.003295,Time used 0.007978s\n",
      "batch 7643, train_loss 0.003717,Time used 0.008976s\n",
      "batch 7644, train_loss 0.006162,Time used 0.007978s\n",
      "batch 7645, train_loss 0.003173,Time used 0.007978s\n",
      "batch 7646, train_loss 0.003228,Time used 0.007979s\n",
      "batch 7647, train_loss 0.004088,Time used 0.007978s\n",
      "batch 7648, train_loss 0.003715,Time used 0.007979s\n",
      "batch 7649, train_loss 0.004014,Time used 0.007979s\n",
      "batch 7650, train_loss 0.004210,Time used 0.007979s\n",
      "batch 7651, train_loss 0.005637,Time used 0.007979s\n",
      "batch 7652, train_loss 0.004134,Time used 0.007979s\n",
      "batch 7653, train_loss 0.002833,Time used 0.007978s\n",
      "batch 7654, train_loss 0.003804,Time used 0.008975s\n",
      "batch 7655, train_loss 0.003968,Time used 0.008977s\n",
      "batch 7656, train_loss 0.003252,Time used 0.007978s\n",
      "batch 7657, train_loss 0.002779,Time used 0.007979s\n",
      "batch 7658, train_loss 0.003891,Time used 0.008977s\n",
      "batch 7659, train_loss 0.002917,Time used 0.007978s\n",
      "batch 7660, train_loss 0.004115,Time used 0.007977s\n",
      "batch 7661, train_loss 0.004494,Time used 0.007979s\n",
      "batch 7662, train_loss 0.002643,Time used 0.008976s\n",
      "batch 7663, train_loss 0.004751,Time used 0.007978s\n",
      "batch 7664, train_loss 0.003138,Time used 0.008976s\n",
      "batch 7665, train_loss 0.003607,Time used 0.009974s\n",
      "batch 7666, train_loss 0.006190,Time used 0.008975s\n",
      "batch 7667, train_loss 0.003119,Time used 0.008976s\n",
      "batch 7668, train_loss 0.003711,Time used 0.008976s\n",
      "batch 7669, train_loss 0.003990,Time used 0.007978s\n",
      "batch 7670, train_loss 0.003285,Time used 0.007979s\n",
      "batch 7671, train_loss 0.003863,Time used 0.008977s\n",
      "batch 7672, train_loss 0.003585,Time used 0.008976s\n",
      "batch 7673, train_loss 0.003679,Time used 0.008976s\n",
      "batch 7674, train_loss 0.003479,Time used 0.009524s\n",
      "batch 7675, train_loss 0.002927,Time used 0.008486s\n",
      "batch 7676, train_loss 0.002567,Time used 0.008976s\n",
      "batch 7677, train_loss 0.003505,Time used 0.007978s\n",
      "batch 7678, train_loss 0.003482,Time used 0.007979s\n",
      "batch 7679, train_loss 0.003686,Time used 0.007978s\n",
      "batch 7680, train_loss 0.002908,Time used 0.008976s\n",
      "batch 7681, train_loss 0.003585,Time used 0.007979s\n",
      "batch 7682, train_loss 0.003397,Time used 0.007979s\n",
      "batch 7683, train_loss 0.003637,Time used 0.007978s\n",
      "batch 7684, train_loss 0.004445,Time used 0.008975s\n",
      "batch 7685, train_loss 0.003546,Time used 0.007979s\n",
      "batch 7686, train_loss 0.003654,Time used 0.009973s\n",
      "batch 7687, train_loss 0.003253,Time used 0.008976s\n",
      "batch 7688, train_loss 0.003975,Time used 0.008976s\n",
      "batch 7689, train_loss 0.002965,Time used 0.007979s\n",
      "batch 7690, train_loss 0.005434,Time used 0.007979s\n",
      "batch 7691, train_loss 0.003324,Time used 0.007979s\n",
      "batch 7692, train_loss 0.003044,Time used 0.007979s\n",
      "batch 7693, train_loss 0.003386,Time used 0.006982s\n",
      "batch 7694, train_loss 0.003534,Time used 0.007979s\n",
      "batch 7695, train_loss 0.003339,Time used 0.007978s\n",
      "batch 7696, train_loss 0.003812,Time used 0.007978s\n",
      "batch 7697, train_loss 0.004456,Time used 0.008976s\n",
      "batch 7698, train_loss 0.002040,Time used 0.007979s\n",
      "batch 7699, train_loss 0.004177,Time used 0.007980s\n",
      "batch 7700, train_loss 0.003171,Time used 0.007978s\n",
      "***************************test_batch 7700, test_rmse_loss 0.060825,test_mae_loss 0.043371,test_mape_loss 13.021070,Time used 0.116689s\n",
      "batch 7701, train_loss 0.002135,Time used 0.008975s\n",
      "batch 7702, train_loss 0.002376,Time used 0.007979s\n",
      "batch 7703, train_loss 0.003786,Time used 0.007980s\n",
      "batch 7704, train_loss 0.004973,Time used 0.006981s\n",
      "batch 7705, train_loss 0.006137,Time used 0.007978s\n",
      "batch 7706, train_loss 0.003504,Time used 0.008976s\n",
      "batch 7707, train_loss 0.002268,Time used 0.008977s\n",
      "batch 7708, train_loss 0.002884,Time used 0.008976s\n",
      "batch 7709, train_loss 0.003581,Time used 0.007979s\n",
      "batch 7710, train_loss 0.004464,Time used 0.007979s\n",
      "batch 7711, train_loss 0.003036,Time used 0.007978s\n",
      "batch 7712, train_loss 0.004024,Time used 0.007979s\n",
      "batch 7713, train_loss 0.003674,Time used 0.007979s\n",
      "batch 7714, train_loss 0.002723,Time used 0.007979s\n",
      "batch 7715, train_loss 0.003065,Time used 0.007979s\n",
      "batch 7716, train_loss 0.003831,Time used 0.007978s\n",
      "batch 7717, train_loss 0.004288,Time used 0.007979s\n",
      "batch 7718, train_loss 0.003101,Time used 0.007979s\n",
      "batch 7719, train_loss 0.004147,Time used 0.008976s\n",
      "batch 7720, train_loss 0.002789,Time used 0.008976s\n",
      "batch 7721, train_loss 0.004621,Time used 0.007978s\n",
      "batch 7722, train_loss 0.003524,Time used 0.008976s\n",
      "batch 7723, train_loss 0.004162,Time used 0.008976s\n",
      "batch 7724, train_loss 0.003454,Time used 0.007979s\n",
      "batch 7725, train_loss 0.002474,Time used 0.008976s\n",
      "batch 7726, train_loss 0.004675,Time used 0.009974s\n",
      "batch 7727, train_loss 0.003234,Time used 0.009974s\n",
      "batch 7728, train_loss 0.004421,Time used 0.010000s\n",
      "batch 7729, train_loss 0.004071,Time used 0.008975s\n",
      "batch 7730, train_loss 0.003209,Time used 0.008976s\n",
      "batch 7731, train_loss 0.004242,Time used 0.008976s\n",
      "batch 7732, train_loss 0.003199,Time used 0.008976s\n",
      "batch 7733, train_loss 0.003019,Time used 0.007978s\n",
      "batch 7734, train_loss 0.002661,Time used 0.007978s\n",
      "batch 7735, train_loss 0.005198,Time used 0.008976s\n",
      "batch 7736, train_loss 0.003470,Time used 0.008977s\n",
      "batch 7737, train_loss 0.003788,Time used 0.008976s\n",
      "batch 7738, train_loss 0.004986,Time used 0.007979s\n",
      "batch 7739, train_loss 0.004103,Time used 0.007978s\n",
      "batch 7740, train_loss 0.003019,Time used 0.007979s\n",
      "batch 7741, train_loss 0.003150,Time used 0.007980s\n",
      "batch 7742, train_loss 0.004280,Time used 0.008976s\n",
      "batch 7743, train_loss 0.003510,Time used 0.008976s\n",
      "batch 7744, train_loss 0.003131,Time used 0.008976s\n",
      "batch 7745, train_loss 0.004496,Time used 0.007979s\n",
      "batch 7746, train_loss 0.003942,Time used 0.007979s\n",
      "batch 7747, train_loss 0.004170,Time used 0.007978s\n",
      "batch 7748, train_loss 0.005090,Time used 0.007979s\n",
      "batch 7749, train_loss 0.002876,Time used 0.007978s\n",
      "batch 7750, train_loss 0.003566,Time used 0.008976s\n",
      "batch 7751, train_loss 0.004325,Time used 0.007978s\n",
      "batch 7752, train_loss 0.004061,Time used 0.008976s\n",
      "batch 7753, train_loss 0.004143,Time used 0.008975s\n",
      "batch 7754, train_loss 0.004119,Time used 0.007980s\n",
      "batch 7755, train_loss 0.002730,Time used 0.007978s\n",
      "batch 7756, train_loss 0.003165,Time used 0.008976s\n",
      "batch 7757, train_loss 0.003459,Time used 0.007979s\n",
      "batch 7758, train_loss 0.003054,Time used 0.007979s\n",
      "batch 7759, train_loss 0.002874,Time used 0.008976s\n",
      "batch 7760, train_loss 0.002373,Time used 0.008976s\n",
      "batch 7761, train_loss 0.002633,Time used 0.007979s\n",
      "batch 7762, train_loss 0.003203,Time used 0.007979s\n",
      "batch 7763, train_loss 0.002626,Time used 0.008977s\n",
      "batch 7764, train_loss 0.003505,Time used 0.007979s\n",
      "batch 7765, train_loss 0.003632,Time used 0.008977s\n",
      "batch 7766, train_loss 0.002609,Time used 0.007978s\n",
      "batch 7767, train_loss 0.004188,Time used 0.007978s\n",
      "batch 7768, train_loss 0.005186,Time used 0.007978s\n",
      "batch 7769, train_loss 0.004631,Time used 0.008976s\n",
      "batch 7770, train_loss 0.003769,Time used 0.008976s\n",
      "batch 7771, train_loss 0.003060,Time used 0.008976s\n",
      "batch 7772, train_loss 0.003434,Time used 0.007980s\n",
      "batch 7773, train_loss 0.004287,Time used 0.007979s\n",
      "batch 7774, train_loss 0.003884,Time used 0.008976s\n",
      "batch 7775, train_loss 0.002503,Time used 0.007979s\n",
      "batch 7776, train_loss 0.003532,Time used 0.007979s\n",
      "batch 7777, train_loss 0.003445,Time used 0.007978s\n",
      "batch 7778, train_loss 0.003510,Time used 0.007978s\n",
      "batch 7779, train_loss 0.004155,Time used 0.007979s\n",
      "batch 7780, train_loss 0.002937,Time used 0.008977s\n",
      "batch 7781, train_loss 0.003148,Time used 0.008975s\n",
      "batch 7782, train_loss 0.002240,Time used 0.008976s\n",
      "batch 7783, train_loss 0.004868,Time used 0.007979s\n",
      "batch 7784, train_loss 0.005468,Time used 0.009973s\n",
      "batch 7785, train_loss 0.003010,Time used 0.008977s\n",
      "batch 7786, train_loss 0.003060,Time used 0.006506s\n",
      "batch 7787, train_loss 0.005101,Time used 0.008976s\n",
      "batch 7788, train_loss 0.003241,Time used 0.008975s\n",
      "batch 7789, train_loss 0.003155,Time used 0.009973s\n",
      "batch 7790, train_loss 0.005218,Time used 0.008976s\n",
      "batch 7791, train_loss 0.003446,Time used 0.008976s\n",
      "batch 7792, train_loss 0.003342,Time used 0.007978s\n",
      "batch 7793, train_loss 0.004386,Time used 0.007980s\n",
      "batch 7794, train_loss 0.003460,Time used 0.007979s\n",
      "batch 7795, train_loss 0.002898,Time used 0.008976s\n",
      "batch 7796, train_loss 0.003623,Time used 0.008977s\n",
      "batch 7797, train_loss 0.003437,Time used 0.008976s\n",
      "batch 7798, train_loss 0.003278,Time used 0.008976s\n",
      "batch 7799, train_loss 0.003719,Time used 0.007979s\n",
      "batch 7800, train_loss 0.002551,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************test_batch 7800, test_rmse_loss 0.060761,test_mae_loss 0.043280,test_mape_loss 12.846392,Time used 0.114693s\n",
      "batch 7801, train_loss 0.003354,Time used 0.007979s\n",
      "batch 7802, train_loss 0.004202,Time used 0.007978s\n",
      "batch 7803, train_loss 0.003660,Time used 0.006981s\n",
      "batch 7804, train_loss 0.003900,Time used 0.007979s\n",
      "batch 7805, train_loss 0.003095,Time used 0.008976s\n",
      "batch 7806, train_loss 0.002778,Time used 0.008977s\n",
      "batch 7807, train_loss 0.003156,Time used 0.007979s\n",
      "batch 7808, train_loss 0.005068,Time used 0.008976s\n",
      "batch 7809, train_loss 0.004045,Time used 0.008977s\n",
      "batch 7810, train_loss 0.003120,Time used 0.008976s\n",
      "batch 7811, train_loss 0.003607,Time used 0.006981s\n",
      "batch 7812, train_loss 0.004904,Time used 0.007979s\n",
      "batch 7813, train_loss 0.003874,Time used 0.007978s\n",
      "batch 7814, train_loss 0.004512,Time used 0.008977s\n",
      "batch 7815, train_loss 0.005581,Time used 0.008975s\n",
      "batch 7816, train_loss 0.004758,Time used 0.008976s\n",
      "batch 7817, train_loss 0.003274,Time used 0.008975s\n",
      "batch 7818, train_loss 0.003446,Time used 0.008978s\n",
      "batch 7819, train_loss 0.004444,Time used 0.008975s\n",
      "batch 7820, train_loss 0.004182,Time used 0.008976s\n",
      "batch 7821, train_loss 0.004422,Time used 0.008976s\n",
      "batch 7822, train_loss 0.003103,Time used 0.008976s\n",
      "batch 7823, train_loss 0.005589,Time used 0.007979s\n",
      "batch 7824, train_loss 0.003627,Time used 0.008977s\n",
      "batch 7825, train_loss 0.002915,Time used 0.008976s\n",
      "batch 7826, train_loss 0.004172,Time used 0.008976s\n",
      "batch 7827, train_loss 0.003968,Time used 0.007978s\n",
      "batch 7828, train_loss 0.003562,Time used 0.007979s\n",
      "batch 7829, train_loss 0.002627,Time used 0.009973s\n",
      "batch 7830, train_loss 0.002872,Time used 0.007979s\n",
      "batch 7831, train_loss 0.003367,Time used 0.007979s\n",
      "batch 7832, train_loss 0.004022,Time used 0.007980s\n",
      "batch 7833, train_loss 0.002261,Time used 0.007978s\n",
      "batch 7834, train_loss 0.003502,Time used 0.008976s\n",
      "batch 7835, train_loss 0.002949,Time used 0.007979s\n",
      "batch 7836, train_loss 0.004321,Time used 0.007978s\n",
      "batch 7837, train_loss 0.002082,Time used 0.007979s\n",
      "batch 7838, train_loss 0.003819,Time used 0.008977s\n",
      "batch 7839, train_loss 0.003776,Time used 0.007978s\n",
      "batch 7840, train_loss 0.003983,Time used 0.007979s\n",
      "batch 7841, train_loss 0.003497,Time used 0.007979s\n",
      "batch 7842, train_loss 0.003508,Time used 0.008977s\n",
      "batch 7843, train_loss 0.002886,Time used 0.008976s\n",
      "batch 7844, train_loss 0.003645,Time used 0.007979s\n",
      "batch 7845, train_loss 0.004500,Time used 0.007978s\n",
      "batch 7846, train_loss 0.003716,Time used 0.008976s\n",
      "batch 7847, train_loss 0.003370,Time used 0.008977s\n",
      "batch 7848, train_loss 0.003399,Time used 0.008976s\n",
      "batch 7849, train_loss 0.003704,Time used 0.007979s\n",
      "batch 7850, train_loss 0.003987,Time used 0.008976s\n",
      "batch 7851, train_loss 0.004584,Time used 0.008976s\n",
      "batch 7852, train_loss 0.002832,Time used 0.007979s\n",
      "batch 7853, train_loss 0.004349,Time used 0.007979s\n",
      "batch 7854, train_loss 0.002350,Time used 0.008976s\n",
      "batch 7855, train_loss 0.004653,Time used 0.007979s\n",
      "batch 7856, train_loss 0.004105,Time used 0.007978s\n",
      "batch 7857, train_loss 0.002589,Time used 0.008976s\n",
      "batch 7858, train_loss 0.002691,Time used 0.008977s\n",
      "batch 7859, train_loss 0.002573,Time used 0.008976s\n",
      "batch 7860, train_loss 0.003038,Time used 0.008977s\n",
      "batch 7861, train_loss 0.003398,Time used 0.008976s\n",
      "batch 7862, train_loss 0.003242,Time used 0.008976s\n",
      "batch 7863, train_loss 0.003790,Time used 0.007979s\n",
      "batch 7864, train_loss 0.004135,Time used 0.007979s\n",
      "batch 7865, train_loss 0.005082,Time used 0.008976s\n",
      "batch 7866, train_loss 0.002984,Time used 0.008976s\n",
      "batch 7867, train_loss 0.004291,Time used 0.008976s\n",
      "batch 7868, train_loss 0.004282,Time used 0.009974s\n",
      "batch 7869, train_loss 0.003996,Time used 0.008976s\n",
      "batch 7870, train_loss 0.005548,Time used 0.010970s\n",
      "batch 7871, train_loss 0.003853,Time used 0.010971s\n",
      "batch 7872, train_loss 0.004373,Time used 0.008975s\n",
      "batch 7873, train_loss 0.003324,Time used 0.008977s\n",
      "batch 7874, train_loss 0.003517,Time used 0.007979s\n",
      "batch 7875, train_loss 0.004005,Time used 0.007979s\n",
      "batch 7876, train_loss 0.004430,Time used 0.008977s\n",
      "batch 7877, train_loss 0.003155,Time used 0.008487s\n",
      "batch 7878, train_loss 0.003030,Time used 0.007979s\n",
      "batch 7879, train_loss 0.003389,Time used 0.008976s\n",
      "batch 7880, train_loss 0.003790,Time used 0.008976s\n",
      "batch 7881, train_loss 0.003388,Time used 0.007979s\n",
      "batch 7882, train_loss 0.005875,Time used 0.008975s\n",
      "batch 7883, train_loss 0.004099,Time used 0.007978s\n",
      "batch 7884, train_loss 0.003469,Time used 0.007978s\n",
      "batch 7885, train_loss 0.002317,Time used 0.007979s\n",
      "batch 7886, train_loss 0.003196,Time used 0.007978s\n",
      "batch 7887, train_loss 0.003148,Time used 0.007979s\n",
      "batch 7888, train_loss 0.002918,Time used 0.008977s\n",
      "batch 7889, train_loss 0.002894,Time used 0.008975s\n",
      "batch 7890, train_loss 0.003304,Time used 0.008976s\n",
      "batch 7891, train_loss 0.003690,Time used 0.008976s\n",
      "batch 7892, train_loss 0.003488,Time used 0.008976s\n",
      "batch 7893, train_loss 0.003647,Time used 0.007979s\n",
      "batch 7894, train_loss 0.004009,Time used 0.007979s\n",
      "batch 7895, train_loss 0.002562,Time used 0.009973s\n",
      "batch 7896, train_loss 0.003518,Time used 0.008976s\n",
      "batch 7897, train_loss 0.002846,Time used 0.008976s\n",
      "batch 7898, train_loss 0.002402,Time used 0.008976s\n",
      "batch 7899, train_loss 0.003140,Time used 0.008976s\n",
      "batch 7900, train_loss 0.003792,Time used 0.008976s\n",
      "***************************test_batch 7900, test_rmse_loss 0.060758,test_mae_loss 0.043305,test_mape_loss 12.927093,Time used 0.102725s\n",
      "batch 7901, train_loss 0.003207,Time used 0.006981s\n",
      "batch 7902, train_loss 0.003522,Time used 0.008976s\n",
      "batch 7903, train_loss 0.002800,Time used 0.007978s\n",
      "batch 7904, train_loss 0.002734,Time used 0.008976s\n",
      "batch 7905, train_loss 0.003396,Time used 0.007978s\n",
      "batch 7906, train_loss 0.002175,Time used 0.007979s\n",
      "batch 7907, train_loss 0.003449,Time used 0.007979s\n",
      "batch 7908, train_loss 0.003399,Time used 0.007979s\n",
      "batch 7909, train_loss 0.002713,Time used 0.007978s\n",
      "batch 7910, train_loss 0.004534,Time used 0.008976s\n",
      "batch 7911, train_loss 0.003873,Time used 0.008976s\n",
      "batch 7912, train_loss 0.003884,Time used 0.008976s\n",
      "batch 7913, train_loss 0.006075,Time used 0.008976s\n",
      "batch 7914, train_loss 0.003864,Time used 0.007978s\n",
      "batch 7915, train_loss 0.004367,Time used 0.007980s\n",
      "batch 7916, train_loss 0.003442,Time used 0.008975s\n",
      "batch 7917, train_loss 0.002263,Time used 0.007979s\n",
      "batch 7918, train_loss 0.001518,Time used 0.007978s\n",
      "batch 7919, train_loss 0.003557,Time used 0.008976s\n",
      "batch 7920, train_loss 0.003311,Time used 0.008976s\n",
      "batch 7921, train_loss 0.002885,Time used 0.008976s\n",
      "batch 7922, train_loss 0.003601,Time used 0.008976s\n",
      "batch 7923, train_loss 0.003898,Time used 0.007978s\n",
      "batch 7924, train_loss 0.003284,Time used 0.007980s\n",
      "batch 7925, train_loss 0.002709,Time used 0.007978s\n",
      "batch 7926, train_loss 0.003751,Time used 0.008976s\n",
      "batch 7927, train_loss 0.003697,Time used 0.007978s\n",
      "batch 7928, train_loss 0.003224,Time used 0.007978s\n",
      "batch 7929, train_loss 0.003388,Time used 0.009974s\n",
      "batch 7930, train_loss 0.006322,Time used 0.007979s\n",
      "batch 7931, train_loss 0.003162,Time used 0.007979s\n",
      "batch 7932, train_loss 0.003492,Time used 0.007979s\n",
      "batch 7933, train_loss 0.002940,Time used 0.007979s\n",
      "batch 7934, train_loss 0.003042,Time used 0.008009s\n",
      "batch 7935, train_loss 0.002572,Time used 0.007979s\n",
      "batch 7936, train_loss 0.003414,Time used 0.007979s\n",
      "batch 7937, train_loss 0.004499,Time used 0.007978s\n",
      "batch 7938, train_loss 0.004469,Time used 0.007979s\n",
      "batch 7939, train_loss 0.003337,Time used 0.009973s\n",
      "batch 7940, train_loss 0.003461,Time used 0.008976s\n",
      "batch 7941, train_loss 0.004339,Time used 0.009974s\n",
      "batch 7942, train_loss 0.003317,Time used 0.008976s\n",
      "batch 7943, train_loss 0.003034,Time used 0.008976s\n",
      "batch 7944, train_loss 0.003077,Time used 0.007978s\n",
      "batch 7945, train_loss 0.005167,Time used 0.007978s\n",
      "batch 7946, train_loss 0.003718,Time used 0.008976s\n",
      "batch 7947, train_loss 0.003552,Time used 0.008977s\n",
      "batch 7948, train_loss 0.002795,Time used 0.008976s\n",
      "batch 7949, train_loss 0.003107,Time used 0.008976s\n",
      "batch 7950, train_loss 0.003126,Time used 0.008976s\n",
      "batch 7951, train_loss 0.003990,Time used 0.007979s\n",
      "batch 7952, train_loss 0.003393,Time used 0.008976s\n",
      "batch 7953, train_loss 0.003121,Time used 0.008977s\n",
      "batch 7954, train_loss 0.003817,Time used 0.007978s\n",
      "batch 7955, train_loss 0.003483,Time used 0.009974s\n",
      "batch 7956, train_loss 0.004238,Time used 0.007978s\n",
      "batch 7957, train_loss 0.002983,Time used 0.007978s\n",
      "batch 7958, train_loss 0.003567,Time used 0.007978s\n",
      "batch 7959, train_loss 0.003136,Time used 0.007978s\n",
      "batch 7960, train_loss 0.004469,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 7961, train_loss 0.003497,Time used 0.008976s\n",
      "batch 7962, train_loss 0.003396,Time used 0.008976s\n",
      "batch 7963, train_loss 0.003984,Time used 0.007979s\n",
      "batch 7964, train_loss 0.004290,Time used 0.007979s\n",
      "batch 7965, train_loss 0.004635,Time used 0.007979s\n",
      "batch 7966, train_loss 0.004187,Time used 0.008976s\n",
      "batch 7967, train_loss 0.003674,Time used 0.007979s\n",
      "batch 7968, train_loss 0.002712,Time used 0.008976s\n",
      "batch 7969, train_loss 0.004668,Time used 0.009973s\n",
      "batch 7970, train_loss 0.003853,Time used 0.008976s\n",
      "batch 7971, train_loss 0.003748,Time used 0.008976s\n",
      "batch 7972, train_loss 0.003128,Time used 0.007979s\n",
      "batch 7973, train_loss 0.003218,Time used 0.007979s\n",
      "batch 7974, train_loss 0.003479,Time used 0.007979s\n",
      "batch 7975, train_loss 0.004165,Time used 0.007979s\n",
      "batch 7976, train_loss 0.003079,Time used 0.007979s\n",
      "batch 7977, train_loss 0.003881,Time used 0.007979s\n",
      "batch 7978, train_loss 0.003540,Time used 0.007980s\n",
      "batch 7979, train_loss 0.003851,Time used 0.007979s\n",
      "batch 7980, train_loss 0.003340,Time used 0.007979s\n",
      "batch 7981, train_loss 0.005347,Time used 0.008976s\n",
      "batch 7982, train_loss 0.003122,Time used 0.008976s\n",
      "batch 7983, train_loss 0.002774,Time used 0.007979s\n",
      "batch 7984, train_loss 0.003929,Time used 0.008976s\n",
      "batch 7985, train_loss 0.003235,Time used 0.007977s\n",
      "batch 7986, train_loss 0.006524,Time used 0.007979s\n",
      "batch 7987, train_loss 0.003429,Time used 0.006982s\n",
      "batch 7988, train_loss 0.004645,Time used 0.006981s\n",
      "batch 7989, train_loss 0.003271,Time used 0.006982s\n",
      "batch 7990, train_loss 0.004157,Time used 0.007977s\n",
      "batch 7991, train_loss 0.004705,Time used 0.007979s\n",
      "batch 7992, train_loss 0.003859,Time used 0.007979s\n",
      "batch 7993, train_loss 0.003176,Time used 0.006981s\n",
      "batch 7994, train_loss 0.003975,Time used 0.006981s\n",
      "batch 7995, train_loss 0.003719,Time used 0.007979s\n",
      "batch 7996, train_loss 0.004136,Time used 0.007979s\n",
      "batch 7997, train_loss 0.002807,Time used 0.007979s\n",
      "batch 7998, train_loss 0.004234,Time used 0.007978s\n",
      "batch 7999, train_loss 0.003312,Time used 0.007979s\n",
      "batch 8000, train_loss 0.003757,Time used 0.007978s\n",
      "***************************test_batch 8000, test_rmse_loss 0.061176,test_mae_loss 0.043694,test_mape_loss 13.269111,Time used 0.112700s\n",
      "batch 8001, train_loss 0.003250,Time used 0.008976s\n",
      "batch 8002, train_loss 0.003691,Time used 0.008976s\n",
      "batch 8003, train_loss 0.005054,Time used 0.007979s\n",
      "batch 8004, train_loss 0.002794,Time used 0.006981s\n",
      "batch 8005, train_loss 0.003308,Time used 0.007979s\n",
      "batch 8006, train_loss 0.003588,Time used 0.007978s\n",
      "batch 8007, train_loss 0.003029,Time used 0.008976s\n",
      "batch 8008, train_loss 0.002997,Time used 0.008976s\n",
      "batch 8009, train_loss 0.003720,Time used 0.008976s\n",
      "batch 8010, train_loss 0.002930,Time used 0.008976s\n",
      "batch 8011, train_loss 0.003580,Time used 0.008976s\n",
      "batch 8012, train_loss 0.004834,Time used 0.007979s\n",
      "batch 8013, train_loss 0.003685,Time used 0.007979s\n",
      "batch 8014, train_loss 0.003615,Time used 0.008975s\n",
      "batch 8015, train_loss 0.002961,Time used 0.008976s\n",
      "batch 8016, train_loss 0.003267,Time used 0.007978s\n",
      "batch 8017, train_loss 0.003937,Time used 0.007979s\n",
      "batch 8018, train_loss 0.002382,Time used 0.007979s\n",
      "batch 8019, train_loss 0.002740,Time used 0.008976s\n",
      "batch 8020, train_loss 0.003859,Time used 0.007979s\n",
      "batch 8021, train_loss 0.004148,Time used 0.007978s\n",
      "batch 8022, train_loss 0.004086,Time used 0.009973s\n",
      "batch 8023, train_loss 0.003131,Time used 0.008977s\n",
      "batch 8024, train_loss 0.003116,Time used 0.008976s\n",
      "batch 8025, train_loss 0.002524,Time used 0.007978s\n",
      "batch 8026, train_loss 0.003681,Time used 0.008976s\n",
      "batch 8027, train_loss 0.003469,Time used 0.007979s\n",
      "batch 8028, train_loss 0.004319,Time used 0.007979s\n",
      "batch 8029, train_loss 0.005597,Time used 0.009974s\n",
      "batch 8030, train_loss 0.005449,Time used 0.007978s\n",
      "batch 8031, train_loss 0.003147,Time used 0.007979s\n",
      "batch 8032, train_loss 0.004459,Time used 0.007980s\n",
      "batch 8033, train_loss 0.003139,Time used 0.008976s\n",
      "batch 8034, train_loss 0.003491,Time used 0.008510s\n",
      "batch 8035, train_loss 0.003261,Time used 0.008489s\n",
      "batch 8036, train_loss 0.003100,Time used 0.008975s\n",
      "batch 8037, train_loss 0.003478,Time used 0.007979s\n",
      "batch 8038, train_loss 0.004094,Time used 0.008976s\n",
      "batch 8039, train_loss 0.004041,Time used 0.007978s\n",
      "batch 8040, train_loss 0.002860,Time used 0.008976s\n",
      "batch 8041, train_loss 0.002776,Time used 0.008976s\n",
      "batch 8042, train_loss 0.003945,Time used 0.008977s\n",
      "batch 8043, train_loss 0.004054,Time used 0.008975s\n",
      "batch 8044, train_loss 0.003492,Time used 0.007979s\n",
      "batch 8045, train_loss 0.003448,Time used 0.007979s\n",
      "batch 8046, train_loss 0.003372,Time used 0.008977s\n",
      "batch 8047, train_loss 0.004462,Time used 0.008975s\n",
      "batch 8048, train_loss 0.003180,Time used 0.007978s\n",
      "batch 8049, train_loss 0.003321,Time used 0.007979s\n",
      "batch 8050, train_loss 0.003192,Time used 0.007978s\n",
      "batch 8051, train_loss 0.004566,Time used 0.008977s\n",
      "batch 8052, train_loss 0.003255,Time used 0.007977s\n",
      "batch 8053, train_loss 0.003080,Time used 0.007978s\n",
      "batch 8054, train_loss 0.004238,Time used 0.007979s\n",
      "batch 8055, train_loss 0.003557,Time used 0.007979s\n",
      "batch 8056, train_loss 0.005121,Time used 0.007979s\n",
      "batch 8057, train_loss 0.003537,Time used 0.008976s\n",
      "batch 8058, train_loss 0.002205,Time used 0.008486s\n",
      "batch 8059, train_loss 0.003346,Time used 0.008976s\n",
      "batch 8060, train_loss 0.003602,Time used 0.007979s\n",
      "batch 8061, train_loss 0.002633,Time used 0.008976s\n",
      "batch 8062, train_loss 0.004580,Time used 0.007978s\n",
      "batch 8063, train_loss 0.003375,Time used 0.008976s\n",
      "batch 8064, train_loss 0.002983,Time used 0.008976s\n",
      "batch 8065, train_loss 0.003668,Time used 0.008976s\n",
      "batch 8066, train_loss 0.004059,Time used 0.008975s\n",
      "batch 8067, train_loss 0.003063,Time used 0.008977s\n",
      "batch 8068, train_loss 0.004439,Time used 0.008976s\n",
      "batch 8069, train_loss 0.003207,Time used 0.007979s\n",
      "batch 8070, train_loss 0.003866,Time used 0.007979s\n",
      "batch 8071, train_loss 0.003756,Time used 0.007978s\n",
      "batch 8072, train_loss 0.002606,Time used 0.007978s\n",
      "batch 8073, train_loss 0.003584,Time used 0.007979s\n",
      "batch 8074, train_loss 0.003365,Time used 0.007979s\n",
      "batch 8075, train_loss 0.003703,Time used 0.007978s\n",
      "batch 8076, train_loss 0.002291,Time used 0.007979s\n",
      "batch 8077, train_loss 0.003705,Time used 0.007979s\n",
      "batch 8078, train_loss 0.003273,Time used 0.008976s\n",
      "batch 8079, train_loss 0.004308,Time used 0.007978s\n",
      "batch 8080, train_loss 0.002210,Time used 0.007979s\n",
      "batch 8081, train_loss 0.003546,Time used 0.008975s\n",
      "batch 8082, train_loss 0.003455,Time used 0.007979s\n",
      "batch 8083, train_loss 0.004883,Time used 0.008976s\n",
      "batch 8084, train_loss 0.004488,Time used 0.007978s\n",
      "batch 8085, train_loss 0.004115,Time used 0.007979s\n",
      "batch 8086, train_loss 0.003319,Time used 0.007979s\n",
      "batch 8087, train_loss 0.003180,Time used 0.007978s\n",
      "batch 8088, train_loss 0.003393,Time used 0.007979s\n",
      "batch 8089, train_loss 0.003095,Time used 0.007979s\n",
      "batch 8090, train_loss 0.003765,Time used 0.007978s\n",
      "batch 8091, train_loss 0.003797,Time used 0.007979s\n",
      "batch 8092, train_loss 0.003360,Time used 0.008976s\n",
      "batch 8093, train_loss 0.003404,Time used 0.007979s\n",
      "batch 8094, train_loss 0.003525,Time used 0.008976s\n",
      "batch 8095, train_loss 0.004184,Time used 0.007979s\n",
      "batch 8096, train_loss 0.004425,Time used 0.008976s\n",
      "batch 8097, train_loss 0.003620,Time used 0.009974s\n",
      "batch 8098, train_loss 0.003074,Time used 0.008975s\n",
      "batch 8099, train_loss 0.003596,Time used 0.007979s\n",
      "batch 8100, train_loss 0.003833,Time used 0.008976s\n",
      "***************************test_batch 8100, test_rmse_loss 0.060773,test_mae_loss 0.043300,test_mape_loss 12.794310,Time used 0.107712s\n",
      "batch 8101, train_loss 0.003343,Time used 0.008976s\n",
      "batch 8102, train_loss 0.003515,Time used 0.007978s\n",
      "batch 8103, train_loss 0.004924,Time used 0.007979s\n",
      "batch 8104, train_loss 0.003021,Time used 0.007979s\n",
      "batch 8105, train_loss 0.002114,Time used 0.007978s\n",
      "batch 8106, train_loss 0.003211,Time used 0.007979s\n",
      "batch 8107, train_loss 0.004279,Time used 0.007979s\n",
      "batch 8108, train_loss 0.003077,Time used 0.007978s\n",
      "batch 8109, train_loss 0.004446,Time used 0.007979s\n",
      "batch 8110, train_loss 0.003243,Time used 0.006981s\n",
      "batch 8111, train_loss 0.003277,Time used 0.007978s\n",
      "batch 8112, train_loss 0.003797,Time used 0.007979s\n",
      "batch 8113, train_loss 0.003141,Time used 0.007979s\n",
      "batch 8114, train_loss 0.003330,Time used 0.007979s\n",
      "batch 8115, train_loss 0.005147,Time used 0.006981s\n",
      "batch 8116, train_loss 0.003867,Time used 0.007979s\n",
      "batch 8117, train_loss 0.004148,Time used 0.006981s\n",
      "batch 8118, train_loss 0.003150,Time used 0.006980s\n",
      "batch 8119, train_loss 0.003728,Time used 0.007978s\n",
      "batch 8120, train_loss 0.003016,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 8121, train_loss 0.003618,Time used 0.007978s\n",
      "batch 8122, train_loss 0.004583,Time used 0.008976s\n",
      "batch 8123, train_loss 0.002914,Time used 0.007979s\n",
      "batch 8124, train_loss 0.003946,Time used 0.007978s\n",
      "batch 8125, train_loss 0.003233,Time used 0.007979s\n",
      "batch 8126, train_loss 0.003960,Time used 0.007979s\n",
      "batch 8127, train_loss 0.004214,Time used 0.007978s\n",
      "batch 8128, train_loss 0.003764,Time used 0.006982s\n",
      "batch 8129, train_loss 0.004411,Time used 0.007979s\n",
      "batch 8130, train_loss 0.003105,Time used 0.007979s\n",
      "batch 8131, train_loss 0.003511,Time used 0.007978s\n",
      "batch 8132, train_loss 0.002441,Time used 0.006981s\n",
      "batch 8133, train_loss 0.003836,Time used 0.007979s\n",
      "batch 8134, train_loss 0.002732,Time used 0.006981s\n",
      "batch 8135, train_loss 0.003573,Time used 0.006981s\n",
      "batch 8136, train_loss 0.002931,Time used 0.006981s\n",
      "batch 8137, train_loss 0.002871,Time used 0.007978s\n",
      "batch 8138, train_loss 0.004114,Time used 0.008977s\n",
      "batch 8139, train_loss 0.004636,Time used 0.008976s\n",
      "batch 8140, train_loss 0.004920,Time used 0.007979s\n",
      "batch 8141, train_loss 0.005561,Time used 0.007978s\n",
      "batch 8142, train_loss 0.004443,Time used 0.008976s\n",
      "batch 8143, train_loss 0.003048,Time used 0.007979s\n",
      "batch 8144, train_loss 0.004104,Time used 0.007979s\n",
      "batch 8145, train_loss 0.003687,Time used 0.007980s\n",
      "batch 8146, train_loss 0.003034,Time used 0.007978s\n",
      "batch 8147, train_loss 0.002976,Time used 0.007978s\n",
      "batch 8148, train_loss 0.002756,Time used 0.007980s\n",
      "batch 8149, train_loss 0.003278,Time used 0.007979s\n",
      "batch 8150, train_loss 0.003283,Time used 0.008976s\n",
      "batch 8151, train_loss 0.004323,Time used 0.007979s\n",
      "batch 8152, train_loss 0.002878,Time used 0.008975s\n",
      "batch 8153, train_loss 0.004505,Time used 0.008976s\n",
      "batch 8154, train_loss 0.003887,Time used 0.008976s\n",
      "batch 8155, train_loss 0.003497,Time used 0.008976s\n",
      "batch 8156, train_loss 0.004439,Time used 0.009974s\n",
      "batch 8157, train_loss 0.002827,Time used 0.009973s\n",
      "batch 8158, train_loss 0.003893,Time used 0.009974s\n",
      "batch 8159, train_loss 0.004556,Time used 0.008976s\n",
      "batch 8160, train_loss 0.003862,Time used 0.008976s\n",
      "batch 8161, train_loss 0.003078,Time used 0.008976s\n",
      "batch 8162, train_loss 0.004147,Time used 0.007978s\n",
      "batch 8163, train_loss 0.005894,Time used 0.008976s\n",
      "batch 8164, train_loss 0.003049,Time used 0.008976s\n",
      "batch 8165, train_loss 0.004663,Time used 0.009973s\n",
      "batch 8166, train_loss 0.003086,Time used 0.008976s\n",
      "batch 8167, train_loss 0.002898,Time used 0.008976s\n",
      "batch 8168, train_loss 0.004565,Time used 0.007979s\n",
      "batch 8169, train_loss 0.004219,Time used 0.007979s\n",
      "batch 8170, train_loss 0.003203,Time used 0.008976s\n",
      "batch 8171, train_loss 0.003184,Time used 0.008977s\n",
      "batch 8172, train_loss 0.003016,Time used 0.008976s\n",
      "batch 8173, train_loss 0.002468,Time used 0.007979s\n",
      "batch 8174, train_loss 0.003831,Time used 0.008977s\n",
      "batch 8175, train_loss 0.003231,Time used 0.008976s\n",
      "batch 8176, train_loss 0.004110,Time used 0.008975s\n",
      "batch 8177, train_loss 0.003387,Time used 0.009508s\n",
      "batch 8178, train_loss 0.002502,Time used 0.008935s\n",
      "batch 8179, train_loss 0.002908,Time used 0.008976s\n",
      "batch 8180, train_loss 0.006415,Time used 0.007979s\n",
      "batch 8181, train_loss 0.004575,Time used 0.008977s\n",
      "batch 8182, train_loss 0.003679,Time used 0.007979s\n",
      "batch 8183, train_loss 0.003524,Time used 0.007978s\n",
      "batch 8184, train_loss 0.003674,Time used 0.008976s\n",
      "batch 8185, train_loss 0.003064,Time used 0.007979s\n",
      "batch 8186, train_loss 0.003900,Time used 0.008976s\n",
      "batch 8187, train_loss 0.004322,Time used 0.007979s\n",
      "batch 8188, train_loss 0.003196,Time used 0.008975s\n",
      "batch 8189, train_loss 0.003455,Time used 0.007979s\n",
      "batch 8190, train_loss 0.003959,Time used 0.007978s\n",
      "batch 8191, train_loss 0.003589,Time used 0.007979s\n",
      "batch 8192, train_loss 0.003080,Time used 0.007979s\n",
      "batch 8193, train_loss 0.003359,Time used 0.007978s\n",
      "batch 8194, train_loss 0.004877,Time used 0.007979s\n",
      "batch 8195, train_loss 0.004461,Time used 0.007979s\n",
      "batch 8196, train_loss 0.002655,Time used 0.007978s\n",
      "batch 8197, train_loss 0.003522,Time used 0.007978s\n",
      "batch 8198, train_loss 0.003082,Time used 0.008978s\n",
      "batch 8199, train_loss 0.002764,Time used 0.007977s\n",
      "batch 8200, train_loss 0.002806,Time used 0.007979s\n",
      "***************************test_batch 8200, test_rmse_loss 0.060779,test_mae_loss 0.043303,test_mape_loss 12.900699,Time used 0.109708s\n",
      "batch 8201, train_loss 0.003824,Time used 0.008976s\n",
      "batch 8202, train_loss 0.003694,Time used 0.008976s\n",
      "batch 8203, train_loss 0.002899,Time used 0.009973s\n",
      "batch 8204, train_loss 0.003720,Time used 0.010972s\n",
      "batch 8205, train_loss 0.003683,Time used 0.009973s\n",
      "batch 8206, train_loss 0.002849,Time used 0.009974s\n",
      "batch 8207, train_loss 0.003743,Time used 0.009974s\n",
      "batch 8208, train_loss 0.003113,Time used 0.008975s\n",
      "batch 8209, train_loss 0.004344,Time used 0.008977s\n",
      "batch 8210, train_loss 0.002317,Time used 0.008975s\n",
      "batch 8211, train_loss 0.004244,Time used 0.009973s\n",
      "batch 8212, train_loss 0.003696,Time used 0.009974s\n",
      "batch 8213, train_loss 0.003655,Time used 0.008976s\n",
      "batch 8214, train_loss 0.003482,Time used 0.009974s\n",
      "batch 8215, train_loss 0.002565,Time used 0.008976s\n",
      "batch 8216, train_loss 0.002568,Time used 0.008976s\n",
      "batch 8217, train_loss 0.005131,Time used 0.008976s\n",
      "batch 8218, train_loss 0.003144,Time used 0.008976s\n",
      "batch 8219, train_loss 0.002779,Time used 0.009973s\n",
      "batch 8220, train_loss 0.003709,Time used 0.008976s\n",
      "batch 8221, train_loss 0.002330,Time used 0.007978s\n",
      "batch 8222, train_loss 0.003599,Time used 0.008976s\n",
      "batch 8223, train_loss 0.005518,Time used 0.008976s\n",
      "batch 8224, train_loss 0.002587,Time used 0.008976s\n",
      "batch 8225, train_loss 0.003753,Time used 0.009973s\n",
      "batch 8226, train_loss 0.003254,Time used 0.008976s\n",
      "batch 8227, train_loss 0.002823,Time used 0.009974s\n",
      "batch 8228, train_loss 0.004701,Time used 0.009973s\n",
      "batch 8229, train_loss 0.002880,Time used 0.007978s\n",
      "batch 8230, train_loss 0.003400,Time used 0.008977s\n",
      "batch 8231, train_loss 0.003399,Time used 0.008975s\n",
      "batch 8232, train_loss 0.004342,Time used 0.007979s\n",
      "batch 8233, train_loss 0.004099,Time used 0.007978s\n",
      "batch 8234, train_loss 0.004726,Time used 0.007978s\n",
      "batch 8235, train_loss 0.003466,Time used 0.008976s\n",
      "batch 8236, train_loss 0.003603,Time used 0.007978s\n",
      "batch 8237, train_loss 0.003416,Time used 0.007980s\n",
      "batch 8238, train_loss 0.004599,Time used 0.007979s\n",
      "batch 8239, train_loss 0.004048,Time used 0.007979s\n",
      "batch 8240, train_loss 0.003618,Time used 0.008975s\n",
      "batch 8241, train_loss 0.003652,Time used 0.008976s\n",
      "batch 8242, train_loss 0.002939,Time used 0.008976s\n",
      "batch 8243, train_loss 0.002292,Time used 0.008976s\n",
      "batch 8244, train_loss 0.003592,Time used 0.008976s\n",
      "batch 8245, train_loss 0.002953,Time used 0.008976s\n",
      "batch 8246, train_loss 0.003414,Time used 0.008976s\n",
      "batch 8247, train_loss 0.004199,Time used 0.008976s\n",
      "batch 8248, train_loss 0.004348,Time used 0.008976s\n",
      "batch 8249, train_loss 0.003023,Time used 0.008976s\n",
      "batch 8250, train_loss 0.003415,Time used 0.008977s\n",
      "batch 8251, train_loss 0.003562,Time used 0.008976s\n",
      "batch 8252, train_loss 0.003603,Time used 0.007979s\n",
      "batch 8253, train_loss 0.003334,Time used 0.008977s\n",
      "batch 8254, train_loss 0.003057,Time used 0.009973s\n",
      "batch 8255, train_loss 0.004247,Time used 0.007978s\n",
      "batch 8256, train_loss 0.005635,Time used 0.006982s\n",
      "batch 8257, train_loss 0.003394,Time used 0.007979s\n",
      "batch 8258, train_loss 0.003353,Time used 0.008976s\n",
      "batch 8259, train_loss 0.003559,Time used 0.009973s\n",
      "batch 8260, train_loss 0.003338,Time used 0.009973s\n",
      "batch 8261, train_loss 0.005195,Time used 0.007979s\n",
      "batch 8262, train_loss 0.003436,Time used 0.007979s\n",
      "batch 8263, train_loss 0.002658,Time used 0.007979s\n",
      "batch 8264, train_loss 0.004763,Time used 0.008976s\n",
      "batch 8265, train_loss 0.002661,Time used 0.008976s\n",
      "batch 8266, train_loss 0.003616,Time used 0.007978s\n",
      "batch 8267, train_loss 0.003103,Time used 0.007978s\n",
      "batch 8268, train_loss 0.002854,Time used 0.007978s\n",
      "batch 8269, train_loss 0.003859,Time used 0.007979s\n",
      "batch 8270, train_loss 0.003979,Time used 0.007978s\n",
      "batch 8271, train_loss 0.003782,Time used 0.008977s\n",
      "batch 8272, train_loss 0.003134,Time used 0.008976s\n",
      "batch 8273, train_loss 0.003728,Time used 0.008975s\n",
      "batch 8274, train_loss 0.003154,Time used 0.008977s\n",
      "batch 8275, train_loss 0.005291,Time used 0.008976s\n",
      "batch 8276, train_loss 0.006333,Time used 0.009973s\n",
      "batch 8277, train_loss 0.004531,Time used 0.009974s\n",
      "batch 8278, train_loss 0.004250,Time used 0.009972s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 8279, train_loss 0.003379,Time used 0.009973s\n",
      "batch 8280, train_loss 0.003616,Time used 0.008976s\n",
      "batch 8281, train_loss 0.003966,Time used 0.008976s\n",
      "batch 8282, train_loss 0.006049,Time used 0.008977s\n",
      "batch 8283, train_loss 0.003666,Time used 0.007979s\n",
      "batch 8284, train_loss 0.002692,Time used 0.007979s\n",
      "batch 8285, train_loss 0.004312,Time used 0.007979s\n",
      "batch 8286, train_loss 0.003768,Time used 0.007979s\n",
      "batch 8287, train_loss 0.003976,Time used 0.008976s\n",
      "batch 8288, train_loss 0.003041,Time used 0.008976s\n",
      "batch 8289, train_loss 0.004024,Time used 0.009973s\n",
      "batch 8290, train_loss 0.002463,Time used 0.008976s\n",
      "batch 8291, train_loss 0.005378,Time used 0.008976s\n",
      "batch 8292, train_loss 0.004308,Time used 0.009973s\n",
      "batch 8293, train_loss 0.003640,Time used 0.009974s\n",
      "batch 8294, train_loss 0.002813,Time used 0.009973s\n",
      "batch 8295, train_loss 0.003852,Time used 0.008977s\n",
      "batch 8296, train_loss 0.002675,Time used 0.008975s\n",
      "batch 8297, train_loss 0.003709,Time used 0.008976s\n",
      "batch 8298, train_loss 0.003219,Time used 0.008976s\n",
      "batch 8299, train_loss 0.002488,Time used 0.009974s\n",
      "batch 8300, train_loss 0.004209,Time used 0.008976s\n",
      "***************************test_batch 8300, test_rmse_loss 0.060915,test_mae_loss 0.043437,test_mape_loss 13.023724,Time used 0.118683s\n",
      "batch 8301, train_loss 0.003458,Time used 0.009973s\n",
      "batch 8302, train_loss 0.003036,Time used 0.008976s\n",
      "batch 8303, train_loss 0.003204,Time used 0.008976s\n",
      "batch 8304, train_loss 0.003344,Time used 0.009974s\n",
      "batch 8305, train_loss 0.003317,Time used 0.008976s\n",
      "batch 8306, train_loss 0.003915,Time used 0.009972s\n",
      "batch 8307, train_loss 0.003276,Time used 0.009973s\n",
      "batch 8308, train_loss 0.002570,Time used 0.008976s\n",
      "batch 8309, train_loss 0.003030,Time used 0.008976s\n",
      "batch 8310, train_loss 0.004913,Time used 0.008976s\n",
      "batch 8311, train_loss 0.003656,Time used 0.008976s\n",
      "batch 8312, train_loss 0.003311,Time used 0.008976s\n",
      "batch 8313, train_loss 0.004246,Time used 0.008976s\n",
      "batch 8314, train_loss 0.003688,Time used 0.008976s\n",
      "batch 8315, train_loss 0.004636,Time used 0.009973s\n",
      "batch 8316, train_loss 0.003313,Time used 0.008976s\n",
      "batch 8317, train_loss 0.005367,Time used 0.009974s\n",
      "batch 8318, train_loss 0.002797,Time used 0.009973s\n",
      "batch 8319, train_loss 0.004794,Time used 0.008976s\n",
      "batch 8320, train_loss 0.003610,Time used 0.008977s\n",
      "batch 8321, train_loss 0.004021,Time used 0.008976s\n",
      "batch 8322, train_loss 0.003409,Time used 0.009974s\n",
      "batch 8323, train_loss 0.003966,Time used 0.009972s\n",
      "batch 8324, train_loss 0.003746,Time used 0.011968s\n",
      "batch 8325, train_loss 0.003571,Time used 0.009974s\n",
      "batch 8326, train_loss 0.003700,Time used 0.008975s\n",
      "batch 8327, train_loss 0.004548,Time used 0.008976s\n",
      "batch 8328, train_loss 0.003851,Time used 0.008976s\n",
      "batch 8329, train_loss 0.002843,Time used 0.008976s\n",
      "batch 8330, train_loss 0.002818,Time used 0.008976s\n",
      "batch 8331, train_loss 0.004486,Time used 0.008977s\n",
      "batch 8332, train_loss 0.002844,Time used 0.009972s\n",
      "batch 8333, train_loss 0.003297,Time used 0.008976s\n",
      "batch 8334, train_loss 0.004236,Time used 0.008976s\n",
      "batch 8335, train_loss 0.003102,Time used 0.008976s\n",
      "batch 8336, train_loss 0.004191,Time used 0.008975s\n",
      "batch 8337, train_loss 0.002655,Time used 0.008976s\n",
      "batch 8338, train_loss 0.003617,Time used 0.008976s\n",
      "batch 8339, train_loss 0.002814,Time used 0.008976s\n",
      "batch 8340, train_loss 0.002265,Time used 0.008976s\n",
      "batch 8341, train_loss 0.003024,Time used 0.007979s\n",
      "batch 8342, train_loss 0.003448,Time used 0.007979s\n",
      "batch 8343, train_loss 0.002911,Time used 0.008976s\n",
      "batch 8344, train_loss 0.002919,Time used 0.008976s\n",
      "batch 8345, train_loss 0.005119,Time used 0.009973s\n",
      "batch 8346, train_loss 0.001373,Time used 0.007979s\n",
      "batch 8347, train_loss 0.004678,Time used 0.008976s\n",
      "batch 8348, train_loss 0.004331,Time used 0.009973s\n",
      "batch 8349, train_loss 0.003780,Time used 0.008976s\n",
      "batch 8350, train_loss 0.004059,Time used 0.008976s\n",
      "batch 8351, train_loss 0.003925,Time used 0.008976s\n",
      "batch 8352, train_loss 0.003313,Time used 0.008976s\n",
      "batch 8353, train_loss 0.004076,Time used 0.008975s\n",
      "batch 8354, train_loss 0.002535,Time used 0.008976s\n",
      "batch 8355, train_loss 0.004076,Time used 0.008976s\n",
      "batch 8356, train_loss 0.003047,Time used 0.007977s\n",
      "batch 8357, train_loss 0.004170,Time used 0.007979s\n",
      "batch 8358, train_loss 0.002597,Time used 0.007979s\n",
      "batch 8359, train_loss 0.003650,Time used 0.008977s\n",
      "batch 8360, train_loss 0.004047,Time used 0.008976s\n",
      "batch 8361, train_loss 0.003229,Time used 0.008976s\n",
      "batch 8362, train_loss 0.003402,Time used 0.007978s\n",
      "batch 8363, train_loss 0.004766,Time used 0.008976s\n",
      "batch 8364, train_loss 0.004490,Time used 0.007979s\n",
      "batch 8365, train_loss 0.002687,Time used 0.009974s\n",
      "batch 8366, train_loss 0.002404,Time used 0.008976s\n",
      "batch 8367, train_loss 0.002796,Time used 0.008976s\n",
      "batch 8368, train_loss 0.005079,Time used 0.007979s\n",
      "batch 8369, train_loss 0.003565,Time used 0.007978s\n",
      "batch 8370, train_loss 0.004510,Time used 0.007978s\n",
      "batch 8371, train_loss 0.003343,Time used 0.007978s\n",
      "batch 8372, train_loss 0.003541,Time used 0.007980s\n",
      "batch 8373, train_loss 0.003017,Time used 0.007978s\n",
      "batch 8374, train_loss 0.003453,Time used 0.007978s\n",
      "batch 8375, train_loss 0.003394,Time used 0.007979s\n",
      "batch 8376, train_loss 0.002218,Time used 0.007979s\n",
      "batch 8377, train_loss 0.003094,Time used 0.008975s\n",
      "batch 8378, train_loss 0.004237,Time used 0.008976s\n",
      "batch 8379, train_loss 0.004371,Time used 0.008976s\n",
      "batch 8380, train_loss 0.003971,Time used 0.008976s\n",
      "batch 8381, train_loss 0.003310,Time used 0.007978s\n",
      "batch 8382, train_loss 0.003188,Time used 0.008977s\n",
      "batch 8383, train_loss 0.003347,Time used 0.008976s\n",
      "batch 8384, train_loss 0.002763,Time used 0.007978s\n",
      "batch 8385, train_loss 0.004149,Time used 0.008976s\n",
      "batch 8386, train_loss 0.004784,Time used 0.009973s\n",
      "batch 8387, train_loss 0.003171,Time used 0.008977s\n",
      "batch 8388, train_loss 0.003333,Time used 0.008976s\n",
      "batch 8389, train_loss 0.003900,Time used 0.008977s\n",
      "batch 8390, train_loss 0.002866,Time used 0.008975s\n",
      "batch 8391, train_loss 0.002611,Time used 0.007979s\n",
      "batch 8392, train_loss 0.003479,Time used 0.007979s\n",
      "batch 8393, train_loss 0.002843,Time used 0.007978s\n",
      "batch 8394, train_loss 0.003014,Time used 0.007979s\n",
      "batch 8395, train_loss 0.003692,Time used 0.007979s\n",
      "batch 8396, train_loss 0.003512,Time used 0.007979s\n",
      "batch 8397, train_loss 0.003137,Time used 0.007979s\n",
      "batch 8398, train_loss 0.003607,Time used 0.007978s\n",
      "batch 8399, train_loss 0.002977,Time used 0.006981s\n",
      "batch 8400, train_loss 0.005091,Time used 0.007979s\n",
      "***************************test_batch 8400, test_rmse_loss 0.060825,test_mae_loss 0.043367,test_mape_loss 13.018781,Time used 0.108710s\n",
      "batch 8401, train_loss 0.003118,Time used 0.008976s\n",
      "batch 8402, train_loss 0.004237,Time used 0.008976s\n",
      "batch 8403, train_loss 0.002820,Time used 0.008975s\n",
      "batch 8404, train_loss 0.004150,Time used 0.008976s\n",
      "batch 8405, train_loss 0.003217,Time used 0.008976s\n",
      "batch 8406, train_loss 0.003342,Time used 0.007979s\n",
      "batch 8407, train_loss 0.003153,Time used 0.006981s\n",
      "batch 8408, train_loss 0.005514,Time used 0.008976s\n",
      "batch 8409, train_loss 0.003250,Time used 0.008976s\n",
      "batch 8410, train_loss 0.003952,Time used 0.007979s\n",
      "batch 8411, train_loss 0.003735,Time used 0.007979s\n",
      "batch 8412, train_loss 0.003413,Time used 0.007979s\n",
      "batch 8413, train_loss 0.004013,Time used 0.007979s\n",
      "batch 8414, train_loss 0.003017,Time used 0.008976s\n",
      "batch 8415, train_loss 0.003146,Time used 0.007978s\n",
      "batch 8416, train_loss 0.002600,Time used 0.008975s\n",
      "batch 8417, train_loss 0.004016,Time used 0.008976s\n",
      "batch 8418, train_loss 0.003962,Time used 0.007979s\n",
      "batch 8419, train_loss 0.002592,Time used 0.008975s\n",
      "batch 8420, train_loss 0.003909,Time used 0.008977s\n",
      "batch 8421, train_loss 0.004528,Time used 0.009973s\n",
      "batch 8422, train_loss 0.003355,Time used 0.010971s\n",
      "batch 8423, train_loss 0.003261,Time used 0.007978s\n",
      "batch 8424, train_loss 0.004083,Time used 0.007978s\n",
      "batch 8425, train_loss 0.004054,Time used 0.007979s\n",
      "batch 8426, train_loss 0.003519,Time used 0.008976s\n",
      "batch 8427, train_loss 0.002775,Time used 0.010970s\n",
      "batch 8428, train_loss 0.005216,Time used 0.007977s\n",
      "batch 8429, train_loss 0.005191,Time used 0.007979s\n",
      "batch 8430, train_loss 0.002973,Time used 0.008976s\n",
      "batch 8431, train_loss 0.004388,Time used 0.008977s\n",
      "batch 8432, train_loss 0.004027,Time used 0.008976s\n",
      "batch 8433, train_loss 0.003547,Time used 0.008976s\n",
      "batch 8434, train_loss 0.002282,Time used 0.007979s\n",
      "batch 8435, train_loss 0.002861,Time used 0.007978s\n",
      "batch 8436, train_loss 0.002760,Time used 0.008976s\n",
      "batch 8437, train_loss 0.003226,Time used 0.008977s\n",
      "batch 8438, train_loss 0.003274,Time used 0.008976s\n",
      "batch 8439, train_loss 0.005417,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 8440, train_loss 0.003703,Time used 0.008976s\n",
      "batch 8441, train_loss 0.004216,Time used 0.009974s\n",
      "batch 8442, train_loss 0.004911,Time used 0.008975s\n",
      "batch 8443, train_loss 0.003076,Time used 0.008976s\n",
      "batch 8444, train_loss 0.004761,Time used 0.008977s\n",
      "batch 8445, train_loss 0.002957,Time used 0.008976s\n",
      "batch 8446, train_loss 0.005862,Time used 0.008976s\n",
      "batch 8447, train_loss 0.003762,Time used 0.007979s\n",
      "batch 8448, train_loss 0.003411,Time used 0.007978s\n",
      "batch 8449, train_loss 0.002359,Time used 0.007979s\n",
      "batch 8450, train_loss 0.003903,Time used 0.008976s\n",
      "batch 8451, train_loss 0.003431,Time used 0.007979s\n",
      "batch 8452, train_loss 0.005736,Time used 0.007978s\n",
      "batch 8453, train_loss 0.004052,Time used 0.006980s\n",
      "batch 8454, train_loss 0.002962,Time used 0.007979s\n",
      "batch 8455, train_loss 0.003157,Time used 0.007978s\n",
      "batch 8456, train_loss 0.003646,Time used 0.008976s\n",
      "batch 8457, train_loss 0.004355,Time used 0.008976s\n",
      "batch 8458, train_loss 0.003614,Time used 0.008976s\n",
      "batch 8459, train_loss 0.003105,Time used 0.008977s\n",
      "batch 8460, train_loss 0.005634,Time used 0.007978s\n",
      "batch 8461, train_loss 0.003028,Time used 0.008976s\n",
      "batch 8462, train_loss 0.002684,Time used 0.008977s\n",
      "batch 8463, train_loss 0.003232,Time used 0.008976s\n",
      "batch 8464, train_loss 0.002676,Time used 0.008976s\n",
      "batch 8465, train_loss 0.002934,Time used 0.008976s\n",
      "batch 8466, train_loss 0.002970,Time used 0.008976s\n",
      "batch 8467, train_loss 0.003130,Time used 0.008976s\n",
      "batch 8468, train_loss 0.002709,Time used 0.008976s\n",
      "batch 8469, train_loss 0.003933,Time used 0.007978s\n",
      "batch 8470, train_loss 0.004379,Time used 0.007979s\n",
      "batch 8471, train_loss 0.003540,Time used 0.007978s\n",
      "batch 8472, train_loss 0.003312,Time used 0.007979s\n",
      "batch 8473, train_loss 0.003978,Time used 0.009973s\n",
      "batch 8474, train_loss 0.003571,Time used 0.008976s\n",
      "batch 8475, train_loss 0.003634,Time used 0.008976s\n",
      "batch 8476, train_loss 0.004329,Time used 0.008976s\n",
      "batch 8477, train_loss 0.004007,Time used 0.007978s\n",
      "batch 8478, train_loss 0.003493,Time used 0.007980s\n",
      "batch 8479, train_loss 0.003013,Time used 0.008976s\n",
      "batch 8480, train_loss 0.005301,Time used 0.008976s\n",
      "batch 8481, train_loss 0.004007,Time used 0.008975s\n",
      "batch 8482, train_loss 0.004178,Time used 0.008975s\n",
      "batch 8483, train_loss 0.003225,Time used 0.008976s\n",
      "batch 8484, train_loss 0.002904,Time used 0.008976s\n",
      "batch 8485, train_loss 0.004437,Time used 0.008976s\n",
      "batch 8486, train_loss 0.003027,Time used 0.008977s\n",
      "batch 8487, train_loss 0.004025,Time used 0.008976s\n",
      "batch 8488, train_loss 0.005863,Time used 0.008976s\n",
      "batch 8489, train_loss 0.003220,Time used 0.008975s\n",
      "batch 8490, train_loss 0.002831,Time used 0.008976s\n",
      "batch 8491, train_loss 0.003993,Time used 0.008976s\n",
      "batch 8492, train_loss 0.004060,Time used 0.008976s\n",
      "batch 8493, train_loss 0.003847,Time used 0.008977s\n",
      "batch 8494, train_loss 0.004486,Time used 0.008976s\n",
      "batch 8495, train_loss 0.003531,Time used 0.008976s\n",
      "batch 8496, train_loss 0.002848,Time used 0.008977s\n",
      "batch 8497, train_loss 0.002610,Time used 0.007978s\n",
      "batch 8498, train_loss 0.002790,Time used 0.008976s\n",
      "batch 8499, train_loss 0.003483,Time used 0.008976s\n",
      "batch 8500, train_loss 0.003718,Time used 0.007978s\n",
      "***************************test_batch 8500, test_rmse_loss 0.061061,test_mae_loss 0.043594,test_mape_loss 13.214673,Time used 0.120698s\n",
      "batch 8501, train_loss 0.004089,Time used 0.009974s\n",
      "batch 8502, train_loss 0.003299,Time used 0.008976s\n",
      "batch 8503, train_loss 0.002928,Time used 0.009974s\n",
      "batch 8504, train_loss 0.003270,Time used 0.009973s\n",
      "batch 8505, train_loss 0.003734,Time used 0.008976s\n",
      "batch 8506, train_loss 0.003553,Time used 0.009974s\n",
      "batch 8507, train_loss 0.002939,Time used 0.008976s\n",
      "batch 8508, train_loss 0.003573,Time used 0.008976s\n",
      "batch 8509, train_loss 0.004014,Time used 0.009974s\n",
      "batch 8510, train_loss 0.004292,Time used 0.008975s\n",
      "batch 8511, train_loss 0.004390,Time used 0.008975s\n",
      "batch 8512, train_loss 0.003126,Time used 0.008977s\n",
      "batch 8513, train_loss 0.004683,Time used 0.008975s\n",
      "batch 8514, train_loss 0.003366,Time used 0.008975s\n",
      "batch 8515, train_loss 0.005353,Time used 0.008976s\n",
      "batch 8516, train_loss 0.003279,Time used 0.007979s\n",
      "batch 8517, train_loss 0.003692,Time used 0.010971s\n",
      "batch 8518, train_loss 0.002609,Time used 0.009973s\n",
      "batch 8519, train_loss 0.003990,Time used 0.008976s\n",
      "batch 8520, train_loss 0.003657,Time used 0.008975s\n",
      "batch 8521, train_loss 0.002798,Time used 0.008976s\n",
      "batch 8522, train_loss 0.004736,Time used 0.008994s\n",
      "batch 8523, train_loss 0.003769,Time used 0.007979s\n",
      "batch 8524, train_loss 0.002937,Time used 0.007979s\n",
      "batch 8525, train_loss 0.003560,Time used 0.008976s\n",
      "batch 8526, train_loss 0.004361,Time used 0.007979s\n",
      "batch 8527, train_loss 0.003326,Time used 0.007979s\n",
      "batch 8528, train_loss 0.003278,Time used 0.015957s\n",
      "batch 8529, train_loss 0.003617,Time used 0.008976s\n",
      "batch 8530, train_loss 0.004425,Time used 0.008975s\n",
      "batch 8531, train_loss 0.003345,Time used 0.007979s\n",
      "batch 8532, train_loss 0.003702,Time used 0.007978s\n",
      "batch 8533, train_loss 0.004139,Time used 0.007978s\n",
      "batch 8534, train_loss 0.003838,Time used 0.008977s\n",
      "batch 8535, train_loss 0.004313,Time used 0.009974s\n",
      "batch 8536, train_loss 0.004040,Time used 0.009973s\n",
      "batch 8537, train_loss 0.004557,Time used 0.008976s\n",
      "batch 8538, train_loss 0.003515,Time used 0.008976s\n",
      "batch 8539, train_loss 0.003130,Time used 0.009973s\n",
      "batch 8540, train_loss 0.003148,Time used 0.008976s\n",
      "batch 8541, train_loss 0.003406,Time used 0.008976s\n",
      "batch 8542, train_loss 0.003377,Time used 0.008976s\n",
      "batch 8543, train_loss 0.004217,Time used 0.007979s\n",
      "batch 8544, train_loss 0.002938,Time used 0.008975s\n",
      "batch 8545, train_loss 0.002516,Time used 0.008976s\n",
      "batch 8546, train_loss 0.002678,Time used 0.007978s\n",
      "batch 8547, train_loss 0.004320,Time used 0.007979s\n",
      "batch 8548, train_loss 0.003372,Time used 0.008976s\n",
      "batch 8549, train_loss 0.002987,Time used 0.008976s\n",
      "batch 8550, train_loss 0.003229,Time used 0.008976s\n",
      "batch 8551, train_loss 0.003944,Time used 0.009974s\n",
      "batch 8552, train_loss 0.004261,Time used 0.008975s\n",
      "batch 8553, train_loss 0.003467,Time used 0.007979s\n",
      "batch 8554, train_loss 0.003205,Time used 0.007978s\n",
      "batch 8555, train_loss 0.003925,Time used 0.007978s\n",
      "batch 8556, train_loss 0.003466,Time used 0.007977s\n",
      "batch 8557, train_loss 0.004471,Time used 0.007979s\n",
      "batch 8558, train_loss 0.004350,Time used 0.007979s\n",
      "batch 8559, train_loss 0.003136,Time used 0.007978s\n",
      "batch 8560, train_loss 0.004292,Time used 0.007978s\n",
      "batch 8561, train_loss 0.003811,Time used 0.008976s\n",
      "batch 8562, train_loss 0.003657,Time used 0.008977s\n",
      "batch 8563, train_loss 0.003950,Time used 0.007978s\n",
      "batch 8564, train_loss 0.003448,Time used 0.007978s\n",
      "batch 8565, train_loss 0.003846,Time used 0.007978s\n",
      "batch 8566, train_loss 0.005377,Time used 0.007979s\n",
      "batch 8567, train_loss 0.004249,Time used 0.008976s\n",
      "batch 8568, train_loss 0.002429,Time used 0.009974s\n",
      "batch 8569, train_loss 0.004234,Time used 0.008975s\n",
      "batch 8570, train_loss 0.003012,Time used 0.008977s\n",
      "batch 8571, train_loss 0.002560,Time used 0.008975s\n",
      "batch 8572, train_loss 0.004225,Time used 0.008977s\n",
      "batch 8573, train_loss 0.003842,Time used 0.008976s\n",
      "batch 8574, train_loss 0.003440,Time used 0.009973s\n",
      "batch 8575, train_loss 0.003692,Time used 0.008487s\n",
      "batch 8576, train_loss 0.003789,Time used 0.008977s\n",
      "batch 8577, train_loss 0.004208,Time used 0.008976s\n",
      "batch 8578, train_loss 0.002942,Time used 0.008975s\n",
      "batch 8579, train_loss 0.003885,Time used 0.008976s\n",
      "batch 8580, train_loss 0.003982,Time used 0.008977s\n",
      "batch 8581, train_loss 0.004449,Time used 0.007978s\n",
      "batch 8582, train_loss 0.004401,Time used 0.008976s\n",
      "batch 8583, train_loss 0.002620,Time used 0.008976s\n",
      "batch 8584, train_loss 0.002652,Time used 0.008975s\n",
      "batch 8585, train_loss 0.004306,Time used 0.008976s\n",
      "batch 8586, train_loss 0.004035,Time used 0.008976s\n",
      "batch 8587, train_loss 0.003658,Time used 0.008976s\n",
      "batch 8588, train_loss 0.003106,Time used 0.008976s\n",
      "batch 8589, train_loss 0.003802,Time used 0.008976s\n",
      "batch 8590, train_loss 0.002023,Time used 0.008976s\n",
      "batch 8591, train_loss 0.003806,Time used 0.009973s\n",
      "batch 8592, train_loss 0.003854,Time used 0.008977s\n",
      "batch 8593, train_loss 0.003578,Time used 0.008975s\n",
      "batch 8594, train_loss 0.004397,Time used 0.008976s\n",
      "batch 8595, train_loss 0.003025,Time used 0.007978s\n",
      "batch 8596, train_loss 0.005536,Time used 0.008976s\n",
      "batch 8597, train_loss 0.003285,Time used 0.010010s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 8598, train_loss 0.002632,Time used 0.008977s\n",
      "batch 8599, train_loss 0.003661,Time used 0.009974s\n",
      "batch 8600, train_loss 0.002299,Time used 0.008976s\n",
      "***************************test_batch 8600, test_rmse_loss 0.060800,test_mae_loss 0.043318,test_mape_loss 12.821532,Time used 0.117707s\n",
      "batch 8601, train_loss 0.004234,Time used 0.008977s\n",
      "batch 8602, train_loss 0.003274,Time used 0.009973s\n",
      "batch 8603, train_loss 0.003985,Time used 0.008977s\n",
      "batch 8604, train_loss 0.002766,Time used 0.008975s\n",
      "batch 8605, train_loss 0.003144,Time used 0.008976s\n",
      "batch 8606, train_loss 0.004791,Time used 0.009974s\n",
      "batch 8607, train_loss 0.002466,Time used 0.008976s\n",
      "batch 8608, train_loss 0.003789,Time used 0.008977s\n",
      "batch 8609, train_loss 0.003601,Time used 0.008975s\n",
      "batch 8610, train_loss 0.004367,Time used 0.008976s\n",
      "batch 8611, train_loss 0.003317,Time used 0.008977s\n",
      "batch 8612, train_loss 0.003013,Time used 0.007979s\n",
      "batch 8613, train_loss 0.002897,Time used 0.008976s\n",
      "batch 8614, train_loss 0.003457,Time used 0.007978s\n",
      "batch 8615, train_loss 0.001797,Time used 0.008976s\n",
      "batch 8616, train_loss 0.003948,Time used 0.008976s\n",
      "batch 8617, train_loss 0.003758,Time used 0.008976s\n",
      "batch 8618, train_loss 0.003829,Time used 0.008976s\n",
      "batch 8619, train_loss 0.003668,Time used 0.008976s\n",
      "batch 8620, train_loss 0.005144,Time used 0.009534s\n",
      "batch 8621, train_loss 0.005295,Time used 0.008976s\n",
      "batch 8622, train_loss 0.003377,Time used 0.008976s\n",
      "batch 8623, train_loss 0.003246,Time used 0.009974s\n",
      "batch 8624, train_loss 0.004772,Time used 0.009973s\n",
      "batch 8625, train_loss 0.003730,Time used 0.009974s\n",
      "batch 8626, train_loss 0.003067,Time used 0.008976s\n",
      "batch 8627, train_loss 0.004068,Time used 0.008976s\n",
      "batch 8628, train_loss 0.003407,Time used 0.008976s\n",
      "batch 8629, train_loss 0.004016,Time used 0.008977s\n",
      "batch 8630, train_loss 0.003172,Time used 0.009974s\n",
      "batch 8631, train_loss 0.002874,Time used 0.008975s\n",
      "batch 8632, train_loss 0.003693,Time used 0.008976s\n",
      "batch 8633, train_loss 0.003507,Time used 0.008975s\n",
      "batch 8634, train_loss 0.003328,Time used 0.009973s\n",
      "batch 8635, train_loss 0.002907,Time used 0.009974s\n",
      "batch 8636, train_loss 0.003542,Time used 0.009973s\n",
      "batch 8637, train_loss 0.002673,Time used 0.008976s\n",
      "batch 8638, train_loss 0.002099,Time used 0.008976s\n",
      "batch 8639, train_loss 0.002838,Time used 0.008976s\n",
      "batch 8640, train_loss 0.003984,Time used 0.007979s\n",
      "batch 8641, train_loss 0.005214,Time used 0.008976s\n",
      "batch 8642, train_loss 0.003961,Time used 0.007979s\n",
      "batch 8643, train_loss 0.007032,Time used 0.008975s\n",
      "batch 8644, train_loss 0.003396,Time used 0.008977s\n",
      "batch 8645, train_loss 0.003402,Time used 0.008976s\n",
      "batch 8646, train_loss 0.003950,Time used 0.009974s\n",
      "batch 8647, train_loss 0.002312,Time used 0.008976s\n",
      "batch 8648, train_loss 0.003790,Time used 0.009973s\n",
      "batch 8649, train_loss 0.002845,Time used 0.008976s\n",
      "batch 8650, train_loss 0.002679,Time used 0.008976s\n",
      "batch 8651, train_loss 0.005037,Time used 0.008976s\n",
      "batch 8652, train_loss 0.003993,Time used 0.008975s\n",
      "batch 8653, train_loss 0.003667,Time used 0.008976s\n",
      "batch 8654, train_loss 0.003171,Time used 0.008000s\n",
      "batch 8655, train_loss 0.004238,Time used 0.007979s\n",
      "batch 8656, train_loss 0.002417,Time used 0.007979s\n",
      "batch 8657, train_loss 0.003313,Time used 0.007979s\n",
      "batch 8658, train_loss 0.004281,Time used 0.007978s\n",
      "batch 8659, train_loss 0.003677,Time used 0.008976s\n",
      "batch 8660, train_loss 0.003569,Time used 0.008976s\n",
      "batch 8661, train_loss 0.003941,Time used 0.008976s\n",
      "batch 8662, train_loss 0.003710,Time used 0.009974s\n",
      "batch 8663, train_loss 0.003498,Time used 0.007978s\n",
      "batch 8664, train_loss 0.003513,Time used 0.007979s\n",
      "batch 8665, train_loss 0.004223,Time used 0.007979s\n",
      "batch 8666, train_loss 0.004358,Time used 0.009973s\n",
      "batch 8667, train_loss 0.002073,Time used 0.006981s\n",
      "batch 8668, train_loss 0.003091,Time used 0.008977s\n",
      "batch 8669, train_loss 0.004555,Time used 0.008975s\n",
      "batch 8670, train_loss 0.003798,Time used 0.007979s\n",
      "batch 8671, train_loss 0.003760,Time used 0.007979s\n",
      "batch 8672, train_loss 0.002617,Time used 0.007979s\n",
      "batch 8673, train_loss 0.005704,Time used 0.008976s\n",
      "batch 8674, train_loss 0.002909,Time used 0.007979s\n",
      "batch 8675, train_loss 0.004976,Time used 0.008976s\n",
      "batch 8676, train_loss 0.003299,Time used 0.009974s\n",
      "batch 8677, train_loss 0.003385,Time used 0.009973s\n",
      "batch 8678, train_loss 0.004113,Time used 0.008976s\n",
      "batch 8679, train_loss 0.003182,Time used 0.008976s\n",
      "batch 8680, train_loss 0.006105,Time used 0.009555s\n",
      "batch 8681, train_loss 0.003366,Time used 0.008487s\n",
      "batch 8682, train_loss 0.002968,Time used 0.008976s\n",
      "batch 8683, train_loss 0.003194,Time used 0.007977s\n",
      "batch 8684, train_loss 0.003866,Time used 0.007979s\n",
      "batch 8685, train_loss 0.002436,Time used 0.007978s\n",
      "batch 8686, train_loss 0.004071,Time used 0.008976s\n",
      "batch 8687, train_loss 0.003784,Time used 0.008976s\n",
      "batch 8688, train_loss 0.004026,Time used 0.008977s\n",
      "batch 8689, train_loss 0.003672,Time used 0.009973s\n",
      "batch 8690, train_loss 0.003629,Time used 0.007979s\n",
      "batch 8691, train_loss 0.002714,Time used 0.008976s\n",
      "batch 8692, train_loss 0.003475,Time used 0.008976s\n",
      "batch 8693, train_loss 0.003650,Time used 0.008976s\n",
      "batch 8694, train_loss 0.003496,Time used 0.008976s\n",
      "batch 8695, train_loss 0.003372,Time used 0.007979s\n",
      "batch 8696, train_loss 0.004472,Time used 0.008976s\n",
      "batch 8697, train_loss 0.003228,Time used 0.007979s\n",
      "batch 8698, train_loss 0.005696,Time used 0.008976s\n",
      "batch 8699, train_loss 0.003389,Time used 0.008976s\n",
      "batch 8700, train_loss 0.003393,Time used 0.008976s\n",
      "***************************test_batch 8700, test_rmse_loss 0.060773,test_mae_loss 0.043290,test_mape_loss 12.869264,Time used 0.112700s\n",
      "batch 8701, train_loss 0.003626,Time used 0.007979s\n",
      "batch 8702, train_loss 0.003708,Time used 0.007978s\n",
      "batch 8703, train_loss 0.003436,Time used 0.008976s\n",
      "batch 8704, train_loss 0.003871,Time used 0.007979s\n",
      "batch 8705, train_loss 0.003985,Time used 0.007978s\n",
      "batch 8706, train_loss 0.002977,Time used 0.008976s\n",
      "batch 8707, train_loss 0.003435,Time used 0.008977s\n",
      "batch 8708, train_loss 0.004654,Time used 0.008545s\n",
      "batch 8709, train_loss 0.003116,Time used 0.007488s\n",
      "batch 8710, train_loss 0.004827,Time used 0.007979s\n",
      "batch 8711, train_loss 0.004462,Time used 0.007978s\n",
      "batch 8712, train_loss 0.003775,Time used 0.007978s\n",
      "batch 8713, train_loss 0.003142,Time used 0.007978s\n",
      "batch 8714, train_loss 0.003253,Time used 0.007979s\n",
      "batch 8715, train_loss 0.003784,Time used 0.007978s\n",
      "batch 8716, train_loss 0.003628,Time used 0.007979s\n",
      "batch 8717, train_loss 0.003055,Time used 0.007979s\n",
      "batch 8718, train_loss 0.003223,Time used 0.007978s\n",
      "batch 8719, train_loss 0.005544,Time used 0.007978s\n",
      "batch 8720, train_loss 0.002505,Time used 0.007978s\n",
      "batch 8721, train_loss 0.003529,Time used 0.007979s\n",
      "batch 8722, train_loss 0.004287,Time used 0.007978s\n",
      "batch 8723, train_loss 0.003330,Time used 0.008976s\n",
      "batch 8724, train_loss 0.002917,Time used 0.007979s\n",
      "batch 8725, train_loss 0.003169,Time used 0.007979s\n",
      "batch 8726, train_loss 0.004127,Time used 0.007979s\n",
      "batch 8727, train_loss 0.004766,Time used 0.007978s\n",
      "batch 8728, train_loss 0.003940,Time used 0.007978s\n",
      "batch 8729, train_loss 0.003967,Time used 0.008976s\n",
      "batch 8730, train_loss 0.002853,Time used 0.008975s\n",
      "batch 8731, train_loss 0.003137,Time used 0.008977s\n",
      "batch 8732, train_loss 0.003889,Time used 0.009003s\n",
      "batch 8733, train_loss 0.003464,Time used 0.008976s\n",
      "batch 8734, train_loss 0.003284,Time used 0.008976s\n",
      "batch 8735, train_loss 0.003879,Time used 0.008976s\n",
      "batch 8736, train_loss 0.003425,Time used 0.007979s\n",
      "batch 8737, train_loss 0.002231,Time used 0.008976s\n",
      "batch 8738, train_loss 0.003384,Time used 0.008976s\n",
      "batch 8739, train_loss 0.003141,Time used 0.008975s\n",
      "batch 8740, train_loss 0.003337,Time used 0.008976s\n",
      "batch 8741, train_loss 0.003950,Time used 0.008976s\n",
      "batch 8742, train_loss 0.005027,Time used 0.008975s\n",
      "batch 8743, train_loss 0.003481,Time used 0.009973s\n",
      "batch 8744, train_loss 0.002628,Time used 0.008976s\n",
      "batch 8745, train_loss 0.002481,Time used 0.008975s\n",
      "batch 8746, train_loss 0.005475,Time used 0.009483s\n",
      "batch 8747, train_loss 0.003112,Time used 0.008487s\n",
      "batch 8748, train_loss 0.003692,Time used 0.007979s\n",
      "batch 8749, train_loss 0.002601,Time used 0.008977s\n",
      "batch 8750, train_loss 0.004149,Time used 0.008976s\n",
      "batch 8751, train_loss 0.004174,Time used 0.007979s\n",
      "batch 8752, train_loss 0.003624,Time used 0.008976s\n",
      "batch 8753, train_loss 0.002685,Time used 0.008975s\n",
      "batch 8754, train_loss 0.002808,Time used 0.009974s\n",
      "batch 8755, train_loss 0.003821,Time used 0.008976s\n",
      "batch 8756, train_loss 0.003166,Time used 0.008976s\n",
      "batch 8757, train_loss 0.003752,Time used 0.008975s\n",
      "batch 8758, train_loss 0.003863,Time used 0.008976s\n",
      "batch 8759, train_loss 0.003003,Time used 0.009973s\n",
      "batch 8760, train_loss 0.003695,Time used 0.007979s\n",
      "batch 8761, train_loss 0.003770,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 8762, train_loss 0.004204,Time used 0.007978s\n",
      "batch 8763, train_loss 0.003533,Time used 0.009973s\n",
      "batch 8764, train_loss 0.003541,Time used 0.008976s\n",
      "batch 8765, train_loss 0.002530,Time used 0.007979s\n",
      "batch 8766, train_loss 0.003283,Time used 0.008977s\n",
      "batch 8767, train_loss 0.004169,Time used 0.007979s\n",
      "batch 8768, train_loss 0.003897,Time used 0.008976s\n",
      "batch 8769, train_loss 0.003369,Time used 0.009974s\n",
      "batch 8770, train_loss 0.002648,Time used 0.008976s\n",
      "batch 8771, train_loss 0.004437,Time used 0.008976s\n",
      "batch 8772, train_loss 0.004314,Time used 0.008977s\n",
      "batch 8773, train_loss 0.002976,Time used 0.008976s\n",
      "batch 8774, train_loss 0.003206,Time used 0.006982s\n",
      "batch 8775, train_loss 0.003795,Time used 0.008976s\n",
      "batch 8776, train_loss 0.003695,Time used 0.008976s\n",
      "batch 8777, train_loss 0.004077,Time used 0.007978s\n",
      "batch 8778, train_loss 0.003648,Time used 0.007979s\n",
      "batch 8779, train_loss 0.002799,Time used 0.008977s\n",
      "batch 8780, train_loss 0.004561,Time used 0.008976s\n",
      "batch 8781, train_loss 0.002095,Time used 0.007978s\n",
      "batch 8782, train_loss 0.004359,Time used 0.008976s\n",
      "batch 8783, train_loss 0.003029,Time used 0.007979s\n",
      "batch 8784, train_loss 0.003597,Time used 0.007979s\n",
      "batch 8785, train_loss 0.004518,Time used 0.007979s\n",
      "batch 8786, train_loss 0.003799,Time used 0.008975s\n",
      "batch 8787, train_loss 0.004771,Time used 0.007979s\n",
      "batch 8788, train_loss 0.004721,Time used 0.007978s\n",
      "batch 8789, train_loss 0.003279,Time used 0.008976s\n",
      "batch 8790, train_loss 0.004281,Time used 0.008977s\n",
      "batch 8791, train_loss 0.002780,Time used 0.007978s\n",
      "batch 8792, train_loss 0.003902,Time used 0.007979s\n",
      "batch 8793, train_loss 0.002935,Time used 0.007978s\n",
      "batch 8794, train_loss 0.004661,Time used 0.008976s\n",
      "batch 8795, train_loss 0.004158,Time used 0.008976s\n",
      "batch 8796, train_loss 0.003610,Time used 0.007978s\n",
      "batch 8797, train_loss 0.004203,Time used 0.007978s\n",
      "batch 8798, train_loss 0.003406,Time used 0.007978s\n",
      "batch 8799, train_loss 0.004469,Time used 0.007979s\n",
      "batch 8800, train_loss 0.002368,Time used 0.007979s\n",
      "***************************test_batch 8800, test_rmse_loss 0.061062,test_mae_loss 0.043529,test_mape_loss 12.759689,Time used 0.112699s\n",
      "batch 8801, train_loss 0.004657,Time used 0.007977s\n",
      "batch 8802, train_loss 0.005974,Time used 0.007979s\n",
      "batch 8803, train_loss 0.003524,Time used 0.008976s\n",
      "batch 8804, train_loss 0.003996,Time used 0.009973s\n",
      "batch 8805, train_loss 0.003196,Time used 0.007979s\n",
      "batch 8806, train_loss 0.005506,Time used 0.007979s\n",
      "batch 8807, train_loss 0.003315,Time used 0.007978s\n",
      "batch 8808, train_loss 0.005011,Time used 0.007979s\n",
      "batch 8809, train_loss 0.003847,Time used 0.007978s\n",
      "batch 8810, train_loss 0.003182,Time used 0.007978s\n",
      "batch 8811, train_loss 0.002220,Time used 0.008976s\n",
      "batch 8812, train_loss 0.002514,Time used 0.007979s\n",
      "batch 8813, train_loss 0.003109,Time used 0.008976s\n",
      "batch 8814, train_loss 0.002801,Time used 0.008975s\n",
      "batch 8815, train_loss 0.003323,Time used 0.007978s\n",
      "batch 8816, train_loss 0.003534,Time used 0.008977s\n",
      "batch 8817, train_loss 0.004146,Time used 0.008975s\n",
      "batch 8818, train_loss 0.003714,Time used 0.008976s\n",
      "batch 8819, train_loss 0.003920,Time used 0.008976s\n",
      "batch 8820, train_loss 0.002683,Time used 0.008976s\n",
      "batch 8821, train_loss 0.003672,Time used 0.008976s\n",
      "batch 8822, train_loss 0.003136,Time used 0.008976s\n",
      "batch 8823, train_loss 0.004301,Time used 0.008977s\n",
      "batch 8824, train_loss 0.003853,Time used 0.007979s\n",
      "batch 8825, train_loss 0.002972,Time used 0.008976s\n",
      "batch 8826, train_loss 0.002858,Time used 0.007979s\n",
      "batch 8827, train_loss 0.003408,Time used 0.008976s\n",
      "batch 8828, train_loss 0.003856,Time used 0.007979s\n",
      "batch 8829, train_loss 0.003916,Time used 0.007979s\n",
      "batch 8830, train_loss 0.003678,Time used 0.008975s\n",
      "batch 8831, train_loss 0.002289,Time used 0.008975s\n",
      "batch 8832, train_loss 0.003587,Time used 0.008976s\n",
      "batch 8833, train_loss 0.004431,Time used 0.008975s\n",
      "batch 8834, train_loss 0.003927,Time used 0.008977s\n",
      "batch 8835, train_loss 0.002385,Time used 0.007978s\n",
      "batch 8836, train_loss 0.003286,Time used 0.007979s\n",
      "batch 8837, train_loss 0.002556,Time used 0.008976s\n",
      "batch 8838, train_loss 0.003985,Time used 0.008977s\n",
      "batch 8839, train_loss 0.004087,Time used 0.007978s\n",
      "batch 8840, train_loss 0.003411,Time used 0.008976s\n",
      "batch 8841, train_loss 0.003155,Time used 0.008976s\n",
      "batch 8842, train_loss 0.003147,Time used 0.008975s\n",
      "batch 8843, train_loss 0.003603,Time used 0.008977s\n",
      "batch 8844, train_loss 0.003330,Time used 0.008976s\n",
      "batch 8845, train_loss 0.003532,Time used 0.008976s\n",
      "batch 8846, train_loss 0.003436,Time used 0.008977s\n",
      "batch 8847, train_loss 0.003753,Time used 0.008977s\n",
      "batch 8848, train_loss 0.002535,Time used 0.009973s\n",
      "batch 8849, train_loss 0.002462,Time used 0.009973s\n",
      "batch 8850, train_loss 0.004380,Time used 0.008977s\n",
      "batch 8851, train_loss 0.003859,Time used 0.008977s\n",
      "batch 8852, train_loss 0.003798,Time used 0.009973s\n",
      "batch 8853, train_loss 0.002896,Time used 0.009975s\n",
      "batch 8854, train_loss 0.002762,Time used 0.008976s\n",
      "batch 8855, train_loss 0.003468,Time used 0.009974s\n",
      "batch 8856, train_loss 0.004694,Time used 0.009974s\n",
      "batch 8857, train_loss 0.002515,Time used 0.008976s\n",
      "batch 8858, train_loss 0.004030,Time used 0.008976s\n",
      "batch 8859, train_loss 0.002954,Time used 0.008976s\n",
      "batch 8860, train_loss 0.003094,Time used 0.008976s\n",
      "batch 8861, train_loss 0.005474,Time used 0.009973s\n",
      "batch 8862, train_loss 0.003519,Time used 0.008976s\n",
      "batch 8863, train_loss 0.003119,Time used 0.008976s\n",
      "batch 8864, train_loss 0.004068,Time used 0.008976s\n",
      "batch 8865, train_loss 0.003469,Time used 0.008976s\n",
      "batch 8866, train_loss 0.005355,Time used 0.007979s\n",
      "batch 8867, train_loss 0.003161,Time used 0.008976s\n",
      "batch 8868, train_loss 0.002913,Time used 0.008976s\n",
      "batch 8869, train_loss 0.002603,Time used 0.007979s\n",
      "batch 8870, train_loss 0.003000,Time used 0.007978s\n",
      "batch 8871, train_loss 0.004316,Time used 0.008976s\n",
      "batch 8872, train_loss 0.004432,Time used 0.008976s\n",
      "batch 8873, train_loss 0.003654,Time used 0.009974s\n",
      "batch 8874, train_loss 0.004447,Time used 0.008976s\n",
      "batch 8875, train_loss 0.004373,Time used 0.007978s\n",
      "batch 8876, train_loss 0.003464,Time used 0.008976s\n",
      "batch 8877, train_loss 0.003189,Time used 0.008976s\n",
      "batch 8878, train_loss 0.002522,Time used 0.008976s\n",
      "batch 8879, train_loss 0.003858,Time used 0.007979s\n",
      "batch 8880, train_loss 0.006169,Time used 0.007979s\n",
      "batch 8881, train_loss 0.002157,Time used 0.006981s\n",
      "batch 8882, train_loss 0.004194,Time used 0.007978s\n",
      "batch 8883, train_loss 0.003737,Time used 0.007978s\n",
      "batch 8884, train_loss 0.004103,Time used 0.007979s\n",
      "batch 8885, train_loss 0.002708,Time used 0.008976s\n",
      "batch 8886, train_loss 0.004159,Time used 0.007979s\n",
      "batch 8887, train_loss 0.003433,Time used 0.008975s\n",
      "batch 8888, train_loss 0.003144,Time used 0.008976s\n",
      "batch 8889, train_loss 0.003571,Time used 0.008976s\n",
      "batch 8890, train_loss 0.002800,Time used 0.007979s\n",
      "batch 8891, train_loss 0.003879,Time used 0.007979s\n",
      "batch 8892, train_loss 0.002427,Time used 0.007978s\n",
      "batch 8893, train_loss 0.003473,Time used 0.007979s\n",
      "batch 8894, train_loss 0.002828,Time used 0.007979s\n",
      "batch 8895, train_loss 0.003678,Time used 0.007978s\n",
      "batch 8896, train_loss 0.002585,Time used 0.008976s\n",
      "batch 8897, train_loss 0.003404,Time used 0.008977s\n",
      "batch 8898, train_loss 0.002685,Time used 0.008975s\n",
      "batch 8899, train_loss 0.004332,Time used 0.007978s\n",
      "batch 8900, train_loss 0.003820,Time used 0.008976s\n",
      "***************************test_batch 8900, test_rmse_loss 0.060996,test_mae_loss 0.043496,test_mape_loss 13.035945,Time used 0.110703s\n",
      "batch 8901, train_loss 0.002979,Time used 0.007978s\n",
      "batch 8902, train_loss 0.004584,Time used 0.007978s\n",
      "batch 8903, train_loss 0.002912,Time used 0.008977s\n",
      "batch 8904, train_loss 0.003589,Time used 0.007978s\n",
      "batch 8905, train_loss 0.003870,Time used 0.008976s\n",
      "batch 8906, train_loss 0.003736,Time used 0.007978s\n",
      "batch 8907, train_loss 0.002772,Time used 0.007978s\n",
      "batch 8908, train_loss 0.004033,Time used 0.008976s\n",
      "batch 8909, train_loss 0.004923,Time used 0.007978s\n",
      "batch 8910, train_loss 0.004919,Time used 0.008976s\n",
      "batch 8911, train_loss 0.003203,Time used 0.007978s\n",
      "batch 8912, train_loss 0.003523,Time used 0.007978s\n",
      "batch 8913, train_loss 0.003171,Time used 0.007979s\n",
      "batch 8914, train_loss 0.003909,Time used 0.007979s\n",
      "batch 8915, train_loss 0.003386,Time used 0.006981s\n",
      "batch 8916, train_loss 0.003492,Time used 0.007979s\n",
      "batch 8917, train_loss 0.003566,Time used 0.007979s\n",
      "batch 8918, train_loss 0.003367,Time used 0.007978s\n",
      "batch 8919, train_loss 0.002706,Time used 0.007979s\n",
      "batch 8920, train_loss 0.005494,Time used 0.007979s\n",
      "batch 8921, train_loss 0.003061,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 8922, train_loss 0.004379,Time used 0.007978s\n",
      "batch 8923, train_loss 0.003183,Time used 0.007979s\n",
      "batch 8924, train_loss 0.004111,Time used 0.007979s\n",
      "batch 8925, train_loss 0.003149,Time used 0.006981s\n",
      "batch 8926, train_loss 0.003605,Time used 0.006982s\n",
      "batch 8927, train_loss 0.004393,Time used 0.007978s\n",
      "batch 8928, train_loss 0.003355,Time used 0.007979s\n",
      "batch 8929, train_loss 0.003898,Time used 0.008975s\n",
      "batch 8930, train_loss 0.002831,Time used 0.009974s\n",
      "batch 8931, train_loss 0.003927,Time used 0.008975s\n",
      "batch 8932, train_loss 0.003086,Time used 0.008976s\n",
      "batch 8933, train_loss 0.003132,Time used 0.008976s\n",
      "batch 8934, train_loss 0.003996,Time used 0.008976s\n",
      "batch 8935, train_loss 0.006752,Time used 0.007979s\n",
      "batch 8936, train_loss 0.003572,Time used 0.007979s\n",
      "batch 8937, train_loss 0.003044,Time used 0.008976s\n",
      "batch 8938, train_loss 0.003834,Time used 0.008976s\n",
      "batch 8939, train_loss 0.003695,Time used 0.008976s\n",
      "batch 8940, train_loss 0.004576,Time used 0.008977s\n",
      "batch 8941, train_loss 0.002848,Time used 0.007979s\n",
      "batch 8942, train_loss 0.004782,Time used 0.008976s\n",
      "batch 8943, train_loss 0.003573,Time used 0.008975s\n",
      "batch 8944, train_loss 0.003698,Time used 0.008976s\n",
      "batch 8945, train_loss 0.003904,Time used 0.007979s\n",
      "batch 8946, train_loss 0.003352,Time used 0.007978s\n",
      "batch 8947, train_loss 0.002767,Time used 0.008976s\n",
      "batch 8948, train_loss 0.003449,Time used 0.008976s\n",
      "batch 8949, train_loss 0.004427,Time used 0.008976s\n",
      "batch 8950, train_loss 0.003396,Time used 0.008977s\n",
      "batch 8951, train_loss 0.003270,Time used 0.007979s\n",
      "batch 8952, train_loss 0.002533,Time used 0.007979s\n",
      "batch 8953, train_loss 0.004208,Time used 0.007979s\n",
      "batch 8954, train_loss 0.003502,Time used 0.008976s\n",
      "batch 8955, train_loss 0.003476,Time used 0.007978s\n",
      "batch 8956, train_loss 0.003345,Time used 0.008976s\n",
      "batch 8957, train_loss 0.003092,Time used 0.008977s\n",
      "batch 8958, train_loss 0.004179,Time used 0.007978s\n",
      "batch 8959, train_loss 0.003512,Time used 0.007979s\n",
      "batch 8960, train_loss 0.004188,Time used 0.008977s\n",
      "batch 8961, train_loss 0.003014,Time used 0.007979s\n",
      "batch 8962, train_loss 0.004005,Time used 0.007979s\n",
      "batch 8963, train_loss 0.004052,Time used 0.007977s\n",
      "batch 8964, train_loss 0.003712,Time used 0.007979s\n",
      "batch 8965, train_loss 0.005295,Time used 0.009974s\n",
      "batch 8966, train_loss 0.004575,Time used 0.008975s\n",
      "batch 8967, train_loss 0.004178,Time used 0.007978s\n",
      "batch 8968, train_loss 0.003713,Time used 0.008976s\n",
      "batch 8969, train_loss 0.004473,Time used 0.007979s\n",
      "batch 8970, train_loss 0.003396,Time used 0.007979s\n",
      "batch 8971, train_loss 0.002657,Time used 0.007979s\n",
      "batch 8972, train_loss 0.004255,Time used 0.007979s\n",
      "batch 8973, train_loss 0.003503,Time used 0.007979s\n",
      "batch 8974, train_loss 0.003373,Time used 0.007979s\n",
      "batch 8975, train_loss 0.003230,Time used 0.007979s\n",
      "batch 8976, train_loss 0.003050,Time used 0.008976s\n",
      "batch 8977, train_loss 0.003575,Time used 0.007978s\n",
      "batch 8978, train_loss 0.003920,Time used 0.007978s\n",
      "batch 8979, train_loss 0.003712,Time used 0.007979s\n",
      "batch 8980, train_loss 0.006336,Time used 0.007978s\n",
      "batch 8981, train_loss 0.005116,Time used 0.007979s\n",
      "batch 8982, train_loss 0.002641,Time used 0.007978s\n",
      "batch 8983, train_loss 0.004277,Time used 0.008976s\n",
      "batch 8984, train_loss 0.003622,Time used 0.008976s\n",
      "batch 8985, train_loss 0.003355,Time used 0.007979s\n",
      "batch 8986, train_loss 0.003700,Time used 0.008976s\n",
      "batch 8987, train_loss 0.003087,Time used 0.008976s\n",
      "batch 8988, train_loss 0.000814,Time used 0.006981s\n",
      "batch 8989, train_loss 0.003641,Time used 0.007979s\n",
      "batch 8990, train_loss 0.003724,Time used 0.007978s\n",
      "batch 8991, train_loss 0.002924,Time used 0.009973s\n",
      "batch 8992, train_loss 0.004816,Time used 0.008976s\n",
      "batch 8993, train_loss 0.003974,Time used 0.007978s\n",
      "batch 8994, train_loss 0.002491,Time used 0.007979s\n",
      "batch 8995, train_loss 0.003874,Time used 0.007979s\n",
      "batch 8996, train_loss 0.002582,Time used 0.008976s\n",
      "batch 8997, train_loss 0.004250,Time used 0.007979s\n",
      "batch 8998, train_loss 0.003348,Time used 0.007978s\n",
      "batch 8999, train_loss 0.003023,Time used 0.007980s\n",
      "batch 9000, train_loss 0.002974,Time used 0.007978s\n",
      "***************************test_batch 9000, test_rmse_loss 0.061012,test_mae_loss 0.043500,test_mape_loss 12.796122,Time used 0.128658s\n",
      "batch 9001, train_loss 0.003369,Time used 0.010969s\n",
      "batch 9002, train_loss 0.003665,Time used 0.018949s\n",
      "batch 9003, train_loss 0.003708,Time used 0.009974s\n",
      "batch 9004, train_loss 0.005488,Time used 0.009978s\n",
      "batch 9005, train_loss 0.003834,Time used 0.007979s\n",
      "batch 9006, train_loss 0.002386,Time used 0.007978s\n",
      "batch 9007, train_loss 0.003122,Time used 0.007979s\n",
      "batch 9008, train_loss 0.003186,Time used 0.009973s\n",
      "batch 9009, train_loss 0.004384,Time used 0.007979s\n",
      "batch 9010, train_loss 0.003365,Time used 0.007978s\n",
      "batch 9011, train_loss 0.004195,Time used 0.008976s\n",
      "batch 9012, train_loss 0.002916,Time used 0.007978s\n",
      "batch 9013, train_loss 0.003469,Time used 0.007979s\n",
      "batch 9014, train_loss 0.005032,Time used 0.007979s\n",
      "batch 9015, train_loss 0.004018,Time used 0.007979s\n",
      "batch 9016, train_loss 0.004266,Time used 0.007978s\n",
      "batch 9017, train_loss 0.003414,Time used 0.007980s\n",
      "batch 9018, train_loss 0.004991,Time used 0.007979s\n",
      "batch 9019, train_loss 0.002969,Time used 0.008977s\n",
      "batch 9020, train_loss 0.002971,Time used 0.008975s\n",
      "batch 9021, train_loss 0.003726,Time used 0.008977s\n",
      "batch 9022, train_loss 0.004531,Time used 0.008976s\n",
      "batch 9023, train_loss 0.002711,Time used 0.008976s\n",
      "batch 9024, train_loss 0.003156,Time used 0.008976s\n",
      "batch 9025, train_loss 0.004276,Time used 0.008976s\n",
      "batch 9026, train_loss 0.004339,Time used 0.008976s\n",
      "batch 9027, train_loss 0.003447,Time used 0.007979s\n",
      "batch 9028, train_loss 0.003613,Time used 0.008976s\n",
      "batch 9029, train_loss 0.002797,Time used 0.008976s\n",
      "batch 9030, train_loss 0.003654,Time used 0.016954s\n",
      "batch 9031, train_loss 0.004497,Time used 0.008995s\n",
      "batch 9032, train_loss 0.004960,Time used 0.008976s\n",
      "batch 9033, train_loss 0.003462,Time used 0.007979s\n",
      "batch 9034, train_loss 0.003249,Time used 0.007979s\n",
      "batch 9035, train_loss 0.002919,Time used 0.008975s\n",
      "batch 9036, train_loss 0.005515,Time used 0.008977s\n",
      "batch 9037, train_loss 0.003696,Time used 0.009973s\n",
      "batch 9038, train_loss 0.003663,Time used 0.008975s\n",
      "batch 9039, train_loss 0.003321,Time used 0.008977s\n",
      "batch 9040, train_loss 0.003148,Time used 0.008976s\n",
      "batch 9041, train_loss 0.003438,Time used 0.008976s\n",
      "batch 9042, train_loss 0.002454,Time used 0.009973s\n",
      "batch 9043, train_loss 0.003265,Time used 0.009973s\n",
      "batch 9044, train_loss 0.002468,Time used 0.008977s\n",
      "batch 9045, train_loss 0.003673,Time used 0.008977s\n",
      "batch 9046, train_loss 0.002648,Time used 0.008975s\n",
      "batch 9047, train_loss 0.002370,Time used 0.008976s\n",
      "batch 9048, train_loss 0.004071,Time used 0.008976s\n",
      "batch 9049, train_loss 0.004909,Time used 0.008976s\n",
      "batch 9050, train_loss 0.003850,Time used 0.008976s\n",
      "batch 9051, train_loss 0.002744,Time used 0.008976s\n",
      "batch 9052, train_loss 0.004494,Time used 0.007979s\n",
      "batch 9053, train_loss 0.004455,Time used 0.008976s\n",
      "batch 9054, train_loss 0.003969,Time used 0.009973s\n",
      "batch 9055, train_loss 0.003515,Time used 0.008976s\n",
      "batch 9056, train_loss 0.005345,Time used 0.008977s\n",
      "batch 9057, train_loss 0.004493,Time used 0.008976s\n",
      "batch 9058, train_loss 0.004377,Time used 0.008977s\n",
      "batch 9059, train_loss 0.003549,Time used 0.008976s\n",
      "batch 9060, train_loss 0.003945,Time used 0.007979s\n",
      "batch 9061, train_loss 0.004335,Time used 0.008976s\n",
      "batch 9062, train_loss 0.003100,Time used 0.007980s\n",
      "batch 9063, train_loss 0.004143,Time used 0.008977s\n",
      "batch 9064, train_loss 0.003299,Time used 0.008976s\n",
      "batch 9065, train_loss 0.003500,Time used 0.008976s\n",
      "batch 9066, train_loss 0.003621,Time used 0.008975s\n",
      "batch 9067, train_loss 0.004554,Time used 0.008977s\n",
      "batch 9068, train_loss 0.003145,Time used 0.008975s\n",
      "batch 9069, train_loss 0.002976,Time used 0.008976s\n",
      "batch 9070, train_loss 0.002637,Time used 0.009974s\n",
      "batch 9071, train_loss 0.003788,Time used 0.009973s\n",
      "batch 9072, train_loss 0.002868,Time used 0.009973s\n",
      "batch 9073, train_loss 0.002495,Time used 0.008976s\n",
      "batch 9074, train_loss 0.002930,Time used 0.008975s\n",
      "batch 9075, train_loss 0.003782,Time used 0.008976s\n",
      "batch 9076, train_loss 0.003536,Time used 0.008975s\n",
      "batch 9077, train_loss 0.004770,Time used 0.008977s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 9078, train_loss 0.003540,Time used 0.008976s\n",
      "batch 9079, train_loss 0.003525,Time used 0.009973s\n",
      "batch 9080, train_loss 0.004166,Time used 0.009974s\n",
      "batch 9081, train_loss 0.003200,Time used 0.008976s\n",
      "batch 9082, train_loss 0.004072,Time used 0.008976s\n",
      "batch 9083, train_loss 0.002967,Time used 0.008976s\n",
      "batch 9084, train_loss 0.003185,Time used 0.007978s\n",
      "batch 9085, train_loss 0.004044,Time used 0.008976s\n",
      "batch 9086, train_loss 0.002540,Time used 0.008976s\n",
      "batch 9087, train_loss 0.005252,Time used 0.008977s\n",
      "batch 9088, train_loss 0.003025,Time used 0.008976s\n",
      "batch 9089, train_loss 0.003326,Time used 0.007978s\n",
      "batch 9090, train_loss 0.003547,Time used 0.007979s\n",
      "batch 9091, train_loss 0.004931,Time used 0.007979s\n",
      "batch 9092, train_loss 0.002780,Time used 0.007979s\n",
      "batch 9093, train_loss 0.002239,Time used 0.008975s\n",
      "batch 9094, train_loss 0.004158,Time used 0.008976s\n",
      "batch 9095, train_loss 0.001963,Time used 0.006982s\n",
      "batch 9096, train_loss 0.002517,Time used 0.008976s\n",
      "batch 9097, train_loss 0.002456,Time used 0.008976s\n",
      "batch 9098, train_loss 0.003582,Time used 0.008976s\n",
      "batch 9099, train_loss 0.003749,Time used 0.008975s\n",
      "batch 9100, train_loss 0.002219,Time used 0.008976s\n",
      "***************************test_batch 9100, test_rmse_loss 0.060743,test_mae_loss 0.043257,test_mape_loss 12.820493,Time used 0.111701s\n",
      "batch 9101, train_loss 0.003379,Time used 0.007978s\n",
      "batch 9102, train_loss 0.004917,Time used 0.007978s\n",
      "batch 9103, train_loss 0.003879,Time used 0.007978s\n",
      "batch 9104, train_loss 0.003960,Time used 0.008976s\n",
      "batch 9105, train_loss 0.002964,Time used 0.008976s\n",
      "batch 9106, train_loss 0.003969,Time used 0.007979s\n",
      "batch 9107, train_loss 0.002973,Time used 0.008976s\n",
      "batch 9108, train_loss 0.002825,Time used 0.008976s\n",
      "batch 9109, train_loss 0.003861,Time used 0.008976s\n",
      "batch 9110, train_loss 0.003465,Time used 0.009973s\n",
      "batch 9111, train_loss 0.002730,Time used 0.008976s\n",
      "batch 9112, train_loss 0.003146,Time used 0.008976s\n",
      "batch 9113, train_loss 0.004745,Time used 0.008976s\n",
      "batch 9114, train_loss 0.002653,Time used 0.008976s\n",
      "batch 9115, train_loss 0.003782,Time used 0.009973s\n",
      "batch 9116, train_loss 0.004092,Time used 0.008976s\n",
      "batch 9117, train_loss 0.002534,Time used 0.009973s\n",
      "batch 9118, train_loss 0.004923,Time used 0.009973s\n",
      "batch 9119, train_loss 0.003384,Time used 0.009974s\n",
      "batch 9120, train_loss 0.003603,Time used 0.008976s\n",
      "batch 9121, train_loss 0.004294,Time used 0.008976s\n",
      "batch 9122, train_loss 0.002586,Time used 0.008976s\n",
      "batch 9123, train_loss 0.003751,Time used 0.008976s\n",
      "batch 9124, train_loss 0.003076,Time used 0.008977s\n",
      "batch 9125, train_loss 0.003651,Time used 0.008976s\n",
      "batch 9126, train_loss 0.002341,Time used 0.009973s\n",
      "batch 9127, train_loss 0.002187,Time used 0.007978s\n",
      "batch 9128, train_loss 0.004990,Time used 0.007979s\n",
      "batch 9129, train_loss 0.002647,Time used 0.007979s\n",
      "batch 9130, train_loss 0.002970,Time used 0.007979s\n",
      "batch 9131, train_loss 0.004511,Time used 0.007979s\n",
      "batch 9132, train_loss 0.003397,Time used 0.008976s\n",
      "batch 9133, train_loss 0.003485,Time used 0.007979s\n",
      "batch 9134, train_loss 0.003555,Time used 0.007979s\n",
      "batch 9135, train_loss 0.004306,Time used 0.007979s\n",
      "batch 9136, train_loss 0.006134,Time used 0.006982s\n",
      "batch 9137, train_loss 0.003125,Time used 0.007978s\n",
      "batch 9138, train_loss 0.003860,Time used 0.008976s\n",
      "batch 9139, train_loss 0.003408,Time used 0.009973s\n",
      "batch 9140, train_loss 0.005159,Time used 0.008976s\n",
      "batch 9141, train_loss 0.003069,Time used 0.018949s\n",
      "batch 9142, train_loss 0.003226,Time used 0.010971s\n",
      "batch 9143, train_loss 0.004655,Time used 0.008977s\n",
      "batch 9144, train_loss 0.003699,Time used 0.010970s\n",
      "batch 9145, train_loss 0.003309,Time used 0.009973s\n",
      "batch 9146, train_loss 0.002933,Time used 0.010970s\n",
      "batch 9147, train_loss 0.003873,Time used 0.008976s\n",
      "batch 9148, train_loss 0.003639,Time used 0.009974s\n",
      "batch 9149, train_loss 0.004707,Time used 0.008976s\n",
      "batch 9150, train_loss 0.002357,Time used 0.010971s\n",
      "batch 9151, train_loss 0.003246,Time used 0.008976s\n",
      "batch 9152, train_loss 0.005778,Time used 0.008975s\n",
      "batch 9153, train_loss 0.003598,Time used 0.008976s\n",
      "batch 9154, train_loss 0.003838,Time used 0.008976s\n",
      "batch 9155, train_loss 0.002409,Time used 0.009974s\n",
      "batch 9156, train_loss 0.003948,Time used 0.008975s\n",
      "batch 9157, train_loss 0.004405,Time used 0.009974s\n",
      "batch 9158, train_loss 0.004380,Time used 0.009973s\n",
      "batch 9159, train_loss 0.002615,Time used 0.009974s\n",
      "batch 9160, train_loss 0.003771,Time used 0.009973s\n",
      "batch 9161, train_loss 0.002437,Time used 0.008977s\n",
      "batch 9162, train_loss 0.003104,Time used 0.008977s\n",
      "batch 9163, train_loss 0.003569,Time used 0.008976s\n",
      "batch 9164, train_loss 0.003230,Time used 0.009973s\n",
      "batch 9165, train_loss 0.005181,Time used 0.008976s\n",
      "batch 9166, train_loss 0.003926,Time used 0.009974s\n",
      "batch 9167, train_loss 0.003572,Time used 0.007979s\n",
      "batch 9168, train_loss 0.002608,Time used 0.008976s\n",
      "batch 9169, train_loss 0.003513,Time used 0.008976s\n",
      "batch 9170, train_loss 0.003794,Time used 0.008976s\n",
      "batch 9171, train_loss 0.004511,Time used 0.008976s\n",
      "batch 9172, train_loss 0.003791,Time used 0.008975s\n",
      "batch 9173, train_loss 0.002540,Time used 0.009973s\n",
      "batch 9174, train_loss 0.004362,Time used 0.008977s\n",
      "batch 9175, train_loss 0.003299,Time used 0.008977s\n",
      "batch 9176, train_loss 0.003431,Time used 0.009973s\n",
      "batch 9177, train_loss 0.003414,Time used 0.008976s\n",
      "batch 9178, train_loss 0.003201,Time used 0.008976s\n",
      "batch 9179, train_loss 0.003024,Time used 0.008976s\n",
      "batch 9180, train_loss 0.003081,Time used 0.008977s\n",
      "batch 9181, train_loss 0.004774,Time used 0.007979s\n",
      "batch 9182, train_loss 0.004941,Time used 0.008976s\n",
      "batch 9183, train_loss 0.003441,Time used 0.008976s\n",
      "batch 9184, train_loss 0.003155,Time used 0.008975s\n",
      "batch 9185, train_loss 0.003408,Time used 0.009974s\n",
      "batch 9186, train_loss 0.003724,Time used 0.008976s\n",
      "batch 9187, train_loss 0.003670,Time used 0.008976s\n",
      "batch 9188, train_loss 0.004348,Time used 0.008975s\n",
      "batch 9189, train_loss 0.003721,Time used 0.008976s\n",
      "batch 9190, train_loss 0.003452,Time used 0.008976s\n",
      "batch 9191, train_loss 0.005005,Time used 0.007979s\n",
      "batch 9192, train_loss 0.002613,Time used 0.007978s\n",
      "batch 9193, train_loss 0.003685,Time used 0.007979s\n",
      "batch 9194, train_loss 0.004231,Time used 0.008976s\n",
      "batch 9195, train_loss 0.003455,Time used 0.007978s\n",
      "batch 9196, train_loss 0.004199,Time used 0.008976s\n",
      "batch 9197, train_loss 0.003961,Time used 0.007978s\n",
      "batch 9198, train_loss 0.003758,Time used 0.008976s\n",
      "batch 9199, train_loss 0.003002,Time used 0.008976s\n",
      "batch 9200, train_loss 0.004789,Time used 0.008976s\n",
      "***************************test_batch 9200, test_rmse_loss 0.061068,test_mae_loss 0.043555,test_mape_loss 12.717467,Time used 0.107711s\n",
      "batch 9201, train_loss 0.004466,Time used 0.008976s\n",
      "batch 9202, train_loss 0.003331,Time used 0.006981s\n",
      "batch 9203, train_loss 0.003361,Time used 0.007979s\n",
      "batch 9204, train_loss 0.004427,Time used 0.007979s\n",
      "batch 9205, train_loss 0.002826,Time used 0.007979s\n",
      "batch 9206, train_loss 0.006494,Time used 0.008975s\n",
      "batch 9207, train_loss 0.003477,Time used 0.008976s\n",
      "batch 9208, train_loss 0.003283,Time used 0.007978s\n",
      "batch 9209, train_loss 0.003609,Time used 0.007978s\n",
      "batch 9210, train_loss 0.001961,Time used 0.007979s\n",
      "batch 9211, train_loss 0.003001,Time used 0.007978s\n",
      "batch 9212, train_loss 0.004075,Time used 0.007488s\n",
      "batch 9213, train_loss 0.002985,Time used 0.007978s\n",
      "batch 9214, train_loss 0.003612,Time used 0.007979s\n",
      "batch 9215, train_loss 0.002332,Time used 0.007979s\n",
      "batch 9216, train_loss 0.004648,Time used 0.008977s\n",
      "batch 9217, train_loss 0.004848,Time used 0.009973s\n",
      "batch 9218, train_loss 0.003361,Time used 0.008976s\n",
      "batch 9219, train_loss 0.004244,Time used 0.007978s\n",
      "batch 9220, train_loss 0.002534,Time used 0.007979s\n",
      "batch 9221, train_loss 0.003575,Time used 0.007979s\n",
      "batch 9222, train_loss 0.003271,Time used 0.008977s\n",
      "batch 9223, train_loss 0.004344,Time used 0.008976s\n",
      "batch 9224, train_loss 0.004507,Time used 0.008976s\n",
      "batch 9225, train_loss 0.003368,Time used 0.007979s\n",
      "batch 9226, train_loss 0.004761,Time used 0.007980s\n",
      "batch 9227, train_loss 0.002772,Time used 0.007979s\n",
      "batch 9228, train_loss 0.002879,Time used 0.007979s\n",
      "batch 9229, train_loss 0.003453,Time used 0.008976s\n",
      "batch 9230, train_loss 0.002971,Time used 0.007978s\n",
      "batch 9231, train_loss 0.003667,Time used 0.008976s\n",
      "batch 9232, train_loss 0.002847,Time used 0.007979s\n",
      "batch 9233, train_loss 0.003281,Time used 0.007979s\n",
      "batch 9234, train_loss 0.004101,Time used 0.008976s\n",
      "batch 9235, train_loss 0.003210,Time used 0.007978s\n",
      "batch 9236, train_loss 0.003487,Time used 0.008976s\n",
      "batch 9237, train_loss 0.003063,Time used 0.008976s\n",
      "batch 9238, train_loss 0.001968,Time used 0.009974s\n",
      "batch 9239, train_loss 0.003085,Time used 0.009972s\n",
      "batch 9240, train_loss 0.004164,Time used 0.009973s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 9241, train_loss 0.003392,Time used 0.008976s\n",
      "batch 9242, train_loss 0.002726,Time used 0.009972s\n",
      "batch 9243, train_loss 0.003347,Time used 0.008976s\n",
      "batch 9244, train_loss 0.004231,Time used 0.008976s\n",
      "batch 9245, train_loss 0.003443,Time used 0.007979s\n",
      "batch 9246, train_loss 0.002569,Time used 0.008976s\n",
      "batch 9247, train_loss 0.003420,Time used 0.008976s\n",
      "batch 9248, train_loss 0.003617,Time used 0.008976s\n",
      "batch 9249, train_loss 0.003003,Time used 0.008976s\n",
      "batch 9250, train_loss 0.003915,Time used 0.007978s\n",
      "batch 9251, train_loss 0.003216,Time used 0.008976s\n",
      "batch 9252, train_loss 0.003409,Time used 0.008976s\n",
      "batch 9253, train_loss 0.004526,Time used 0.007979s\n",
      "batch 9254, train_loss 0.002992,Time used 0.007979s\n",
      "batch 9255, train_loss 0.003909,Time used 0.008976s\n",
      "batch 9256, train_loss 0.003401,Time used 0.008976s\n",
      "batch 9257, train_loss 0.005750,Time used 0.008976s\n",
      "batch 9258, train_loss 0.003969,Time used 0.007978s\n",
      "batch 9259, train_loss 0.002255,Time used 0.007978s\n",
      "batch 9260, train_loss 0.003651,Time used 0.007978s\n",
      "batch 9261, train_loss 0.003274,Time used 0.007980s\n",
      "batch 9262, train_loss 0.003855,Time used 0.007979s\n",
      "batch 9263, train_loss 0.002939,Time used 0.008976s\n",
      "batch 9264, train_loss 0.002929,Time used 0.008976s\n",
      "batch 9265, train_loss 0.003989,Time used 0.009973s\n",
      "batch 9266, train_loss 0.004111,Time used 0.008976s\n",
      "batch 9267, train_loss 0.003946,Time used 0.008976s\n",
      "batch 9268, train_loss 0.004566,Time used 0.008976s\n",
      "batch 9269, train_loss 0.004243,Time used 0.007979s\n",
      "batch 9270, train_loss 0.003276,Time used 0.008976s\n",
      "batch 9271, train_loss 0.003562,Time used 0.008975s\n",
      "batch 9272, train_loss 0.003453,Time used 0.008977s\n",
      "batch 9273, train_loss 0.003652,Time used 0.008975s\n",
      "batch 9274, train_loss 0.005677,Time used 0.007978s\n",
      "batch 9275, train_loss 0.004588,Time used 0.008977s\n",
      "batch 9276, train_loss 0.002922,Time used 0.008976s\n",
      "batch 9277, train_loss 0.002928,Time used 0.008975s\n",
      "batch 9278, train_loss 0.002833,Time used 0.007979s\n",
      "batch 9279, train_loss 0.002644,Time used 0.007979s\n",
      "batch 9280, train_loss 0.003780,Time used 0.007978s\n",
      "batch 9281, train_loss 0.004239,Time used 0.007980s\n",
      "batch 9282, train_loss 0.003498,Time used 0.008976s\n",
      "batch 9283, train_loss 0.004822,Time used 0.008976s\n",
      "batch 9284, train_loss 0.004739,Time used 0.008976s\n",
      "batch 9285, train_loss 0.004056,Time used 0.007979s\n",
      "batch 9286, train_loss 0.003953,Time used 0.007979s\n",
      "batch 9287, train_loss 0.003481,Time used 0.007979s\n",
      "batch 9288, train_loss 0.003193,Time used 0.007979s\n",
      "batch 9289, train_loss 0.002995,Time used 0.008976s\n",
      "batch 9290, train_loss 0.003657,Time used 0.007978s\n",
      "batch 9291, train_loss 0.003894,Time used 0.007979s\n",
      "batch 9292, train_loss 0.004736,Time used 0.007980s\n",
      "batch 9293, train_loss 0.003109,Time used 0.007978s\n",
      "batch 9294, train_loss 0.003311,Time used 0.007979s\n",
      "batch 9295, train_loss 0.004680,Time used 0.008975s\n",
      "batch 9296, train_loss 0.003213,Time used 0.008977s\n",
      "batch 9297, train_loss 0.005209,Time used 0.010970s\n",
      "batch 9298, train_loss 0.004637,Time used 0.008976s\n",
      "batch 9299, train_loss 0.003360,Time used 0.007979s\n",
      "batch 9300, train_loss 0.003975,Time used 0.007979s\n",
      "***************************test_batch 9300, test_rmse_loss 0.060926,test_mae_loss 0.043420,test_mape_loss 12.733686,Time used 0.106716s\n",
      "batch 9301, train_loss 0.003389,Time used 0.007979s\n",
      "batch 9302, train_loss 0.003200,Time used 0.006981s\n",
      "batch 9303, train_loss 0.003509,Time used 0.006981s\n",
      "batch 9304, train_loss 0.003223,Time used 0.006981s\n",
      "batch 9305, train_loss 0.005386,Time used 0.006982s\n",
      "batch 9306, train_loss 0.003900,Time used 0.008976s\n",
      "batch 9307, train_loss 0.003158,Time used 0.007978s\n",
      "batch 9308, train_loss 0.003149,Time used 0.007980s\n",
      "batch 9309, train_loss 0.001722,Time used 0.005984s\n",
      "batch 9310, train_loss 0.003406,Time used 0.006982s\n",
      "batch 9311, train_loss 0.004409,Time used 0.007980s\n",
      "batch 9312, train_loss 0.003470,Time used 0.007978s\n",
      "batch 9313, train_loss 0.002842,Time used 0.007979s\n",
      "batch 9314, train_loss 0.002786,Time used 0.006981s\n",
      "batch 9315, train_loss 0.003645,Time used 0.006981s\n",
      "batch 9316, train_loss 0.003844,Time used 0.007979s\n",
      "batch 9317, train_loss 0.003290,Time used 0.007979s\n",
      "batch 9318, train_loss 0.003326,Time used 0.007979s\n",
      "batch 9319, train_loss 0.004087,Time used 0.006981s\n",
      "batch 9320, train_loss 0.003685,Time used 0.006981s\n",
      "batch 9321, train_loss 0.003982,Time used 0.007979s\n",
      "batch 9322, train_loss 0.003552,Time used 0.007979s\n",
      "batch 9323, train_loss 0.002560,Time used 0.007978s\n",
      "batch 9324, train_loss 0.004023,Time used 0.008976s\n",
      "batch 9325, train_loss 0.003259,Time used 0.006981s\n",
      "batch 9326, train_loss 0.003969,Time used 0.007979s\n",
      "batch 9327, train_loss 0.003471,Time used 0.007978s\n",
      "batch 9328, train_loss 0.003420,Time used 0.007980s\n",
      "batch 9329, train_loss 0.004176,Time used 0.007978s\n",
      "batch 9330, train_loss 0.003270,Time used 0.007979s\n",
      "batch 9331, train_loss 0.005072,Time used 0.006981s\n",
      "batch 9332, train_loss 0.003681,Time used 0.007979s\n",
      "batch 9333, train_loss 0.002509,Time used 0.006981s\n",
      "batch 9334, train_loss 0.002601,Time used 0.006981s\n",
      "batch 9335, train_loss 0.004928,Time used 0.006981s\n",
      "batch 9336, train_loss 0.002526,Time used 0.006981s\n",
      "batch 9337, train_loss 0.002785,Time used 0.006981s\n",
      "batch 9338, train_loss 0.004416,Time used 0.008976s\n",
      "batch 9339, train_loss 0.003597,Time used 0.009974s\n",
      "batch 9340, train_loss 0.003940,Time used 0.009972s\n",
      "batch 9341, train_loss 0.004660,Time used 0.007979s\n",
      "batch 9342, train_loss 0.003999,Time used 0.008976s\n",
      "batch 9343, train_loss 0.002599,Time used 0.008976s\n",
      "batch 9344, train_loss 0.003443,Time used 0.008977s\n",
      "batch 9345, train_loss 0.003532,Time used 0.009973s\n",
      "batch 9346, train_loss 0.003599,Time used 0.008977s\n",
      "batch 9347, train_loss 0.003975,Time used 0.008977s\n",
      "batch 9348, train_loss 0.003097,Time used 0.008976s\n",
      "batch 9349, train_loss 0.003998,Time used 0.008976s\n",
      "batch 9350, train_loss 0.003091,Time used 0.007979s\n",
      "batch 9351, train_loss 0.002901,Time used 0.008977s\n",
      "batch 9352, train_loss 0.006248,Time used 0.008975s\n",
      "batch 9353, train_loss 0.003808,Time used 0.007978s\n",
      "batch 9354, train_loss 0.002148,Time used 0.007978s\n",
      "batch 9355, train_loss 0.003030,Time used 0.008975s\n",
      "batch 9356, train_loss 0.003157,Time used 0.008976s\n",
      "batch 9357, train_loss 0.002594,Time used 0.007977s\n",
      "batch 9358, train_loss 0.003867,Time used 0.007979s\n",
      "batch 9359, train_loss 0.003880,Time used 0.008976s\n",
      "batch 9360, train_loss 0.003868,Time used 0.008975s\n",
      "batch 9361, train_loss 0.002968,Time used 0.008976s\n",
      "batch 9362, train_loss 0.003157,Time used 0.008976s\n",
      "batch 9363, train_loss 0.003009,Time used 0.008976s\n",
      "batch 9364, train_loss 0.003426,Time used 0.008976s\n",
      "batch 9365, train_loss 0.003762,Time used 0.009973s\n",
      "batch 9366, train_loss 0.004278,Time used 0.008976s\n",
      "batch 9367, train_loss 0.003776,Time used 0.008976s\n",
      "batch 9368, train_loss 0.003211,Time used 0.009974s\n",
      "batch 9369, train_loss 0.004969,Time used 0.008976s\n",
      "batch 9370, train_loss 0.003475,Time used 0.010971s\n",
      "batch 9371, train_loss 0.003120,Time used 0.010970s\n",
      "batch 9372, train_loss 0.003475,Time used 0.009974s\n",
      "batch 9373, train_loss 0.003830,Time used 0.009973s\n",
      "batch 9374, train_loss 0.002781,Time used 0.009973s\n",
      "batch 9375, train_loss 0.004089,Time used 0.008976s\n",
      "batch 9376, train_loss 0.003177,Time used 0.009974s\n",
      "batch 9377, train_loss 0.003991,Time used 0.009973s\n",
      "batch 9378, train_loss 0.005010,Time used 0.008976s\n",
      "batch 9379, train_loss 0.002872,Time used 0.008976s\n",
      "batch 9380, train_loss 0.002957,Time used 0.009974s\n",
      "batch 9381, train_loss 0.004959,Time used 0.009973s\n",
      "batch 9382, train_loss 0.003676,Time used 0.009974s\n",
      "batch 9383, train_loss 0.005778,Time used 0.009973s\n",
      "batch 9384, train_loss 0.003004,Time used 0.008976s\n",
      "batch 9385, train_loss 0.003691,Time used 0.008977s\n",
      "batch 9386, train_loss 0.005550,Time used 0.008977s\n",
      "batch 9387, train_loss 0.003996,Time used 0.009973s\n",
      "batch 9388, train_loss 0.004906,Time used 0.008976s\n",
      "batch 9389, train_loss 0.004871,Time used 0.008976s\n",
      "batch 9390, train_loss 0.002125,Time used 0.008977s\n",
      "batch 9391, train_loss 0.005429,Time used 0.008976s\n",
      "batch 9392, train_loss 0.002694,Time used 0.008976s\n",
      "batch 9393, train_loss 0.003490,Time used 0.008976s\n",
      "batch 9394, train_loss 0.002371,Time used 0.009973s\n",
      "batch 9395, train_loss 0.003735,Time used 0.010970s\n",
      "batch 9396, train_loss 0.002703,Time used 0.008976s\n",
      "batch 9397, train_loss 0.003810,Time used 0.008975s\n",
      "batch 9398, train_loss 0.003310,Time used 0.007979s\n",
      "batch 9399, train_loss 0.003980,Time used 0.007979s\n",
      "batch 9400, train_loss 0.003094,Time used 0.007979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************test_batch 9400, test_rmse_loss 0.061082,test_mae_loss 0.043629,test_mape_loss 13.269782,Time used 0.115691s\n",
      "batch 9401, train_loss 0.003465,Time used 0.008975s\n",
      "batch 9402, train_loss 0.002650,Time used 0.008977s\n",
      "batch 9403, train_loss 0.004568,Time used 0.008976s\n",
      "batch 9404, train_loss 0.003541,Time used 0.008975s\n",
      "batch 9405, train_loss 0.004434,Time used 0.008977s\n",
      "batch 9406, train_loss 0.004249,Time used 0.008976s\n",
      "batch 9407, train_loss 0.003348,Time used 0.007978s\n",
      "batch 9408, train_loss 0.002681,Time used 0.007979s\n",
      "batch 9409, train_loss 0.005141,Time used 0.008976s\n",
      "batch 9410, train_loss 0.002739,Time used 0.008976s\n",
      "batch 9411, train_loss 0.004200,Time used 0.008976s\n",
      "batch 9412, train_loss 0.003544,Time used 0.007978s\n",
      "batch 9413, train_loss 0.003508,Time used 0.008977s\n",
      "batch 9414, train_loss 0.002756,Time used 0.008977s\n",
      "batch 9415, train_loss 0.004533,Time used 0.008976s\n",
      "batch 9416, train_loss 0.002241,Time used 0.006982s\n",
      "batch 9417, train_loss 0.002797,Time used 0.008976s\n",
      "batch 9418, train_loss 0.004909,Time used 0.008977s\n",
      "batch 9419, train_loss 0.003745,Time used 0.008975s\n",
      "batch 9420, train_loss 0.004093,Time used 0.007978s\n",
      "batch 9421, train_loss 0.003603,Time used 0.008976s\n",
      "batch 9422, train_loss 0.003938,Time used 0.007979s\n",
      "batch 9423, train_loss 0.004156,Time used 0.007980s\n",
      "batch 9424, train_loss 0.003336,Time used 0.008975s\n",
      "batch 9425, train_loss 0.004019,Time used 0.008976s\n",
      "batch 9426, train_loss 0.004111,Time used 0.008976s\n",
      "batch 9427, train_loss 0.002845,Time used 0.008976s\n",
      "batch 9428, train_loss 0.003570,Time used 0.007979s\n",
      "batch 9429, train_loss 0.003276,Time used 0.007978s\n",
      "batch 9430, train_loss 0.003530,Time used 0.007979s\n",
      "batch 9431, train_loss 0.004016,Time used 0.008976s\n",
      "batch 9432, train_loss 0.002875,Time used 0.008976s\n",
      "batch 9433, train_loss 0.003862,Time used 0.008976s\n",
      "batch 9434, train_loss 0.003298,Time used 0.008976s\n",
      "batch 9435, train_loss 0.005863,Time used 0.008975s\n",
      "batch 9436, train_loss 0.002228,Time used 0.007978s\n",
      "batch 9437, train_loss 0.003773,Time used 0.008976s\n",
      "batch 9438, train_loss 0.004252,Time used 0.007979s\n",
      "batch 9439, train_loss 0.004933,Time used 0.008975s\n",
      "batch 9440, train_loss 0.002717,Time used 0.008976s\n",
      "batch 9441, train_loss 0.005048,Time used 0.009973s\n",
      "batch 9442, train_loss 0.004276,Time used 0.008977s\n",
      "batch 9443, train_loss 0.003044,Time used 0.007978s\n",
      "batch 9444, train_loss 0.002703,Time used 0.008976s\n",
      "batch 9445, train_loss 0.002934,Time used 0.009973s\n",
      "batch 9446, train_loss 0.003543,Time used 0.008976s\n",
      "batch 9447, train_loss 0.003262,Time used 0.008975s\n",
      "batch 9448, train_loss 0.003649,Time used 0.007978s\n",
      "batch 9449, train_loss 0.003903,Time used 0.008977s\n",
      "batch 9450, train_loss 0.003771,Time used 0.008975s\n",
      "batch 9451, train_loss 0.003703,Time used 0.008977s\n",
      "batch 9452, train_loss 0.003392,Time used 0.008976s\n",
      "batch 9453, train_loss 0.002607,Time used 0.007979s\n",
      "batch 9454, train_loss 0.004504,Time used 0.007978s\n",
      "batch 9455, train_loss 0.002650,Time used 0.007979s\n",
      "batch 9456, train_loss 0.002911,Time used 0.008976s\n",
      "batch 9457, train_loss 0.003244,Time used 0.008976s\n",
      "batch 9458, train_loss 0.003255,Time used 0.007979s\n",
      "batch 9459, train_loss 0.004130,Time used 0.008976s\n",
      "batch 9460, train_loss 0.003722,Time used 0.007978s\n",
      "batch 9461, train_loss 0.003470,Time used 0.007978s\n",
      "batch 9462, train_loss 0.004246,Time used 0.008976s\n",
      "batch 9463, train_loss 0.003504,Time used 0.007978s\n",
      "batch 9464, train_loss 0.003616,Time used 0.007979s\n",
      "batch 9465, train_loss 0.004351,Time used 0.008976s\n",
      "batch 9466, train_loss 0.003408,Time used 0.008976s\n",
      "batch 9467, train_loss 0.002901,Time used 0.008976s\n",
      "batch 9468, train_loss 0.003934,Time used 0.008976s\n",
      "batch 9469, train_loss 0.004273,Time used 0.008976s\n",
      "batch 9470, train_loss 0.004753,Time used 0.008977s\n",
      "batch 9471, train_loss 0.003728,Time used 0.008975s\n",
      "batch 9472, train_loss 0.004873,Time used 0.007980s\n",
      "batch 9473, train_loss 0.004338,Time used 0.007979s\n",
      "batch 9474, train_loss 0.002441,Time used 0.007979s\n",
      "batch 9475, train_loss 0.002778,Time used 0.007979s\n",
      "batch 9476, train_loss 0.002806,Time used 0.007978s\n",
      "batch 9477, train_loss 0.003296,Time used 0.008976s\n",
      "batch 9478, train_loss 0.005078,Time used 0.007979s\n",
      "batch 9479, train_loss 0.002887,Time used 0.008976s\n",
      "batch 9480, train_loss 0.003269,Time used 0.008976s\n",
      "batch 9481, train_loss 0.002878,Time used 0.008976s\n",
      "batch 9482, train_loss 0.003304,Time used 0.008976s\n",
      "batch 9483, train_loss 0.003079,Time used 0.007979s\n",
      "batch 9484, train_loss 0.003954,Time used 0.008976s\n",
      "batch 9485, train_loss 0.003248,Time used 0.008994s\n",
      "batch 9486, train_loss 0.004650,Time used 0.007979s\n",
      "batch 9487, train_loss 0.003515,Time used 0.008976s\n",
      "batch 9488, train_loss 0.003387,Time used 0.008975s\n",
      "batch 9489, train_loss 0.003691,Time used 0.008977s\n",
      "batch 9490, train_loss 0.003125,Time used 0.008976s\n",
      "batch 9491, train_loss 0.004222,Time used 0.008975s\n",
      "batch 9492, train_loss 0.002989,Time used 0.010971s\n",
      "batch 9493, train_loss 0.003834,Time used 0.008977s\n",
      "batch 9494, train_loss 0.002446,Time used 0.007978s\n",
      "batch 9495, train_loss 0.003857,Time used 0.007979s\n",
      "batch 9496, train_loss 0.003908,Time used 0.007978s\n",
      "batch 9497, train_loss 0.002686,Time used 0.007979s\n",
      "batch 9498, train_loss 0.005212,Time used 0.007979s\n",
      "batch 9499, train_loss 0.003091,Time used 0.007979s\n",
      "batch 9500, train_loss 0.003888,Time used 0.007978s\n",
      "***************************test_batch 9500, test_rmse_loss 0.061116,test_mae_loss 0.043585,test_mape_loss 12.719312,Time used 0.107712s\n",
      "batch 9501, train_loss 0.003067,Time used 0.008976s\n",
      "batch 9502, train_loss 0.003705,Time used 0.008977s\n",
      "batch 9503, train_loss 0.003938,Time used 0.007978s\n",
      "batch 9504, train_loss 0.005021,Time used 0.008976s\n",
      "batch 9505, train_loss 0.002421,Time used 0.007978s\n",
      "batch 9506, train_loss 0.002832,Time used 0.008977s\n",
      "batch 9507, train_loss 0.004273,Time used 0.007978s\n",
      "batch 9508, train_loss 0.003095,Time used 0.007979s\n",
      "batch 9509, train_loss 0.003699,Time used 0.007978s\n",
      "batch 9510, train_loss 0.003617,Time used 0.007978s\n",
      "batch 9511, train_loss 0.004116,Time used 0.008976s\n",
      "batch 9512, train_loss 0.003168,Time used 0.008976s\n",
      "batch 9513, train_loss 0.004445,Time used 0.007979s\n",
      "batch 9514, train_loss 0.003204,Time used 0.007979s\n",
      "batch 9515, train_loss 0.006863,Time used 0.007979s\n",
      "batch 9516, train_loss 0.003777,Time used 0.007978s\n",
      "batch 9517, train_loss 0.003498,Time used 0.007978s\n",
      "batch 9518, train_loss 0.003671,Time used 0.007978s\n",
      "batch 9519, train_loss 0.004271,Time used 0.008976s\n",
      "batch 9520, train_loss 0.002760,Time used 0.007978s\n",
      "batch 9521, train_loss 0.002923,Time used 0.007978s\n",
      "batch 9522, train_loss 0.002824,Time used 0.007980s\n",
      "batch 9523, train_loss 0.003087,Time used 0.007978s\n",
      "batch 9524, train_loss 0.003721,Time used 0.007978s\n",
      "batch 9525, train_loss 0.002737,Time used 0.007979s\n",
      "batch 9526, train_loss 0.005030,Time used 0.007978s\n",
      "batch 9527, train_loss 0.003659,Time used 0.008976s\n",
      "batch 9528, train_loss 0.002473,Time used 0.008976s\n",
      "batch 9529, train_loss 0.003958,Time used 0.008975s\n",
      "batch 9530, train_loss 0.004095,Time used 0.008976s\n",
      "batch 9531, train_loss 0.003255,Time used 0.008976s\n",
      "batch 9532, train_loss 0.002969,Time used 0.009974s\n",
      "batch 9533, train_loss 0.004621,Time used 0.009973s\n",
      "batch 9534, train_loss 0.003705,Time used 0.010991s\n",
      "batch 9535, train_loss 0.003127,Time used 0.009974s\n",
      "batch 9536, train_loss 0.003509,Time used 0.018949s\n",
      "batch 9537, train_loss 0.003219,Time used 0.008978s\n",
      "batch 9538, train_loss 0.004818,Time used 0.009972s\n",
      "batch 9539, train_loss 0.004739,Time used 0.011967s\n",
      "batch 9540, train_loss 0.004577,Time used 0.009974s\n",
      "batch 9541, train_loss 0.003020,Time used 0.009973s\n",
      "batch 9542, train_loss 0.004724,Time used 0.009973s\n",
      "batch 9543, train_loss 0.005020,Time used 0.008976s\n",
      "batch 9544, train_loss 0.002851,Time used 0.009974s\n",
      "batch 9545, train_loss 0.002628,Time used 0.009973s\n",
      "batch 9546, train_loss 0.003537,Time used 0.009973s\n",
      "batch 9547, train_loss 0.003577,Time used 0.009974s\n",
      "batch 9548, train_loss 0.005957,Time used 0.009973s\n",
      "batch 9549, train_loss 0.002881,Time used 0.009973s\n",
      "batch 9550, train_loss 0.003174,Time used 0.009974s\n",
      "batch 9551, train_loss 0.003071,Time used 0.009973s\n",
      "batch 9552, train_loss 0.003477,Time used 0.010972s\n",
      "batch 9553, train_loss 0.004567,Time used 0.009972s\n",
      "batch 9554, train_loss 0.004391,Time used 0.009974s\n",
      "batch 9555, train_loss 0.002490,Time used 0.010972s\n",
      "batch 9556, train_loss 0.003028,Time used 0.009973s\n",
      "batch 9557, train_loss 0.004144,Time used 0.009973s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 9558, train_loss 0.003491,Time used 0.008976s\n",
      "batch 9559, train_loss 0.004138,Time used 0.009973s\n",
      "batch 9560, train_loss 0.003942,Time used 0.009973s\n",
      "batch 9561, train_loss 0.003819,Time used 0.008976s\n",
      "batch 9562, train_loss 0.002722,Time used 0.008976s\n",
      "batch 9563, train_loss 0.003212,Time used 0.008977s\n",
      "batch 9564, train_loss 0.003148,Time used 0.008975s\n",
      "batch 9565, train_loss 0.004078,Time used 0.007980s\n",
      "batch 9566, train_loss 0.002720,Time used 0.008977s\n",
      "batch 9567, train_loss 0.004140,Time used 0.008976s\n",
      "batch 9568, train_loss 0.002575,Time used 0.008976s\n",
      "batch 9569, train_loss 0.003673,Time used 0.008977s\n",
      "batch 9570, train_loss 0.003519,Time used 0.008976s\n",
      "batch 9571, train_loss 0.002219,Time used 0.008976s\n",
      "batch 9572, train_loss 0.004853,Time used 0.008976s\n",
      "batch 9573, train_loss 0.004190,Time used 0.009974s\n",
      "batch 9574, train_loss 0.003224,Time used 0.009973s\n",
      "batch 9575, train_loss 0.002987,Time used 0.007979s\n",
      "batch 9576, train_loss 0.004018,Time used 0.009973s\n",
      "batch 9577, train_loss 0.003592,Time used 0.008975s\n",
      "batch 9578, train_loss 0.003434,Time used 0.010971s\n",
      "batch 9579, train_loss 0.003221,Time used 0.008976s\n",
      "batch 9580, train_loss 0.003442,Time used 0.008977s\n",
      "batch 9581, train_loss 0.003016,Time used 0.008976s\n",
      "batch 9582, train_loss 0.003953,Time used 0.007979s\n",
      "batch 9583, train_loss 0.005111,Time used 0.007979s\n",
      "batch 9584, train_loss 0.004382,Time used 0.007979s\n",
      "batch 9585, train_loss 0.004151,Time used 0.008976s\n",
      "batch 9586, train_loss 0.004719,Time used 0.007979s\n",
      "batch 9587, train_loss 0.003808,Time used 0.007979s\n",
      "batch 9588, train_loss 0.003709,Time used 0.007979s\n",
      "batch 9589, train_loss 0.004010,Time used 0.008976s\n",
      "batch 9590, train_loss 0.003270,Time used 0.008976s\n",
      "batch 9591, train_loss 0.004112,Time used 0.008977s\n",
      "batch 9592, train_loss 0.002430,Time used 0.007979s\n",
      "batch 9593, train_loss 0.003143,Time used 0.008977s\n",
      "batch 9594, train_loss 0.003558,Time used 0.008976s\n",
      "batch 9595, train_loss 0.004131,Time used 0.007978s\n",
      "batch 9596, train_loss 0.003997,Time used 0.008976s\n",
      "batch 9597, train_loss 0.005009,Time used 0.008976s\n",
      "batch 9598, train_loss 0.003582,Time used 0.009973s\n",
      "batch 9599, train_loss 0.004602,Time used 0.008976s\n",
      "batch 9600, train_loss 0.002554,Time used 0.008976s\n",
      "***************************test_batch 9600, test_rmse_loss 0.061144,test_mae_loss 0.043600,test_mape_loss 12.705034,Time used 0.114694s\n",
      "batch 9601, train_loss 0.002509,Time used 0.007978s\n",
      "batch 9602, train_loss 0.003254,Time used 0.008976s\n",
      "batch 9603, train_loss 0.003684,Time used 0.009974s\n",
      "batch 9604, train_loss 0.002393,Time used 0.009485s\n",
      "batch 9605, train_loss 0.004400,Time used 0.008976s\n",
      "batch 9606, train_loss 0.004112,Time used 0.008976s\n",
      "batch 9607, train_loss 0.003179,Time used 0.007978s\n",
      "batch 9608, train_loss 0.003112,Time used 0.008977s\n",
      "batch 9609, train_loss 0.003543,Time used 0.008976s\n",
      "batch 9610, train_loss 0.004841,Time used 0.008976s\n",
      "batch 9611, train_loss 0.004916,Time used 0.007980s\n",
      "batch 9612, train_loss 0.002594,Time used 0.007979s\n",
      "batch 9613, train_loss 0.003014,Time used 0.007978s\n",
      "batch 9614, train_loss 0.002677,Time used 0.008976s\n",
      "batch 9615, train_loss 0.004608,Time used 0.008976s\n",
      "batch 9616, train_loss 0.003730,Time used 0.008976s\n",
      "batch 9617, train_loss 0.003301,Time used 0.008975s\n",
      "batch 9618, train_loss 0.003184,Time used 0.008977s\n",
      "batch 9619, train_loss 0.003422,Time used 0.008975s\n",
      "batch 9620, train_loss 0.004713,Time used 0.008975s\n",
      "batch 9621, train_loss 0.003680,Time used 0.008976s\n",
      "batch 9622, train_loss 0.002967,Time used 0.009973s\n",
      "batch 9623, train_loss 0.003514,Time used 0.009974s\n",
      "batch 9624, train_loss 0.003089,Time used 0.008976s\n",
      "batch 9625, train_loss 0.003462,Time used 0.008976s\n",
      "batch 9626, train_loss 0.003600,Time used 0.009974s\n",
      "batch 9627, train_loss 0.003088,Time used 0.008975s\n",
      "batch 9628, train_loss 0.004284,Time used 0.007978s\n",
      "batch 9629, train_loss 0.002710,Time used 0.008976s\n",
      "batch 9630, train_loss 0.002923,Time used 0.007978s\n",
      "batch 9631, train_loss 0.004927,Time used 0.008975s\n",
      "batch 9632, train_loss 0.004054,Time used 0.008977s\n",
      "batch 9633, train_loss 0.005341,Time used 0.007978s\n",
      "batch 9634, train_loss 0.003531,Time used 0.008976s\n",
      "batch 9635, train_loss 0.003302,Time used 0.007979s\n",
      "batch 9636, train_loss 0.003473,Time used 0.008976s\n",
      "batch 9637, train_loss 0.003379,Time used 0.007978s\n",
      "batch 9638, train_loss 0.003800,Time used 0.008976s\n",
      "batch 9639, train_loss 0.004459,Time used 0.007980s\n",
      "batch 9640, train_loss 0.003751,Time used 0.007979s\n",
      "batch 9641, train_loss 0.004746,Time used 0.007979s\n",
      "batch 9642, train_loss 0.003486,Time used 0.007979s\n",
      "batch 9643, train_loss 0.003580,Time used 0.009973s\n",
      "batch 9644, train_loss 0.003260,Time used 0.008976s\n",
      "batch 9645, train_loss 0.002391,Time used 0.007979s\n",
      "batch 9646, train_loss 0.003043,Time used 0.008976s\n",
      "batch 9647, train_loss 0.003239,Time used 0.008977s\n",
      "batch 9648, train_loss 0.002706,Time used 0.007978s\n",
      "batch 9649, train_loss 0.002560,Time used 0.007979s\n",
      "batch 9650, train_loss 0.003437,Time used 0.007979s\n",
      "batch 9651, train_loss 0.003572,Time used 0.007978s\n",
      "batch 9652, train_loss 0.004018,Time used 0.009973s\n",
      "batch 9653, train_loss 0.006531,Time used 0.007979s\n",
      "batch 9654, train_loss 0.002528,Time used 0.007978s\n",
      "batch 9655, train_loss 0.002895,Time used 0.007979s\n",
      "batch 9656, train_loss 0.003512,Time used 0.007979s\n",
      "batch 9657, train_loss 0.003972,Time used 0.008976s\n",
      "batch 9658, train_loss 0.004018,Time used 0.007979s\n",
      "batch 9659, train_loss 0.002702,Time used 0.007977s\n",
      "batch 9660, train_loss 0.003153,Time used 0.007979s\n",
      "batch 9661, train_loss 0.003772,Time used 0.007978s\n",
      "batch 9662, train_loss 0.003649,Time used 0.007979s\n",
      "batch 9663, train_loss 0.002930,Time used 0.007978s\n",
      "batch 9664, train_loss 0.003876,Time used 0.007978s\n",
      "batch 9665, train_loss 0.003704,Time used 0.008977s\n",
      "batch 9666, train_loss 0.003298,Time used 0.007979s\n",
      "batch 9667, train_loss 0.004350,Time used 0.007978s\n",
      "batch 9668, train_loss 0.004106,Time used 0.009974s\n",
      "batch 9669, train_loss 0.003528,Time used 0.008975s\n",
      "batch 9670, train_loss 0.003047,Time used 0.008977s\n",
      "batch 9671, train_loss 0.003717,Time used 0.009973s\n",
      "batch 9672, train_loss 0.002236,Time used 0.008976s\n",
      "batch 9673, train_loss 0.003822,Time used 0.008976s\n",
      "batch 9674, train_loss 0.006032,Time used 0.008976s\n",
      "batch 9675, train_loss 0.004479,Time used 0.008975s\n",
      "batch 9676, train_loss 0.004698,Time used 0.008976s\n",
      "batch 9677, train_loss 0.004138,Time used 0.008977s\n",
      "batch 9678, train_loss 0.003090,Time used 0.008976s\n",
      "batch 9679, train_loss 0.004104,Time used 0.008976s\n",
      "batch 9680, train_loss 0.003988,Time used 0.007979s\n",
      "batch 9681, train_loss 0.002747,Time used 0.008977s\n",
      "batch 9682, train_loss 0.002709,Time used 0.008975s\n",
      "batch 9683, train_loss 0.003044,Time used 0.008976s\n",
      "batch 9684, train_loss 0.005315,Time used 0.008977s\n",
      "batch 9685, train_loss 0.002375,Time used 0.008976s\n",
      "batch 9686, train_loss 0.002952,Time used 0.008976s\n",
      "batch 9687, train_loss 0.003687,Time used 0.008976s\n",
      "batch 9688, train_loss 0.003480,Time used 0.008976s\n",
      "batch 9689, train_loss 0.003696,Time used 0.008976s\n",
      "batch 9690, train_loss 0.002409,Time used 0.008976s\n",
      "batch 9691, train_loss 0.004257,Time used 0.008977s\n",
      "batch 9692, train_loss 0.003791,Time used 0.008975s\n",
      "batch 9693, train_loss 0.005027,Time used 0.008976s\n",
      "batch 9694, train_loss 0.003344,Time used 0.008976s\n",
      "batch 9695, train_loss 0.004839,Time used 0.009974s\n",
      "batch 9696, train_loss 0.004000,Time used 0.008976s\n",
      "batch 9697, train_loss 0.002626,Time used 0.007979s\n",
      "batch 9698, train_loss 0.003261,Time used 0.007978s\n",
      "batch 9699, train_loss 0.003742,Time used 0.008977s\n",
      "batch 9700, train_loss 0.003890,Time used 0.008976s\n",
      "***************************test_batch 9700, test_rmse_loss 0.060909,test_mae_loss 0.043456,test_mape_loss 13.097439,Time used 0.115691s\n",
      "batch 9701, train_loss 0.003630,Time used 0.009974s\n",
      "batch 9702, train_loss 0.004222,Time used 0.007979s\n",
      "batch 9703, train_loss 0.003492,Time used 0.007978s\n",
      "batch 9704, train_loss 0.002992,Time used 0.007978s\n",
      "batch 9705, train_loss 0.003520,Time used 0.007978s\n",
      "batch 9706, train_loss 0.003363,Time used 0.007978s\n",
      "batch 9707, train_loss 0.003547,Time used 0.008976s\n",
      "batch 9708, train_loss 0.004826,Time used 0.008976s\n",
      "batch 9709, train_loss 0.003427,Time used 0.008976s\n",
      "batch 9710, train_loss 0.003238,Time used 0.008977s\n",
      "batch 9711, train_loss 0.003214,Time used 0.007978s\n",
      "batch 9712, train_loss 0.004868,Time used 0.007978s\n",
      "batch 9713, train_loss 0.003662,Time used 0.007978s\n",
      "batch 9714, train_loss 0.003079,Time used 0.007979s\n",
      "batch 9715, train_loss 0.003201,Time used 0.008977s\n",
      "batch 9716, train_loss 0.002782,Time used 0.008976s\n",
      "batch 9717, train_loss 0.002948,Time used 0.008976s\n",
      "batch 9718, train_loss 0.004929,Time used 0.008976s\n",
      "batch 9719, train_loss 0.004310,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 9720, train_loss 0.003412,Time used 0.009973s\n",
      "batch 9721, train_loss 0.003025,Time used 0.008976s\n",
      "batch 9722, train_loss 0.003707,Time used 0.007979s\n",
      "batch 9723, train_loss 0.002565,Time used 0.007980s\n",
      "batch 9724, train_loss 0.003095,Time used 0.007979s\n",
      "batch 9725, train_loss 0.005208,Time used 0.008995s\n",
      "batch 9726, train_loss 0.003481,Time used 0.007977s\n",
      "batch 9727, train_loss 0.003119,Time used 0.008977s\n",
      "batch 9728, train_loss 0.004392,Time used 0.008977s\n",
      "batch 9729, train_loss 0.003508,Time used 0.009974s\n",
      "batch 9730, train_loss 0.003573,Time used 0.008977s\n",
      "batch 9731, train_loss 0.003927,Time used 0.008976s\n",
      "batch 9732, train_loss 0.003233,Time used 0.007979s\n",
      "batch 9733, train_loss 0.003616,Time used 0.007978s\n",
      "batch 9734, train_loss 0.003189,Time used 0.008976s\n",
      "batch 9735, train_loss 0.003750,Time used 0.007979s\n",
      "batch 9736, train_loss 0.003453,Time used 0.007979s\n",
      "batch 9737, train_loss 0.001929,Time used 0.006981s\n",
      "batch 9738, train_loss 0.002952,Time used 0.007979s\n",
      "batch 9739, train_loss 0.004255,Time used 0.008975s\n",
      "batch 9740, train_loss 0.003910,Time used 0.006981s\n",
      "batch 9741, train_loss 0.003815,Time used 0.009974s\n",
      "batch 9742, train_loss 0.002839,Time used 0.007979s\n",
      "batch 9743, train_loss 0.004074,Time used 0.008976s\n",
      "batch 9744, train_loss 0.002933,Time used 0.006981s\n",
      "batch 9745, train_loss 0.003658,Time used 0.006982s\n",
      "batch 9746, train_loss 0.003607,Time used 0.007978s\n",
      "batch 9747, train_loss 0.003581,Time used 0.008977s\n",
      "batch 9748, train_loss 0.003260,Time used 0.008006s\n",
      "batch 9749, train_loss 0.003047,Time used 0.006981s\n",
      "batch 9750, train_loss 0.003632,Time used 0.007978s\n",
      "batch 9751, train_loss 0.004732,Time used 0.007979s\n",
      "batch 9752, train_loss 0.004275,Time used 0.007978s\n",
      "batch 9753, train_loss 0.004314,Time used 0.007979s\n",
      "batch 9754, train_loss 0.003366,Time used 0.007979s\n",
      "batch 9755, train_loss 0.003513,Time used 0.008976s\n",
      "batch 9756, train_loss 0.003876,Time used 0.007978s\n",
      "batch 9757, train_loss 0.004398,Time used 0.007978s\n",
      "batch 9758, train_loss 0.002722,Time used 0.008976s\n",
      "batch 9759, train_loss 0.003343,Time used 0.008976s\n",
      "batch 9760, train_loss 0.003505,Time used 0.007978s\n",
      "batch 9761, train_loss 0.003190,Time used 0.007979s\n",
      "batch 9762, train_loss 0.004656,Time used 0.007978s\n",
      "batch 9763, train_loss 0.003372,Time used 0.007979s\n",
      "batch 9764, train_loss 0.004668,Time used 0.007979s\n",
      "batch 9765, train_loss 0.003986,Time used 0.007979s\n",
      "batch 9766, train_loss 0.003731,Time used 0.007979s\n",
      "batch 9767, train_loss 0.002999,Time used 0.007978s\n",
      "batch 9768, train_loss 0.003305,Time used 0.008976s\n",
      "batch 9769, train_loss 0.002955,Time used 0.007979s\n",
      "batch 9770, train_loss 0.003686,Time used 0.007978s\n",
      "batch 9771, train_loss 0.003082,Time used 0.008976s\n",
      "batch 9772, train_loss 0.004723,Time used 0.006981s\n",
      "batch 9773, train_loss 0.004442,Time used 0.006981s\n",
      "batch 9774, train_loss 0.003834,Time used 0.007979s\n",
      "batch 9775, train_loss 0.003646,Time used 0.008975s\n",
      "batch 9776, train_loss 0.004033,Time used 0.007978s\n",
      "batch 9777, train_loss 0.003315,Time used 0.008977s\n",
      "batch 9778, train_loss 0.002973,Time used 0.008975s\n",
      "batch 9779, train_loss 0.003059,Time used 0.008977s\n",
      "batch 9780, train_loss 0.004059,Time used 0.007978s\n",
      "batch 9781, train_loss 0.003881,Time used 0.008975s\n",
      "batch 9782, train_loss 0.003252,Time used 0.009974s\n",
      "batch 9783, train_loss 0.003027,Time used 0.007979s\n",
      "batch 9784, train_loss 0.003901,Time used 0.007978s\n",
      "batch 9785, train_loss 0.003689,Time used 0.008976s\n",
      "batch 9786, train_loss 0.003761,Time used 0.008975s\n",
      "batch 9787, train_loss 0.003314,Time used 0.008977s\n",
      "batch 9788, train_loss 0.006252,Time used 0.008976s\n",
      "batch 9789, train_loss 0.004304,Time used 0.008976s\n",
      "batch 9790, train_loss 0.003283,Time used 0.008976s\n",
      "batch 9791, train_loss 0.004777,Time used 0.008976s\n",
      "batch 9792, train_loss 0.002641,Time used 0.007979s\n",
      "batch 9793, train_loss 0.003017,Time used 0.007978s\n",
      "batch 9794, train_loss 0.003688,Time used 0.008976s\n",
      "batch 9795, train_loss 0.004114,Time used 0.008976s\n",
      "batch 9796, train_loss 0.002923,Time used 0.009973s\n",
      "batch 9797, train_loss 0.003487,Time used 0.008976s\n",
      "batch 9798, train_loss 0.003310,Time used 0.009974s\n",
      "batch 9799, train_loss 0.002741,Time used 0.008976s\n",
      "batch 9800, train_loss 0.003520,Time used 0.008976s\n",
      "***************************test_batch 9800, test_rmse_loss 0.061331,test_mae_loss 0.043754,test_mape_loss 12.707948,Time used 0.116690s\n",
      "batch 9801, train_loss 0.003063,Time used 0.008976s\n",
      "batch 9802, train_loss 0.003978,Time used 0.008975s\n",
      "batch 9803, train_loss 0.004868,Time used 0.007978s\n",
      "batch 9804, train_loss 0.003215,Time used 0.008976s\n",
      "batch 9805, train_loss 0.003609,Time used 0.008975s\n",
      "batch 9806, train_loss 0.003597,Time used 0.006982s\n",
      "batch 9807, train_loss 0.003583,Time used 0.008976s\n",
      "batch 9808, train_loss 0.004185,Time used 0.007979s\n",
      "batch 9809, train_loss 0.003059,Time used 0.007979s\n",
      "batch 9810, train_loss 0.002721,Time used 0.009974s\n",
      "batch 9811, train_loss 0.002959,Time used 0.009973s\n",
      "batch 9812, train_loss 0.003437,Time used 0.008976s\n",
      "batch 9813, train_loss 0.004995,Time used 0.007978s\n",
      "batch 9814, train_loss 0.006157,Time used 0.008976s\n",
      "batch 9815, train_loss 0.002966,Time used 0.008976s\n",
      "batch 9816, train_loss 0.004271,Time used 0.008976s\n",
      "batch 9817, train_loss 0.003395,Time used 0.008976s\n",
      "batch 9818, train_loss 0.005017,Time used 0.008976s\n",
      "batch 9819, train_loss 0.003880,Time used 0.008976s\n",
      "batch 9820, train_loss 0.002831,Time used 0.008976s\n",
      "batch 9821, train_loss 0.002484,Time used 0.009974s\n",
      "batch 9822, train_loss 0.003226,Time used 0.008976s\n",
      "batch 9823, train_loss 0.003139,Time used 0.008976s\n",
      "batch 9824, train_loss 0.003618,Time used 0.008976s\n",
      "batch 9825, train_loss 0.002942,Time used 0.008976s\n",
      "batch 9826, train_loss 0.005175,Time used 0.008976s\n",
      "batch 9827, train_loss 0.003555,Time used 0.008976s\n",
      "batch 9828, train_loss 0.004414,Time used 0.010971s\n",
      "batch 9829, train_loss 0.004273,Time used 0.008976s\n",
      "batch 9830, train_loss 0.003645,Time used 0.010971s\n",
      "batch 9831, train_loss 0.003263,Time used 0.008976s\n",
      "batch 9832, train_loss 0.004463,Time used 0.008976s\n",
      "batch 9833, train_loss 0.003236,Time used 0.012965s\n",
      "batch 9834, train_loss 0.003298,Time used 0.011968s\n",
      "batch 9835, train_loss 0.003157,Time used 0.008976s\n",
      "batch 9836, train_loss 0.003292,Time used 0.007979s\n",
      "batch 9837, train_loss 0.002130,Time used 0.007979s\n",
      "batch 9838, train_loss 0.002838,Time used 0.007978s\n",
      "batch 9839, train_loss 0.004342,Time used 0.009973s\n",
      "batch 9840, train_loss 0.003883,Time used 0.008976s\n",
      "batch 9841, train_loss 0.004408,Time used 0.010971s\n",
      "batch 9842, train_loss 0.002527,Time used 0.009974s\n",
      "batch 9843, train_loss 0.002636,Time used 0.008977s\n",
      "batch 9844, train_loss 0.005149,Time used 0.007978s\n",
      "batch 9845, train_loss 0.002995,Time used 0.009974s\n",
      "batch 9846, train_loss 0.004011,Time used 0.009972s\n",
      "batch 9847, train_loss 0.002822,Time used 0.009974s\n",
      "batch 9848, train_loss 0.003481,Time used 0.009973s\n",
      "batch 9849, train_loss 0.002455,Time used 0.008976s\n",
      "batch 9850, train_loss 0.005070,Time used 0.008976s\n",
      "batch 9851, train_loss 0.004669,Time used 0.008975s\n",
      "batch 9852, train_loss 0.003735,Time used 0.008975s\n",
      "batch 9853, train_loss 0.003158,Time used 0.008977s\n",
      "batch 9854, train_loss 0.003795,Time used 0.008976s\n",
      "batch 9855, train_loss 0.003401,Time used 0.008976s\n",
      "batch 9856, train_loss 0.003047,Time used 0.008975s\n",
      "batch 9857, train_loss 0.002481,Time used 0.008976s\n",
      "batch 9858, train_loss 0.002902,Time used 0.009974s\n",
      "batch 9859, train_loss 0.004643,Time used 0.009973s\n",
      "batch 9860, train_loss 0.003733,Time used 0.008976s\n",
      "batch 9861, train_loss 0.003483,Time used 0.007979s\n",
      "batch 9862, train_loss 0.004189,Time used 0.008976s\n",
      "batch 9863, train_loss 0.002710,Time used 0.009973s\n",
      "batch 9864, train_loss 0.003029,Time used 0.008976s\n",
      "batch 9865, train_loss 0.003690,Time used 0.009973s\n",
      "batch 9866, train_loss 0.003043,Time used 0.009974s\n",
      "batch 9867, train_loss 0.004897,Time used 0.008977s\n",
      "batch 9868, train_loss 0.004725,Time used 0.008976s\n",
      "batch 9869, train_loss 0.003868,Time used 0.009974s\n",
      "batch 9870, train_loss 0.002865,Time used 0.008977s\n",
      "batch 9871, train_loss 0.005050,Time used 0.008976s\n",
      "batch 9872, train_loss 0.003605,Time used 0.008976s\n",
      "batch 9873, train_loss 0.003141,Time used 0.008998s\n",
      "batch 9874, train_loss 0.002671,Time used 0.010971s\n",
      "batch 9875, train_loss 0.004180,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 9876, train_loss 0.005236,Time used 0.007979s\n",
      "batch 9877, train_loss 0.002979,Time used 0.009973s\n",
      "batch 9878, train_loss 0.003737,Time used 0.008975s\n",
      "batch 9879, train_loss 0.003283,Time used 0.006981s\n",
      "batch 9880, train_loss 0.004445,Time used 0.007979s\n",
      "batch 9881, train_loss 0.003955,Time used 0.007980s\n",
      "batch 9882, train_loss 0.002607,Time used 0.006981s\n",
      "batch 9883, train_loss 0.003339,Time used 0.008976s\n",
      "batch 9884, train_loss 0.003182,Time used 0.008976s\n",
      "batch 9885, train_loss 0.002825,Time used 0.007978s\n",
      "batch 9886, train_loss 0.006223,Time used 0.007979s\n",
      "batch 9887, train_loss 0.003296,Time used 0.009973s\n",
      "batch 9888, train_loss 0.004387,Time used 0.007979s\n",
      "batch 9889, train_loss 0.003809,Time used 0.007978s\n",
      "batch 9890, train_loss 0.003183,Time used 0.007979s\n",
      "batch 9891, train_loss 0.003014,Time used 0.007978s\n",
      "batch 9892, train_loss 0.003590,Time used 0.007979s\n",
      "batch 9893, train_loss 0.003032,Time used 0.007979s\n",
      "batch 9894, train_loss 0.002953,Time used 0.007978s\n",
      "batch 9895, train_loss 0.002464,Time used 0.006982s\n",
      "batch 9896, train_loss 0.004227,Time used 0.007978s\n",
      "batch 9897, train_loss 0.004351,Time used 0.007979s\n",
      "batch 9898, train_loss 0.003828,Time used 0.008976s\n",
      "batch 9899, train_loss 0.004755,Time used 0.006981s\n",
      "batch 9900, train_loss 0.004140,Time used 0.008976s\n",
      "***************************test_batch 9900, test_rmse_loss 0.060819,test_mae_loss 0.043304,test_mape_loss 12.822518,Time used 0.110705s\n",
      "batch 9901, train_loss 0.002907,Time used 0.008975s\n",
      "batch 9902, train_loss 0.003593,Time used 0.006982s\n",
      "batch 9903, train_loss 0.002950,Time used 0.007979s\n",
      "batch 9904, train_loss 0.003296,Time used 0.007978s\n",
      "batch 9905, train_loss 0.004150,Time used 0.007978s\n",
      "batch 9906, train_loss 0.004215,Time used 0.007979s\n",
      "batch 9907, train_loss 0.004154,Time used 0.008976s\n",
      "batch 9908, train_loss 0.006407,Time used 0.009973s\n",
      "batch 9909, train_loss 0.003892,Time used 0.008976s\n",
      "batch 9910, train_loss 0.003042,Time used 0.008976s\n",
      "batch 9911, train_loss 0.005685,Time used 0.008976s\n",
      "batch 9912, train_loss 0.002851,Time used 0.008976s\n",
      "batch 9913, train_loss 0.002991,Time used 0.007979s\n",
      "batch 9914, train_loss 0.002958,Time used 0.007978s\n",
      "batch 9915, train_loss 0.003686,Time used 0.008977s\n",
      "batch 9916, train_loss 0.002699,Time used 0.008975s\n",
      "batch 9917, train_loss 0.002946,Time used 0.008976s\n",
      "batch 9918, train_loss 0.002580,Time used 0.008976s\n",
      "batch 9919, train_loss 0.003452,Time used 0.008976s\n",
      "batch 9920, train_loss 0.003711,Time used 0.008976s\n",
      "batch 9921, train_loss 0.003524,Time used 0.008977s\n",
      "batch 9922, train_loss 0.003229,Time used 0.008976s\n",
      "batch 9923, train_loss 0.002646,Time used 0.008977s\n",
      "batch 9924, train_loss 0.003375,Time used 0.008975s\n",
      "batch 9925, train_loss 0.003439,Time used 0.008976s\n",
      "batch 9926, train_loss 0.003327,Time used 0.008976s\n",
      "batch 9927, train_loss 0.003272,Time used 0.009973s\n",
      "batch 9928, train_loss 0.004469,Time used 0.008976s\n",
      "batch 9929, train_loss 0.006110,Time used 0.008976s\n",
      "batch 9930, train_loss 0.003699,Time used 0.008976s\n",
      "batch 9931, train_loss 0.003496,Time used 0.009974s\n",
      "batch 9932, train_loss 0.003204,Time used 0.008975s\n",
      "batch 9933, train_loss 0.004253,Time used 0.008977s\n",
      "batch 9934, train_loss 0.003595,Time used 0.007979s\n",
      "batch 9935, train_loss 0.003749,Time used 0.007978s\n",
      "batch 9936, train_loss 0.003701,Time used 0.007978s\n",
      "batch 9937, train_loss 0.003487,Time used 0.007979s\n",
      "batch 9938, train_loss 0.004941,Time used 0.007979s\n",
      "batch 9939, train_loss 0.003574,Time used 0.008976s\n",
      "batch 9940, train_loss 0.003345,Time used 0.007979s\n",
      "batch 9941, train_loss 0.003948,Time used 0.008976s\n",
      "batch 9942, train_loss 0.002883,Time used 0.007978s\n",
      "batch 9943, train_loss 0.004123,Time used 0.008977s\n",
      "batch 9944, train_loss 0.003894,Time used 0.007978s\n",
      "batch 9945, train_loss 0.003153,Time used 0.008976s\n",
      "batch 9946, train_loss 0.003106,Time used 0.007979s\n",
      "batch 9947, train_loss 0.002551,Time used 0.007978s\n",
      "batch 9948, train_loss 0.002825,Time used 0.007979s\n",
      "batch 9949, train_loss 0.003499,Time used 0.008977s\n",
      "batch 9950, train_loss 0.003543,Time used 0.007978s\n",
      "batch 9951, train_loss 0.002569,Time used 0.006982s\n",
      "batch 9952, train_loss 0.003747,Time used 0.008977s\n",
      "batch 9953, train_loss 0.003447,Time used 0.008975s\n",
      "batch 9954, train_loss 0.003321,Time used 0.007979s\n",
      "batch 9955, train_loss 0.002939,Time used 0.007978s\n",
      "batch 9956, train_loss 0.003419,Time used 0.007979s\n",
      "batch 9957, train_loss 0.004215,Time used 0.007979s\n",
      "batch 9958, train_loss 0.003574,Time used 0.008975s\n",
      "batch 9959, train_loss 0.003057,Time used 0.008976s\n",
      "batch 9960, train_loss 0.003765,Time used 0.007978s\n",
      "batch 9961, train_loss 0.003344,Time used 0.007979s\n",
      "batch 9962, train_loss 0.003135,Time used 0.008976s\n",
      "batch 9963, train_loss 0.003214,Time used 0.007979s\n",
      "batch 9964, train_loss 0.003474,Time used 0.008976s\n",
      "batch 9965, train_loss 0.004252,Time used 0.007979s\n",
      "batch 9966, train_loss 0.004040,Time used 0.007978s\n",
      "batch 9967, train_loss 0.003952,Time used 0.007978s\n",
      "batch 9968, train_loss 0.002914,Time used 0.007979s\n",
      "batch 9969, train_loss 0.003137,Time used 0.008976s\n",
      "batch 9970, train_loss 0.005179,Time used 0.009974s\n",
      "batch 9971, train_loss 0.003921,Time used 0.007978s\n",
      "batch 9972, train_loss 0.004318,Time used 0.007979s\n",
      "batch 9973, train_loss 0.003351,Time used 0.007980s\n",
      "batch 9974, train_loss 0.003511,Time used 0.008975s\n",
      "batch 9975, train_loss 0.004166,Time used 0.007979s\n",
      "batch 9976, train_loss 0.003450,Time used 0.007978s\n",
      "batch 9977, train_loss 0.003660,Time used 0.007979s\n",
      "batch 9978, train_loss 0.002820,Time used 0.007979s\n",
      "batch 9979, train_loss 0.003571,Time used 0.007980s\n",
      "batch 9980, train_loss 0.003908,Time used 0.007979s\n",
      "batch 9981, train_loss 0.004321,Time used 0.007978s\n",
      "batch 9982, train_loss 0.003423,Time used 0.007979s\n",
      "batch 9983, train_loss 0.003010,Time used 0.007979s\n",
      "batch 9984, train_loss 0.003518,Time used 0.007979s\n",
      "batch 9985, train_loss 0.002934,Time used 0.007979s\n",
      "batch 9986, train_loss 0.002824,Time used 0.007978s\n",
      "batch 9987, train_loss 0.003264,Time used 0.007980s\n",
      "batch 9988, train_loss 0.002834,Time used 0.008975s\n",
      "batch 9989, train_loss 0.006224,Time used 0.007979s\n",
      "batch 9990, train_loss 0.003519,Time used 0.007979s\n",
      "batch 9991, train_loss 0.003606,Time used 0.008976s\n",
      "batch 9992, train_loss 0.002567,Time used 0.008976s\n",
      "batch 9993, train_loss 0.002988,Time used 0.007978s\n",
      "batch 9994, train_loss 0.003404,Time used 0.007979s\n",
      "batch 9995, train_loss 0.004016,Time used 0.007978s\n",
      "batch 9996, train_loss 0.003440,Time used 0.008976s\n",
      "batch 9997, train_loss 0.003754,Time used 0.007979s\n",
      "batch 9998, train_loss 0.001932,Time used 0.007978s\n",
      "batch 9999, train_loss 0.003127,Time used 0.007979s\n",
      "batch 10000, train_loss 0.007911,Time used 0.008975s\n",
      "***************************test_batch 10000, test_rmse_loss 0.060860,test_mae_loss 0.043427,test_mape_loss 13.097981,Time used 0.110705s\n",
      "batch 10001, train_loss 0.003929,Time used 0.009485s\n",
      "batch 10002, train_loss 0.003875,Time used 0.009974s\n",
      "batch 10003, train_loss 0.003682,Time used 0.007978s\n",
      "batch 10004, train_loss 0.004479,Time used 0.009973s\n",
      "batch 10005, train_loss 0.004345,Time used 0.009973s\n",
      "batch 10006, train_loss 0.003879,Time used 0.008976s\n",
      "batch 10007, train_loss 0.004808,Time used 0.009973s\n",
      "batch 10008, train_loss 0.003089,Time used 0.008976s\n",
      "batch 10009, train_loss 0.004483,Time used 0.008976s\n",
      "batch 10010, train_loss 0.003687,Time used 0.007980s\n",
      "batch 10011, train_loss 0.004004,Time used 0.008975s\n",
      "batch 10012, train_loss 0.004636,Time used 0.008977s\n",
      "batch 10013, train_loss 0.002965,Time used 0.007979s\n",
      "batch 10014, train_loss 0.003124,Time used 0.008976s\n",
      "batch 10015, train_loss 0.002818,Time used 0.007979s\n",
      "batch 10016, train_loss 0.003987,Time used 0.008976s\n",
      "batch 10017, train_loss 0.002801,Time used 0.008977s\n",
      "batch 10018, train_loss 0.003998,Time used 0.007979s\n",
      "batch 10019, train_loss 0.003432,Time used 0.008976s\n",
      "batch 10020, train_loss 0.004315,Time used 0.009974s\n",
      "batch 10021, train_loss 0.002960,Time used 0.008976s\n",
      "batch 10022, train_loss 0.001882,Time used 0.007978s\n",
      "batch 10023, train_loss 0.003198,Time used 0.008976s\n",
      "batch 10024, train_loss 0.002893,Time used 0.008975s\n",
      "batch 10025, train_loss 0.005643,Time used 0.008976s\n",
      "batch 10026, train_loss 0.004251,Time used 0.008976s\n",
      "batch 10027, train_loss 0.003629,Time used 0.008976s\n",
      "batch 10028, train_loss 0.003007,Time used 0.008976s\n",
      "batch 10029, train_loss 0.003269,Time used 0.008976s\n",
      "batch 10030, train_loss 0.002549,Time used 0.007979s\n",
      "batch 10031, train_loss 0.004154,Time used 0.007979s\n",
      "batch 10032, train_loss 0.003800,Time used 0.007978s\n",
      "batch 10033, train_loss 0.003347,Time used 0.007979s\n",
      "batch 10034, train_loss 0.003740,Time used 0.008976s\n",
      "batch 10035, train_loss 0.004766,Time used 0.007978s\n",
      "batch 10036, train_loss 0.002791,Time used 0.008977s\n",
      "batch 10037, train_loss 0.004481,Time used 0.007978s\n",
      "batch 10038, train_loss 0.004407,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 10039, train_loss 0.004459,Time used 0.007979s\n",
      "batch 10040, train_loss 0.002621,Time used 0.008977s\n",
      "batch 10041, train_loss 0.003446,Time used 0.007979s\n",
      "batch 10042, train_loss 0.004482,Time used 0.008976s\n",
      "batch 10043, train_loss 0.003164,Time used 0.008976s\n",
      "batch 10044, train_loss 0.003220,Time used 0.007979s\n",
      "batch 10045, train_loss 0.004598,Time used 0.007979s\n",
      "batch 10046, train_loss 0.002636,Time used 0.007979s\n",
      "batch 10047, train_loss 0.003807,Time used 0.009974s\n",
      "batch 10048, train_loss 0.003743,Time used 0.007978s\n",
      "batch 10049, train_loss 0.003830,Time used 0.008976s\n",
      "batch 10050, train_loss 0.002766,Time used 0.007979s\n",
      "batch 10051, train_loss 0.003691,Time used 0.008977s\n",
      "batch 10052, train_loss 0.002668,Time used 0.008975s\n",
      "batch 10053, train_loss 0.002902,Time used 0.009974s\n",
      "batch 10054, train_loss 0.002763,Time used 0.007978s\n",
      "batch 10055, train_loss 0.003575,Time used 0.008976s\n",
      "batch 10056, train_loss 0.003623,Time used 0.006982s\n",
      "batch 10057, train_loss 0.004088,Time used 0.006981s\n",
      "batch 10058, train_loss 0.005844,Time used 0.005984s\n",
      "batch 10059, train_loss 0.003470,Time used 0.008977s\n",
      "batch 10060, train_loss 0.004171,Time used 0.006982s\n",
      "batch 10061, train_loss 0.003393,Time used 0.008977s\n",
      "batch 10062, train_loss 0.003689,Time used 0.007979s\n",
      "batch 10063, train_loss 0.003118,Time used 0.008976s\n",
      "batch 10064, train_loss 0.003580,Time used 0.008976s\n",
      "batch 10065, train_loss 0.003744,Time used 0.008977s\n",
      "batch 10066, train_loss 0.003210,Time used 0.008976s\n",
      "batch 10067, train_loss 0.002867,Time used 0.008976s\n",
      "batch 10068, train_loss 0.004006,Time used 0.007979s\n",
      "batch 10069, train_loss 0.002696,Time used 0.007979s\n",
      "batch 10070, train_loss 0.002861,Time used 0.007978s\n",
      "batch 10071, train_loss 0.004316,Time used 0.008977s\n",
      "batch 10072, train_loss 0.003802,Time used 0.008976s\n",
      "batch 10073, train_loss 0.006688,Time used 0.009973s\n",
      "batch 10074, train_loss 0.003244,Time used 0.008976s\n",
      "batch 10075, train_loss 0.003638,Time used 0.007979s\n",
      "batch 10076, train_loss 0.002612,Time used 0.007979s\n",
      "batch 10077, train_loss 0.004060,Time used 0.008977s\n",
      "batch 10078, train_loss 0.002253,Time used 0.009973s\n",
      "batch 10079, train_loss 0.003856,Time used 0.008976s\n",
      "batch 10080, train_loss 0.004367,Time used 0.009974s\n",
      "batch 10081, train_loss 0.003261,Time used 0.010970s\n",
      "batch 10082, train_loss 0.002481,Time used 0.008976s\n",
      "batch 10083, train_loss 0.004028,Time used 0.008976s\n",
      "batch 10084, train_loss 0.004018,Time used 0.008976s\n",
      "batch 10085, train_loss 0.003877,Time used 0.009973s\n",
      "batch 10086, train_loss 0.003560,Time used 0.008976s\n",
      "batch 10087, train_loss 0.003462,Time used 0.008976s\n",
      "batch 10088, train_loss 0.003135,Time used 0.008976s\n",
      "batch 10089, train_loss 0.003061,Time used 0.008976s\n",
      "batch 10090, train_loss 0.003790,Time used 0.008976s\n",
      "batch 10091, train_loss 0.004109,Time used 0.007979s\n",
      "batch 10092, train_loss 0.004738,Time used 0.007978s\n",
      "batch 10093, train_loss 0.003135,Time used 0.007979s\n",
      "batch 10094, train_loss 0.003125,Time used 0.008976s\n",
      "batch 10095, train_loss 0.004705,Time used 0.008977s\n",
      "batch 10096, train_loss 0.003715,Time used 0.008976s\n",
      "batch 10097, train_loss 0.004736,Time used 0.008976s\n",
      "batch 10098, train_loss 0.003800,Time used 0.008976s\n",
      "batch 10099, train_loss 0.003127,Time used 0.008976s\n",
      "batch 10100, train_loss 0.003629,Time used 0.007977s\n",
      "***************************test_batch 10100, test_rmse_loss 0.060975,test_mae_loss 0.043522,test_mape_loss 13.120235,Time used 0.109706s\n",
      "batch 10101, train_loss 0.003108,Time used 0.008978s\n",
      "batch 10102, train_loss 0.004105,Time used 0.008975s\n",
      "batch 10103, train_loss 0.003865,Time used 0.008976s\n",
      "batch 10104, train_loss 0.002993,Time used 0.008976s\n",
      "batch 10105, train_loss 0.004133,Time used 0.008976s\n",
      "batch 10106, train_loss 0.003281,Time used 0.008976s\n",
      "batch 10107, train_loss 0.003693,Time used 0.007978s\n",
      "batch 10108, train_loss 0.003636,Time used 0.007979s\n",
      "batch 10109, train_loss 0.004640,Time used 0.008975s\n",
      "batch 10110, train_loss 0.004431,Time used 0.007979s\n",
      "batch 10111, train_loss 0.002761,Time used 0.007978s\n",
      "batch 10112, train_loss 0.002491,Time used 0.007979s\n",
      "batch 10113, train_loss 0.002311,Time used 0.008977s\n",
      "batch 10114, train_loss 0.002866,Time used 0.007978s\n",
      "batch 10115, train_loss 0.003456,Time used 0.007979s\n",
      "batch 10116, train_loss 0.003592,Time used 0.007979s\n",
      "batch 10117, train_loss 0.003813,Time used 0.007979s\n",
      "batch 10118, train_loss 0.004804,Time used 0.007979s\n",
      "batch 10119, train_loss 0.003236,Time used 0.008975s\n",
      "batch 10120, train_loss 0.002932,Time used 0.008976s\n",
      "batch 10121, train_loss 0.003307,Time used 0.007979s\n",
      "batch 10122, train_loss 0.003555,Time used 0.009974s\n",
      "batch 10123, train_loss 0.004330,Time used 0.007979s\n",
      "batch 10124, train_loss 0.003241,Time used 0.008977s\n",
      "batch 10125, train_loss 0.003864,Time used 0.008975s\n",
      "batch 10126, train_loss 0.003181,Time used 0.008976s\n",
      "batch 10127, train_loss 0.003248,Time used 0.007979s\n",
      "batch 10128, train_loss 0.003153,Time used 0.008975s\n",
      "batch 10129, train_loss 0.004005,Time used 0.008976s\n",
      "batch 10130, train_loss 0.002428,Time used 0.008976s\n",
      "batch 10131, train_loss 0.003406,Time used 0.008976s\n",
      "batch 10132, train_loss 0.002862,Time used 0.008975s\n",
      "batch 10133, train_loss 0.004636,Time used 0.007979s\n",
      "batch 10134, train_loss 0.003908,Time used 0.007979s\n",
      "batch 10135, train_loss 0.004644,Time used 0.007978s\n",
      "batch 10136, train_loss 0.003566,Time used 0.007979s\n",
      "batch 10137, train_loss 0.003972,Time used 0.008976s\n",
      "batch 10138, train_loss 0.002610,Time used 0.008976s\n",
      "batch 10139, train_loss 0.004950,Time used 0.008976s\n",
      "batch 10140, train_loss 0.003717,Time used 0.008976s\n",
      "batch 10141, train_loss 0.003221,Time used 0.008976s\n",
      "batch 10142, train_loss 0.003279,Time used 0.008975s\n",
      "batch 10143, train_loss 0.004373,Time used 0.008975s\n",
      "batch 10144, train_loss 0.005692,Time used 0.007979s\n",
      "batch 10145, train_loss 0.003292,Time used 0.008976s\n",
      "batch 10146, train_loss 0.004035,Time used 0.008976s\n",
      "batch 10147, train_loss 0.002703,Time used 0.007979s\n",
      "batch 10148, train_loss 0.003821,Time used 0.007979s\n",
      "batch 10149, train_loss 0.003793,Time used 0.008976s\n",
      "batch 10150, train_loss 0.003269,Time used 0.009012s\n",
      "batch 10151, train_loss 0.003930,Time used 0.007979s\n",
      "batch 10152, train_loss 0.003359,Time used 0.008976s\n",
      "batch 10153, train_loss 0.003940,Time used 0.008976s\n",
      "batch 10154, train_loss 0.002623,Time used 0.008976s\n",
      "batch 10155, train_loss 0.003723,Time used 0.008976s\n",
      "batch 10156, train_loss 0.003341,Time used 0.008977s\n",
      "batch 10157, train_loss 0.004047,Time used 0.008976s\n",
      "batch 10158, train_loss 0.004205,Time used 0.008976s\n",
      "batch 10159, train_loss 0.003489,Time used 0.008976s\n",
      "batch 10160, train_loss 0.003575,Time used 0.008977s\n",
      "batch 10161, train_loss 0.004049,Time used 0.008975s\n",
      "batch 10162, train_loss 0.004291,Time used 0.008976s\n",
      "batch 10163, train_loss 0.004683,Time used 0.009974s\n",
      "batch 10164, train_loss 0.003792,Time used 0.009974s\n",
      "batch 10165, train_loss 0.002041,Time used 0.006981s\n",
      "batch 10166, train_loss 0.003089,Time used 0.008977s\n",
      "batch 10167, train_loss 0.003741,Time used 0.008976s\n",
      "batch 10168, train_loss 0.003778,Time used 0.008976s\n",
      "batch 10169, train_loss 0.003687,Time used 0.008976s\n",
      "batch 10170, train_loss 0.002890,Time used 0.009973s\n",
      "batch 10171, train_loss 0.003657,Time used 0.009974s\n",
      "batch 10172, train_loss 0.003101,Time used 0.009484s\n",
      "batch 10173, train_loss 0.003459,Time used 0.008975s\n",
      "batch 10174, train_loss 0.002964,Time used 0.008976s\n",
      "batch 10175, train_loss 0.003810,Time used 0.008976s\n",
      "batch 10176, train_loss 0.003384,Time used 0.008976s\n",
      "batch 10177, train_loss 0.003398,Time used 0.008975s\n",
      "batch 10178, train_loss 0.003462,Time used 0.008975s\n",
      "batch 10179, train_loss 0.003881,Time used 0.007979s\n",
      "batch 10180, train_loss 0.005686,Time used 0.008976s\n",
      "batch 10181, train_loss 0.003079,Time used 0.006981s\n",
      "batch 10182, train_loss 0.002842,Time used 0.006982s\n",
      "batch 10183, train_loss 0.003609,Time used 0.009974s\n",
      "batch 10184, train_loss 0.004497,Time used 0.007978s\n",
      "batch 10185, train_loss 0.003536,Time used 0.008976s\n",
      "batch 10186, train_loss 0.004022,Time used 0.007979s\n",
      "batch 10187, train_loss 0.004113,Time used 0.007979s\n",
      "batch 10188, train_loss 0.002961,Time used 0.008976s\n",
      "batch 10189, train_loss 0.005974,Time used 0.007978s\n",
      "batch 10190, train_loss 0.003053,Time used 0.007979s\n",
      "batch 10191, train_loss 0.003236,Time used 0.006981s\n",
      "batch 10192, train_loss 0.003266,Time used 0.007979s\n",
      "batch 10193, train_loss 0.002416,Time used 0.007979s\n",
      "batch 10194, train_loss 0.002876,Time used 0.008976s\n",
      "batch 10195, train_loss 0.002623,Time used 0.006981s\n",
      "batch 10196, train_loss 0.003374,Time used 0.007979s\n",
      "batch 10197, train_loss 0.003188,Time used 0.007979s\n",
      "batch 10198, train_loss 0.003807,Time used 0.007979s\n",
      "batch 10199, train_loss 0.003143,Time used 0.008975s\n",
      "batch 10200, train_loss 0.002861,Time used 0.007978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************test_batch 10200, test_rmse_loss 0.060771,test_mae_loss 0.043305,test_mape_loss 12.916238,Time used 0.113695s\n",
      "batch 10201, train_loss 0.002864,Time used 0.008976s\n",
      "batch 10202, train_loss 0.003886,Time used 0.008976s\n",
      "batch 10203, train_loss 0.003610,Time used 0.008976s\n",
      "batch 10204, train_loss 0.003593,Time used 0.007979s\n",
      "batch 10205, train_loss 0.003973,Time used 0.008976s\n",
      "batch 10206, train_loss 0.003158,Time used 0.008976s\n",
      "batch 10207, train_loss 0.003522,Time used 0.008975s\n",
      "batch 10208, train_loss 0.003794,Time used 0.008976s\n",
      "batch 10209, train_loss 0.005920,Time used 0.008976s\n",
      "batch 10210, train_loss 0.004488,Time used 0.009974s\n",
      "batch 10211, train_loss 0.002673,Time used 0.007978s\n",
      "batch 10212, train_loss 0.003388,Time used 0.008977s\n",
      "batch 10213, train_loss 0.004543,Time used 0.008975s\n",
      "batch 10214, train_loss 0.003575,Time used 0.007979s\n",
      "batch 10215, train_loss 0.002416,Time used 0.009974s\n",
      "batch 10216, train_loss 0.005534,Time used 0.009973s\n",
      "batch 10217, train_loss 0.003538,Time used 0.008977s\n",
      "batch 10218, train_loss 0.003012,Time used 0.011969s\n",
      "batch 10219, train_loss 0.004322,Time used 0.019947s\n",
      "batch 10220, train_loss 0.003159,Time used 0.011968s\n",
      "batch 10221, train_loss 0.003707,Time used 0.018949s\n",
      "batch 10222, train_loss 0.004795,Time used 0.010971s\n",
      "batch 10223, train_loss 0.002978,Time used 0.010971s\n",
      "batch 10224, train_loss 0.004059,Time used 0.022938s\n",
      "batch 10225, train_loss 0.003685,Time used 0.013962s\n",
      "batch 10226, train_loss 0.003953,Time used 0.009973s\n",
      "batch 10227, train_loss 0.002490,Time used 0.010971s\n",
      "batch 10228, train_loss 0.002908,Time used 0.010971s\n",
      "batch 10229, train_loss 0.004282,Time used 0.009972s\n",
      "batch 10230, train_loss 0.002964,Time used 0.010971s\n",
      "batch 10231, train_loss 0.004166,Time used 0.008976s\n",
      "batch 10232, train_loss 0.003993,Time used 0.010971s\n",
      "batch 10233, train_loss 0.005701,Time used 0.009973s\n",
      "batch 10234, train_loss 0.003016,Time used 0.009973s\n",
      "batch 10235, train_loss 0.002079,Time used 0.010970s\n",
      "batch 10236, train_loss 0.003903,Time used 0.009974s\n",
      "batch 10237, train_loss 0.003105,Time used 0.009973s\n",
      "batch 10238, train_loss 0.002808,Time used 0.009974s\n",
      "batch 10239, train_loss 0.004300,Time used 0.008976s\n",
      "batch 10240, train_loss 0.005018,Time used 0.008976s\n",
      "batch 10241, train_loss 0.003583,Time used 0.009974s\n",
      "batch 10242, train_loss 0.003855,Time used 0.008976s\n",
      "batch 10243, train_loss 0.003781,Time used 0.009973s\n",
      "batch 10244, train_loss 0.003633,Time used 0.009974s\n",
      "batch 10245, train_loss 0.003975,Time used 0.007979s\n",
      "batch 10246, train_loss 0.003350,Time used 0.008976s\n",
      "batch 10247, train_loss 0.003729,Time used 0.008976s\n",
      "batch 10248, train_loss 0.002910,Time used 0.009973s\n",
      "batch 10249, train_loss 0.002863,Time used 0.009974s\n",
      "batch 10250, train_loss 0.002867,Time used 0.008976s\n",
      "batch 10251, train_loss 0.003654,Time used 0.009974s\n",
      "batch 10252, train_loss 0.003592,Time used 0.008976s\n",
      "batch 10253, train_loss 0.003437,Time used 0.008976s\n",
      "batch 10254, train_loss 0.003299,Time used 0.010972s\n",
      "batch 10255, train_loss 0.003868,Time used 0.008975s\n",
      "batch 10256, train_loss 0.003393,Time used 0.008976s\n",
      "batch 10257, train_loss 0.003250,Time used 0.008975s\n",
      "batch 10258, train_loss 0.003318,Time used 0.011968s\n",
      "batch 10259, train_loss 0.003092,Time used 0.009973s\n",
      "batch 10260, train_loss 0.003677,Time used 0.009974s\n",
      "batch 10261, train_loss 0.004884,Time used 0.009973s\n",
      "batch 10262, train_loss 0.004825,Time used 0.008976s\n",
      "batch 10263, train_loss 0.003147,Time used 0.008993s\n",
      "batch 10264, train_loss 0.004482,Time used 0.008976s\n",
      "batch 10265, train_loss 0.003407,Time used 0.008977s\n",
      "batch 10266, train_loss 0.003520,Time used 0.008976s\n",
      "batch 10267, train_loss 0.003504,Time used 0.008977s\n",
      "batch 10268, train_loss 0.002826,Time used 0.007979s\n",
      "batch 10269, train_loss 0.005808,Time used 0.008975s\n",
      "batch 10270, train_loss 0.003277,Time used 0.008977s\n",
      "batch 10271, train_loss 0.004218,Time used 0.007978s\n",
      "batch 10272, train_loss 0.008457,Time used 0.007979s\n",
      "batch 10273, train_loss 0.003629,Time used 0.008976s\n",
      "batch 10274, train_loss 0.004296,Time used 0.008975s\n",
      "batch 10275, train_loss 0.003571,Time used 0.008976s\n",
      "batch 10276, train_loss 0.003692,Time used 0.007978s\n",
      "batch 10277, train_loss 0.002966,Time used 0.007979s\n",
      "batch 10278, train_loss 0.003934,Time used 0.007979s\n",
      "batch 10279, train_loss 0.004282,Time used 0.007978s\n",
      "batch 10280, train_loss 0.004912,Time used 0.007979s\n",
      "batch 10281, train_loss 0.003582,Time used 0.008976s\n",
      "batch 10282, train_loss 0.004068,Time used 0.008975s\n",
      "batch 10283, train_loss 0.004301,Time used 0.007978s\n",
      "batch 10284, train_loss 0.002590,Time used 0.008977s\n",
      "batch 10285, train_loss 0.003100,Time used 0.007978s\n",
      "batch 10286, train_loss 0.003680,Time used 0.007978s\n",
      "batch 10287, train_loss 0.008832,Time used 0.008976s\n",
      "batch 10288, train_loss 0.003256,Time used 0.008975s\n",
      "batch 10289, train_loss 0.004021,Time used 0.008977s\n",
      "batch 10290, train_loss 0.002534,Time used 0.008976s\n",
      "batch 10291, train_loss 0.003647,Time used 0.009973s\n",
      "batch 10292, train_loss 0.004068,Time used 0.009974s\n",
      "batch 10293, train_loss 0.003587,Time used 0.009974s\n",
      "batch 10294, train_loss 0.003351,Time used 0.008976s\n",
      "batch 10295, train_loss 0.004485,Time used 0.008976s\n",
      "batch 10296, train_loss 0.003854,Time used 0.009973s\n",
      "batch 10297, train_loss 0.002433,Time used 0.008976s\n",
      "batch 10298, train_loss 0.003447,Time used 0.008975s\n",
      "batch 10299, train_loss 0.003769,Time used 0.008976s\n",
      "batch 10300, train_loss 0.004684,Time used 0.009974s\n",
      "***************************test_batch 10300, test_rmse_loss 0.062142,test_mae_loss 0.044463,test_mape_loss 13.667587,Time used 0.120718s\n",
      "batch 10301, train_loss 0.003800,Time used 0.009973s\n",
      "batch 10302, train_loss 0.002974,Time used 0.008976s\n",
      "batch 10303, train_loss 0.003293,Time used 0.008976s\n",
      "batch 10304, train_loss 0.003935,Time used 0.009974s\n",
      "batch 10305, train_loss 0.004292,Time used 0.008976s\n",
      "batch 10306, train_loss 0.003461,Time used 0.009973s\n",
      "batch 10307, train_loss 0.003379,Time used 0.006981s\n",
      "batch 10308, train_loss 0.003011,Time used 0.007979s\n",
      "batch 10309, train_loss 0.004085,Time used 0.006981s\n",
      "batch 10310, train_loss 0.002967,Time used 0.008976s\n",
      "batch 10311, train_loss 0.002691,Time used 0.007978s\n",
      "batch 10312, train_loss 0.002690,Time used 0.008976s\n",
      "batch 10313, train_loss 0.003739,Time used 0.008977s\n",
      "batch 10314, train_loss 0.004346,Time used 0.008976s\n",
      "batch 10315, train_loss 0.003200,Time used 0.009974s\n",
      "batch 10316, train_loss 0.002971,Time used 0.008975s\n",
      "batch 10317, train_loss 0.003197,Time used 0.008976s\n",
      "batch 10318, train_loss 0.004666,Time used 0.008977s\n",
      "batch 10319, train_loss 0.003106,Time used 0.008976s\n",
      "batch 10320, train_loss 0.003925,Time used 0.011968s\n",
      "batch 10321, train_loss 0.004840,Time used 0.009974s\n",
      "batch 10322, train_loss 0.002460,Time used 0.008976s\n",
      "batch 10323, train_loss 0.004098,Time used 0.011968s\n",
      "batch 10324, train_loss 0.003667,Time used 0.009973s\n",
      "batch 10325, train_loss 0.002992,Time used 0.009973s\n",
      "batch 10326, train_loss 0.003381,Time used 0.008977s\n",
      "batch 10327, train_loss 0.003657,Time used 0.008976s\n",
      "batch 10328, train_loss 0.004836,Time used 0.010970s\n",
      "batch 10329, train_loss 0.003813,Time used 0.007979s\n",
      "batch 10330, train_loss 0.004573,Time used 0.009973s\n",
      "batch 10331, train_loss 0.003391,Time used 0.009974s\n",
      "batch 10332, train_loss 0.004175,Time used 0.009972s\n",
      "batch 10333, train_loss 0.003122,Time used 0.009974s\n",
      "batch 10334, train_loss 0.004194,Time used 0.008976s\n",
      "batch 10335, train_loss 0.003762,Time used 0.009974s\n",
      "batch 10336, train_loss 0.003639,Time used 0.008976s\n",
      "batch 10337, train_loss 0.003495,Time used 0.008977s\n",
      "batch 10338, train_loss 0.003344,Time used 0.008976s\n",
      "batch 10339, train_loss 0.004986,Time used 0.007979s\n",
      "batch 10340, train_loss 0.003045,Time used 0.008976s\n",
      "batch 10341, train_loss 0.003041,Time used 0.008976s\n",
      "batch 10342, train_loss 0.003173,Time used 0.009974s\n",
      "batch 10343, train_loss 0.002973,Time used 0.009973s\n",
      "batch 10344, train_loss 0.003045,Time used 0.008976s\n",
      "batch 10345, train_loss 0.004630,Time used 0.008976s\n",
      "batch 10346, train_loss 0.002902,Time used 0.008976s\n",
      "batch 10347, train_loss 0.003384,Time used 0.008976s\n",
      "batch 10348, train_loss 0.002784,Time used 0.008976s\n",
      "batch 10349, train_loss 0.004161,Time used 0.008975s\n",
      "batch 10350, train_loss 0.004087,Time used 0.009974s\n",
      "batch 10351, train_loss 0.004639,Time used 0.007978s\n",
      "batch 10352, train_loss 0.003719,Time used 0.008976s\n",
      "batch 10353, train_loss 0.003631,Time used 0.008976s\n",
      "batch 10354, train_loss 0.003501,Time used 0.008976s\n",
      "batch 10355, train_loss 0.004329,Time used 0.007978s\n",
      "batch 10356, train_loss 0.003837,Time used 0.008977s\n",
      "batch 10357, train_loss 0.003693,Time used 0.008975s\n",
      "batch 10358, train_loss 0.003332,Time used 0.008976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 10359, train_loss 0.003373,Time used 0.008976s\n",
      "batch 10360, train_loss 0.003133,Time used 0.008976s\n",
      "batch 10361, train_loss 0.003733,Time used 0.008976s\n",
      "batch 10362, train_loss 0.003683,Time used 0.008976s\n",
      "batch 10363, train_loss 0.002795,Time used 0.009973s\n",
      "batch 10364, train_loss 0.004892,Time used 0.008976s\n",
      "batch 10365, train_loss 0.003363,Time used 0.008976s\n",
      "batch 10366, train_loss 0.004071,Time used 0.008977s\n",
      "batch 10367, train_loss 0.003034,Time used 0.008975s\n",
      "batch 10368, train_loss 0.004195,Time used 0.008976s\n",
      "batch 10369, train_loss 0.003253,Time used 0.008977s\n",
      "batch 10370, train_loss 0.004043,Time used 0.008975s\n",
      "batch 10371, train_loss 0.003295,Time used 0.008977s\n",
      "batch 10372, train_loss 0.003873,Time used 0.008976s\n",
      "batch 10373, train_loss 0.002872,Time used 0.008977s\n",
      "batch 10374, train_loss 0.003484,Time used 0.008975s\n",
      "batch 10375, train_loss 0.003814,Time used 0.008977s\n",
      "batch 10376, train_loss 0.003591,Time used 0.007978s\n",
      "batch 10377, train_loss 0.003277,Time used 0.008976s\n",
      "batch 10378, train_loss 0.003668,Time used 0.008976s\n",
      "batch 10379, train_loss 0.001367,Time used 0.006981s\n",
      "batch 10380, train_loss 0.003854,Time used 0.009973s\n",
      "batch 10381, train_loss 0.005027,Time used 0.008976s\n",
      "batch 10382, train_loss 0.003515,Time used 0.008976s\n",
      "batch 10383, train_loss 0.004209,Time used 0.008976s\n",
      "batch 10384, train_loss 0.004081,Time used 0.008976s\n",
      "batch 10385, train_loss 0.003359,Time used 0.007978s\n",
      "batch 10386, train_loss 0.003179,Time used 0.008975s\n",
      "batch 10387, train_loss 0.003191,Time used 0.008976s\n",
      "batch 10388, train_loss 0.002669,Time used 0.008976s\n",
      "batch 10389, train_loss 0.005012,Time used 0.009973s\n",
      "batch 10390, train_loss 0.005626,Time used 0.009973s\n",
      "batch 10391, train_loss 0.003510,Time used 0.036902s\n",
      "batch 10392, train_loss 0.004807,Time used 0.009973s\n",
      "batch 10393, train_loss 0.002953,Time used 0.010970s\n",
      "batch 10394, train_loss 0.002998,Time used 0.009974s\n",
      "batch 10395, train_loss 0.003701,Time used 0.009973s\n",
      "batch 10396, train_loss 0.004924,Time used 0.009973s\n",
      "batch 10397, train_loss 0.003782,Time used 0.008976s\n",
      "batch 10398, train_loss 0.003381,Time used 0.008975s\n",
      "batch 10399, train_loss 0.003977,Time used 0.009973s\n",
      "batch 10400, train_loss 0.004659,Time used 0.008977s\n",
      "***************************test_batch 10400, test_rmse_loss 0.060752,test_mae_loss 0.043285,test_mape_loss 12.900108,Time used 0.128657s\n",
      "batch 10401, train_loss 0.002847,Time used 0.010971s\n",
      "batch 10402, train_loss 0.003316,Time used 0.009974s\n",
      "batch 10403, train_loss 0.003257,Time used 0.009973s\n",
      "batch 10404, train_loss 0.003485,Time used 0.009973s\n",
      "batch 10405, train_loss 0.003413,Time used 0.009974s\n",
      "batch 10406, train_loss 0.003146,Time used 0.009974s\n",
      "batch 10407, train_loss 0.003733,Time used 0.008976s\n",
      "batch 10408, train_loss 0.004074,Time used 0.009973s\n",
      "batch 10409, train_loss 0.003730,Time used 0.009974s\n",
      "batch 10410, train_loss 0.003676,Time used 0.009973s\n",
      "batch 10411, train_loss 0.003175,Time used 0.009974s\n",
      "batch 10412, train_loss 0.004774,Time used 0.008975s\n",
      "batch 10413, train_loss 0.003253,Time used 0.010971s\n",
      "batch 10414, train_loss 0.002864,Time used 0.009973s\n",
      "batch 10415, train_loss 0.004150,Time used 0.007978s\n",
      "batch 10416, train_loss 0.004310,Time used 0.008976s\n",
      "batch 10417, train_loss 0.003740,Time used 0.008975s\n",
      "batch 10418, train_loss 0.003303,Time used 0.009973s\n",
      "batch 10419, train_loss 0.003529,Time used 0.008976s\n",
      "batch 10420, train_loss 0.005228,Time used 0.009973s\n",
      "batch 10421, train_loss 0.002410,Time used 0.010972s\n",
      "batch 10422, train_loss 0.002434,Time used 0.009972s\n",
      "batch 10423, train_loss 0.003752,Time used 0.008975s\n",
      "batch 10424, train_loss 0.003396,Time used 0.009974s\n",
      "batch 10425, train_loss 0.004257,Time used 0.008976s\n",
      "batch 10426, train_loss 0.003158,Time used 0.009973s\n",
      "batch 10427, train_loss 0.003683,Time used 0.009974s\n",
      "batch 10428, train_loss 0.003256,Time used 0.008976s\n",
      "batch 10429, train_loss 0.003133,Time used 0.009973s\n",
      "batch 10430, train_loss 0.003472,Time used 0.009973s\n",
      "batch 10431, train_loss 0.004056,Time used 0.009974s\n",
      "batch 10432, train_loss 0.002962,Time used 0.008976s\n",
      "batch 10433, train_loss 0.003829,Time used 0.008977s\n",
      "batch 10434, train_loss 0.002982,Time used 0.008976s\n",
      "batch 10435, train_loss 0.002720,Time used 0.008977s\n",
      "batch 10436, train_loss 0.003272,Time used 0.008976s\n",
      "batch 10437, train_loss 0.003795,Time used 0.008977s\n",
      "batch 10438, train_loss 0.004163,Time used 0.009973s\n",
      "batch 10439, train_loss 0.003384,Time used 0.009974s\n",
      "batch 10440, train_loss 0.002998,Time used 0.008976s\n",
      "batch 10441, train_loss 0.002057,Time used 0.009974s\n",
      "batch 10442, train_loss 0.004122,Time used 0.009973s\n",
      "batch 10443, train_loss 0.004256,Time used 0.008976s\n",
      "batch 10444, train_loss 0.003370,Time used 0.008976s\n",
      "batch 10445, train_loss 0.003288,Time used 0.008976s\n",
      "batch 10446, train_loss 0.004361,Time used 0.008977s\n",
      "batch 10447, train_loss 0.003609,Time used 0.008977s\n",
      "batch 10448, train_loss 0.003565,Time used 0.008976s\n",
      "batch 10449, train_loss 0.003587,Time used 0.008976s\n",
      "batch 10450, train_loss 0.003633,Time used 0.008975s\n",
      "batch 10451, train_loss 0.003148,Time used 0.009974s\n",
      "batch 10452, train_loss 0.002414,Time used 0.008976s\n",
      "batch 10453, train_loss 0.003764,Time used 0.007978s\n",
      "batch 10454, train_loss 0.003481,Time used 0.007979s\n",
      "batch 10455, train_loss 0.004364,Time used 0.008975s\n",
      "batch 10456, train_loss 0.003022,Time used 0.008976s\n",
      "batch 10457, train_loss 0.003036,Time used 0.007979s\n",
      "batch 10458, train_loss 0.003242,Time used 0.008976s\n",
      "batch 10459, train_loss 0.003836,Time used 0.008976s\n",
      "batch 10460, train_loss 0.002726,Time used 0.008976s\n",
      "batch 10461, train_loss 0.003436,Time used 0.008976s\n",
      "batch 10462, train_loss 0.003835,Time used 0.008976s\n",
      "batch 10463, train_loss 0.003850,Time used 0.008975s\n",
      "batch 10464, train_loss 0.003496,Time used 0.007979s\n",
      "batch 10465, train_loss 0.003765,Time used 0.007979s\n",
      "batch 10466, train_loss 0.003058,Time used 0.007978s\n",
      "batch 10467, train_loss 0.005414,Time used 0.007979s\n",
      "batch 10468, train_loss 0.003236,Time used 0.007979s\n",
      "batch 10469, train_loss 0.004393,Time used 0.008975s\n",
      "batch 10470, train_loss 0.003524,Time used 0.008976s\n",
      "batch 10471, train_loss 0.004441,Time used 0.008976s\n",
      "batch 10472, train_loss 0.004290,Time used 0.008976s\n",
      "batch 10473, train_loss 0.002977,Time used 0.008976s\n",
      "batch 10474, train_loss 0.004501,Time used 0.008976s\n",
      "batch 10475, train_loss 0.003824,Time used 0.007978s\n",
      "batch 10476, train_loss 0.003254,Time used 0.008976s\n",
      "batch 10477, train_loss 0.004435,Time used 0.008975s\n",
      "batch 10478, train_loss 0.003454,Time used 0.009974s\n",
      "batch 10479, train_loss 0.003202,Time used 0.008976s\n",
      "batch 10480, train_loss 0.003348,Time used 0.009542s\n",
      "batch 10481, train_loss 0.002999,Time used 0.009464s\n",
      "batch 10482, train_loss 0.004090,Time used 0.008976s\n",
      "batch 10483, train_loss 0.004520,Time used 0.008976s\n",
      "batch 10484, train_loss 0.002944,Time used 0.011968s\n",
      "batch 10485, train_loss 0.004083,Time used 0.013962s\n",
      "batch 10486, train_loss 0.003007,Time used 0.007979s\n",
      "batch 10487, train_loss 0.005763,Time used 0.009974s\n",
      "batch 10488, train_loss 0.002749,Time used 0.009974s\n",
      "batch 10489, train_loss 0.002219,Time used 0.009974s\n",
      "batch 10490, train_loss 0.004086,Time used 0.009974s\n",
      "batch 10491, train_loss 0.002696,Time used 0.009973s\n",
      "batch 10492, train_loss 0.002934,Time used 0.009974s\n",
      "batch 10493, train_loss 0.003880,Time used 0.008977s\n",
      "batch 10494, train_loss 0.004456,Time used 0.008976s\n",
      "batch 10495, train_loss 0.002659,Time used 0.008975s\n",
      "batch 10496, train_loss 0.003820,Time used 0.009974s\n",
      "batch 10497, train_loss 0.004454,Time used 0.009974s\n",
      "batch 10498, train_loss 0.004250,Time used 0.008975s\n",
      "batch 10499, train_loss 0.003563,Time used 0.009974s\n",
      "batch 10500, train_loss 0.003499,Time used 0.009973s\n",
      "***************************test_batch 10500, test_rmse_loss 0.061073,test_mae_loss 0.043568,test_mape_loss 13.132302,Time used 0.116689s\n",
      "batch 10501, train_loss 0.004031,Time used 0.008977s\n",
      "batch 10502, train_loss 0.003004,Time used 0.009990s\n",
      "batch 10503, train_loss 0.003080,Time used 0.009485s\n",
      "batch 10504, train_loss 0.002706,Time used 0.009973s\n",
      "batch 10505, train_loss 0.003804,Time used 0.009973s\n",
      "batch 10506, train_loss 0.004243,Time used 0.008977s\n",
      "batch 10507, train_loss 0.002982,Time used 0.008977s\n",
      "batch 10508, train_loss 0.002946,Time used 0.008975s\n",
      "batch 10509, train_loss 0.003197,Time used 0.009974s\n",
      "batch 10510, train_loss 0.004192,Time used 0.009974s\n",
      "batch 10511, train_loss 0.003398,Time used 0.008975s\n",
      "batch 10512, train_loss 0.004979,Time used 0.009974s\n",
      "batch 10513, train_loss 0.003697,Time used 0.008976s\n",
      "batch 10514, train_loss 0.003796,Time used 0.009973s\n",
      "batch 10515, train_loss 0.001734,Time used 0.008976s\n",
      "batch 10516, train_loss 0.004431,Time used 0.008977s\n",
      "batch 10517, train_loss 0.003490,Time used 0.008976s\n",
      "batch 10518, train_loss 0.004139,Time used 0.008976s\n",
      "batch 10519, train_loss 0.003193,Time used 0.008976s\n",
      "batch 10520, train_loss 0.004105,Time used 0.008976s\n",
      "batch 10521, train_loss 0.004355,Time used 0.009974s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 10522, train_loss 0.003747,Time used 0.008975s\n",
      "batch 10523, train_loss 0.004728,Time used 0.009974s\n",
      "batch 10524, train_loss 0.004383,Time used 0.008976s\n",
      "batch 10525, train_loss 0.003586,Time used 0.008976s\n",
      "batch 10526, train_loss 0.004513,Time used 0.009973s\n",
      "batch 10527, train_loss 0.004544,Time used 0.008977s\n",
      "batch 10528, train_loss 0.006005,Time used 0.011967s\n",
      "batch 10529, train_loss 0.002565,Time used 0.008976s\n",
      "batch 10530, train_loss 0.004243,Time used 0.008976s\n",
      "batch 10531, train_loss 0.004230,Time used 0.008976s\n",
      "batch 10532, train_loss 0.003726,Time used 0.007979s\n",
      "batch 10533, train_loss 0.003175,Time used 0.007979s\n",
      "batch 10534, train_loss 0.003012,Time used 0.007978s\n",
      "batch 10535, train_loss 0.002689,Time used 0.007979s\n",
      "batch 10536, train_loss 0.003762,Time used 0.007978s\n",
      "batch 10537, train_loss 0.003751,Time used 0.008976s\n",
      "batch 10538, train_loss 0.004155,Time used 0.008976s\n",
      "batch 10539, train_loss 0.003855,Time used 0.007978s\n",
      "batch 10540, train_loss 0.002976,Time used 0.008976s\n",
      "batch 10541, train_loss 0.003822,Time used 0.007979s\n",
      "batch 10542, train_loss 0.003641,Time used 0.008977s\n",
      "batch 10543, train_loss 0.003445,Time used 0.008976s\n",
      "batch 10544, train_loss 0.002911,Time used 0.008976s\n",
      "batch 10545, train_loss 0.003162,Time used 0.008976s\n",
      "batch 10546, train_loss 0.003687,Time used 0.008975s\n",
      "batch 10547, train_loss 0.003367,Time used 0.008976s\n",
      "batch 10548, train_loss 0.004098,Time used 0.008976s\n",
      "batch 10549, train_loss 0.003790,Time used 0.008976s\n",
      "batch 10550, train_loss 0.003166,Time used 0.009974s\n",
      "batch 10551, train_loss 0.003088,Time used 0.009973s\n",
      "batch 10552, train_loss 0.002977,Time used 0.009975s\n",
      "batch 10553, train_loss 0.004094,Time used 0.008977s\n",
      "batch 10554, train_loss 0.003311,Time used 0.008976s\n",
      "batch 10555, train_loss 0.002984,Time used 0.008976s\n",
      "batch 10556, train_loss 0.002972,Time used 0.008976s\n",
      "batch 10557, train_loss 0.005482,Time used 0.008977s\n",
      "batch 10558, train_loss 0.003357,Time used 0.009973s\n",
      "batch 10559, train_loss 0.002888,Time used 0.009973s\n",
      "batch 10560, train_loss 0.004095,Time used 0.008572s\n",
      "batch 10561, train_loss 0.003979,Time used 0.008976s\n",
      "batch 10562, train_loss 0.004215,Time used 0.010970s\n",
      "batch 10563, train_loss 0.003957,Time used 0.009974s\n",
      "batch 10564, train_loss 0.003331,Time used 0.009973s\n",
      "batch 10565, train_loss 0.002872,Time used 0.009974s\n",
      "batch 10566, train_loss 0.004842,Time used 0.009973s\n",
      "batch 10567, train_loss 0.002908,Time used 0.008976s\n",
      "batch 10568, train_loss 0.004244,Time used 0.008976s\n",
      "batch 10569, train_loss 0.004104,Time used 0.009973s\n",
      "batch 10570, train_loss 0.004762,Time used 0.008976s\n",
      "batch 10571, train_loss 0.003578,Time used 0.008976s\n",
      "batch 10572, train_loss 0.003748,Time used 0.007978s\n",
      "batch 10573, train_loss 0.003276,Time used 0.007978s\n",
      "batch 10574, train_loss 0.003952,Time used 0.007979s\n",
      "batch 10575, train_loss 0.002323,Time used 0.008977s\n",
      "batch 10576, train_loss 0.004866,Time used 0.007979s\n",
      "batch 10577, train_loss 0.003217,Time used 0.008976s\n",
      "batch 10578, train_loss 0.003356,Time used 0.008976s\n",
      "batch 10579, train_loss 0.003635,Time used 0.008976s\n",
      "batch 10580, train_loss 0.002751,Time used 0.008976s\n",
      "batch 10581, train_loss 0.002849,Time used 0.007979s\n",
      "batch 10582, train_loss 0.002822,Time used 0.009973s\n",
      "batch 10583, train_loss 0.003561,Time used 0.008977s\n",
      "batch 10584, train_loss 0.003861,Time used 0.009973s\n",
      "batch 10585, train_loss 0.002822,Time used 0.008976s\n",
      "batch 10586, train_loss 0.004226,Time used 0.008976s\n",
      "batch 10587, train_loss 0.002834,Time used 0.008977s\n",
      "batch 10588, train_loss 0.003488,Time used 0.007979s\n",
      "batch 10589, train_loss 0.003704,Time used 0.008975s\n",
      "batch 10590, train_loss 0.003434,Time used 0.007978s\n",
      "batch 10591, train_loss 0.003303,Time used 0.008976s\n",
      "batch 10592, train_loss 0.003550,Time used 0.008976s\n",
      "batch 10593, train_loss 0.002908,Time used 0.007979s\n",
      "batch 10594, train_loss 0.003353,Time used 0.007978s\n",
      "batch 10595, train_loss 0.003837,Time used 0.007979s\n",
      "batch 10596, train_loss 0.002751,Time used 0.007979s\n",
      "batch 10597, train_loss 0.003844,Time used 0.007979s\n",
      "batch 10598, train_loss 0.002804,Time used 0.007979s\n",
      "batch 10599, train_loss 0.003208,Time used 0.008976s\n",
      "batch 10600, train_loss 0.005117,Time used 0.008976s\n",
      "***************************test_batch 10600, test_rmse_loss 0.060834,test_mae_loss 0.043382,test_mape_loss 13.016184,Time used 0.128656s\n",
      "batch 10601, train_loss 0.002536,Time used 0.008976s\n",
      "batch 10602, train_loss 0.003493,Time used 0.008975s\n",
      "batch 10603, train_loss 0.003338,Time used 0.008977s\n",
      "batch 10604, train_loss 0.003372,Time used 0.009972s\n",
      "batch 10605, train_loss 0.003142,Time used 0.008977s\n",
      "batch 10606, train_loss 0.002993,Time used 0.008976s\n",
      "batch 10607, train_loss 0.004234,Time used 0.008977s\n",
      "batch 10608, train_loss 0.003667,Time used 0.008976s\n",
      "batch 10609, train_loss 0.003878,Time used 0.008976s\n",
      "batch 10610, train_loss 0.004909,Time used 0.008977s\n",
      "batch 10611, train_loss 0.003383,Time used 0.007979s\n",
      "batch 10612, train_loss 0.004410,Time used 0.008975s\n",
      "batch 10613, train_loss 0.006183,Time used 0.008977s\n",
      "batch 10614, train_loss 0.002753,Time used 0.008976s\n",
      "batch 10615, train_loss 0.003728,Time used 0.008976s\n",
      "batch 10616, train_loss 0.003254,Time used 0.008975s\n",
      "batch 10617, train_loss 0.002732,Time used 0.007979s\n",
      "batch 10618, train_loss 0.003699,Time used 0.007979s\n",
      "batch 10619, train_loss 0.003278,Time used 0.007979s\n",
      "batch 10620, train_loss 0.003543,Time used 0.007979s\n",
      "batch 10621, train_loss 0.003467,Time used 0.008976s\n",
      "batch 10622, train_loss 0.004062,Time used 0.008976s\n",
      "batch 10623, train_loss 0.003092,Time used 0.008975s\n",
      "batch 10624, train_loss 0.004129,Time used 0.008977s\n",
      "batch 10625, train_loss 0.003621,Time used 0.007978s\n",
      "batch 10626, train_loss 0.003485,Time used 0.007978s\n",
      "batch 10627, train_loss 0.006855,Time used 0.007979s\n",
      "batch 10628, train_loss 0.003962,Time used 0.008976s\n",
      "batch 10629, train_loss 0.003226,Time used 0.008976s\n",
      "batch 10630, train_loss 0.003075,Time used 0.008976s\n",
      "batch 10631, train_loss 0.004232,Time used 0.008976s\n",
      "batch 10632, train_loss 0.003309,Time used 0.008976s\n",
      "batch 10633, train_loss 0.003609,Time used 0.007996s\n",
      "batch 10634, train_loss 0.003808,Time used 0.009972s\n",
      "batch 10635, train_loss 0.003467,Time used 0.008978s\n",
      "batch 10636, train_loss 0.003857,Time used 0.008977s\n",
      "batch 10637, train_loss 0.005804,Time used 0.007978s\n",
      "batch 10638, train_loss 0.003738,Time used 0.008976s\n",
      "batch 10639, train_loss 0.006566,Time used 0.008975s\n",
      "batch 10640, train_loss 0.004438,Time used 0.007978s\n",
      "batch 10641, train_loss 0.002633,Time used 0.008977s\n",
      "batch 10642, train_loss 0.004804,Time used 0.007979s\n",
      "batch 10643, train_loss 0.003373,Time used 0.008976s\n",
      "batch 10644, train_loss 0.003589,Time used 0.008976s\n",
      "batch 10645, train_loss 0.003291,Time used 0.008976s\n",
      "batch 10646, train_loss 0.003968,Time used 0.008975s\n",
      "batch 10647, train_loss 0.003730,Time used 0.007979s\n",
      "batch 10648, train_loss 0.003179,Time used 0.007979s\n",
      "batch 10649, train_loss 0.002992,Time used 0.008977s\n",
      "batch 10650, train_loss 0.003833,Time used 0.007979s\n",
      "batch 10651, train_loss 0.002868,Time used 0.007979s\n",
      "batch 10652, train_loss 0.003229,Time used 0.007978s\n",
      "batch 10653, train_loss 0.003621,Time used 0.007979s\n",
      "batch 10654, train_loss 0.004625,Time used 0.007979s\n",
      "batch 10655, train_loss 0.002355,Time used 0.007978s\n",
      "batch 10656, train_loss 0.003916,Time used 0.008976s\n",
      "batch 10657, train_loss 0.002933,Time used 0.008976s\n",
      "batch 10658, train_loss 0.002347,Time used 0.008976s\n",
      "batch 10659, train_loss 0.003995,Time used 0.007979s\n",
      "batch 10660, train_loss 0.003831,Time used 0.008976s\n",
      "batch 10661, train_loss 0.004585,Time used 0.007978s\n",
      "batch 10662, train_loss 0.002441,Time used 0.008976s\n",
      "batch 10663, train_loss 0.004706,Time used 0.008976s\n",
      "batch 10664, train_loss 0.002499,Time used 0.008976s\n",
      "batch 10665, train_loss 0.002889,Time used 0.008976s\n",
      "batch 10666, train_loss 0.003888,Time used 0.007979s\n",
      "batch 10667, train_loss 0.004776,Time used 0.007979s\n",
      "batch 10668, train_loss 0.003716,Time used 0.007978s\n",
      "batch 10669, train_loss 0.003392,Time used 0.009974s\n",
      "batch 10670, train_loss 0.004629,Time used 0.008976s\n",
      "batch 10671, train_loss 0.004703,Time used 0.008976s\n",
      "batch 10672, train_loss 0.003590,Time used 0.008976s\n",
      "batch 10673, train_loss 0.003669,Time used 0.008976s\n",
      "batch 10674, train_loss 0.004015,Time used 0.007979s\n",
      "batch 10675, train_loss 0.002954,Time used 0.007979s\n",
      "batch 10676, train_loss 0.005156,Time used 0.008976s\n",
      "batch 10677, train_loss 0.003275,Time used 0.008976s\n",
      "batch 10678, train_loss 0.003335,Time used 0.008976s\n",
      "batch 10679, train_loss 0.003452,Time used 0.008977s\n",
      "batch 10680, train_loss 0.004504,Time used 0.008976s\n",
      "batch 10681, train_loss 0.003558,Time used 0.007978s\n",
      "batch 10682, train_loss 0.002983,Time used 0.007978s\n",
      "batch 10683, train_loss 0.003721,Time used 0.008976s\n",
      "batch 10684, train_loss 0.003058,Time used 0.007978s\n",
      "batch 10685, train_loss 0.003032,Time used 0.008976s\n",
      "batch 10686, train_loss 0.002794,Time used 0.008976s\n",
      "batch 10687, train_loss 0.003729,Time used 0.008976s\n",
      "batch 10688, train_loss 0.002858,Time used 0.008977s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 10689, train_loss 0.003023,Time used 0.007978s\n",
      "batch 10690, train_loss 0.002763,Time used 0.009974s\n",
      "batch 10691, train_loss 0.002638,Time used 0.007979s\n",
      "batch 10692, train_loss 0.003288,Time used 0.008976s\n",
      "batch 10693, train_loss 0.002531,Time used 0.007979s\n",
      "batch 10694, train_loss 0.003305,Time used 0.008976s\n",
      "batch 10695, train_loss 0.003132,Time used 0.008976s\n",
      "batch 10696, train_loss 0.002935,Time used 0.008976s\n",
      "batch 10697, train_loss 0.005052,Time used 0.007979s\n",
      "batch 10698, train_loss 0.002783,Time used 0.007979s\n",
      "batch 10699, train_loss 0.003148,Time used 0.007978s\n",
      "batch 10700, train_loss 0.002325,Time used 0.006981s\n",
      "***************************test_batch 10700, test_rmse_loss 0.060758,test_mae_loss 0.043287,test_mape_loss 12.791140,Time used 0.116690s\n",
      "The total time is 111.656853s\n"
     ]
    }
   ],
   "source": [
    "train_log = []\n",
    "test_log = []\n",
    "#开始时间\n",
    "timestart = time.time()\n",
    "trained_batches = 0 #记录多少个batch \n",
    "for epoch in range(100):\n",
    "   \n",
    "    total_1oss = 0 #记录Loss\n",
    "    for batch in next_batch(shuffle(train_set), batch_size=128):\n",
    "        #每一个batch的开始时间\n",
    "        batchstart = time.time()\n",
    "        \n",
    "        batch = torch.from_numpy(batch).float().to(device)  # (batch, seq_len)\n",
    "        # 使用短序列的前12个值作为历史，最后一个值作为预测值。\n",
    "        x, label = batch[:, :12], batch[:, -1]\n",
    "        hidden, out = model(x.unsqueeze(-1))\n",
    "        prediction = out[:, -1, :].squeeze(-1)  # (batch)\n",
    "        loss = loss_func(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #correct += (prediction == label).sum().item()\n",
    "        #累加loss\n",
    "        #total_1oss += loss.item( )\n",
    "        trained_batches += 1\n",
    "        #计算平均oss与准确率\n",
    "        #train_loss = total_1oss / train_batch_num\n",
    "        #train_log.append(train_loss)   \n",
    "        # 每训练一定数量的batch，就在测试集上测试模型效果。\n",
    "        #if trained_batches % 100 == 0:\n",
    "        train_log.append(loss.detach().cpu().numpy().tolist());\n",
    "        train_batch_time = (time.time() - batchstart)\n",
    "        print('batch %d, train_loss %.6f,Time used %.6fs'%(trained_batches, loss,train_batch_time))\n",
    "        print('batch %d, train_loss %.6f,Time used %.6fs'%(trained_batches, loss,train_batch_time),file=f)\n",
    "    \n",
    "        \n",
    "        # 每训练一定数量的batch，就在测试集上测试模型效果。\n",
    "        if trained_batches % 100 == 0:\n",
    "            #每一个batch的开始时间\n",
    "            batch_test_start = time.time()\n",
    "            #在每个epoch上测试\n",
    "            all_prediction = []\n",
    "            for batch in next_batch(test_set, batch_size=128):\n",
    "                batch = torch.from_numpy(batch).float().to(device)  # (batch, seq_len)\n",
    "                x, label = batch[:, :12], batch[:, -1]\n",
    "                hidden, out = model(x.unsqueeze(-1))\n",
    "                #hidden, out = model(batch)\n",
    "                prediction = out[:, -1, :].squeeze(-1)  # (batch)\n",
    "                all_prediction.append(prediction.detach().cpu().numpy())\n",
    "\n",
    "            all_prediction = np.concatenate(all_prediction)\n",
    "            all_label = test_set[:, -1]\n",
    "            # 没有进行反归一化操作。\n",
    "            #all_prediction = denormalize(all_prediction)\n",
    "            #all_label = denormalize(all_label)\n",
    "            # 计算测试指标。\n",
    "            rmse_score = math.sqrt(mse(all_label, all_prediction))\n",
    "            mae_score = mae(all_label, all_prediction)\n",
    "            mape_score = mape(all_label, all_prediction)\n",
    "            test_log.append([rmse_score, mae_score, mape_score])\n",
    "            test_batch_time = (time.time() - batch_test_start)\n",
    "            print('***************************test_batch %d, test_rmse_loss %.6f,test_mae_loss %.6f,test_mape_loss %.6f,Time used %.6fs'%(trained_batches, rmse_score,mae_score,mape_score,test_batch_time))\n",
    "            print('***************************test_batch %d, test_rmse_loss %.6f,test_mae_loss %.6f,test_mape_loss %.6f,Time used %.6fs'%(trained_batches, rmse_score,mae_score,mape_score,test_batch_time),file=f)\n",
    "\n",
    "        #每一个epoch的结束时间\n",
    "        #elapsed = (time.time() - epochstart)\n",
    "    #print('epoch %d, train_loss %.6f,test_rmse_loss %.6f,test_mae_loss %.6f,test_mape_loss %.6f,Time used %.6fs'%(epoch+1, train_loss,rmse_score,mae_score,mape_score,elapsed))\n",
    "    #print('epoch %d, train_loss %.6f,test_rmse_loss %.6f,test_mae_loss %.6f,test_mape_loss %.6f,Time used %.6fs'%(epoch+1, train_loss,rmse_score,mae_score,mape_score,elapsed),file=f)\n",
    "    \n",
    "#计算总时间\n",
    "timesum = (time.time() - timestart)\n",
    "print('The total time is %fs'%(timesum))\n",
    "print('The total time is %fs'%(timesum),file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_loss曲线\n",
    "x = np.linspace(0,len(train_log),len(train_log))\n",
    "plt.plot(x,train_log,label=\"train_loss\",linewidth=1.5)\n",
    "#plt.plot(x_test,test_log[:,0],label=\"test_rmse_loss\",linewidth=1.5)\n",
    "#plt.plot(x_test,test_log[:,1],label=\"test_mae_loss\",linewidth=1.5)\n",
    "#plt.plot(x_test,test_log[:,2],label=\"test_mape_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('1.1manualRNNtrainloss.jpg')\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.plot(x_test,test_log[:,0],label=\"test_rmse_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('1.1manualRNNtestrmseloss.jpg')\n",
    "#plt.clf()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.plot(x_test,test_log[:,1],label=\"test_mae_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('1.1manualRNNtestrmaeloss.jpg')\n",
    "#plt.clf()\n",
    "\n",
    "#test_loss曲线\n",
    "x_test= np.linspace(0,len(test_log),len(test_log))\n",
    "test_log = np.array(test_log)\n",
    "plt.plot(x_test,test_log[:,2],label=\"test_mape_loss\",linewidth=1.5)\n",
    "plt.xlabel(\"number of batches*100\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('1.1manualRNNtestrmapeloss.jpg')\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
